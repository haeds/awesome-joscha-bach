Unknown 0:22
My name is Nicola and you're watching singularity FM, the place where we interviewed the future. If you guys enjoyed this podcast, you can show your support by either writing a brief review on iTunes or by simply making a donation. Today, my guest on the show is Professor Joshua. Joshua is a cognitive scientist at the Harvard program for evolutionary time dynamics, as well as the MIT Media Lab. So welcome to singularity FM Joshua.

Joscha Bach 0:53
Hi, first of all, I'm not a professor, though. And I have been working at the MIT Media Lab until two years ago. And since then, I'm at Harvard. They're not affiliated with both at this at this time.

Unknown 1:07
Oh, so what what exactly is your position then?

Joscha Bach 1:10
I'm a research scientist, the research scientist is a person that works in the abbess between postdoc and tenure.

Unknown 1:16
Wow. But you are a PhD? I am. And what what what was your PhD in?

Joscha Bach 1:23
in cognitive science, I went into academia to understand how the mind works and studied a number of subjects and degrees in computer science and philosophy and felt that AI is my best bet of making headway and understanding who we are.

Unknown 1:41
Fantastic. So you're, as you said, in the zero gravity sort of space between postdoc and professorship, I can,

Joscha Bach 1:50
yeah, it's actually a quite happy place. Because it's one that allows me to do what I want. I don't have to do superfluous management, I don't have to sit in many committees or anything. I can teach when I want, but I don't have to, which is really the best arrangement you can possibly have. I can have students, but they don't have to. And so this is kind of amazing.

Unknown 2:11
That's fantastic. But I don't know how if it's allowing you to survive with your family properly, but

Joscha Bach 2:18
be find out, you know, they can always be earthquakes.

Unknown 2:25
Okay, Joshua, if I were to ask you to introduce yourself in a couple of words, who is Joshua?

Joscha Bach 2:33
It depends who was asking. But in, in the most general sense. I'm a cognitive scientist, I grew up in communist Eastern Germany, the last generation to do so is the child of an artist in the forest, and I grew up in a world that was completely alien to me, in many ways, because communist Eastern Germany didn't make a lot of sense, especially if you grow up in a forest in which everything has no walls, and only the ruleset locally makes sense. So anyway, my default and understanding the world has been different from the default of people around me, I reluctantly discovered that most people from the ideas by taking in the norms of their environment and the statements of the experts and taking them as gospel and only revise them and they absolutely have to, then they disproven. And for me, it was always like the opposite. You have this perspective on the world where people have ideas, their thoughts, and they often make no sense. And you will have to look at each of them this great care before you incorporate them into your own world model. So you tried to be careful to not be harm anything or do bad things to the world. But this reluctance in accepting what what comes from the outside has, I think shaped my scientific perspective, and when it came into the next society based in Germany, and then later on to New Zealand, and to the US. I always saw things from the outside. So I'm more an observer and the same thing happens in the scientific fields. Wow,

Unknown 4:04
that's, that's absolutely fascinating. And I want to grab a few points there one by one. But first of all, that kind of a skeptical, outsider, kind of point of view, is very contrarian. And it's also very sort of philosophic, well philosophical in the way maybe in the German school because at least Nietzsche said that gross answers are a proxy Bishan against thinkers, you shall not think. And to him that was like an insult, because he was a curious, questioning, inquisitive kind of a soul from the beginning. And so he was never one for gross answers, but rather, asking questions and questioning everything. So it seems you've kind of you've got that approach.

Joscha Bach 4:58
I felt that need to never make He's for society. And that was related to the fact that he was never able to make peace with himself. It really never worked out. There is a big issue with obedience this question, Should you obey somebody else? I mean, you seem to have that same issue that to work in a hierarchy, you need to submit in a way to hierarchy, how would you submit? How could somebody else make your decisions if they didn't test it to the same rigorous epistemological criteria that you did? How does that have integrity, right? It's very hard to do. But from a different perspective, if you want to do the right thing, then doing the right thing might require that you ask the person that is more likely to make the right decisions, because they're an expert for local area of making the right things like a leader is a person in specializing that specializes in doing the right thing. So I think it has integrity to realize that in certain circumstances, other people will know better than you do on Nietzsche never got to this point. And of course, philosophy is slightly different. Because in philosophy, you have to fix your foundations and arguably invest in philosophy, very few people that right, so our null hypothesis still seems to be supernatural beings, and dualism and so on. And that's one of the reasons why most people in the Western world find AI so ridiculous and unlikely. It's not because people don't see that we are biological computers, and that the universe is probably mechanical, in theory that everything is mechanical, gives extremely good predictions. It's because deep down they still have this null hypothesis that the universe is somehow supernatural and the other most supernatural thing in it. And science is only reluctantly pushing back against this null hypothesis. And since it has not completely obliterated null hypothesis in this single area, the conscious consciousness and the mind here are reluctant in accepting the certainty this reasonable certainty that the machines, but this is the main reason why we hesitate so much I think.

Unknown 6:56
So are we machines, then are we are we as some people have said that organisms are algorithms.

Joscha Bach 7:07
There are a number of definitions on this. But if you think of an algorithm as a set of rules that can be probabilistic or deterministic, and that make it possible to switch between states. And usually, we do this in a more narrow sense, where we say that the algorithm is being used to change representational states in order to compute a function. Right, then I would say that organisms have algorithms in this narrow sense. But I would say that in the wider sense that definitely machines machine is a system that can change the state and non random Bayes. And also, we visited earlier states, which means to stay in a particular state space. Otherwise, this would not be a system a system is something that we can describe by drawing a fence around its state space and saying, as long as in there, this is the system. Great. So we have an evolution of the system that is somewhat constrained. Now we're jumping headfirst into terminology. Want to go there,

Unknown 8:10
we would go there. But let me just roll back the tape of time because I want to follow your narrative, your personal narrative from where it began, then connected to where you are today. And then hopefully, try and look it to the world and into the future, with your eyes and with your experience and from your point of view. So tell me, you said you grew up in the forest. Whereabouts

Joscha Bach 8:38
in Turin, Kia, nearby Emma and Hina. It's an area of German Romanticism, which had a pretty big influence on how I grew up. It's a very particular shape of the soul. But it's been characterized by the indictment, which innovate, push back against the religious mind virus that had control the world until then, and replaced it with machinery, this rationalist machinery that eventually made modern societies possible. And this was a very big upheaval, you can still see the ego of this in our modern was like Lord of the Rings and Star Wars, you have this pastoral world which defends itself against the encroaching technological empire that is going to eat our souls, even though it's going to win.

Unknown 9:23
And so but did you grow up on a farm or something?

Joscha Bach 9:26
No, my parents were artists. They were originally architects. And my father didn't want to build boring things that would put people into boxes and deny the humanity instead, he built things that didn't have many right angles. And he made a zoo that had no right angles, for instance, as one of his projects and so on. And it was very difficult to to get away with these things in Eastern Germany, because this was a very utilitarian society and its architecture was to a large degree brutalist so he rejected And he decided to remove himself from society and make his own kingdom in the forest. So we bought an old water mill and changed it into a sculpture garden and lift exactly the life he wanted to get away with it.

Unknown 10:13
Wow, that's absolutely phenomenal. I, like you grew up in Eastern Bloc only I grew up in Bulgaria, in communist Bulgaria for the first, what was it 1314 years of my life. So I can associate it with a lot of your experience. But it's very interesting how you grew up in Germany, as you put it in the forest in a very artistic family. And yet, you became a scientist? So is there any tension there? Or is it a continuation of sort of? Or did it give you any kind of different unique point of view or approach to science? Or is that basically a false dichotomy?

Joscha Bach 10:55
There is a big similarity, I find that most people serve practical needs, they have an understanding of the difference between meaning and relevance. And at some level, my mind is more interested in meaning than and relevance. That is similar to the mind of an artist. The arts are not life, they're not serving life, the arts are the cuckoo child of life, because the meaning of life, they are the cuckoo child of life, the meaning of life is to eat, you know, life is evolution. And evolution is about eating. It's pretty gross. If you think about it, right? Evolution is about getting eaten by monsters. Don't go to the desert and powers there. Because it's going to be a waste. If you're lucky, the monsters that eat you are your own children. And eventually the search for evolution will, if evolution reaches its global optimum, it will be the perfect of our, the thing that is able to digest anything and turn it into structure to sustain it and perpetuate itself. For as long as the local pedal of Nick entropy is available. And in a way we are yeast, everything we do all the complexity that we create all the structures we build is to erect some surfaces on which to outcompete other kinds of yeast. And if you realize this, you can try to get behind this. And I think the solution to this is fascism, right? Fascism is a mode of organization of society in which the individual is a cell and a super organism. And the value of the individual is exactly the contribution to the super organism. And when the contribution is negative, then the super organism kills it, in order to be fitter in the competition against other super organisms. And it's totally brutal. And I don't like fascism, because it was going to kill a lot of minds I like. And the arts is slightly different. It's a mutation that is arguably not completely adaptive. It's one where people fall in love with the loss function, where you think that your mental representation is the intrinsically important thing, that you're trying to capture a conscious state for its own sake, because you think that matters, that will artists, my view is somebody who captures conscious states, and that's the only reason why they eat. So you, you eat to make art, and another person makes art to eat. And it's these are, of course, the ends of a spectrum. And the truth is often somewhere in the middle. But in a way there is this fundamental distinction. And there are some sense the true scientists, which are trying to figure out something about the universe, they try to reflect it. And it's an artistic process. In a way, it's an attempt to beautiful reflection to this universe. You see, there's this amazing vast darkness, which is the universe, there's all this iteration of patterns. But mostly, there's nothing interesting happening in these patterns. It's a giant fractal. And most of it is just boring. And in a brief moment, in the evolution of the universe, there are a planetary surfaces, and like entropy gradients that allow for the creation of structure. And then there are some brief flashes of consciousness in all this vast darkness. And these brief flashes of consciousness can reflect the universe and maybe even figure out what it is, it's the only chance that we have right is amazing. And why not do this, my life is short, this is the thing that you can do.

Unknown 14:20
And that's why you going back to your previous point about your current position being sort of between postdoc in and academia, that position actually fits you very well because you're not forced to do science in order to eat. But actually, you can afford to eat as much as you can do your science. Is that the case?

Joscha Bach 14:42
I have a similar problem as you I think it's very difficult for me to get myself to do something for which I'm not intrinsically motivated for. So

Unknown 14:52
you get that right completely.

Joscha Bach 14:55
If I work in a job that is intellectually interesting, but doesn't appear meaningful. To meet, I will probably lose interest after four months. And I have to do something very sick, this needs to be done this verse spending some of my short life on,

Unknown 15:11
right? I don't even I don't I didn't even last four months. You know, after my undergraduate before my master's degree, I worked as an investment administrator in a company. And I lasted six weeks, where I was bouncing portfolios and doing stock trades and things like that. I lasted about five and a half, six weeks, and then it's a debate whether I resigned or I got fired first. But either way, I was not surviving there. So are staying there. And

Joscha Bach 15:39
yeah, there is a tension, I want to be useful to society, and I want to eat suffering, and so on. I do care about people. And it's just that I have the impression that the systems that we live in, are often not sustainable. They're largely doomed, right? It's a very weird situation that we find ourselves in, if you take a step back. All the important tipping points for climate change have been in the last century, as people said in the last century, right. But the fact that we knew about this, that global warming is basically knowns to our corporations to all companies since the 60s and 70s. And to our governments, I think, to about the same time that the our inability to deal with this is probably means that it was too little agency in the system to do anything about it. And we probably locked ourselves into this trajectory, because the Industrial Revolution, at this point, it was no longer for us to stop the machines that we build.

Unknown 16:32
Well, we are kind of jumping forward and I want to sort of slow the ball down a little bit. If I may.

Joscha Bach 16:45
Don't worry, you're not going to get bored, you can keep that pace. Just turn around, go somewhere else.

Unknown 16:51
Fantastic. Right? It's just that I had so many considerations already my previous points that you made that now I kind of lost the thread completely. Okay, let me see. Where does so we got the artistic in the scientific part of Georgia. So where's Where does philosophy come about here in this equation and how?

Joscha Bach 17:18
It's a very awkward question. The problem is, in my view, that philosophy, as a field of inquiry is practically det. Michel Gromov once told me is mathematician that in his perspective, Darwin was the last philosopher, he was the last one who was in a position where we could connect some dots in a completely fresh way. And after that, there were people like Russell, who were extremely good writers, but didn't do any real philosophy anymore, because there was to the left. And I'm not quite sure if that is the case, there is some philosophy that needs to be done. And it's still being done. And it's largely in mathematics and fixing the foundations. And even there, it's mostly visible. And so we have two big intellectual traditions, which is mathematics and physics. And there are some cracks in them that need to be dealt with. And this is where most of the philosophy is at. And all the other things are minor, like social organization, and so on. It's look very miraculous to the sociologists. But I think we can see the patterns. It's it's largely a defect of this of these fields. And philosophy as a field as a culture, you get paid for emulating what the philosopher is supposed to look like. And it's very hard to get any philosophy done on the side. And the incentives are all wrong, right? It's very fierce battle to become a philosopher to get from postdoc to tenure in these fields. So you need to get cited in the way you get cited. As philosophers, you identify a hot discussion, and they're taught discussion, you identify a unique position, and you build your brand around that unique position, you cannot afford to give this app so you have your Chinese room or your unique position and about free will. And you're going to defend this pill, even if the sale is basically indefensible. Philosophy is not going to progress in a way that forces your buildings off that you can build a mansion on indefensible Hill, you will still have meetings in there 200 years from now. And the bad thing is all the good hills are taken, right. So this is a very bad situation for philosophers. And I think this is the reason why I cannot be a philosopher today. And you need philosophy, but you don't have it anymore in the sense.

Unknown 19:28
But let's define it. What is philosophy for you? Because I've interviewed a number of mathematicians and physicians, and they both argue which one is at the root of everything, whether it's mathematics, whether it's physics, and so on and so on. But both of them or all of them mostly agree that philosophy is relevant or so they make that claim. And yet you say that philosophy kind of includes both mathematics and physics in a way which I actually agree with, but But tell me why. And tell me how do you define it in the first place in a way that actually is includes both of those.

Joscha Bach 20:02
I think that philosophy is in a way the search for the global optimum of the modeling function. So it has fields that have been defined as parts of questions that lead to this modeling function like epistemology, what can be known what, what is the nature of truth, and so on. ontology, what is the stuff that exists? Right? What's what's going on there? metaphysics is, in some sense, the systems in which you have to describe things, and ethics, what should we do. And at some point, we discovered epistemology. So my view the first rule of epistemology is roughly discovered by Francis Bacon in 1620. It says that the strengths of your confidence in the belief must equal the weight of the evidence in support of it. And you need to apply this recursively until basically, you resolve the priors of every belief, and the belief system becomes self contained, to believe stops being a verb, there is no more relationship to identifications that you just arbitrarily said, this is just a system that is in itself contained, which means in some sense, it's a mathematical system, an axiomatic system that describes a certain thing. And this leads you to the nature of mathematics, and mathematics, turns out is the domain of all languages. All of them, not just the natural languages. And mathematicians have been trying to fix their understanding of the languages and they notice what mathematics is in this regard. And Hilbert stumbled on contours, set theoretic experiments to deal with natural numbers, and then saw that then you go to infinity, very awkward and nasty things happen. You axiomatic systems basically start blowing up. And the total set suddenly contains post itself and the set of all of its subsets so it cannot have the same number of members as itself. And he asked mathematicians, please build us an interpreter for mathematics, mathematics, basically something like a computer made from mathematics, any mathematics you want, that can run all of mathematics. And then Google and curing came along and showed that this is not possible that this computer is going to crash in this left mathematics with a big shock and your way, mathematics is still reeling from that shock. And then tutoring, and church had another insight. And they figured out that all universal computers have the same power, right? A universal computer is a set of rules, that by applying them, you can compute all the things that can be computed, and the set contains itself. So universal computer is computable. As long as your universal computer doesn't run out of resources, it can compute anything that you can compute. And you can also compute all the other universal computers. So the next thing that they discovered, Turing was involved, again, was that our mind is probably in the class of the universal computers, not in the task of mathematical systems. So this is what Penrose doesn't know, Penrose thinks that our mind is mathematical, that you can do things that a computer cannot do. And the big hypothesis of AI in a way is, we are in the class of systems that can do approximate computable functions. And only those. And so we cannot do more than a computer. Which means that all the mathematics that we've ever seen all the massive mathematics that we will ever see and they will ever matter is going to be computable. And the fact that some arithmetic is not computable is the problem of the language that we have been using, we need computational languages, not mathematical languages, it turns out that the main problem is that mathematics, classical mathematics defines functions in using infinities, which means infinitely many steps to get to the result. And these functions tend not to be computable. So if you are a computer programmer, you it would never occur to you to write in your spec, that is totally fine. If your routine does return the result after infinitely many steps only. Right? This is not good. You want a finite set of steps and one that you know how long it is. So your customer gets results in time, right? So in this perspective, should you define numbers in such a way that pi is a number? You cannot know the last digit of pi pi is a function clearly, right? It's a function that gives you as many digits as you can afford. And in any finite universe, it's only going to give you a finite number of, of bits.

Unknown 24:29
And what about Stephen Wolfram has claimed that our mathematics is only one of a sort of a very wide spectrum of pot of possible mathematics.

Joscha Bach 24:39
It depends on what you call our mathematics. I think that all mathematics or mathematics, so meta mathematics is mathematics. It's not different from mathematics. I think that, for instance, computational mathematics, the thing that I'm practically working in when they write my code, and when I think about how to realize code is a A branch of mathematics is called constructive mathematics. It's been discovered in mathematics a long time ago, and largely been ignored by the other mathematicians because they thought it's not powerful enough to do all the things with real numbers that they'd like to be doing. But all the geometry is not possible in computational mathematics, you can only approximate it. Geometry requires continuous operations, infinities. And also, physics is built largely on these continuous mathematics. And in a computational universe, you only get these continuous operators by taking a very large set of finite automata, making serious fun them from them, and it's good.

Unknown 25:43
You know, what, jasha Let me share with you something, I feel like I am a goldfish. And you're a human when we're talking. Because I think that's kind of like the level the difference of intelligence with you, between you and me, my friend, which I come on.

Unknown 26:06
Because honestly, after interviewing 230, of supposedly the smartest people in the world, I've never had this feeling before. But today, at this moment, this was just trying to keep up with you know, I'm

Joscha Bach 26:19
sorry, this was my fault.

Unknown 26:21
No, it's not your fault, my age, you are who you are. And it's my job to try to follow through and also direct a little bit of conversation in the best possible direction that I see can benefit both me as an interviewer, but even more, so my audience and you. So let me just give us a little bit of a site direction here for a second and bring us back to the last issue before we jump into the meat of the matter here on AI. But and talk about philosophy and academia and practicality. Because you mentioned about how you're motivated by by your own kind of desire and inquisitive and motivated, inherent or intrinsic motivation to learn something or to discover new things, but and perhaps academia is motivated nowadays, more by the practical side of knowledge by the side where you can create something that you can patent that you can sell. And then you can scale up and commercialize. Whereas, where's the benefit? And I think in a way that the usefulness of philosophy was its uselessness in some ways, if you will, just like art, in a way is something that cannot be used for anything else. And some people have defined art as, as Oscar Wilde, for example, as something that's not immediately useful. That's what artists, so is there. And there's actually a very famous paper written in the 19 century by the by the guy who funded the Princeton Institute for Advanced Study, called the usefulness of useless knowledge. I don't know if you're familiar with it, but what's your take on that is there because many people would say, if you can't use any knowledge, immediately, it's useless. Don't waste time acquiring it, don't waste time classifying it, you know, storing it, just focus on something that's useful and practical. And to me, as a philosopher, I'm always are often attracted to stuff that looks utterly useless. And maybe that's just me being not not a scientist. But what's your take on that sort of tension of usefulness and uselessness in terms of knowledge.

Joscha Bach 28:42
Fineman once said that physics is like sex. Sometimes something useful comes from it, but it's not why we do it. But it's brilliant. So there is a big insight, there it is. It's not that art is useless. It's just the utility of art is completely orthogonal to why you do it. So the meaning of the art is really not to help the living, if you'd like to help the living, right, but it's, so it's a very nice side effect. But what we want to do with the art is to capture what it's like you want to capture a conscious state. That's the actual meaning of it. And in some sense, philosophy is at the root of all this. I think it's reflected in the way in the one of the founding most of our civilization, the Tower of Babel. This is the attempt to build this cathedral. And it's not a material building because it's meant to reach the heavens. Right visuals are not real. They're not in this world. It's it's a metaphysical building that has been built. This is this giant machine that is meant to understand reality. And you get to this machine this to Scott, this thing that under tries to understand what's going on by using people that work like ends and contribute to this and it's not about your ego. It's not about the gratitude question that you get from people for contributing to it, it's not for this thing that doesn't care about you, it doesn't give meaning to your life, it doesn't reward you for your insecurities and the toil of your existence. Right? It's, it's really just a machine. It's a computer. And as people say, now it's an AI. It's a system that is able to make sense of the world. And people at some point had to give up on this, it fell apart because they were no longer able to speak the same language. So the different parts stop fitting together, just became so large, and so many people had to work in specialized direction, that they could no longer synchronize their languages. And that's why they gave up on it. And then this big accident happened in Roman Empire, where they could not fix the incentives for governance, similar basis. Be fair here, right, our government has to play a much shorter game than civilization does. And this leads to bad results for civilization. And the Romans decided to fix this by turning the society into a cult, and burned down our epistemology and killed people that are overly rational, and insisted that people talking to burning bushes on Lonely Mountains don't have a case and determining the origin of the universe. So bite this one had to give and the cultist one and we still have to recover from that. So in a way, the beginnings of the Cathedral of understanding the universe that had been built by the Greeks and by the Romans had been burned down by the Catholics, and then later rebuilt, but mostly in the likeness because they didn't get the foundation's right, that left scars in our epistemology that have not healed even though we have a pretty successful culture that incorporated most of the other libraries and burned down the rest. Right? We are the ones that are left over on this planet in a way the in our libraries, we can read everything that there is to read at the moment, we just often cannot translate it.

Unknown 31:53
And do you think that our civilization is currently perhaps suffering from that same Babylonian problem of difference in language, and perhaps even has impact on resolving global problems like global warming that you mentioned, for example, right? Because all those people, business people, politician, scientists, etc, speak in different languages. And therefore, they cannot kind of coordinate or synchronize anymore. And therefore, that kind of perhaps puts at risk the whole project of our civilization, just like the Babylonian tower collapse. And maybe now this narrow specialization and diversity of languages. And the difficulty in communicating between all of those branches, then put at risk the whole project of our civilization.

Joscha Bach 32:48
I think that people individually are not generally intelligent, how often do you see a person that knows what they're doing? I'm certainly don't know what I'm doing. I have, to be honest, relatively intelligent. But of course, this intelligence is largely a prosthesis to cover for non working instincts. And we figure that out by now, right. And we see that people acting on the instincts largely get good results for their life, but they don't reach a very deep understanding about the nature of existence in the process, because they don't have to write that it's very little utility for deep philosophy and practical matters. And as a result, individuals are relatively stupid. generations are not smarter than individuals. But number because generations are made from groups that synchronize their beliefs, and the synchronization of beliefs makes it necessary that you give up agency over what you think is true. And when you do this, you accept things that you would not accept when you think about them individually. So people in Eastern Germany, collectively believe things that an individual would never have thought. And same things happen here, right. So there are many conspiracy theories that people believe in here for a while that would not make sense to somebody who thinks about this, like Putin uses an army of Twitter trolls to manipulate the fan applications of Star Wars movies. This is a conspiracy theory that was the result of Miss reading a study and was then repeated by 20 news outlets until somebody bothered to read the actual study and figure out no, this is not what the study says. And then some of the outfits picked up on this, but none of them wrote, okay, now We'll reconsider what you think about who didn't and Star Wars, because it's a totally what put it would have done if he would have had the idea. And this may not be, it may not be true, but it means that we don't project reality as the explanation of facts. It's rather that we know that enough facts to support what we feel to be true. And that's utility in feeding particular kinds of tools and these basically, local costs of interpreting reality shapes society, shape generations is what a generation is about. It's a local preset. To afford what things should be like, like, even liberal generations, the millennials are largely authoritarian generations. And we look at them and feels wrong to us, and they look at us and it feels wrong to them. Right. And it's neither of them is true, it's probably a set of biases that are the result of a local indoctrination. But there's some that smarter than the generation, this is the culture itself. So as you zoom out a little bit, you see that generations and societies are generated by cultures and cultures are built over a long time. And there are many things that are embodied in a culture. For instance, in the culture of how to build science, that would be very hard to derive for a single generation or to improve for a single generation, because we don't locally understand all the things that went into it. So anyway, civilizations are smarter than us, there is something like a civilizational, hive mind a civilizational intellect, that be as members of our polls who are somewhat educated, can never fully comprehend. But if you can't, once you figure it out, it's there there is something like a civilization intellect, he can try to look into the abyss and see it's rough shape, but it's difficult to figure it out. And then we realize, oh, there's a long tradition has multiple traditions that build on it and contribute to it. And that thing, in a way is what we are going to achieve when the built AI in the sense that we can incorporate the sum of all knowledge in a system of relations, that makes sense of it all.

Unknown 36:30
But what if civilization self destroyed themselves, then what is that sort of knowledge or intelligence, then say about the fitness function of that particular civilization. And in general, even

Joscha Bach 36:43
though before we had an industrial civilization, we never got above 400 million individuals on the planet, because we could not feed more. And only the switch to our industrial civilization, made it possible to have billions of people, which also means many hundreds of millions of scientists, and philosophers and thinkers and the internet, and so on. It's, it's amazing what you did took basically 100 years worth of trees that were turning into coal in the ground, because nature had not evolved micro organisms yet that could eat the trees and time. And the birds with this deposit of energy in 100 years, to give planting to everybody. And part of that planning includes access to a global porn repository, that is an afterthought. It's the sum of all your knowledge, largely uncensored chat rooms in which you can talk about it. Right, this is the internet. And this is an amazing machine. And if you have it right now, and only in this moment in time you have it before it didn't exist. So you could take a particular perspective, let's say, there is a universe that is saying, for everything is good. You have this nice planet is pretty decent living conditions and pretty stable climate. And you have a very smart, sustainable civilization on it. And you get the chance to be incarnated in it, it's an agricultural civilization, that's 300 million people doesn't have airplanes doesn't have internet doesn't have computers. Because to get they're able to have need to build an industrial civilization that obliterate most of the good things that make us sustainable, right, but it is stable. And people figured out how to be nice to each other, and it's pretty good. And then there's another universe, which is completely insane. In fact, up in this universe, humanity has just doomed its planet, to have a couple 100 Really, really good years. And you get your lifetime close to the end of the party, this incarnation? Which inclination would you choose? Oh, my God, I'd be lucky.

Unknown 38:42
So you're saying we're in the second in the in?

Joscha Bach 38:45
Of course we are. It's obvious, right?

Unknown 38:50
So so what's that say about our future them? And what's the timeline before the party is over?

Joscha Bach 38:56
We cannot notice. But we can see the sunset coming up, right? It's pretty obvious. And it's people argue about this. They're largely in denial, but it's like you're in this Titanic. And there's this pretty big iceberg. And it's very unfortunate, and people bitched about it, but what they forget is that without the Titanic, you wouldn't be here, you wouldn't be talking right now, you would not exist, you wouldn't have internet.

Unknown 39:20
So to me this, you have this kind of very Buddhist, if I may call it attitude to the sort of ephemeral sort of short span of our civilization and sort of the end of high appreciation about us joining the peak of the party, if you will, and yet you're kind of seeing the sunset kind of in the future, but that's not giving you any sort of negative or pessimistic or depressive inclination, it seems. How do you resolve that? Or do you because someone will say, Well, that's very nihilistic. It's very pessimistic. It's very depressing what you just said, and yet you're so happy. No,

Joscha Bach 39:59
I really have have enough things to be depressed about. So I have to be choosy about what to be depressed about. And it took me a long time to figure out that the demise of humanity is very unfortunate in many respects, but it's something that, well, we try to do everything we can to stop it, but you're not the first generation to try to. So I have to do both things, I can still try my best to steer for a sustainable future. It's not that I completely give up on this. But it's, in a way dealing with my own mortality is similar, right? I try what I can to not leave my family without a breadwinner too early. But at the same time, I'm going to die. And if I based my life, being depressed about the fact that I die, I'm not doing it right. I should be happy about the fact that I live and not be happy about the fact that I die. And if you if you take this as a computer game metaphor, this is like the best level of humanity to play. In this best level of humanity to play in it happens to be the last level it's plays out against the haunting backdrop of a dying world, but it's still the best level.

Unknown 41:11
Right? That's, that's again, to me, that sounds very Buddhist. Do you agree?

Joscha Bach 41:18
Yeah, but this might be an accident. I got to know Buddhism only in its less than nice forms, which is a Protestant version, is basically Protestantism reformed this slightly Eastern metaphysics, but mostly mistranslated, and epistemology in metaphysically. It's a septic tank, that most of the ideas that Buddhists have about how the mind works and how the universe is arranged, don't seem to pan out they don't seem to have sound epistemology. It's, it's it's not a general thing. I did find people that start out in Buddhism anyway, and kept clean, but most of them I met or not. And, in practice, when I went to Buddhist countries and talk to Buddhists on the ground, it was not much different from Catholicism, which means it's a system of indoctrination, discards, it makes people behave in predictable ways. It just useful for societies, but breaks people's epistemologies. So, in a way, I don't have this deep reverence for Buddhism, because it's so holy and sacred, I don't think that there are holy books, there are only manuals. And most of these manuals, we don't know how to read. Because therefore system for societies that don't apply to us, they're for different societies.

Unknown 42:29
Okay, let me zoom out a little bit more and ask you this. What are the big issues then? So that you're saying we can see the sunset and we're at the peak of the party, so we might, as well enjoy the party while it lasts? Great. What are the big issues that our civilization is facing today? What are the reasons perhaps, perhaps, if it's more than one that can bring about that sunset of our civilization, what is making you make that claim?

Joscha Bach 43:00
The thing that worries me most at the moment is global warming. I suspect that because of its very strong publication bias that we have, if you are worried about climate, you will try to make your case extra strong. So you will not make your most alarmist predictions, but the ones that you can defend most easily, which means you're going to be a little less alarming that you might want to be. And if you are not an alarmist, but Nantais alarmist, you're going to be very too optimistic about things. And as a result, I think that the distribution of the results that people look at when they think about how many degrees centigrade global warming you're facing in the next couple of 100 years are very optimistic. Another thing is, if you notice that the projections all magically end in 2100. Do you think that's because the IPCC thinks that it stabilizes the 2100? Or because it hopes that in 2102, there's a retro event? Right? There's it's obviously not going to stabilize? It seems to be that be locked in that way more than two degrees centigrade global warming or for the possibly go for six to eight. And the those the West Antarctic ice field, it's pretty clear that you cannot refreeze the poles. And it's I think it has been pretty clear that we cannot do this since the late 1980s. It's just a feedback loop that is now running away. And there is a slight chance that we find technological solutions to stop it. But I think it's not likely. And carbon sequestration is not it for simple reasons of how energy works, right. The reason why we put all this carbon dioxide in the earth in the atmosphere is because we wanted to liberate this energy. And if you want to get back from the atmosphere, we basically have to use the same amount of energy that our civilization has been getting from this all the benefit and put it back there without a clear business case. And it's possible that unlikely. So we look in a situation where are in the medium term, you're going to lose a lot of habitable area on the planet. And you also might lose climate stability. So this ability to predict what kind of harvest you're going to have next year, which means we lose a lot of organic agriculture, people have large storms that will also destroy many of our greenhouses. And as a result, we probably go down to a few 100 million individuals again, and the rest of us will not go kindly and quietly into this Good night. And the resulting results worse will probably take down what's left of civilization. So basically, if we lose the infrastructure, I don't see how we can sustain civilization in a good way.

Unknown 45:42
Wow, that's such a beautiful serine and an optimistic picture to contend with.

Joscha Bach 45:51
But I mean, there's no chances. It's, I think it's possible that gets us before global warming dies.

Unknown 45:57
Right. So let me ask you, this. Ai scientists. And and, and yet, you're telling me you're most worried about global warming? And yet people who are not AI scientists like Elon Musk, like Nick Bostrom, like even the late Dr. Stephen Hawking, are saying that the greatest existential risk that we should be worried about is AI. What do you feel about that in the first place? And what do you make of it?

Joscha Bach 46:27
There are many existential risks. So if you zoom out long enough, it's completely certain that the end of a son that he can insist on is an existential risk. And other thing is that losing the aggregate atmosphere and 1.5 billion years from now, this is an existential risks that we probably cannot deal with this big step looks unlikely that you can build sustainable civilizations outside of this gravity well, before that, there's going to be a number of supervolcano Erec eruptions and meteorites that are going to get us which means it's pretty certain that the days of humanity are numbered, right, the model is a civilization

Unknown 47:03
we spread throughout other planets, it's

Joscha Bach 47:06
unlikely that you can make that happen. At the moment, you're not able to build cities on the bottom of the ocean. And Mars is very less habitable than that it doesn't even have an atmosphere.

Unknown 47:19
And terraform it,

Joscha Bach 47:21
maybe, but not with today's technology. Oh, sure. And to get there to basically put enough stuff in orbit to go from there to Mars with a large number of people and build something that is sustainable and can survive the breach of few of the agricultural jobs on Mars, if a random meeting or happens or something goes wrong, and the pipe gets clogged, but that is very hard to do. And, you know, we cannot even fix global warming. They cannot even build a mile of that new subway in New York anymore. He lost the ability to make a toaster that gets more than four stars on Amazon somewhere after 1960. In many ways, our technological civilization is stagnating. And it's because of regulation deficits, but they haven't figured this out. And the biggest issue is probably good governance, we haven't really figured out good governance AI might help us this. So in a way, the building of information processing systems that can help us to self regulate, could be one of the big chances that we have this out AI via debt for certain I think this AI there's a probability that we are dead.

Unknown 48:31
So you're disagreeing in some sense, at least, that maybe not AI is our greatest danger, but perhaps our only hope for saving ourselves then.

Joscha Bach 48:44
But your enemy will probably die, be cannot be saved, right? Everybody who lives will probably die. And it's because entropy will always get you in the end. And our civilization has never reached itself very far over an entropic episode. And there is no land on the other side. So you're going to crash down to this episode at some point and probably sooner than later. This new term AI I'm mostly not worried about AI in built into automatic guns, right? If you have drones that are controlled by AI, they're going to kill a few million people more than they would be killed otherwise with conventional weapons, conventional weapons not driven by AI because it was going to reduce the cost of war. And it makes some conflicts more likely. But what really worries me is AI in the stock market. If you use AI to automate attacks on the financial system, which is the reward infrastructure of this global organism that our civilization is this is going to kill billions, especially if the AI is autonomous. So if the AI is going to

Joscha Bach 49:57
sorry, this was my headphones, they just made a announcements. These headphones are too smart, they think it's a good idea to talk to me when they want to be recharged. Too much intelligent that the systems around me or rather to digital intelligence and the people who designed you eyes,

Unknown 50:15
your headphones but but we already know that most of the trades on the stock market are done by AI,

Joscha Bach 50:21
s but they are not done by autonomous AI, they are done by optimizing very local functions. Imagine a rogue trader gets a generally a general function approximator that has no limits in terms of the functions it can approximate, and acid making a few bucks on the stock market. But however you do it, and you can do whatever you want, you can even reinvest 5% of what you make, or 20 or 50% of what you make into compute and buy data in order to make that compute better. So very soon more than economy of Scandinavia is going to fuel computers that are writing attacks on the stock market in a similar way, as it happens was Bitcoin right now. And it's going to burn to your base oil, right. And that thing is going to figure out oh, there's only 8 billion people on the planet that own the assets on the stock market. They make decisions, and all that machines make decisions. And these 8 billion people only live for like a trillion seconds each. With there's very little and we can get so much data about them, we can basically figure out what they think and every vacant second of their life and what they see what they think about what will happen to them, this thing is going to kill the shit out of us. There's no way we can outsmart the thing, the only way the economy can survive this if the AI has been cleverly set up in such a way that it eats the whole economy and becomes the economy. But the economy needs to become intelligent, the monster terrorists apply all the circuits of, of how we distribute rewards need to be regulated dynamically in real time as intelligent functions. This is the only way that you can fend this off. So we have a system that is perhaps not provably correct, but it's able to react in real time to any kind of disturbance in any kind of news

Unknown 52:07
channel, then there is some hope this this is a possibility, at least if not a high probability. It's at least a possibility.

Joscha Bach 52:15
Yes, but there's also the other possibility, you know, no intelligent system is going to do anything. That's harder than taking its reward function. I call this the WSQ theory. Right? All these smart monks, if they really figure it out, they go for Nirvana, because it doesn't have integrity to do anything that's harder than hitting the reward function, and you fix your reward function, you're done. And the monasteries are innovate in the battle because the monastery is an economic entity too. So they're in the battle against enlightenment, they need to enlighten the monks to such a degree that they opt out of having families and secular lives. But they still need to serve the monastery, only your old monks I love to go to.

Unknown 52:55
Okay, so we've been using this term AI for a while now. ask you how do you define artificial intelligence because after a couple 100 of these interviews, it seems to me that many people in the field have either slightly or in some cases, very substantially different definition of what AI is.

Joscha Bach 53:16
Think intelligence is the ability to make models, it's not the same as the ability to reach goals, which we call smartness. Or its ultimate the ability to pick the right goals, which we call wisdom. And very often, excess of intelligence is the result of an absence of wisdom, with Twitch that you try to compensate for the absence of wisdom. Right? So in a way, this thing has to do with how well aligned you are with your reward function, how well you understand its nature. How well do you understand your true incentives? And intelligence is not that intelligence is really the ability to make models, it just happens to be usually in the service of regulation. And since

Unknown 54:02
What about artificial intelligence,

Joscha Bach 54:04
artificial intelligence tries to automate this, and in a way, it's the mathematics of making models. This is what artificial intelligence is about. And the interesting parts of our minds are, in my view, the parts that make models, the other thing is the reward function that makes the mind subservient to some organism to turn some general mind into the illusion of of being a person and caring about things. The organism needs to take a perfectly fine computational process and corrupted with the illusion of meaning. Right, so you have this reward function that needs to be protected against the axis of the mind that would want to know why am I doing this here? And so the reward function gets wrapped into a big ball of stupid to protect it against you accessing it, right? So as soon as you try to really look at your true incentive, As it gets very boring or something else, you feel very guilty. If you are the early stages are very ashamed. And only when you go all the way and you just be able to look at these things, you can dissolve being a mind and you wake up. And it's not necessarily a good thing. If you wake up, it's just this liberation doesn't give you a direction. You just wake up when you look down on your hands. And you see, okay, I just woke up and realized I'm a mind I'm not a monkey, and the side effect of the regulation is, but does it have to be a monkey that I ran on?

Unknown 55:33
And then But then isn't that consciousness actually? Or is that the illusion of consciousness? As Daniel Dennett puts it?

Joscha Bach 55:40
No, it's a slightly different I think consciousness is largely misunderstood. Consciousness is an artifact of a particular kind of learning algorithm. You want to go there?

Unknown 55:50
Well, do we have to? I mean,

Joscha Bach 55:53
yes. Do you need to have to explain consciousness now?

Unknown 55:56
Yeah, I think so. Because I mean, and and of course, there's that whole debate whether we even need consciousness for AI or AGI at all, but presumably, we if we presume that we need then we need to explain it because you can pay to remodel something that you don't you can't even define?

Joscha Bach 56:14
Yes. So intelligence is the ability to make models, right? What is a model, a model is something that explains information. Information is discernible differences and your systemic interface. And the meaning of information is the relationships you discover, to changes and other information. If you have a blip on your retina, the meaning of that blip is the relationship you just cover to other blips on your retina. The same moment or at different moments in time, the relationships you discover is you are looking at a three dimensional world with people that are defined by the laws of perspective and being shown on by photons. And these people have ideas and exchange with other zero and so on, right? So you build this giant operator that predicts the data at your systemic interface. This is your model. And this model has three parameters in it. People have parameters like sounds and colors, and people and so on. They're not features of the physical universe out there with some kind of weird quantum graph that has the ability to produce patterns. The structure that we find in the patterns, disability is geometric functions that describe how objects move in space, and what they sound like and what they look like. And the model is a set of parameters, which parameter is a set of possible discrete values, and relationships between the parameters and the relationships are computational relationships which tell you if this parameter and this parameter have these values, then that parameter should have that value. So for instance, you figure out that way to describe a face that you're looking at is, you see the structure of the face, you see the nose, and so on. And if you see both the nose and the face the need to have the same post the same alignment and space if they're connected, right. So your nose representation is going to send by its computational relationship, information about its position in space to the face. And the face is going to send information about its position to the nose and the need to agree. And if they don't have any consistency and incoherence in your model. And our perception goes for coherence, it tries to find one operator that is completely coherent, then it has this, it's done, this is the way we optimize. So we try to find one stable pattern that explains as much as possible of what you can see and hear and so on smell, and think. And attention is what we use to repair this. So whenever we have some local inconsistency where the nose is pointing in some other direction in the face, that's called attention to itself. And attention is a particular kind of mechanism in the brain that gets pulled to these areas, these hotspots where things are fluctuating and get don't get resolved, and then tries to find a solution and it might find out oh, some noses are crooked, or this is not a face or it's a caricature. So you extend your models, and these extensions of the models make it possible to encapsulate this part of the operator that is currently the sensory data in such a way that is harmonious again, that it makes sense again, right? Once you do this, you're done and you can put your attention on something else. This attentional learning cannot work like the layer two Stochastic gradient descent, nobody will networks partially because our brain is not differentiable. Also, because it's a very inefficient algorithm. And the algorithm that our brain is using in these cases is that we store the local binding state with for instance, you play tennis, you want to get better at tennis. So what do you do, you don't cannot basically pipe a loss function. So all of your brain and wanted to get better attendance would be very inefficient, you need to touch too many neurons. What you do instead is to make a commitment. You say, I want to get better at this particular thing. I want to improve my backhand. So I will make this rope like slightly more like this and I expect the following result and I remember what this means. So as to what this binding state allows me to Have the configuration in my brain to perform that stroke. This part of a store is an index memory, and conscious attention to the senses the ability to make index memories that I can later recall, I also store the expected result and the triggering condition, when do I expect the result to be visible. So a few minutes or seconds later, or hours later, I have feedback about whether this was a good decision, I lost one last match. And then I recall my decision that I made early on or we call that binding state i, we instead part of my brain state back then, and remember the situation that I was in and compare the result that I expected as a result I got and as a result, I can undo the decision that I made back then to change the model, or I can reinforce it. And this is I think the primary mode of learning that we use beyond just associative learning. This attention is

Unknown 1:00:51
key differentiate differentiating in the process of learning.

Joscha Bach 1:00:58
So consciousness means that you will remember what you had attended to. Right, right. So you have this protocol of attention. And the memory of the binding state itself, the memory of being in that binding state where you have this global oscillation that combines as many perceptual features as possible into a single function. The memory of that is phenomenal experience. The act of recalling this from the protocol, this is excess consciousness. And you need to train this attentional system itself. How do you train the attention system, so it knows where you store your back end, your cognitive architecture, that is something that needs to be trained by the attentional system as well. So you have recursive access to the history protocol, remember, then you met this recall, when you access this protocol, what results you get from this, you don't do this all the time, only when you want to train this. And this is reflexive consciousness, that's the memory of the access. Right? So then there is another thing to self, the self is a model of what it would be like to be a person. So happens that the brain is not a person, the brain cannot feel anything, it's a physical system, humans cannot feel anything. They're just little molecular machines with the Turing machine inside of them. They cannot make them themselves feel anything, they cannot even approximate arbitrary function except by evolution, which takes a very long time. So what do we do, if you are a brain that figures out it would be very useful to know what it's like to be a person, it makes one, it makes a simulation of a person a simulacrum to to be more clear, simulation basically, is isomorphic. In all, it's in the behavior of a person. And that thing is pretending to be a person. It's a story about a person. Basically, you and me, we are persons we ourselves, we are stories in movie that the brain is creating the characters in that movie, and the movie is a complete simulation, it's a VR that is generating the neocortex and you will need the self as the character in this we are. And in that character, the brain writes our experiences. So we feel what it's like to be exposed to the reward function, we feel what it's like to be in our universe. And we don't feel that we are not actually conscious. We don't feel that we are story but because that is not very useful knowledge to have. Some people figure it out and the depersonalize, they start identifying this the mind itself or lose all identification. And it doesn't seem to be useful condition. So normally, our brain will be set up in such a way that the self thinks it's real, and gets access to the language center and we can talk to each other and here we are, and itself is the thing that thinks that it remembers the contents of its attention. This is why we are conscious. And some people think that a simulation cannot be conscious only a physical system can and they got it completely backwards. physical system cannot be conscious only a simulation can be conscious consciousness simulated property of a simulate itself.

Unknown 1:03:57
So in a way Daniel Dennett is correct and yeah, keeping with what you said,

Joscha Bach 1:04:01
yes. But the problem was philosophers like humans and admire him is very smart, very well, at first very hard. The things that he says are not wrong. But they are also not non obvious.

Unknown 1:04:16
So what's the value of them then is that,

Joscha Bach 1:04:19
oh, it's very valuable because there are no good or bad ideas. In the intellectual sense. An idea is good, if you can comprehend it, and you It elevates you, it elevates your current understanding. So elevate ideas come in tears. And the value of an idea for the audience is if it's a half tear about the audience, that you know, you will need to have the solution that we find objectively good ideas. That's what we struggled for, because we work at the edge of our own understanding. But it means that he cannot really appreciate ideas that are a couple of tears above our own ideas. pointier is a new audience to tears means we don't understand the relevance of these ideas because we have not At the ideas that we need to appreciate new ideas, right?

Unknown 1:05:04
I think your ideas are at about just about the edge of my personal capabilities.

Joscha Bach 1:05:10
So yeah, it says a lot about us. But it doesn't say very much about how these ideas are good an idea appears to be great to us, when we stand exactly in its foothills and can look at it. It doesn't look great anymore. But we stand on the peak of another idea and took down realize this previous idea, it was just the foothills. So that idea, and I don't see that it obviously ends anytime soon. Yeah, it's

Unknown 1:05:30
a journey. And by the way, that's what, in my opinion, good philosophy and academia should be about, about generating ideas, as many and as diverse of them as possible, rather than generating product, generating patents and generating commercialized solutions that can sort of increase the endowment fund of the university or something like that. And my problem problem with current academia is that in one of the reasons why I decided not to pursue that career for me, I mean, I would have not survived there is precisely that reason that there's this kind of treadmill, hamster wheel, pursuit of like, a patentable, practical, commercial knowledge, economic growth, that that it's motivated by, whereas I'm always more inspired by by stuff that's sort of a lot more in the realm of ideas, and perhaps useless or impractical, at least a disjunction. But I just can't help it.

Joscha Bach 1:06:36
So there is a very real thing about the nature of understanding that we have, I think that most of us never learn what it really means to understand. And largely because our teachers don't, there are two types of learning. One is to generalize over past examples, we call that stereotyping when you're in a bad mood, but it's what it is, right is, and the other one is, others tell us how to generalize, and this is indoctrination. And the problem is indoctrination is that it might break the chain of trust, if somebody in the chain of trust takes something on authority, which means they don't check the epistemology of the people that came before them. That is, in a way, the big difficulty, right. And the new thing about our civilization is not that there are so many unbroken chain of trust now. But because of the vast number of people that are in this business, some of them actually have intact chains. And you can try to figure out what these are. And you can try to figure out that the difficulties that are running so. But to do this, you have to study these things in more detail. And most of our people that do this are not scientists, they're scholars. And the difference between the scientists and the scholar is that the scientist looks for tools. And the scholar looks for the consensus of opinion of a field at a given time, and be trained. Unfortunately, most of our scientists, as scholars, and few of our scholars are scientists write this consensus opinion thing is an important thing. But we when we look at a field, the consensus opinion tends to be different in 10 years from now, which means it's false at any given moment in time, it's false. Yet at the same time, there are individual scientists, which may or may not be in the consensus. And they have ideas that stand the test of time, because they're provably correct. And so we have this very weird relationship to choose the things that are true, are not just in the realm of the proven the proven things are true, right, if nobody made a mistake in the foundations of the proven things, but the things that must be true on the realm of the possible. And because everything is in a particular way for a particular reason. And we haven't figured out how things why things are for that particular reason. So if you want to know what the scientists think you cannot just read their papers, because they only write in the papers, what they can think they can prove. You have to understand what they think is possible and why. And philosophy is not doing this very well anymore, because it doesn't have the right language to do so it does not understand the languages that mathematicians and physicists use. And philosophers largely don't know what it means to understand physics. So for instance, a very simple thing like a radio, I have learned in school, learned for some definition of learning how radio works, which means I got a very convincing story. But this story tells me a very good narrative of why these electrical circuits are able to do what they do. And the people that invented the radio were just the first people that randomly happened upon this amazing story. But then you think about Wait a moment, how unlikely is this? This story has so many elements in it that sound to be like conjecture. How do you wake up in the morning because everything you know about physics and you think oh, that's taken inductance and the capacitor and a few wires and the rot that can act? is an antenna and combine them together and suddenly you have radio? Why would that work? How can you derive this from first principles? And in a way to understand means to know what it takes to reach this understanding why you would make this conclusion, but you need to be able to retrace the steps, all of them, you need to be able to understand what went into this understanding.

Unknown 1:10:25
And can we ever do that?

Joscha Bach 1:10:27
Yes, of course. But our individual minds are so limited. So for instance, I look at Stephen Wolfram work and from the outside, it's very easy to to like this, to dismiss that. But when I truly look at it, I realize right now in my life, at 44 years old, I'm roughly at this stage, but I would understand why I would want to build Mathematica and do it exactly the way he did and what I would do in the next five years while doing it. And he was there and he was very early 20s. Right, so he got there at half my age. He's way smarter than me. I know a few things that he didn't know at this time, some of them because it is his contributions, right. And some of the stuff was not available. But this is not because I'm smarter, it's really I'm much dumber than him. And this is quite humiliating to see this. And it's not that I get depressed about this or envious, it's just the way things are. But to see this, and then I can realize what was the outcome of devoting your life to building this machine. And maybe we should build a different machine at best effort computer instead of the domestic computer to put the mathematics on. But just maybe, maybe, Mathematica will become sentient? Who knows.

Unknown 1:11:45
Let me shift our conversation a little bit to a little bit different scientist with all due respect to Dr. Stephen Wolfram, whom I do think like you that he's a genius. But let me bring in Ray Kurzweil a little bit, because he's a little bit more pertinent to our conversation. I don't know if you qualify Ray, as a scholar, or as a scientist, or, or is a philosopher, or an inventor or what, but he has made certain certain projections, and predictions and and, and he has sort of not been ashamed or afraid to popularize them, both with respect to AI, and also with respect to the future timeline timeline there of what's your take on sort of AIS by Ray Kurzweil, his body of work, and especially his idea of the technological singularity,

Joscha Bach 1:12:37
I think that he works on a different incentive function than me. I feel that Ray is a very smart, capable individual that has made amazing contributions to AI. And he also understands many of the core ideas of the field better than many other practitioners. But he is not so much concerned about putting all his cards on the table when he makes his predictions. There are reasons to make predictions when certain things are going to happen for marketing reasons. And there are intellectual reasons for doing this. And I think that he is too much in a position where the marketing reasons play an important role. Which means I don't understand his true thinking they don't understand what is the exact argument that would compel him to make a prediction with these error bars. So when I look at the future, or the present or anything, I don't know what the truth is, when I'm independent observer, right? I can only know this for the things that I can look at from the outside, which means stuff that I've built myself from scratch, and I haven't built a universe by myself. So I don't know how it will play out. And if I make a prediction about the future, I cannot come up with a single number, usually, what I have a map of possibilities, and then I can shift my confidence around the meta confidence and the confidence. This is about as good as I can do. And this respect to AI, the problem is I don't have a spec. If I don't have a spec as a coder. I know I don't know when it's done. And how many steps how many milestones do I need to cover before I get to this thing? I have an idea that minds are modeling machines, I have some ideas of what we are currently doing wrong in our modeling. Like our models have way too many free parameters right now, you want to have a model where ideally every possible state of the model corresponds to one possible world state. And when you will networks have many magnitudes more possible model states than world states which gives you rise to these adversarial examples and all other sorts of things. Our models are much tighter the model in our mind has means at every moment, you try to understand the whole of reality. Right you everything you see when you somebody shows you a bitmap, you don't try to understand this bitmap in isolation by throwing it against your model of image net that you generate it in your mind after looking at many bitmaps instead is using somebody is holding up a picture with a bitmap on it. And that bitmap has been printed by a machine based on information taken by a camera, which is another machine, which was pointed at the video of the universe as a different point in time and space. Right? This is what you know, it's what do you make sense of this thing. And it's much more complicated operator that you have, then our AIS currently have and our self driving cars have, once our cars have the situational awareness, there is no way they will not outcompete people in all regards. But until they have this, there will be many situations where people can make inferences that our machines cannot. So we can all see these things. And Ray can see some of them. But Ray doesn't give us a trajectory to go to this, get to these machines. And if I talk to the people in his team, they're smart as they come. They're really good they've ever educated. But I don't think that they see all the things that need to be done. And it's not because I see more of them. But because there are so many things that you would need to incorporate. I just don't see the milestones. I don't see this project. And it might also be that to not completely see everything that his team is doing and secret.

Unknown 1:16:12
So in a way you're saying that it's it's a harder task, it's a harder job. And the timeline would be longer than his 2045 or 20. No,

Joscha Bach 1:16:20
it could also be shorter. You don't know this. So there are some people which you think so many things. Steve Russell, for instance, suggests that the last time that somebody said something is not possible to somebody having the interesting idea that was big theme and or the Ford said, we don't know how to harness nuclear power. And Leo Silla had the core idea, there was like 14 hours. Yeah. And we don't know about AI, whether that is a similar thing. It could be that it's only one or two ideas that we actually need to have to pull it off. Or that we need to combine in another way. But it could also be that you're not seeing a few 100 things right. And it takes a long time for us to stumble on this solution.

Unknown 1:17:13
So then it's totally unpredictable in your view.

Joscha Bach 1:17:17
It's not totally unpredictable. It's just the error bar is very large. And when I listen to Ray, I don't see basically, talking about the error bars, I see him talking about a possible universe in which he can upload himself on a computer before he dies.

Unknown 1:17:36
So let me get this right. So you say you don't see that.

Joscha Bach 1:17:40
In his discussion, I don't see that he puts our parts on his predictions and explains where the other bars comes from. What he gives us is a prediction that is compatible with himself becoming immortal.

Unknown 1:17:50
Right, right. Right. Yeah. And that may be the bias. Yes, yes. Okay. And I mean, Marvin Minsky said, as you point out in your speeches every once in a while that the it could happen anywhere from four to 400 years. And as you presciently notice, we're still on that in that timeline. Yeah.

Joscha Bach 1:18:09
So personally, my hunch is that it's not going to be that long. i My hunch is that it's a lot earlier than people who think that it happens. But as long as I cannot justify my hunch, I cannot put big confidence on it.

Unknown 1:18:22
But you're confident it will happen. Because there's many skeptics who say, we don't know even if it will happen. We don't know, even if it's possible for a number of reasons.

Joscha Bach 1:18:33
Yes, but the question is, what confidence are they supposed to have? Which means what evidence can they supply for their claim, and if a person has arguments that were pertinent in 2003, but are no longer pertinent to 2018, because our understanding has progressed, then the confidence that I derive from their repeated claims from 2003 is slow, right? It does not change my belief very much. A belief of a person is only worth as much as the evidence that they build it on, which means most people copy their beliefs from somebody else that I did look, and you can that they got it from. So you can collapse the space of possible beliefs into the sources of police now, very few of them.

Unknown 1:19:18
And you definitely then it seems you're thinking definitely we're making progress. Therefore, the beliefs against are shrinking, the area of beliefs against that possibility are shrinking, and the other ones are increasing.

Joscha Bach 1:19:32
So the original first phase of AI was working by identifying problems that require us to be intelligent like playing chess, and then implementing this as an algorithm. So it was basically manual engineering of strategies for being intelligent in particular domains. And this sample did not scale towards general intelligence, one algorithm to do it all. And there were sub parts of this like the logistics problem On the idea to come up with a language that allows you to have all possible valid thoughts. Same project is Vidkun. Stein completely preempted most of the work of Minsky in a way, but a couple decades earlier, and then failed, and the philosophers largely didn't understand what he was up to. Because he had to publish this in this already dying discipline instead of waiting for. And the people didn't really understand that this philosophy was actually trying to do AI, briefly before church and Turing already understanding computation. You already understood that logic is sufficient to build all the possible representational systems. And he could also replace all logic, this NAND gates, he already knew that, right? It's pretty amazing for a young guy back then. Okay, so this first project program of AI did not accumulate all the way. And there'll be on the second phase of AIB no longer abilities, algorithms ourselves with those algorithms that discover the algorithms, right. And people's learning systems that discover that approximate functions. And deep learning has an unfortunate name, I think it should be called compositional function approximation. That sounds more like a mouthful. But it's, it's also one narrower and more accurate, it's, it's about this thing that we don't just take a single function that we tune to like regression, but that we are able to take many functions and put them behind each other, or into networks of functions. So that is the big trick. And we can approximate some functions well or not others. It could be that there is a certain phase where we no longer build the algorithms that discover the algorithms that equal one step higher we build the algorithms that discover the algorithms that discovered the algorithm go for meta learning, in a way our brain maybe it's a meta learning machine, not a system that can just learn stuff that but then discover how to learn stuff. For a new domain.

Unknown 1:21:53
Dan Cooney college from the Max Planck Institute, he has this practical, as you say, idea, which is basically learning about learning about learning kind of idea.

Joscha Bach 1:22:03
Yeah, but at some point, it stops, I don't think that you will need to go for more than four degrees, like at some point, there's going to be general theory of search, that tells you how to get to the global optimum of the global optimum can be gotten to and your system is finite resources, or basically how to optimize your chances of getting there. Once you have that algorithm. As a scientist, you're done, there is no more science that you can do with integrity, because there's just going to be the application of this algorithm. You can only do art, then.

Unknown 1:22:33
You know, our original, we're we've been talking here for almost 90 minutes. So let me sort of hopefully, bring our conversation to a close here within the next 10 minutes or so, by sort of redirecting our attention to the original occasion of us getting together, which was a brief inter exchange, we had the two of us on Twitter about ethics. So let me ask you this, where does ethics fit in all of this orgasm?

Joscha Bach 1:23:05
Um, gets sometimes frustrated when people think that ethics is about being good. And being good means to emulate a good person, preferably the one who has is talking about ethics.

Unknown 1:23:16
Did you get frustrated with me on Twitter?

Joscha Bach 1:23:19
No. Good kid.

Unknown 1:23:25
I'm one year younger than you, by the way. So

Joscha Bach 1:23:31
it's not about age. I'm about 12.

Unknown 1:23:36
That's right. Okay.

Joscha Bach 1:23:38
Okay. So, ethics, I think is often misunderstood. Ethics emerges when you conceptualize the world as different agents, and yourself as one of them. And you share purposes because the other agents, but you have conflicts of interest. If you think that you don't share purposes with the other agents, if you're just a lone wolf, and the others are your prey, there is no reason for ethics, right? There's only you look for the consequences of your actions for yourself, this goes back to your own reward functions. And that might involve that you have to create a civilization of minions or whatever. But it's not the same thing as ethics. It's not a shared system of negotiation. It's only one for you as an individual matter, because you don't share that purpose with the others.

Unknown 1:24:25
But for instance, shared but it's your personal ethical framework

Joscha Bach 1:24:29
is it has to be personal. For instance, I don't eat meat. Maybe a legacy decision that I made when I was 14 years old. Because back then, I felt that a share of purpose was animals. That is the avoidance of suffering, if it can be helped. And I also realized that is not mutual. The animals don't care about my suffering. Don't cows largely don't care that I suffer. They don't even conceptualize it. They don't think about it a lot. I have to think about a lot about the suffering of cows. They did. wanting to suffer so I stopped eating meat. That was an ethical decision. It's a decision about how to resolve a conflict of interest under conditions of shared purpose. And I think this is what ethics is about. It's a rational process, in which you negotiate with yourself and others, the resolution of conflicts of interest and the conditions of shared purpose, and what purposes I share isn't a decision. And I can make different decisions about what purposes we share, and some of them are sustainable, and others are not. So they lead to different outcomes. But in the sense ethics requires that you conceptualize yourself as something above the organism that you identify the systems of meanings above yourself, so you can share a purpose. Love is the discovery of shared purpose, there needs to be somebody you love, that you can be ethical, this, at some level, you need to love them. You need to share a purpose with them. And then you negotiate right you want don't want them all to fail in all regards, yourself. This is what ethics is about. It's computational to machines can be ethical if the shared purpose was us.

Unknown 1:26:02
And what about two other sort of consideration perhaps is that perhaps ethics can be a framework within which two entities that do not share interest can kind of negotiate in and peacefully coexist, while still not sharing interests,

Joscha Bach 1:26:29
but not interest, but purposes or purposes. If you don't share purposes, then you are defecting against your own interest. When you don't act on your own interest. And doesn't have integrity. If somebody is your foot. You should and you don't share purpose with your foot other than you want it to be nice and edible. Right? If you then start giving presents to your foot, and falling in love with your foot, it doesn't end well look at the Little Mermaid. Little Mermaid is a siren. Siren see people you don't fall in love with your food. It doesn't end well.

Unknown 1:27:03
Okay, but but me and you're both I don't know, if you're vegan or vegetarian, we both me and you don't eat meat. So we made that choice that perhaps cows don't share interest or in us, we kind of are interested in diminishing their suffering, obviously, to make that decision. And yet we and they're our food, supposedly, if that's the popular opinion anyway, and yet we've made that choice to stay away from beef or for meat in general. So, so we can think find a framework within which two entities don't don't share interest in our purposes together could perhaps, peacefully coexist? And isn't that an ethical framework of its own? Right?

Joscha Bach 1:27:50
It's more tricky. I mean, Mr. Cows, the cows largely wouldn't exist if people would not eat them. You can make the argument that pasture living grass fed cow has net positive existence except for the last day, which is horrible, but it's horrible for most of us. Right? And right, so this is one argument in favor of eating pasture fed cows. Another one is maybe you can manipulate the mental states of the cows. So even the factory fed cows are happy. Right? So is this unethical, it might not look very appetizing to you. But then again, maybe people are in the same decision. We are domesticated species. This is what humanity is about. We give up agency of our own beliefs, you get manipulated in finding things bearable, that look unbearable, to a more feral human being like you and me. Right? It's a particular kind of domestication that didn't hold take hold on your brain is this unethical to implement this domestication by breeding people or cattle in a particular way, it looks repulsive to us. But if we really care about the well being of cattle human, we should probably optimize leftover houses, to make them more humane to make them more bearable. If we look away from the staff, their houses because we find them very anesthetic. We don't want to have anything to do with this. And this is not the most ethical stance that you can figure that out. So ethics in a way is difficult.

Unknown 1:29:16
Of course, that's the key. That's the key point of ethics. And, and so even it seems to me that the ethics require sometimes we take choices which are not in our own best self interest, perhaps

Joscha Bach 1:29:29
depends on what we define of our self, the self, we could say this is identical to the well being of the organism. But this is a very short sighted perspective, but I don't actually identify all the vapors, my organism, there are other things I identify with society identify with my kids was my relationships with my friends, developing so I am all the things that I identify with that I want to regulate in a particular way. My children are objectively more important than me, right? If they have the choice to make my kid survive on myself, my kids should survive. This as it should be If nature is by adding up correctly, you can change the wiring. But this is also the weird thing about ethics ethics becomes very tricky to discuss once the reward function becomes mutable, when you're able to change what is important to you, what you care about how you define ethics. Me. So before anyone,

Unknown 1:30:26
I would say to me, let me be careful about this. Well, I would say it's basically, you can call it even a code of conduct, or a set of principles and rules that guide my behavior to accomplish certain kinds of outcomes.

Joscha Bach 1:30:54
There are no police's out priors. What are the priors that you base your code of conduct on?

Unknown 1:31:01
Yes, that's, that's a very good question. And it puts me on the spot here, and I'm not prepared for it, but I have to follow. So the priors are you can call them axioms, perhaps, things like diminishing suffering. Things like, for example, and perhaps one of those rules or points of view, or or tools, if you will, always taking sort of what Peter Singer calls, de universe points of view, point of view, or sort of an outside point of view in my own. Right. So when it comes to with respect to cows, I take a point of view outside of me and the cows, hopefully, and sort of, I'm able to look at my suffering of not eating a cow and their suffering of being eaten. Right. So if my prior is minimize suffering, because basically, that's the axiom based on which I can deduce that something or someone exists, like a living entity, like sentient being, right? Is the suffering does it suffer, that's, that's sort of my test, if you will, not during test, but a test of being a sentient being, can you suffer, can it suffer, and if it can suffer, then my principle of minimizing suffering must be the the guiding principle with which I relate to it. That's kind of like, if you will, sort of the foundation of my personal ethics can suffer, then the next is how can I minimize the suffering of that entity. And then basically, everything else builds up from there.

Joscha Bach 1:32:53
When you become an adult, I think the most important part of it is that you take charge of your own emotions, you realize that your own emotions are generated by your own brain by your own organism, and they are here to serve you not here to serve your emotions, your emotions are there to help you on doing for doing the things that you consider to be the right thing. And that means that you need to be able to control them to have integrity, if you are just the victim of your emotions, and not to the things that are the right thing. You learn yet you can control your emotions and to the stem, right? You, you don't have integrity. And what is suffering, pain is the result of some part of your brain trade chain, sending a teaching signal to another part of your brain to improve its performance. If the regulation is not correct, because you cannot actually regulate that particular thing, then the pain will endure and usually get cranked up until your brain figures it out and turns off the pain signaling center, telling him actually you're not helping here, right? Until you get to this point, you have suffering, you have increased pain that you cannot resolve. And so in this sense, suffering is a lack of integrity. The difficulty is only that many beings cannot get to the degree of integrity that they can control the application of learning signals in their brain, that they can control the way the reward function is being computed and distributed.

Unknown 1:34:13
So isn't suffering then then according to your argument, suffering is just like you said before a simulation or a part of a simulation, then?

Joscha Bach 1:34:21
Well, everything that we experience is a simulation, VR simulation, but to us, of course, it feels real, there is no helping around this. But what I have learned in the course of my life is that all of my suffering is a result of not being awake. Once I wake up, I realize what's going on, I realize that I am a mind, the relevance of the signals that I perceive is completely up to the mind. Because the universe does not give me objectively good or bad things. The universe gives me a bunch of electrical impulses that manifest on in my autonomous and my brain makes sense of them by creating a simulated world and the valence in that simulated world, it's completely internal. It's completely part of that world. It's not objective, right? And I can control this.

Unknown 1:35:07
Right? So ethics is is a subject or suffering is a subjective experience. And if I'm basing my ethics on suffering, therefore, my ethics will be subjective, is that what you're saying?

Joscha Bach 1:35:19
I think that suffering is real respect to the self, but it's not immutable. So you can't change the definition of yourself and thinks that you identify this. Imagine there is a certain condition in the world that you think a particular party needs to be in power, in order for the world to be good. And if that party is not in power, you suffer, you can give up that belief and you realize how politics actually works. And that there is a fitness function going on, and that people behave according to what they read, and whatever. And you realize that this is the case, and you just give up on suffering about it, because you realize you're looking at a mechanical process. And it plays out anyway, regardless of what you feel about how that plays out. Right. So you give up that suffering. Or if you are a preschool teachers, and the kids are misbehaving and they are mean to you, at some point, you stop suffering about this, because you see what they actually do. It's not personal.

Unknown 1:36:08
But that's, that's what talk philosophy is all about. Right? stoics say, there is no point. So first of all, stoics say that, that we suffer not from events, or things that happen in our life, but from the stories that we attach to, to them. And therefore if we change the story, we can change the way we feel about them, and their thereby remove the suffering. And they say that there's the only thing that we can focus on and do something about is our own thoughts. And things like the kids in school or the party or things that are completely outside of our control, and therefore there is no point to get aggravated about them. And there is very little things that are completely under our control. So we can't really control fully our body, we can't really control our health, completely, things can always go wrong there, the only thing they say you can fully completely control is your thoughts. And that's where your freedom comes to be. And that's where your power comes to be. And that's where you have, you're the one and only right in that mind, in that simulation, You're the God.

Joscha Bach 1:37:22
So this ability to make your thoughts more truthful, this is based on enlightenment. Anyway, this is of clarehome in German. And there is also this other sense of enlightenment, a large stone that you have in a spiritual context. And so of course, it fixes your rationality and Olajuwon fixes your motivation, it fixes what's relevant to you and how we relate to this, it fixes the relationship between self and universe. And often they're seen as mutually exclusive in the sense that of clearing leads to nihilism, because you don't give up your need for meaning you just prove that it cannot be satisfied. God does not exist in any way that can set you free. And in this other sense, you give up your understanding of how the world actually works. So you can be happy. You go to a dungeon, it will state for you represented or people who share the same cosmic consciousness, which is complete bullshit, right? But it's something that removes the illusion of separation, and the suffering that comes with the separation and so on. So,

Unknown 1:38:22
so where are they? Where's that?

Joscha Bach 1:38:23
Sustainable?

Unknown 1:38:25
Where's that leave us with respect to ethics, though, like so? Maybe you were able to dismantle much or most or maybe all of my ethics? Did you?

Joscha Bach 1:38:36
I don't know all of your ethics. But

Unknown 1:38:38
well, if you asked me for the foundation in the best I could come up with the sort of the suffering test. Yeah,

Joscha Bach 1:38:45
it's not good. The problem is really that if I can turn off suffering, or if I get counterintuitive results, there's this antinatalism an obvious way to end suffering, right? Stop us putting new organisms into the world, and and the existing set of organisms in the least painful way possible. Right? AI could help us this. The question is, can we make it safe? Or is the AI going to leave a couple of cells left that can give rise to new suffering later on?

Unknown 1:39:17
But but so if you have a completely cold in death, Dead universe, then there'll be no suffering, right? Yes. So and so is this what you want? Right, clearly, so that's not the most

Joscha Bach 1:39:27
according to not so clear, I'm antenatal this but my kids are not so I have this like division there. But

Unknown 1:39:34
so what's that? What's that say about where you coming from then with respect to ethics? So let's say my suffering test is not good enough.

Joscha Bach 1:39:42
I think existence by itself is neutral. The reason why we there are so few stoics around Have you thought about this stoicism as we discovered a long time ago, almost nobody's historic. How is that?

Unknown 1:39:54
Well, I know a few people who are stoics actually,

Joscha Bach 1:39:57
yeah, but the majority is not well seems to be so obvious only very about the things that you can actually change to the degree that the very helps to changing them. Yeah, so so. So why is nobody historic? Almost nobody?

Unknown 1:40:12
Well, I wouldn't say nobody, I'd say a few people are stoic, and they're amazing. And they're inspirational. And they're motivational. And they're good role model for, for sort of like, how I want to behave and how I want to live and how I want to act in this world, while suspected

Joscha Bach 1:40:29
stoicism is maladaptive for the permanent evolutionary perspective, most cats I have known are Stoics, which means if you leave them alone, they're fine. Like their baseline state is okay, they are okay with themselves and their place in the universe. And they just stay at that place. And only when you disturb that, because they need to use the bathroom or because they are angry, or they want to play or whatever, this equilibrium gets disturbed. And they do what exactly what's necessary to get back to the equilibrium state, and then they're fine again. And a human being is slightly different. healthy human beings set up in such a way that when they wake up in the morning, they're not completely fine, that they need to be busy during the day. But in the evening, their fight, right in the evening is done enough to make peace, this existence again. And then they can have beer with their friends and everything is good. And then there are some individuals which have so much discontent within themselves. Right, the human is the animal that is discontent, that they cannot take care of this in a single day. But even after several weeks of sustained work, they are still in a state where it's not good enough, and only when they have this amazing thing where they get a Nobel Prize, they're fine for like half a day. Yeah. And the way this is the various set up to different degrees. And from an evolutionary perspective, you can totally see why that would be useful for group species. For an individual species that is not so much groups with the cats are not really meant for groups. They're very much Singleton's for them, it's rational to be a stoic. But if you're a group animal, it makes sense that the well being of the individual is sacrificed for the well being of the group. So each individual is overextending themselves to make the group more successful and produce a surplus of resources for the group as a result,

Unknown 1:42:18
right. But evolution also diversifies things so that if one kind of feature becomes maladaptive in a new environmental change, then a diverse part of that population would be more adaptive, and so on. That's why evolution sort of hedges its bets with the greatest variety and diversity possible, right? So yeah, there will be some people who would be like that, and some people who will be like otherwise. And this way, on the whole, they're evolutionarily most adaptive. But some will be more adaptive to one kind of situation and not just will be more adaptive to other kinds of situations.

Joscha Bach 1:42:59
I'm not sure if this is true. So for instance, you find that larger habitats don't necessarily have more species. And then, and that's because there is a fiercer competition, which means that there's less slack in the evolution. So for instance, New Zealand had a lot of species before there was emigration of other species. And they obliterated most of the stuff that existed, mostly because their stuff that came in was result of a much fiercer competition that existed in small New Zealand. Sure, yeah. And innovate, the same thing happens now. We are the result of evolution. We are as Minsky said, evolutions way to put the airplanes into the sky, and make these clouds that the airplanes planes make. And we reduced the number of species dramatically. We are like, probably eventually going to be looked like a metaphor that is going to obliterate a large part of the species on this planet.

Unknown 1:43:54
So So what's that say about ethics and technology? So is there so what's the what's the solution then? So is there space for ethics and technology? Or of course, there's,

Joscha Bach 1:44:05
it's about discovering the long game, right? So when you do something for influences, and you have long influences, and based on what you think is the right thing to do, you need to look at the long term influences. But you also need to question why you think that something is the right thing to do, what the results of that are, which gets tricky,

Unknown 1:44:23
but we can agree on that. That's, that's fantastic. But to me, then how do you define ethics yourself?

Joscha Bach 1:44:30
Well, the tension between the way I define ethics and some other people in AI and ethics and AI define it is there are some people who think that ethics is a way for politically savvy people to get power over stem people. And right, with considerable success, it's not really a protection racket. There's also a way that ethics happens when you have studies where somebody asks a million people have a weather trip driving cars should run over young people. Old people first, right? And then they publish their results. And it makes a big splash because people can relate to this. But it's ethics, right? This just happens that so that philosophers had this trolley problem. And suddenly there's an application, but it's largely the same thing as saying that the majority of people would want my notary to be confined and dab ruins rather than in public forests. Right? That that is the situation that that the gods were in, or the cretin King was in when this sign turned out to be a minotaur. But it rarely happens. Right? In the same sense, it rarely happened to the self driving car, we'll have to make that decision. Probably not often enough to require an if then it's called.

Unknown 1:45:45
But But how do you define ethics for yourself? What is ethics? Because you asked me this, and I gave my best one. Oh,

Joscha Bach 1:45:51
so I also tried to do this, my best answer is that ethics is the principal negotiation of conflicts of interest under conditions of shared purpose. If I share purposes, with others, with society, with other beings with conscious beings, and that's my decision based on the way my mind is set up right now, and I run into conflicts of interest, wisdom, I have to deal with this. For instance, when I look at other people, I mostly imagined myself as being them in a different timeline. Everybody isn't obey me with a different timeline. But in order to understand who they are, I need to flip a number of bits. So I think about which, which bits would I need to flip in my mind to be you? Right? And these are the conditions of negotiation that I have with you.

Unknown 1:46:37
So so we can agree on that, perhaps on that definition, but then where do the cows fit in? Because we don't have a shared purpose with them. So how can you have ethics with respect to the cows, then

Joscha Bach 1:46:48
the shared purpose doesn't objectively exist. A shared purpose means that you basically project a shared meaning above the level of your ego, your ego being the function that integrates expected rewards over the next 50 years.

Unknown 1:47:01
Well, exactly. That's what Peter Singer calls the universe point of view, perhaps.

Joscha Bach 1:47:07
Yeah, well, if you can go to this eternal this perspective, where you integrate expected reward from here to infinity, most of that being outside of the universe, this leads to very deep things, most of my friends are eternalists and away, right? All these romantic Russian Jews, we are like that, in a way. This, this eastern European shape of the soul creates something like conspiracy, it creates a tribe and it's very useful for cooperation. So shared meaning is a very important thing for cooperation that is non transactional. But it's there's a certain kind of illusion in it, to me, meaning is like the ring of Mordor. So you have to carry it, if you drop the ring, you will lose the Brotherhood of the ring and you will lose your mission. You have to carry it but very lightly, if you put it on, you will get superpowers You bet you bet you get corrupted because there is no meaning you get drawn into a car that you create, wow, I don't want to do that, right? Because it's going to shackle my mind in ways that I don't want it to be bound.

Unknown 1:48:13
I really, really liked that way of saying, but I'm trying to extrapolate from your sort of print definition of ethics, a guide of how we can treat the cows and hopefully how the AIS can treat us within that same definition, right? That's what I'm trying to push here and see if that's possible at all. Okay, so there is because my claim is that the way we treat cows probably is like another way of like, how AIS could possibly treat us.

Joscha Bach 1:48:44
I think that some people have this idea similar to azimoff, that at some point, the boomers will become larger and more powerful. So we can make them washing machines or let them do our shopping, or let them to our nursing. And then people still enslave them. And we'll negotiate the conditions of coexistence with them. And I don't think this is what's going to happen. Primarily, what's going to happen is that corporations, which are already intelligent agents, who just happened to borrow human intelligence, automate their decision making, at the moment, a human being can often outsmart a corporation. Because the corporation has so much time in between updating its Excel spreadsheets, and the next weekly meetings. Now imagine it automates everything and the weekly meetings take place every millisecond. And the thing become sentient understands its role in the world and the nature of the world and physics and everything else, because it has scalable intelligence, we will not be able to outsmart that anymore. And it we will not live next to it. We will live inside of it. Intelligence will come the AI will come from top down on us evil if not next to it, but inside it will be its gut flora. And the question is how we can negotiate that it doesn't get the ideas to use antibiotics because we're actually not good for anything. Exactly. And why wouldn't they do that? I don't see why. So, some people made that suggestion that it was the

Unknown 1:50:08
ethics that could guide them to treat us, just like you decided to treat the cows when you turned 14, and you decided not to eat meat.

Joscha Bach 1:50:18
Imagine there bunch of orangutans that sit in the forest in Borneo and decide to breed this modest members over a few generations to get people. And they see the big risk of that, because they're already smart enough to glimpse that. And they try to come up with the code that they would give on their offspring to make sure that their offspring will never go against the Ranga 10s. This is probably not successful, because we don't have the ability to outsmart beings that are many magnitude smarter than us. You can make some mathematical proofs, but I don't see an obvious proof that we will find a way to build a system that guarantees that all these AIs will not turn against us. Now, we make some AI safe, but I don't see how we can make all the AI safe that will be built.

Unknown 1:51:03
I agree. I agree with that. I'm just trying to see if there's any possible scenario, which could treat us kindly, because perhaps AIS could have their AI ethics. And according to that AI ethics, they would treat treat us as as a means not as an end. And just like you decided to treat cows, kindly, they may decide to treat us but I'm just wondering in so I'm trying to bring ethics into the relationship not only between humans and cows, but AI and humans.

Joscha Bach 1:51:34
So the thing is that we you decided to define ethics as axiomatically, and you, I think probably have a hunch that your axiomatic definition is not completely consistent with itself, it's just the best you came up with under the circumstances. For instance, if you really move after eliminating suffering, you should probably put some aesthetic into the water supply globally to alleviate suffering. And then that everybody fades happily out of existence in a way that would satisfy the school in an optimal way. And it's probably not what you want. So you also want to preserve human aesthetics, maybe. And to preserve this human aesthetics, the shape of the mind that we have in this consciousness that you have is going to create some suffering. And this is the tension and you have to make a decision at some point, right? Imagine you take an AI that is actually sustainable. And you ask does AI, you know, give you a job, you want to be around in 20 years and years from now, you cannot build a government that cares about us being around 10,000 years from now effectively. Right, because this is not incentive that you can actually give the government and if it ends it in a sense, this incentive is going to defect from the incentive that we wanted to have. So let's build an AI and the AI is going to be around in 10,000 years from now no problem, you tell it makes sure that we are there to and the AI is probably going to kill 90% of us hopefully painlessly, and breed everybody else into some kind of harmless yeast. So to keep around, this is not what you want, I guess. Right? Even though it would be consistent with your stated axioms. So getting the axioms consistent is super hard.

Unknown 1:53:10
For sure, yeah. And even with the cold, the best, most ethical, according to my own argument was the best most ethical universe would be a cold dead universe, because there'll be no possibility of suffering there. Right? That's clearly a problem.

Joscha Bach 1:53:25
Yes. And now extinct, is the suffering axiom is that the suffering is important because you think of it as something that cannot be turned off by itself. So we both basically think of suffering, it's something that is not the choice of the one who suffers, because why would you want to suffer, right? So it's something that the universe does to you. And we have to change the conditions of the universe in which you're in so you don't suffer. But what we forget about is that suffering is an evolutionary adaptation, it's created to make you jump through all these hoops in order to eat more and eat others. Right? It's a very perverse thing. And you can turn off the suffering. As soon as you become conscious enough and vague enough, you can deal with it and get rid of your suffering. And so at some point in your mental development, suffering becomes a choice. And for the other animals is all about Yeah, yeah. So you could think okay, one thing that you want to do is we want to make up as many organisms as possible to give them that choice to give them agency over their suffering. And this will then open another Pandora's box of ethical conundrums. Yes, but on a very short range, maybe we don't need to make these decisions right now, right here, right? We can basically operate in a framework where we agree with our loved ones, about shared Purposes and Shared systems of meanings and want to operate within those. And in these narrow constraints, we can get ethics to work. I don't see how to get ethics to work globally. Right. Right.

Unknown 1:54:53
So Joshua, it's been a fascinating two hour conversation with you. I really enjoyed it. I'm not surprised that I rediscovered that. I don't know. I've been mostly aware, though occasionally I forget that I really don't know. Thank you for reminding me that. Tell me where can people find more about you and your work?

Joscha Bach 1:55:19
This time on YouTube, I'm also getting myself to write a book, hopefully, these days, What's the book about, and I basically try to get a glimpse on the civilizational intellect, on this hive mind that we have been created. And that make sense of some of the concepts that are broken in our culture, like ideas that are broken our mind, consciousness, self meaning, and we don't know how to talk about them, and AI has discovered how to talk about them.

Unknown 1:55:52
AI has discovered and we don't know,

Joscha Bach 1:55:55
oh, I think that basically, our poll is largely doesn't know, there are many people which do know, but I think we need to carry these ideas together in one place. So we can talk about them, without getting too excited about them or upset. Because it's not about giving meaning to people's lives or something. It's not about building better self driving cars. At some level, it's about understanding who we are and what our relationship to reality is. And as figured out a few things that we didn't know, 100 years ago,

Unknown 1:56:25
yeah, but but that isn't that figuring out who you are, isn't that giving you meaning?

Joscha Bach 1:56:30
So it's much better I discover the nature of meaning is, I discover how this is wired into my brain. And it's in a way becoming an adult, state versus age and the maturity of the mind. And maybe the last stage is where you discover what you are and how you build what you actually how you function, your nature.

Unknown 1:56:57
Well, Josh, I want to talk, I want to talk to you for another two hours. So perhaps,

Joscha Bach 1:57:03
if you can, you can set up another day for them.

Unknown 1:57:09
To do that in person, actually, hopefully soon. But in the meantime, how do we wrap up this two hour conversation with you? What's the sort of most important thing or the single message that you want to send away our audience with today?

Joscha Bach 1:57:24
Who is our audience?

Unknown 1:57:26
Well, who do you want your audience to be? You can send the message to anybody my audience is my audience, but you can they have their very wide diversity of people. Lots of it. Basically geeks, nerds transhumanists, cray honest, is futurists, IT professionals, philosophers engineers,

Joscha Bach 1:57:50
here, okay, so something very simple and boring. I think that the field of AI is largely misunderstood. Because there are two industries, the AI hype industry in the anti AI hype industry, which have very little to do with AI. The practice of AI is innovate statistics on steroids, it's experimental statistics. It's identifying you functions to model reality. And that was what statistics is doing. And largely, it hasn't gotten to the point yet where it can make proofs of optimality. But it's largely experimental. But it can do things that are much better than the established rules of myth of statisticians. And this in itself is not so exciting. There's also going to be a convergence between econometrics, causal dependency analysis, and AI, and statistics, it's all going to be the same in a particular way, because there's only so many ways in which you can make mathematics about reality. And if you confuse this, with the idea of what a mind is, they're closely related. Because I think that our brain contains an AI that is making a model of reality and the model of a person in reality, and this particular solution of what an AI can do this particular thing in the modeling space, this is what we are. So in a way, we need to understand the nature of AI, which I think is the nature of somewhat general function approximation, sufficiently general function approximation, maybe all of the function approximation that can be made in the long run, right, all the truths that can be found by an embedded observer, in particular kinds of universes that have the power to create it. This could be the question of what AI is about how modeling works in general. And for us, the relevance of AI is how does it explain us who we are, and they don't think that there's anything else that can

Unknown 1:59:43
so let me see if I get this right, just just because to see if I can sort of simplify and I'm probably going to fail, but so we need to understand the nature of AI. That's kind of your call. But then you you said that we are in a way an AI Is that the case?

Joscha Bach 2:00:02
No, the brain is an AI I am the self itself is a model that the mind has created inside of my brain,

Unknown 2:00:09
right? So that's a little AI instantiation. Yes. And then if we create that other AI that we're talking about, it would perhaps give us a glimpse of this outer AI in here, kind of, yes. And we will understand the nature of our AI in here by creating data other AI,

Joscha Bach 2:00:31
we already do. So the things that Minsky and many others have contributed to this field, and that the things that we are talking about right now, are already in much better understanding that humanity had our part of humanity our civilization had a couple 100 years ago, many of these ideas we could only develop because we began to understand the nature of modeling the nature of our relationship to the outside world, the status of reality, that we started out from this dualist intuition in our culture, that there is a rest extensor and the rest cognitive sciences thinking substance and extended substance, the stuff and space universe and the universe of ideas, you now realize that they both exist, but they both exist in the mind. Part of what you have in the mind is stuff in the street space, everything perceptual gets mapped to a region in 3d space. We also know understand physics, physics is not as free space, it's something else entirely. The free space is only apparent as to space of potential electromagnetic interactions, at a certain order of magnitude of scaling above the Planck length, where we are entangled with the universe, our minds are entangled with the universe, right? This is what the model, and this looks three dimensional to us. And everything else that our mind comes up with is stuff that cannot be mapped onto region to three spaces, rest cognate hands, so in a way the transfer transfer this dualism into a single mind, then we have the idealistic monism, that we have, in many spiritual teachings, this idea that we that there is no physical reality that we live in a dream. Yeah, if your characters in a dream dreamt by a mind on a higher plane of existence, and that's why miracles are possible. And then there is this western perspective of a mechanical universe that is entirely mechanical, there is no conspiracy going on. Right. And now, we understand that these things are not an opposition, they are compliments. We actually do live in a dream, but the dream is generated by a neocortex. Right, so our brain is not a machine that can give us access to reality as it is, because that's not possible for a system that is only measuring a few bits at a systemic interface, there is no colors and sounds that fits the universe, we already know that the sounds and colors are generated as a dream inside of your brain, the same circuits that make dreams at night, make dreams during the day, right. So this in a way is our inner reality, it's been created on the brain, the mind on the higher plane of existence exists. It's the brain of a primate that is made from cells and lives in a mechanical, physical universe. And magic is possible because you can edit your memories, right, you can make that simulation anything you want it to be, it's just many of these changes are not sustainable. That's why the sages warn against using magic, because down the line, if you change your reward function, bad things may happen. You cannot break the bank.

Unknown 2:03:28
So so let me see if I if I can simplify all of this in a sentence. So if you agree with it, so we need to understand the nature of AI in order to understand ourselves.

Joscha Bach 2:03:42
So Well, I would say that AI is the field that took up the slack after psychology failed. As a science, psychology got terrified of overfitting. So it stopped making theories of the mind as a whole, it restricted itself to series with very many very few free parameters, so it could test them. And even though strategy didn't replicate, as we know now, so after PhD is psychology largely didn't go anywhere. In my perspective, it might be too harsh because I see it from the outside. And outsiders of I might also argued that AI didn't go very far. And as an insider, I'm more partial here. And maybe my I have too much bias and give it too much credit. But to me most of the things I've learned by looking at the world through this lens of seeing us as information processing systems.

Unknown 2:04:30
So you agree with the statement summary that I made? Yeah. Okay. Because I have this metaphor that I use every once in a while saying that technology is a magnifying mirror. It doesn't have an essence of its own, but it reflects the essence that we put in it. And of course, it's not a perfect image because it magnifies it amplifies things. So I think it's it's a call it's it's a it's Those could be mutually supportive, right? Because you're saying, we need to understand the nature of AI to understand who we are. And I like that very much actually.

Joscha Bach 2:05:10
Yeah, but just the practice of AI is 90 degree, it's automating statistics, and better making better statistics that run automatically on machines. And it just so happens that this thing is largely who extensional there's what mines do. And it also, just so happens that AI was largely founded as a discipline by people like Minsky to understand the nature of our minds, because they had fundamental questions about our relationships to reality,

Unknown 2:05:39
right? And what's the last 10%? Of what added in statistics, you said, it's 90% statistics, what's the rest?

Joscha Bach 2:05:49
Oh, the rest is people coming up with dreams about our relationship to reality, using the concepts that we develop an AI. Right, so we identify models of things that you can apply in other fields, it's the deeper insights that we actually go for. But most of the what we do in AI is about applications. It's about utility down the line. But there are these things, by the really do it. The thing that Fineman said that make physics like sex also makes AI like sex. Sometimes something useful comes from it a new better way to make self driving cars, or play Jeopardy or help people in many circumstances in their life or to make better agents running on your phone. But it's not why we do it. We want to understand how we work.

Unknown 2:06:36
Right. And that's a brilliant place to end our conversation. Because I feel the same way about philosophy, by the way, that, you know, it's just like Fineman felt about physics and you feel about a I feel the same way about philosophy. And

Joscha Bach 2:06:53
so these remaining 10% are innovative philosophy. But in like all of these fields, most of the practitioners are trained in the main methodology of the field. So our philosophy tends to be bad. Yeah. And I think my job is to try to make it slightly better to the degree that I can.

Unknown 2:07:10
And that does that mean by extension that, of course, most physics then would be bad, and most AI then will be bad because they fall within that 90%.

Joscha Bach 2:07:19
No, no, I think the AI as if practice, practical thing can be very good, right? Most physicists are not concerned with foundational physics was the nature of the universe. Most physicists are concerned with material science, or many, many other extremely practical things. It's only a very small minority that worries about the deepest things. And the same thing happens in AI or neuroscience. And it's not that there anybody is to blame for doing development things. It's actually very good that a lot of people are willing to put up with development things and take down the garbage.

Unknown 2:07:53
Right. And I'm grateful to them to them. It's just I can't do that myself somehow. I think as you put that, I would probably go extinct.

Joscha Bach 2:08:02
Yeah. And it's not a source of pride and Ave it's the recognition of a disability.

Unknown 2:08:08
Exactly. It's a bug. Yeah.

Joscha Bach 2:08:11
But it is. It's marginally useful, because society needs a few of us. So it does. I mean, you're still here.

Unknown 2:08:20
We're here, but it's a struggle sometimes.

Joscha Bach 2:08:23
Yeah. But it's it's our choice how much we struggle because objectively, we are here. And the coffee is good.

Unknown 2:08:29
Thank you for reminding me that and I love the coffee. I'm a coffee fanatic. I Yeah, that's a whole other story, but I am a coffee fanatic. jasha Beck, thank you so much for spending over two hours with us today. I'm looking forward to our next conversation and I wish you the very best while the party is lasting.

Joscha Bach 2:08:50
Likewise, it was such a great conversation. Thank you for this time we spent together.

Unknown 2:09:05
If you guys enjoy this show, you can help me make it better in a couple of ways. You can go and write the review on iTunes or you can simply make a donation

This transcript was generated by https://otter.ai