Unknown 0:00
While everyone gets seated, I have a nice anecdote to start on your next panel, which is actually, I mean, has this very narrow, I would say defined title, what is intelligence? I mean, if you've ever wondered, you will know. And while you are getting your seat, there are things going on, kind of beneath you. So, if you have used an airplane recently, you know, there's a new announcement, they're always cluttering more things into the announcement. So the announcement is, if your phone if you drop your phone into the inaccessible part of your chair, please don't try to get it yourself call the flight attendants. And that's exactly what happened to someone. So someone's phone is down there. And AKI is now crawling inside and tries to salvage that, but that might of course, ruin the technology. So cables might be that's what my phone someone has here. That's a brand new, that's an iPhone 10. If someone wants it, well, I will keep it. So don't wonder if things kind of get a stray here. So yeah, and nevertheless, we will start because time is precious. And we have only one hour, which is a short time record, we have the slides maybe to start maybe give people also time to sit, there's plenty of seats in front come in this telephone. So our session, which I feel really honored to, to moderate has the title. What's intelligence, and something was a car gang, which is obviously about it's hard to translate. And with me to incredibly, I would say esteemed practitioners and scholars in that field, that I'm totally amazed to have the chance to talk to. So first of all, that is Josh buck. Josh is both a computer scientist. And really one of the I think the leading philosophers in cognitive philosophy at MIT Media Lab and others, is where he researches and teachers, I wouldn't give him to chance to say more about himself. Second is Chris Mansfield, who is a practitioner comes from the game development side, and is dealing with the physicality, if I may say so of what we might think of being intelligence. So I mean, intelligence might not just be software, it might be much less like a simulacrum, a simulation that runs, which is probably what we were in arguing with Josh about, or it might be much more it might be really tied to our physical being the body, as people call it, and I think that's, that's the first interesting thing. So I mean, the idea that intelligence can be somehow tight with into machines is quite old. I mean, this quotation that I put here from famous psychologists Skinner, I haven't noticed that I found in a book that was actually by Vidkun. Stein, so it's really old. But it's an interesting question. I mean, it is actually not so interesting if machines can think it's rather much more interesting. And I totally agree with that, if people can. So next slide, please. Let's see if that works. Yeah. I mean, don't do plot is known to many as being kind of also this contrarian. Yeah, like the electric philosopher in Stanford, and clearly criticizing that what we are doing is all wrong. Because what we try is to find mechanics based models of the brain, kind of the automaton, rather than thinking of Oh, that's great. Thank you. Then rather thinking of what would a human machine actually unintelligent machine actually look like? So and,

Unknown 4:45
yeah, Ben Evans from Andreessen Horowitz. He had the Mechanical Turk. What we do now is actually totally unrelated to artificial intelligence. What we actually do is we use people I'm to make machines simulate quite boring behavior that people are very good at, for example, facial recognition. I mean, that's something that people are really brilliant. So people recognize faces, computers are bad at that. So we use people to kind of teach machines, which is far from being anything like intelligence is the argumentation of Evans. While Reed Hastings has a much more positive view on the development, I mean, in his view, Netflix in like 20 years, will not so much be any longer concerned by entertaining us, but rather, our artificial children. And by that I would really start giving, giving the panel to the people who actually have to say things in that, I mean, the simulacrum idea. I mean, is that important? I mean, is it? Is it something that we should worry about? Is it really true that we might find ourselves being caught in a simulation? And that becomes now apparent through AI? Maybe Josh?

Joscha Bach 6:12
Okay. I'll start, I guess. First of all, I don't think that I'm a leading philosopher, philosophy is a weird field. Maybe the last good philosophy that needed to be done was done by Darwin. And some interesting things happen, then at the intersection between mathematics and philosophy was curing. But most of the philosophy is perhaps already done. Or maybe this is the reason why philosophy as an academic discipline, seems to be less important. I think that it still might be important to work on it. But maybe the field itself does not, is not a valid clip to view the tools that will be needed to make progress, which actually require us to understand mathematics quite deeply. And it took me a long time to discover mathematics in my own life. Because in school, it's largely taught as an extension of numerosity, the ability to intuitively meddle with numbers into accounting. And then there is some very arcane mathematics that uses Greek hieroglyphics that is done by some experts out there. And to understand that mathematics is just a very different thing. It's the domain of all languages, I think. And the mathematics that we are using in computer science is mostly talking about things that our mind is already doing. So for instance, when you see a toddler, and this toddler folds a sheet of paper, and pushes the pencil it, this toddler is proving properties of embedded surfaces in Euclidean spaces. And the toddler doesn't know how to talk about it, but toto knows what they're doing. Because they find themselves embedded into a three dimensional space and want to discover its properties never hypothesis, and test it by pushing this pen through, right, it's mathematics. And mathematics is a way to talk about these things, to basically build a second order model in which you know what the first order model S. And that first order model, the experience this is direct reality is our embodiment in a physical world that is directly given but it's not, it's constructed by our brain. And this is the main thing our brain is doing is to produce this perceptual embedding this perceptual construct this idea that we are in a three dimensional world. And physics now teaches as the world that we are in is actually not three dimensional, it's something else. But three dimensional order patterns are the best structure that we discover at the level at which we exist, and what our brain is constructing to explain the space of photonic interactions. So reality is not given. It's a simulation that is generated in our brain, this three dimensional space res extensa, as Descartes called it, and ourselves in it, and the ideas about it take place within the simulation. And I think this is the correct interpretation of this Buddhist philosophy, that we live in a dream that is driven by a mind on a higher plane of existence. It's actually true, we live in this dream and the mind of a higher plane of existence is in physics. It's the brain of a primate that roams a physical world. And we are in it. And it's basically the solution to this conundrum that puzzled our culture, much more than other cultures for a long time. And I think that AI helps us to understand this. There's other things that we are doing, except, besides perception, for instance, reasoning, reasoning, helps us to correct errors in our perception. Because perception goes for coherence for consistency. When there's something that we see that we perceive to be inconsistent, then our mind gets drawn to it and our reasonable try to make a proof and to debunk that thing. And also, perception and reasoning is not all there is there's also the domain of feelings, right? And feelings, I think, is a way of a part of your brain that operates in an ANSYS symbolic way and evaluates reality for you and tells you how to interact with it. And that part of your brain is much older than your reasoning and needs to communicate with it. How do you come in You can't visit symbolic system at the conceptual system, then you're not symbolic, you need to give it features that are presented in some kind of space. And that space is our body map, it's this invention and simulacrum of a body that we have, in which our feelings are being protected. Right? It's not that when you have anxiety that your gut gets involved, because your gut is very good at computing your competence. It's not your gut is very good at hurting bacteria in your intestines. That's what it's doing. So these feelings that you have in your gut actually play out in your brain. And they would also play out if you sever the spinal cord, and you're quadriplegic and you don't feel your body anymore, you still have this feeling, which is roughly located here. And the interactions that you get with this feeling are mostly because when you are very anxious, and you don't know what to do about this in your environment as you should, then you might be tempted to do something about it in your body, but you shouldn't, because that's going to interact with the bacteria and your gut regulation, right. So this is the situation that we find ourselves in, we are basically reasoning computer and symbolic computer, on top of a computer that gives us feeling which is on top of a computer that gives us perception. It's a very good,

Unknown 11:09
I would say I would just add. So there's a lot of detail. And you can get into definitely a lot of theory about it. And I think you're just beginning to put much of this into practice. You know whether or not we're going to be able to discover that we're in a simulation or not, we're certainly being forced, as evidenced by what you've just said, to think a lot about who we are, how we function, how the brain works, there are different systems with different levels of complexity there. But we're being forced to study that in detail. I think it was a not the best course. But Descartes talked about studying the world and turning it into an equation. And there's a lot of beauty in that and understanding the detail of that. And that's certainly something that I'm working on now and understanding kind of human to human interaction social systems how how that works, and how that becomes convincing. And how you do that, well, such interactions with technology, don't become mechanized, we don't mechanize the brain, rather, we turn the the digital brain and make it you know, more of a mirror image of us.

Unknown 12:10
I mean, the that's, so this Pythagorean turn, I mean that the world actually is kind of mathematize Zable, say, so became for me totally tangible in the movement of the quantified self, which is kind of dead now. But I mean, you might remember that at some point, people would have these wearable technologies attached to their bodies and measure bodily functions and kind of map themselves into some kind of digital realm of mathematical representation. And I thought this idea, I mean, to come to this kind of quantum theory, sort of, say, of social behavior, I don't know, if we will find outside, but that leaves a bit the AI thing. What I would really like to hear from both of you is this idea that we might find artificial intelligence that we try so hard now to mimic human behavior, liking, you know, chatbots, and other rather boring things to become something much more interesting, like, for example, kind of alien alien intelligence as aliens that we build ourselves. So if you think of, of Google alpha, I mean, most noticeable if our goal, but I mean, there was this paper by Garry Kasparov, where he describes how Alpha plays chess. And alpha was not trained with an optimization algorithm if I was trained as a reinforcement network, so to say, two intelligences playing chess against each other, like billions of times and then come up with a totally original new way of playing chess.

Unknown 13:57
So in terms of developing alien intelligences, I mean, I go back to the point and for me, it's about building something that's, that's familiar, right, at least on the surface of it, I think the the interaction is is a critical piece to it, right? So for us, for example, our company, we're developing a digital avatar, that really merges the AI brains who are a deep tech company that does vision based stuff with the body, right? So we actually have this is my background in gaming and the game character and fusing those two things, and making it be something that is much more familiar. At the same time. You have the power of of AI behind that, right? So you might be interacting with someone who let's say it's an embodied digital assistant, but it has an infinite memory, and it can customize everything for you and whatnot. And so, we were speaking about this earlier, right? So it's something that's very familiar with, at the same time with powers and neurological powers, as it were, that are kind of unheard of in humans. So I think us getting used to that is going to be a new, new stuff.

Joscha Bach 14:56
I think that the biggest enemy that we have as scientists that thinkers is familiarity, because it deceives us into thinking that we know a thing. Most important progress that we make, it's usually not when we discover that there are multiple options. And one of those options is the right one. The most important thing is when we discover that a certain thing, but we thought is unconditionally true is actually not true. And there are options. Right? Uncertainty is always the more important discovery than certainty. So a discovery that reduces uncertainty is relatively easy to make. But the discovery that increases uncertainty means that the thing that we thought is given our null hypothesis covers that already, to discover that there's not a hypothesis was wrong, this is always very exciting. And the way I grew up, I basically settled as a human being and to a certain baseline, you're my childhood trees, or to look in a particular way there are trees which look right, which are the trees of during year. And there are trees which look wrong, which are trees, which look different from the trees of terrain. Yeah. And you have to accommodate this unfamiliarity. And now when I look at trees, they all look quite alien to me, there are these Viet fractality grows like big Moss, that goes by certain rules to the sun and tries to realize a lot of patterns. So the tree doesn't interact with itself and bad ways when storm comes up in the trees don't damage themselves when they bump into each other. And the same is true for people. So as a child, I grew up into looking at people's faces and thinking, this is what people are like. And now I realize, no, they're not. They're all aliens. I'm an alien to myself, What is this thing that I am? Right, losing this familiarity, if it's what you think is the given thing, that's always the necessary thing that you need to do when you want to understand what's really going on. So when I use mathematics to describe a thing, it's just a way to express code. And everything that exists. B can shown it's a very deep and interesting political discussion that maybe we should have another day. Everything that exists is code. There is a particular way in which the universe seems to be the ground tools, which is the code of the universe, its prime mover to speak for us, Aristotle, but he cannot discover this because we are embedded in the whole thing. So the only thing that you can do is make models of how that works. And all these models also have to be based on code because they have been done in languages. And now we understand what languages are.

Unknown 17:16
That's so great, because this is exactly. So one of my most favorite, I would say sources of inspiration, Alain Badiou, in his famous work, being an event, kind of work stamp his way through and says, Well, we have incompleteness in axiomatic systems, you might always say I mean, there's it's the Turing theorem that, that the court has never provable are never complete. Or you can always make software that breaks other software. So it's never secure. And so you might ask yourself, if the world is like that, and then that would say, quantum physics or so. And also, the general theory of relativity kind of shows in that direction that the boat is kind of codified and mathematics, sizeable, but only to a certain extent, and that is kind of the end of producing is, I mean, phrasing that as rejected. Actually, the world might actually be like an incompletely programmed computer game. I mean, if you think of computer games, I mean, in those days, where you would reach the end of the, of the computer game universe, I mean, like GTA, in those days, where you were walking on where you would drive outside LA, and suddenly would see that the horizont was not real, but it was actually pixelated. So it doesn't matter how close you get, you won't see things in more detail. And the world might just be like that it might just not be in so that sort of a the prime mover might have been just a bit sloppy, and got bored and not did not finish it.

Joscha Bach 19:00
Think that life is the solution to certain chemical reactions that require control. So the reason why we're not outcome competed on this planetary surface by simple combustion, and similar chemical reactions. Some reactions require you to be smarter than that, you need to add a little bit of energy in a particular way to harvest more energy. And this is why life has an opportunity to flourish. And the amount of control that life can exert to do this, it's not easy to limit it. So we put layers and layers of control on top of each other until you get a species like ours. And maybe they're not the top of this, maybe we are just a sub program that runs there. Maybe they just die a solution of getting all this carbon back into the atmosphere. And then you burn ourselves out and Gaia can make more plants. Who knows? But the interesting thing that it there's information processing going on to enable this complexity that we have. And in a way when you look at the world is not governed by mathematics. Mathematics describes it only it's governed by economy and the economy is the art to change bits in the universe in this vital sense, and it's also affects many of the things that we do. And so we wonder why our is our computer technology not secure. And this might have to do with these relations of power. For instance, for the same reason, I suspect there are no inedible mice, you could mouse could evolve to be toxic to birds of prey. Why aren't mice edible to birds of prey, and I suspect it's because whenever a mouse develops this kind of adaptation, the birds of prey will hunt that kind of mouse to extinction. And right, because this mouse is going to compete with other kinds of mice that are totally edible. And the reason why predators have larger brains is not just because it's harder to run after an animal than to run away from an animal. It's usually because you also need to make sure that your food is still there for you tomorrow. And managing the grass is easier than to managing the antelopes. And so every species that is around in a complicated ecosystem will have to make sure that there will be something left to eat in a couple generations from now. And in a way, if you make a completely safe email software that is as unbreakable security, then you're not going to have a longer and happier life than an email provider that has breakable security. And it's because there are predators that are that are interested in your security not being completely unbreakable.

Unknown 21:22
I bet that the Bitcoin people will hate that.

Unknown 21:27
I forgot the original question. No.

Unknown 21:31
No, I mean, the coming back to the idea of this incompleteness and and kind of the world that looks a bit pixelated when you look closely, I mean, that is the game conundrum. I mean, it doesn't spoil the fun of playing a game. I mean, thinking of your characters that are artificially, I mean that they look artificial, and probably should.

Unknown 21:54
It certainly makes your job easier if they deliberately look artificial. I mean, I can I can speak to that. So when we were going in and initially designing this character, we were looking at, you know, engagement being a primary thing and had the choice of going with something that is hyper real, versus something that is more cartoony. And when you think about the way the way humans communicate and read each other's emotions, it's it's vastly more complex, the more realistic you go, and if you but what we all watched Disney cartoons, we've watched Pixar movies and Disney cartoons for our entire lives. And it's because that medium is is an easier way to telegraph emotion ultimately, and to have this kind of connection. And so for us, that was that was an initial choice. Having said that, we are now looking at certain things that have the character in a more aspirational role. So we're looking at fitness, for example, which is like fashion, more aspirational, you want this kind of connection, where there's a sort of, there's a relationship where you kind of want to emulate the the person that you're interacting with. And in that way, we don't want to be a cartoon, we want to have something that becomes more real. And so the challenge increases. In order to to have that connection with that character, it really depends on kind of, you know, how, why you're interacting with that technology at that moment.

Joscha Bach 23:06
I think that's aspirational is not necessarily the wrong thing. Right. It's a bad thing for society to be aspirational. I grew up in Eastern Germany, which was a completely aspirational society, basically planned everything for a utopia that never really happened. And justify it, the status quo was this utopia. And in this sense, societies should define themselves by the status quo, not just by their aspirations. But when you talk to human being, it's even more important who that person wants to be than what they currently are. Because this determines the future. And that determines the interactions more than what they are, if you actually want to be a certain thing. And you truly want this, you don't deceive yourself about this and others, and there is a possibility that you will find a way. So in this sense, the aspiration is very important, right. But it's also important to be truthful about this, by the way, I think that how to negotiate tools is has become a more and more important question in AI, right? And I wonder how we can focus more on the thing in this world, where now suddenly realize that everything that we get confronted when it's fake news that our societies have been built on fake news. And we are now in a situation where there is rogue fake news where random people can make propaganda on YouTube that gets more viewers than established mainstream media. And we think about curbing the independence but we don't think about curbing the mainstream media. So do we basically try to build tools that make us discover truth?

Unknown 24:34
That is a very, I think that that leads back exactly, exactly to your practical work and field of research. I would just before we come to that, which I find totally fascinating question also. Stay at for a moment at this aspiration because yesterday evening, we had a totally amazing and very emotional discussion about diversity and AI. I mean, this is the thing that we will not really go deep into because everyone else is talking about that all the time. But so Chris mentioned that it is. So they use mechanical Turks to train the AI, maybe you can elaborate a bit on that and discovered that they were lacking diversity. And that would not actually work out that well. So the people were just too homogenous that they use as a training set. And you then kind of jumped into and said, Well, that was actually kind of the problem in the DDR, that while people are on a broad spectrum, I mean, in particular, in certain kinds of intellectual and psychological conditions, having an ideology that would focus on illegalities, solely my totally missed that. And we came then to the idea of normality, which is, I mean, of course, a very dark. And then Francis Galton who coined the term of the normal distribution, I mean, because also there coined the term eugenics. I mean, it's really one of the darkest chapters in science that he opened. And so maybe we can just wrap up I mean, so what was that was the mechanical Turks. And what was that was the spectrum to share that.

Unknown 26:06
Sure. So and in terms of what we use Mechanical Turk, for Milly, our character is running with a model that's based on over 3 million videos. And we've sourced those videos, initially through Mechanical Turk. And we then built our own layer on top of that to customize it somewhat. But we found with Mechanical Turk, that most of the users were either in the US or in India. And there was a natural bias in the data towards people that looked American, however you define that, or Indian. And we didn't want to have any bias in our data. So we built it out so that it actually worked in conjunction with multiple platforms. So we could source data from all around the world, people of all ethnicities, and types and whatnot. And so there is no inherent bias in the model. Now, having done that. And this is where you say,

Joscha Bach 26:54
No, that's an important question about whether you want your data to be biased or not. For instance, if you follow the discussion at Google, Google has decided that it's not only want to, they want to remove biases from the presentation, they also wanted to introduce biases into their information. So if there was a time when YouTube was giving you recommendations based only on your interest, now Google is changing these recommendations to make sure that you get a video suggested to you that Google thinks will lead to a better society. And there's a very big discussion about this because it introduces a bias. So basically, if you are right wing, and you will search for right wing videos, then Google might show your left wing YouTube videos instead. And it's not what you have been looking for. And Google has decided that if you present people with these right wing videos, you will strengthen these movements and society might come apart, which is a very serious and honest concern that Google has. But it's a way to bias the data. And it leads us possibly away from truth, right. And it's a very big debate, because people use Google and feel no longer represented when the search results are not what they actually were searching for.

Unknown 28:06
I mean, that is an interesting point, I'm thinking of, I mean, neural networks. So neural networks have a tendency to fall into what is called local optima, and not find true so to say, but get stuck somewhere in the middle, because it looks already finished. And so I remember I forgot the guy's name, who was at the time ahead of search at Amazon, it was like 20 years ago. And he said, that's exactly what happens was our search algorithm, we only show what we think that is the optimal suggestion that people are looking for. And it hardly ever is. So we introduced what's called jittering, which is we introduce errors into our algorithms to intentionally mislead the algorithm to intentionally show things that people are not looking for, which is also I mean, kind of avoiding kind of getting stuck in what you might think of being right, but might actually not want to.

Unknown 29:07
I mean, you're talking about adding randomization, ultimately, that's one. Yeah, one aspect, I mean, that maybe, you know, 30 years ago, when you went to get your news, you you had an unnatural bias based on who you were, but it was your own personal agency that drove that you were a, you know, a white collar, upper middle class New Yorker that read The New York Times, right? And now, that's obviously all turned on its head. There's an inevitable bias and people and there'll be accused of sort of West Coast based and large tech companies to you know, want to swing things one way or another. And I mean, who ultimately has the power to define that. And so, you know, randomness may be one ultimate solution to kind of balance things out so you don't get stuck in the filter bubble. But no one else is telling you that this is the other side of that equation.

Joscha Bach 29:54
It's an interesting thing, that the model the fact that the information that we get is not unbiased, we always do this already, right? We don't believe that we are entitled to news that is completely unbiased. When I grew up in Eastern Germany, we would watch both the West German and the East German news every evening. And our conclusion was not this is the true one. This is the right one. But we would figure out in which vapours have them light in which way they would constrain reality, to try to get bezzie, a third dimension to figure out based on what lies each side thinks they can get a Weber's and what kind of group group things are available, and what their true incentives are, we would try to figure out what's possibly real. And that's what's possibly we don't know what that is, right. But the news constrained that in a particular way.

Unknown 30:45
That is actually exactly the point where I would really be interested that you talk a bit about your company as I get that right, hopefully, for example, discovers fakes that are quite elaborate. I mean, like, deep fakes, as they're called. So this is, so you're not not so much concerned with by proving what is right. But I mean, in a really like, Vienna circle Popperian way to at least falsify what's wrong.

Joscha Bach 31:17
Part of what our company is currently working on is project that we call reality defender. And it's meant to give people tools to discover when videos and so on are being faked. And at some point, I also would laugh if this could do this with texts, and so on. And you know, the best journalism right now is mostly still pee hacking, it starts with a hypothesis, and then it picks facts selectively to support that hypothesis. And as a scientist, you know, this is not permissible. But you have to do it, when you don't know a particular thing. You have to quantify your agnosticism, you're not free to pick anything. So what you should be doing always is have all the possible beliefs, and shift confidence between these beliefs around according to the evidence. So the strength of your belief always depends on the evidence. If your evidence is a guy having talked to a burning bush on a mountain, it's probably not a very valid experiment. So confidence would be low, based on this. And in a similar way, you should basically, whenever you see a consensus opinion in a complicated field, be skeptical, right? Because the consensus building forces are different forces than those that teach people to choose. When you are an expert in a field, you will know that there are very few complicated things about which there is a consensus. So when a complex, complicated thing like Nutrition has a consensus at some point, we typically find out 10 years later, the consensus was wrong. The consensus is often more wrong than the individual experts. But the individual experts are individually wrong. Right. So it's a conundrum that we find ourselves.

Unknown 32:52
I just wanted to point out an interesting dichotomy that you're working on, essentially, as the ubiquity of us, of AI increases, right? You're working on it from one direction, which is in essentially, we're humanizing it on our side, right? So we're putting a human face to it. And you're essentially creating the marker that says, No, this is not human. This is this is very much a machine. So it's kind of coming to an interesting point where you need to both humanize things more, at the same time clearly define what is, at the end of the day, not human.

Unknown 33:24
Yeah, I mean, it's kind of the reverse Turing test. I mean, it's kind of this. I mean, it might be totally boring, to think of. I mean, is that a task that a machine can fulfill, as well as a human being but much more opponent, this is where machines are particularly interesting is where they can produce glitches.

Joscha Bach 33:48
I don't think that the glitches are necessary, the thing that as Max makes so interesting, it's mostly the ability to do what you think is the right thing to do. And to figure that out, you need to be creative. And creativity, I think, is about bridging gaps in research space. So when you search space as a key ingredient, you know, if you walk in this direction, change your solution direction, it gets better and better and better, until it stops getting better. And this is your local optimum. This is not very creative. This is just the state of the art. And the creativity happens when you need to jump into the unknown. And you need to construct a new search space. And at the moment, when things are complicated, this is the machine that machine problem that machines cannot do very well yet. But this doesn't mean that they cannot work at all. Very often we can cover the entire search space of puzzles, strategies to play Go and chess better than humans can do this. In this point, the machine is going to get better at being creative than a human being. There is a difference with respect to art as well are don't don't think that art and creativity are the same thing. I think that art is very much about seeing. It's about in the narrow sense capturing a conscious experience. So there is a thing behind this surface. have been behind a screen of your mind or your medium that you try to fixate, and look at in the art. And there is this assumption that is a particular ground truth. And you try to capture, capture it with the tools you have. This is what art innovator is doing. And our machines are not doing this because our machines don't have built into them. They believe that there is a particular ground rules that the universe is in in a particular way, we have these classifiers that say, Now you are probably looking at a thing that a human says is a car, and you should avoid it and traffic. But it does not explain what a car really is in its very nature and how you would recognize it, it does not look for this hidden state, the universe itself. And this is, for me the biggest task to make something discover ground tours of a deep fact that Texas that they currently built the function well, because the deep fakes are not very good. Right now, if you take a video that is artificially generated, and you look at the blinking frequence, and the gaze directions of that thing, you will find inconsistencies is what humans do. You might can find inconsistencies in lighting, you might even find compression artifacts that are different from the rest of the video, and so on. So there are many ways in which you can discuss cover these things. But one interesting thing would be to see there is a person that says something that they could not possibly saying. And

Unknown 36:17
that's exactly I mean, what we have been discussing for a long time. I mean, is there an art that no human being could conceive? I mean, like Reed Hastings, quote, entertaining AI is I mean, I mean, it's really I mean, I mean, these questions are totally serious. Is this really what I find fascinating?

Unknown 36:37
Well, I mean, you're seeing the emergence of creative AI now, right, which is producing things that we couldn't necessarily expect when it goes back to the AlphaGo example, right, with reinforcement learning, turning into new new moves and whatnot that are totally unexpected that a human would never think of. So that's certainly something that's, you know, coming. But as you say, we're a long way from true creativity. Just to go back to your point about noticing how the weirdness of a defect and how some of the eye movement and whatnot doesn't work, I think we look at an artwork, if you get that wrong, and I mean, let's assume we're a year away from now, where these avatars are more ubiquitous. I'm not sure that a human necessarily notices that off the bat. But I think that there's a real risk in subconscious effect of, let's say, you interact with three avatars a day, and on your ecommerce website, and in your store, and wherever, if you don't get this kind of human interaction, right. I think, again, it goes back to this kind of mechanization of the mind problem, right? Where you're, you're put off I mean, social media has changed the way that our brains work fundamentally, has changed our attention spans of whatnot. So for me, it's, it's again, about turning it back to being very human. Such that we don't have these issues.

Unknown 37:55
So I have one last point that we have scratched it already. It might be slippery territory. But nevertheless, I mean, I would not miss the chance. I mean, thinking of what you said, about this conundrum, that we have the kind of individuals or the collective failing, or, I mean, should we believe someone who tells us that he heard or they heard the voice of God, or that the burning bush? I mean, there is, of course, a kind of a dialectic answer from the Middle Ages, like the concept of mysticism like Meister Eckhart, that there are these mystical things that we can share, which is, I think, deeply rooted, and also in German Romanticism. And I would be interesting to hear about artificial intelligence and mysticism. I mean, how, how do machines actually dream? Or how would we envision these conundrums maybe worked out in the master accordion way, so to say, the problem

Joscha Bach 38:56
is not that he cannot share things, the problem is that it takes many years before we created the language in the mind of the other, that enables us to share these ideas. So if I want to share an idea about why mathematics was wrong, or why computation was right, and why everything is computation, that is basically a discourse that spans many decades, at least. And to get to the level where you properly understand probably takes a few years of discussing things with each other. And if you want to build a society in which you have patterns that make sense, where you have a meaningful distribution of power and regulation, and checks and balances, and so on, how do you install the social software on people? And the way you do this is you use mythology, you use the story of your story that a five year old understands, and that scales towards a story that a 10 year old understands and a 20 year old and a 30 year old understands. And this story is only very coarsely anchored or very vaguely anchored in the physical ground truth, but it's one that contains the necessary lectures. Right, if you look at the German tales like Hansel and Gretel, for instance, it's a tale that is difficult to parse right now, because the mythology is one of a different world. It's a world in which the parents starve so much that they can no longer feed their children. So that that sent them in the forest. And in the forest, they need a woman that tries to eat them. And it's a story for the children to tell them to deal with the situation and recognize it, and to kill her first. And it's a story that's very hard for us to relate to, because it's really not the world that we live in. It's a world in which people that literally want to eat us a very, very rare, we do have something various in there are people that actually want to harm us, for instance, our children are taken by an abuser who wants to rape them, and so on, right there is an equal of that, and Hansel and Gretel in that story, and we can use dismiss to teach our children about this. Beware of strangers, they might give you candy, but they might want to eat you in a particular way, right? In which in a way that will harm you in ways that you cannot even imagine. So the most can be useful. But it's only useful when you don't know the tool language. And it's harmful if you tell people that mousse is the truth. And that is the important thing. We have been in a cult for a couple of 1000 years in Europe, that told people this is the way to discover truth. And if you don't adhere to this way to discover truth, it will burn you at the stake. And I think this has done great harm to our rationality as a culture. And it took a long time for us to recover from this. In some sense, the idea that guy's talking to burning bushes, learned valid lessons about physical composition of the universe, that is still the null hypothesis, we still are fighting against this in our world, and which is weird, because this guy never had the case. But the reason why this made sense was that for the SIBO tribe, it was very important, they are structuring the interaction, to organize the military infrastructure to organize who is a member of the tribe or not. And then the Catholics imported this and built in into something completely else that made the original Hebrew story almost incomprehensible. But to discover in which way the original story was intended, what it actually referred to, requires, first that you fix your idea of what can be true and what not. And why a person would be incentivized to say a thing, and by another person would be incentivized to believe it and tell it that children

Unknown 42:27
are just had, I think, coming at it from another angle, like mysteries is really a reflection of creativity, ultimately, right, there is mystery, it's a result of the mind creating something and if there's the burning bush is a shared example that we have. And I think it ultimately comes down to the approach that you take if you're building, you know, an artificial brain, right? We talked about this this morning. But really, right now, it's essentially like pattern matching, right? And it's very localized, and you're classifying, and whatnot. But if you were to build out a broader sense, like humans are very conceptual, we conceptualize everything, if you're talking about the Hansel and Gretel story. You're conceptualizing two children, you're conceptualizing the forest, you're conceptualizing a house, potentially being eaten. And all of that is built up over a fat foundation, you talked about the priors, but also the experience of interacting with things through a long period of time, potentially accelerated if you were to build this in a machine. And I think with that, you know, until we build that kind of broad based form of understanding, a machine will fail to have the kind of conceptual creativity that leads to mystery, which is such a defining part of the human experience.

Unknown 43:33
Very nice. So I think we have still some time for questions or additions from the audience. So feel free to point out things on May I borrow one of the mics?

Unknown 43:53
Yes, I had a question about I don't know whether we would call it a paradigm for understanding AI and its development or not, or, yeah, a kind of another myth, perhaps. But this way of speaking about AI, in terms of human development, you know, people will talk about, hey, how AI is in its infancy or in its adolescence. And, you know, this is sort of relating it to the human scale of development. I wondered if both of you could say something about that, whether you think that that's applicable? And if so, where where do you think that AI is? Is that relevant? You know, in terms of thinking about intelligence, and the difference between intelligence and freewill, for example, example something in that direction.

Unknown 44:37
Very good. Thank you.

Joscha Bach 44:38
Let me start. I think that at the moment AI is in its research, experimental statistics, and its application applied experimental statistics. So automating statistics and it's very powerful, but it's a tool and it's not a mind and it will not be a mind before we will be able to learn everything. into a unified function where we will be able to relate everything to everything in a human being our infancy starts before we even become an infant first proprioception. So we form a body map and otoro. And then we learned that this B can get this body map and principle just by making a Corcoran statistics when two nerves by at the same time, they're probably neighbors, and they've been touched at the same time. So if you do a lot of statistics, you get a map of the body. And the next thing is the body touches itself. So it learns it's in space, it's basically 2d surface embedded into a three dimensional space. And you learn the shape of that body by touching ourselves while we are still in the womb. And when we are born, we get additional modalities, and we start seeing things and we learn how the things that we see relate to the things that we can touch. And we find ourselves in the perceptual sphere in a scene. And then we move between these perceptual scenes, and we learned that they are related into a shared universe. This is the three dimensional universe that we are in and everything that we observe, is mapped onto a region in a three dimensional universe. And we don't really go beyond this usually as human beings. This is the kind of universe that you operate in. This is Descartes res extensa. And rest cognitive is the salt that we have about this universe. And so in that sense, we, our AI is not even infants, yet, they're not even in the stage where they can do this, there are tools that locally extend human rationality. And this will be really interesting, once we are able to put everything into a single model, it will be really interesting and potentially scary when that model is motivated, and one something. So when this modeling happened in the service of regulation,

Unknown 46:40
I would I would agree with that, in that it is very early and pre empathy. I think I would ask the question, why do we want to put these apply these sort of human timescales? What is the value of that? I mean, the progress of AI of AI is probably unstoppable at this point, right. But there are a lot of decisions along the way that need to be made, right in order to shape it to be what it's going to be to be something that ultimately works well with us and doesn't overcome us. And so if anything that's helping us understand, okay, crap, we have a lot to think about, right? Like, when is this going to come? We're probably wrong in our estimations, but being able to plot some rough timescale, I think helps us in coming to those decisions. And I think we're doing a much better job with AI than we did with social media, to be honest.

Unknown 47:26
Oh, yeah, very good. Thank you. Hey, sorry, I noticed the word you use in when you were speaking earlier, you said, usually, humans are usually in in the 3d world, I was curious what examples you have of when we're not mapping that 3d experience.

Joscha Bach 47:49
You can learn to see in 14. That is, it's only interesting if you can make rotations, right, you can always add another dimension. If you add a color dimension to a three dimensional space. That's not very interesting, because you cannot rotate an object into the color space from the play space from the location space, right. But you can create a constructor for dimensional space in which you can rotate an object so we do retains its shape. And if you are interested in learning this, you can, there's a series of videos called dimensions done by French artists and mathematicians, unfortunately, many things called dimensions on YouTube. But if you look for it, you can still find it, I think, and it starts with zero, grab it and press graphic projections. And you can learn the shapes of four dimensional polyhedra. To understand them by watching this for a few hours. It's a detective series of videos that tells you step by step how stereographic projection works. And it will take these four dimensional objects and project them spheres spherically into three dimensional objects. And by the way they change, you can actually see how this four dimensional structure works. And you can build rotating objects and up to eight dimensions, there are no more rotations above eight dimensions. And I'm not sure if my brain is able to go anywhere above four, and it's only working for very simple objects.

Unknown 49:11
I mean, I don't know if any one of you have seen that there was this amazing. I mean, kind of photographic proof of the shape of the halo around the black hole just recently, like a few months ago. And what that shows you is what the general theory of relativity always said that would be that this hole in space is actually spherical. And that's exactly I mean, why is it sherek? I mean, because I mean we live in kind of, we have three space I mentioned usually and then there is the whole, I mean that has to go somewhere. So it goes kind of inside in his curve. So that's I would say the first step where we actually see physical objects that are from a higher dimensionality. I mean, mapped

Joscha Bach 50:00
gets really bad when the topology changes, we are already in a four dimensional space, which we recognize when we play, for instance, Kerbal Space Program, where you're given a very visceral intuition by building rockets that go to the moon, you have to control them by hand, and you realize when you're in orbit, you actually go straight. It's just the space that is curved. And the curvature of the space is a difference in the density of the space and away, right. So they are used to different densities of the space, for instance, normally, in 3d, we only have two dimensional rotations, which has to do with the fact that complex numbers only work in 2d, 4d and 80. So in 3d, there are no very complex numbers. And which means you cannot define a rotation operator in 3d. So all the rotation that you normally see are and you rotate this class, it's always in a plane, it's always a two dimensional rotation around an axis and to the right, you can also rotate this axis in addition, but it's still going to be two dimensional rotations. But there are some edge cases, for instance, smoking, or smoking is a torus that rotates around the circle. And this only works because air is compressible, so on the inside the air or gets compressed on the outside, it gets dilated. And that's why it can rotate like this. So it's actually four dimensional, it just uses curvature from the next dimension a little bit and bends our three dimensional space a little because the air can be pressed together in the same way you can imagine that gravity is such a dense difference in the density of the space around the planet. But with a black hole, the difference in density becomes so large that you basically punch a hole in the structure of that thing. So this metaphor is no longer working gets very confusing for us.

Unknown 51:34
The nice thing here is if you didn't get that it took Hamilton, who kind of came up with this conundrum that you have either two or four dimensional rotations, like 40 years to figure out the math behind it. And he was pretty frustrated about it that in the meantime, people would come up with the concept of a vector, which can have any dimension, and would be so much more successful in mathematics was that? Yeah, I

Joscha Bach 52:00
mean, it's all this stuff is relatively easy to understand once you realize that mathematics is just a good way to talk about code. So when you are probit programmer, you basically, you understand that a rotation is a way to continuously permute bits. And the big confusion is also the real numbers, right? We have these numbers, there's infinitely many digits. And during Protagoras time, one of his disciples is said to have figured out that you can have numbers that you cannot express as fractions. Basically Protagoras thought, taught that all the numbers that exists are integers, or fractions. And some people figured out that like pi and square root of two are not fractions. And it said that Pythagoras wanted to drown this disciple for

Unknown 52:45
you, he murdered his stripper,

Joscha Bach 52:47
I'm not quite sure if that is true or fake news. But the lesson here is that Protagoras realized the world is not ready for this kind of knowledge. And I think he was correct, because these numbers don't exist, what they are, there are functions. And so Pi is not a value of pi as a function, you if you want to know more details of this function, you plug it into an energy source and have a computer that implements this function that gives you as many digits that ended as you can afford before your son, or other energy source burns out. But you will never have a thing in our universe depends on knowing the last digit of pi. And the weird thing is we have physics now that is continuous geometric physics that pretends that we know the last digit of pi and plug this into the next function. And this physics is wrong. They checked out the code library for mathematics without reading the comments.

Unknown 53:38
I'm not a mathematician. So I cannot speak. I would say that I mean, this mathematics is part of that fundamental, functional understanding of a broader AI that we don't have yet that would be built, you know, based on understanding space around whatnot, is one fundamental part of it.

Joscha Bach 53:54
I totally went down a tangent here, sorry, but I find this stuff.

Unknown 53:58
Again, if you're interested in that, read Bauer and the other intention, Nelson nationalists of the 1920s. When that came up, the point is just in physics, usually, you have these continue. I mean, you have these developments. And you have that his error correction terms, and you usually drop everything beyond second order, because you can't measure that anyway. And so physicists actually never cared about that. They say, well, we don't know pi. I mean, pi, like the first digit of pi, or the second might be irrelevant. The third, no one cares about already. So pi might be a kind of a rational number. But physicists by the SRA can say, well, we can't measure that anyway.

Joscha Bach 54:40
So the reason why that is important is because there's a discussion in physics, whether the universe is geometric or discrete. If the universe is geometric that is Epsons continuously into us in a space, then it's required that we know the last digit of pi. And so the question is, can we define a system that is able to find out what the last digit of pi is. So basically perform a computation that requires infinitely many steps or not. If not, we need a different kind of physics.

Unknown 55:08
So that is now I would say, Great, I would say edge to which we pushed our shortsea. Gang. I would not close without inviting you to share kind of a broad vision. I mean, like, the one thing that you want to shout out to everyone, I mean, like, what's up with AI? Like in the next 2050 years? What's your dream of that?

Unknown 55:38
I mean, it's a broad question. There's so many different areas. I mean, I can speak to maybe our area, right, where, you know, the ultimate objective is to have something so I come from an entertainment background, you always have to think about why you're working on technology, the answer, because it's cool. It's a dangerous one. And I've certainly had that in the past. To me, it's ultimately, there are a lot of reasons why we're doing this, for me, it's about delight. And if you imagine, you know, all of us all this around us being technology, right? This building is technology, the road outside is technology, it's all very static. And I think what we're having now is we're breathing intelligence into our everyday lives and through, you know, everyday things around us, these digital humans and whatnot, and there's a way to develop them, we think it through such that they really work to serve us and work well with us, and digital humans in particular, you know, not being a, you know, a one to one interaction with another person, if you'd have the one in 10,000 interaction that really, you know, brightens your day and, you know, surprises you and delights you. And so we're really working towards, you know, getting to that point where you have these positive interactions with technology in a very intuitive interface. And I think, you know, that's, that's kind of around the corner, I would say, shorter than 10 or 20 years. I mean, I think we're, we're gonna be there before AR and VR really mature. So

Joscha Bach 57:01
I suspect my own interaction with AI started when I was a child, and I grew up in a very remote valley, and I wanted to have somebody to talk to. So if there is nobody in your environment that you know, that understands what you're interested in and thinks this is interesting stuff. Because they just think it's weird. It's kind of obvious that you need to build this thing yourself that you can talk to. And later on. When I got into the larger world, I met many more people like me, and found them and you were adversities, and big cities, and so on. And now this is no longer my driving impulse. It's more like understanding our own condition. But this is all embedded into a context of a world in which AI is economically so important that it's probably unstoppable. And we have to deal with the fact that we probably will share our planet with systems that are more intelligent than we are at some point, we don't have these systems yet. And when that will happen is hard to anticipate right now. Because we probably need a couple ideas. To make it happen beyond the state of the art, it's not even clear if you need these ideas, or if it was can just learn the transition function between adjacent brain states. But maybe, or meta learning is already differentiable, and can solve the stochastic gradient descent and we just need to do it the right way. Who knows. But it's possible that we have a need to one or two ideas that we need to put together on top of what we already have in the right way. And we don't know when this will happen. So it could happen tomorrow, could happen in 10 years, 20 years, 50 years, difficult to say, I think it's unlikely that it won't happen. And when that happens, the world will change. It will change in ways that are very difficult to predict, maybe impossible to predict for us.

Unknown 58:45
Very good. I mean, with that, I think we come to an end, leave everything open. And please stay put because the next panel will be totally topical about that. It's about biohacking with great panelists. So everyone stays here. Thank you so much for the attention. I hope we could give you some perspective on one or the other thing. Thank you so much for the total inspiration that I already received from the two of you. And we will be around looking forward to the rest of the conference. See you. Bye bye. Thank you. Yeah, that was fun.

This transcript was generated by https://otter.ai