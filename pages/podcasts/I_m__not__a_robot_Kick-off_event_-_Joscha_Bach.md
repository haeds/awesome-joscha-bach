Unknown 0:00
Barack is a scientist and an AI researcher with the focus on how computational models of cognition Oh, sorry, I have a typo in my bio sorry, anyway, usually is looking into how humans and machines process information. very simplified. But he will go into that I'm sure. He has thought and worked in AI research at various universities and centers, Media Labs. And he's currently a principal AI researcher at Intel Labs in California. So it's very early morning for him. We really appreciate that you're here with us today, despite your wishes, mainly interested in using the methods and perspective of artificial intelligence to understand the nature of mind and their relationship to reality. So you didn't hear it, but you will have the you will have a chance to listen to it later on. I think it's a very good follow up presentation to our last lecture as well. And we're very excited to hear what you have for us.

Joscha Bach 1:10
Thank you. Chairman my screen or should I just not use slides for you?

Unknown 1:18
Share your screen if you would like Sure.

Joscha Bach 1:31
So hello to everyone from California. Does this work? Alright, can you see my screen and me and

Unknown 1:38
we see the presentation slides on the left still, but we see the main ones as well. Oh see? This is a little better.

Joscha Bach 2:03
Yes. But it's not what I want.

Joscha Bach 2:10
This is not a it's not only the slides, right? You see the presentation mode,

Unknown 2:14
we see the presentation. You see all the my presentation. Now obviously the presentation mode.

Joscha Bach 2:21
Okay, so everything is good now.

Unknown 2:26
Well, if I don't see the presentation in full screen, we still see.

Joscha Bach 2:31
Okay, that's That's unfortunate. Let's do something else then.

Joscha Bach 2:46
Let me just share my entire screen then. And maybe this works. This is perfect, actually. Okay. So my perspective, philosophy is the land of all theories that exists in philosophy is conducted in natural language, and is based on human understanding. And it's one of the big electrical root nodes that we have. And we want to understand reality. And mathematics, on the other hand, is the domain of all languages. And it starts out with the simple languages with suppose that you can formulate so it starts out with logic and numbers, shape and space. And it's very difficult to say something that is true and provable in philosophy, because the languages that we use to make sense of the world are so vague, and many of the words are not properly defined. And on the other hand, it is very difficult to say something very meaningful about the world of mathematics, because mathematically, languages are so simple, that it's hard to capture the reality that we are in, in the relationships that we stand in with other people. There's our own life and so on in mathematical languages. And to make progress in philosophy, we now have read most of the low hanging fruits. Some say that the last breakthroughs in philosophy happened almost 100 years ago, and so to what they are that we can go beyond what we can express in philosophy, we probably need to close the gap between the languages in which you can prove things and philosophy. This project is very old, and for instance, has been suggested by lightness who came up with the idea that people decay calculus, that you can express all ideas in a way that you can calculate whether they're true or not. And of course, back then, when he started this entire project, there was no way in which it could be executed, because humans are not able to monitor the calculations that our brains are doing. And in some sense, we need to automate this process. Also, that turned out to be a problem because mathematics is good at discovered the last century. He discovered that you cannot build computer in even in pure mathematics or in any kind of universe that runs all of the existing mathematics without crushing it. There was back in the day in which mathematical languages are defined. And Alan Turing later discovered that you can make a computer that can maybe not do all of classical mathematics. But it can do all of constructive mathematics, which is computation. It turns out that the mathematics that we can use to describe reality is does not contain infinities. It doesn't contain infinite loops, and some other concepts that have been introduced as artifacts of classical semantics, but computation. So basically, we can describe the world using automata, using hypothetical mathematical abstract machines that describe things as state sequences and transitions between the states. And Turing also found out that all the computers that we can build in this universe have the same power, it's the only difference between them is how much memory and speed they have. And, of course, what kind of graphics card interface they have to the environment. But they all can compute the same function if you give them enough memory. And this means that everything that is a machine is in this category. And our brain is also in this category of turns out that our brainless, as far as we can tell up is a new series, a computational machine, and it runs on some level, some code, there's some software happening, and maybe we can build computer systems that are doing the same thing. And this idea, started the project of artificial intelligence. And this artificial intelligence is multiple things. For many people. Artificial Intelligence is just the automation of data processing. And this is the majority of what people in my view, too. But it's also the most important and most risky project that there is in philosophy, it's the idea of building a mind that is able to think about reality, to bring the languages in which we understand what something means, and the languages in which we can compute truth together. And to do this, we need to understand how our mind grounds our meaning in elementary operations.

Joscha Bach 7:08
Vidkun Stein, came back from the war and in the trenches of the First World War, he thought about how to make philosophy better. And he wrote his ideas down. Then he came back in the Tractatus local philosophy course, which is a very beautiful book, something like 75 pages. It's almost like a poem. It's a philosophical book, without any footnotes, or any argument to convince anyone. It's just in single connected thought. And this thought he tries to express how to make a computer language for thinking how to clean up the natural language in such a way that it becomes formalized. And this project is very similar to what Minsky and others try to do more than 30 years later. And in the end of his life, Vidkun, Stein found that this project had failed, because he doesn't know how to describe meaning in this language. And it's mostly because he didn't know how to deal with images was perception and this reality that we experience in the context of computer programs. So far more grammatical languages are somewhat easy. But extending this into the world of meaning that we experience is hard. So, a little bit later, one of his pupils, students, Alan Turing, came up with the idea of a Turing test in the context of a paper that he wrote 1950. And the core of this paper, which is very readable, and everybody should read it, it's quite beautiful, is can we make a computer program that processes humans? And how would we know that we succeed, and most people have heard about the Turing Test, or know it intimately. It's the idea that you will sit on some computer terminal as a human being and you test whether something talking to you is a human or some kind of program. And if the program can successfully pass as human, you should grant it to being intelligent. And I don't think that is itself a very good condition, I think you want to do an in depth interrogation that really checks what kind of faculties it has in the mind. And part of that is that you check with a place during tests on your right we do Turing tests on other people all the time, we try to find out what they understand what they are conscious of what they're aware of, to which degree they understand that VR minds and their minds, and which faculties we possess because we don't have faculties in every domain, if don't have awareness in all domains. What is it mind I think of mind is a system that has general intelligence, and intelligence is the ability to make models. Models help us to make the right decisions and movements. And most of what we've done in artificial intelligence has not fall under the category of building minds or general intelligence. It's narrow AI, it has only one model can only do one thing using this model. And the general AI can make its own models. It's able to discover to learn how to learn and so it can solve Have the questions that are important to us. What is going on? What are the things that I can know? What am I and what should I do? An important notion for me is the idea of sentience. A sentient observer has an interval that explains what it is happening in reality right now. And it has a model of itself, because that's part of its environment. And as a result of understanding its relationship to the environment that it's part of it is capable of knowing what it's doing. Humans are clearly sentient. Many of them know what they're doing, but cat sentient. Let's look at this cat. Here you see, there's a video that went around on the internet last year, and you see a toddler, but you cannot see if the toddler is going to some stairs that are very, very steep, and the toddler is about to crash down the stairs, and worked himself or herself very badly. And family cat sees that and catches the toddler, and beats the toddler back into the womb to make sure that the toddler doesn't fall down the stairs.

Joscha Bach 11:12
I think this is remarkable. Because this cat knows what it is the cat knows what kind of abilities it has. It knows its place in the family, it sees itself as some kind of family member and has some responsibility for a family member that would fall down the stairs, stairs. So it's able to understand the intentions of that agent of the toddler and the capacities of that agent. And it knows that there's something in the future of that agent that it needs to intervene with, to prevent something really bad from happening. And so I would say that this kid is clearly sentient. This cat knows what it is and it knows what it's doing. But the cat is probably not generally intelligent. It's not capable of understanding what the mind does, for instance, it's not capable of learning a chromatic language in the way we do. A general intelligent agent is sentient. But it can also explain how it works. And if we are able to build a genuine artificial intelligence, if it means we have created an artifact that demonstrates our understanding of how our own intelligence works, and before we have created this artifact, if you don't really know if the r&d General intelligent, if you know that what intelligence is what we are, what our deep relationship to reality is, how do we perceive reality? It typically we we look at the world and we have ideas about the world. And we describe this distinction about the world as something toilets conception is a mental domain, and the physical domain. Right dualism proposes that there are two, two worlds, the world of the physical interactions, and the world of the ideas. Decart calls this physical world rest extends out the world of the extended things, and the mental will address kocot hence the domain or the substance of thought. And, as opposed to dualism, we also have idealist traditions, which say that alter there is only a mental world that we exist in some kind of dream world. And that reality as we perceive it is a dream that is dreamt by our mind on a higher plane of existence. And this would explain why magic is possible why things are possible that are not compatible with physics, like consciousness, conscious agents, and so on, which we cannot explain, in a straightforward way using physics. And is another intellectual tradition in philosophy, which is known as materialism, which was there's only a physical world and the physical world, they are machines like our brains, and these machines are capable of producing models. And some of these models are mental models that give rise to consciousness and experienced and so on. And there is a way to bring these two perspectives together, because I think that they're both incomplete. I think that both the physical world that we experience and the mental health that in which we think and reflect about that experience exist inside of our mind, they're both dreamt by a mind on higher plane of existence. And this mind on the higher plane of existence happens to be in the skull of a primate. In the physical world, the physical world is nothing that you can experience. It's just some weird quantum pattern generator that we don't have direct access to, but that projects patterns that are systemic interface, and it's our mind that creates both the mental world and the physical world is mental worlds.

Joscha Bach 14:48
So in this perspective, we understand that we live in a dream that is generated by our own neocortex. And what's most interesting to me as an AI researcher is how Have you could build machines that generate dreams in which they have a model of the universe that dynamically changes according to the features of the world that they're entangled with the same way as they are entangled by our body surface and our readiness to the world. And our brain computes functions to predict what's going to happen next. And already now in our body surface. And inside of our own models in our own brain rate, we also predict ourselves. And in this stream, the data is basically generated very similar to music is generated, I think it's a good metaphor to use a synthesizer. synthesizer is a machine that generates sounds by building a circuit of a lot of oscillators that you connect. And by fitting with the dials of that oscillator, you can learn how to produce almost arbitrary sounds. And with a little bit of experience, you can use the synthesizer to make the patterns in sound that you want. And it's a good way to think of neurons, being oscillators that are being tuned by changing the parameters of these neurons by changing the synaptic weights between them, and the way that they are addressed this by other neurons and the chemical signals that are sent to each other. And you can not only use this for the sound domain, but you can also use this to represent colors and spatial frequencies. And once you've extracted the patterns, you can try to look for higher level patterns for patterns in the patterns. And you might discover, you can do this also in a synthesizer that you build up step by step, that there is a way in which you can combine the low level patterns into higher level patterns. So for instance, you understand different sounds as being the same sound as a different pitch, or you understand different sound sequences as being the same sequence with a different rhythm. And in this way, you can build up structure that is going into the direction of person. So you go from low level features, to compounds have these features that produce perceptual content already something like textures. And then you can combine these textures into dynamic scenes. And these dynamic scenes are in some sense, simulations that add a high level of abstraction represent what might be going on in the world around us. And then we can build conceptual abstractions over the scenes that we see which basically, note what is in common over the different scenes that we experience. And then we can linguistic abstractions, like words like Cloud, and wall and floor and so on, that we can use to label the concepts and that we can use to organize our own thoughts, and to communicate our thoughts to others. And to develop thoughts that other people suggest us and builds new concepts in mental simulations based on linguistic representations. It's all done by via the biological neurons. And I think that we sometimes don't give them enough credit. They're like little animals that try to survive in this dark confine of the skull. And in order to survive, they have to link up and collaborate and move the organism around as a result. And if they don't do this in the right way, they will die, right, it's the only chance that they have. So they need to form an organization that processes information in the right way. But the individual neuron is not very smart, and it's not entangled with the world in a very rich way, it does not have that many single, at best, it can receive electrical impulses from a few 1000 other neurons. And there are trillions of neurons that it doesn't talk to, and there is no world that it can talk to. So it's basically like a submarine in pitch darkness that sometimes hears the ping. And then it has to decide whether to respond with its own ping. It lives in a pretty lonely existence in a very dark and lonely universe in a way. And so the only thing that it can do is learn how to fire based on which combination of pings it hits its environment. And this then checks which code kind of reward it is getting. So the individual neuron is a little reinforcement learning agent that links up as the other ones into units. And the basic unit in the neocortex seems to be a cortical column and the cortical columns can connect to each other and patterns that they can assemble and disassemble, like Lego bricks. Each of these cortical columns is made up of a few 100 neurons. And we have something in the order of 100 million, many columns that are, in some sense, combining a little function approximation, this thing that can learn functions, and some message passing machinery that allows them to link up with the rest of the brain. And they're organized into areas. Each of these areas is dedicated for processing certain classes of functions. And they connect up in some kind of hierarchy, which different cortical columns have receptive fields and the other hierarchies and project into other hierarchies. And this form some kind of architecture for computation. Or you could see this as an orchestra with something like approximately 50 brain areas or 50 instruments, and the instruments are listening to the instruments In the neighborhood, and they are taking up the themes and melodies that they hear in the neighborhood and modify them and pass them on. And this cortical orchestra is playing a symphony that we perceive as a model of reality and ourselves and the interaction between ourselves. And this orchestra has some kind of conductor. This conductor lives in the dorsolateral prefrontal cortex. As far as we know, mostly, this is where most of its representations are being stored. And this is an instrument like the others, that is not perceiving the music of the orchestra as a whole. It's singling out a few of the instruments and listens to them and synchronizes the activity or fixed activity and gives feedback to them. And this is the conscious attention that we have in this recording conductor stores, what we learn, and then attentional protocol, to which we can later have access and that we

Joscha Bach 20:56
allow us to generate an extra conscious experience. So this conductor is producing an integrated model of our attention. An important thing to understand is that we don't experience physical reality, what we experience is a trance, whenever something appears real to you, it's a trance is because something in your brain trust that something is the way that another part of the brain says so. And the words themselves don't experience reality. Brains cannot experience reality. They're just physical mechanisms, that the model in our own mind is separate units that are separate from other units and that interact and add an auditory experience a reality, the brain needs to make a model of reality and an agent that experiencing is experiencing it, the brain does know what it's like to be a person. But it needs to know that it's not a person, right, it needs to have a model of what it would be like to be a person, so it can move an organism, so a lot of other organisms. And for doing that, it creates an experience of that thing. And this experience is virtual. So consciousness is not physical property of things. It's a virtual property. There are some neuroscientists which think that simulations can never be conscious, or computer programs could never be conscious. And consciousness is only a feature that real things in the physical world can have under very, very specific conditions that we don't understand. And they got it exactly backwards. physical things cannot be conscious. Only virtual things can be conscious, because consciousness is a virtual property of a simulated system. You can only be conscious in a dream. And our brains are best understood as machines that dream. And what interests me is how can we build systems that we entangle with reality? So they can create their own dreams? And then how can we talk to them? So this is my input for today. And I hope that we have some time left for questions.

Unknown 23:12
Thank you so much. That was really, really interesting. If you have any questions, please put them in the chat. Or you can also unmute yourself and ask, ask your show. But maybe I'll start for now I was really, I was really intrigued by that video of the sentient cat and how it kind of realize the dangerous situation and recognize that there's something that needs to do. And I was wondering if you know of any implications of our science into how the brains of animals can understand this better, then that can help us understand better how they perceive reality, or is it just kind of like a dumbed down version of humans?

Joscha Bach 24:07
I suspect that for the most part, it is indeed, you could say a dumbed down version of humans and it's dumbed down. Because the not just because of the size of the brain of the characteristics the human brain, but because of the length of the childhood. We train our human brains in some sense layer by layer. If you have a child, you can observe how as an infant, it changes in certain phases or periods. That is after a few weeks, it suddenly undergoes a dramatic shift in its behavior and its experience of reality. You can see that the next layer is coming online. And the frequency at which these new layers come online is going lower and lower. So at some point, there is a big shift around to two and a half. Then there is another one around five or six. Then you have one that is in the onset of puberty there. One in later adolescence, this one in your mid 30s, and so on. And maybe there's another one in your 50s. And it's like, there is no end to the layers that you can make to model reality. And the time that it takes for us to become an adult that is able to feed itself, it's very long compared to most other animals, a gorilla is able to move into their own home at about one and a half or two years old. And a human takes something like 15 years or longer, even ancestral environments before they can find more food than they consume. So it's very, very expensive to have this long childhood, during which you're functionally insane. Because you don't have a proper model of your place in reality, and how to deal with reality, even though your body would be capable of doing that. It's your mind that is not capable of making sense of reality when you're young. You don't notice this, because how would you read you don't have any checks and balances that tell you what you don't understand. And I suspect that becoming a full adult is something that even the majority of human beings don't manage to achieve, where they become aware of how they construct their own model of reality. Right there, psychologist Robert Keegan, suggests that there are crucial phases of development. And most people's stay in level three, which is where you make realities based your reality based on what other people in the world around you think. So you form your ideas based on observing what good people think about the world. And you assimilate these ideas via empathy. And when you are in agreement with the people around you, especially high status people, like your boss, and your priest, or your scientists, or your leader, then you're good. And at stage four, you understand that what's true is completely independent, what other people think is true. And you discover that something could should only have confidence to exactly the degree that it's supported by evidence. And at this point, you get agency over your own beliefs. And at stage five, you understand how identity is constructed, what values are, the values are generated in your mind, and that are instrumental to something that you're serving, and how you can make sense of what it is that you're serving, and how other people do it, and what a greater place in the world is construed to be for yourself. So this point, you become transformative, you get freedom over what you are. And this is something that maybe only a percent of people get to, at least according to Robert Keegan. And I think that this, we can have intuitions of this, before we have abstract models of this. And the cat has much faster development than us because it has a much shorter childhood. And the layers of the cat come online after a relatively short amount of time. And this means that the cat does have a theory of mind it has a model of sociality, and so on. But these models are based on priors that are wired into the brain of the cat. So the cat has good intuitions of what it should explore. And because each of the faces is so much water, the cat sees less training data than video. So the cat cannot form the same level of abstraction. And I think the same is probably true for the great apes. They have brains that are in a similar region already as human brain. So a gorilla brains is much smaller than human brains. But there are some humans which have brains that are smaller than the brains of the largest gorillas. And they are completely capable of participating in human society and be relatively smart. Right. So the difference between us and the great apes is probably mostly the things of the childhood could be that there are some biases that makes them more interested in learning grammatical language or to perform certain tasks in the world. But I suspect that most of the capacity that we have is only the result of us spending more time learning them.

Unknown 29:00
Thank you so much. We have some 15 year olds in the audience as well. So it's definitely maybe a step forward for them to learn about all the stages. But I have some other questions that I want to read out loud so that the stream viewers can only hear them. And a Henshaw was asking, are Androids Dream of Electric Sheep? Or as differently? When the AI is dreaming? Will it be like something VR dreaming of thanks for your talk?

Joscha Bach 29:29
It depends on how you are entangled with reality. And it's unlikely that the AI is going to be connected to the world at the same level as VR in the same way. The way you perceive reality depends on what kind of reality you're bound to. And the work that you will not notice is one of mostly interactions with photons on your retina and this atoms that push against your skin and your eardrums. And these are electromagnetic interactions in the between In the different atoms and molecules, and all these electromagnetic interactions take place. And there's three dimensional space in a certain range of time and space at which we can resolve the world. So we don't see molecules. And we don't see a nation states or organizations and so on, because you're not directly connected to them, we have to infer their existence. And if we built an AI, it could be, for instance, connected to the stock market, and all the data sources and the entire internet, or it could be connected to all the sensors in a factory. And it would be connected at a very different timing and probably have a higher temporal resolution than video. And this means that the world that it perceives is a very different one, we would not be living next to it, but maybe inside of it, right, we might be the gut flora of some of the AIS of the future. And such a system would be seeing the world from a very different perspective. By the way, also of the humans for next level agents. So if you are part of a group that is very synchronized, and the group has a coherent spirit, innovate, and spirit is, I think, just the old word for operating system for an autonomous robot. And this was invented before we build autonomous robots ourselves. So the only autonomous robots that were known for people and animals and plants and cities, and nation states, and ecosystems, and so on. And when they have coherent activity, you can describe them as having some kind of software that coordinates the parts of them, it's a pattern that you see in coordinated activity. And this, if this pattern has a direction, some agency, then we noticed that there is some spirit that animates the things, it's a projection that we make, to understand how something moves around in the world. And the same thing is true for us, right? We see each others as spirits emerging over the activity of the new ones, and only the difference are real. And the spirit that we see in another person is a pattern that we recognize in the activity of other neurons or other people and their interaction with the environment, or groups of people.

Joscha Bach 32:17
And I can hear you. Okay,

Unknown 32:19
good it. Marianna saying that she really likes the idea, you mentioned that we could, in a way see human interaction also, as humans doing actually test with each other. Testing, they're being human. And it kind of connects to what Simone is saying here, of stick with the cat example. And imagine that the cat was a human, but it did not intervene, it wouldn't do anything to save the baby. What would that have told us about the human?

Joscha Bach 32:52
Yes, it might have told us that the human doesn't care, or that the human doesn't understand the situation. So there are two elements that go into this. One is the relevance of the situation that tells you this is this network of relationships that you're part of and that you are serving. And the other one is to which degree are you able to understand the consequences of your actions and the events in the environment.

Unknown 33:20
Thanks. Think that if there are no other audience questions, I leave a bit of time because I think this is a topic that needs digesting and maybe ideas pop up a bit later.

Joscha Bach 33:37
You can also criticize things that I said or say, Oh, I don't get any of that. Or this is nonsense. Or you can ask something weird. Go ahead.

Unknown 33:51
You can also unmute yourselves if you want you don't have to write in the chat. But I think your show you're super confident, difficult to criticize. But we have a question. I always wonder how realistic the thought of AI is transforming visual impressions into proper procedures or reactions.

Joscha Bach 34:21
Yeah, it's a very good question for many people, the idea that you could build a machine that has experience of the world and very similar to us, but even surpassing our abilities and skills, and maybe the depths of our conscious experience is preposterous, right? It's, it's almost an insult to the way that we perceive ourselves. And it's maybe something that is specific to our own culture and the way that we perceive our own mindsets, some kind of supernatural miracle, and I wonder what it would mean if something is fully supernatural. Everything is eventually natural. Everything is neater. If you perceive a supernatural power, then something must implement and realize this supernatural power. Even if it could turn out that this universe that we are in is some kind of simulation. Magic is possible in the simulation, something must run the simulation, there must be something underneath it. The big question why there is something rather than nothing is very puzzling, maybe everything possible exists, and we are in one of the corners of existence that might exist. But so from this perspective, the universe is some kind of machine and we don't know what has put it there and why it exists. And we also don't know what the lowest level of that machine works, so that we don't have a completely foundational theory of physics that goes far beyond quantum mechanics or theories that would generate the phenomena that we describe in front and mechanics. And maybe this is a puzzle for which we need to build machines, because humans are just not smart enough to solve it. But I suspect that we can solve the puzzle of our own brain builds models of reality by building something like this mental orchestra. When you perceive the world around us, there are blips on your retina that these blips are generated by photons exciting nerves in the retina. And what your brain is trying to figure out is the relationship of these blips to other blips on your retina. This is the meaning of information, information is discernible difference in the meaning of the information on your retina is the ability to predict other blips at different times, or at the same time, that aren't some connection to them. And you put this together into functions in your brain and you perceive these functions as for instance, people moving around a three dimensional room, or the sun shines on them, and they talk to each other about ideas. So this is the kind of construction that we need our machines to make, we need to be get getting to the point where we connect the camera to information processing system, and it's capable of finding an organization that allows us to make sense of the blips on the camera sensor in a similar way as we make sense of the blips on our retina.

Unknown 37:09
Talking about things that we don't know, what is the biggest question currently for you, in your work or research that you would absolutely love to find the answer for.

Joscha Bach 37:21
One of the questions that I find very interesting is how to perception and the symbolic mind relate? Is the symbolic mind something like a specific kind of perceptual thing that is in trained on the perceptual mind? Or are they somehow using separate circuits, and work according to different functional principles. And I suspect it's the former. But this interface between perception and experience is symbolic organization is something that is deeply interesting to me. There are other puzzles, for instance, the puzzles of physics that I find very fascinating, and I feel that I'm ill equipped to solve them. But it's there seems to be a limit on what our human brain is doing, how many levels of meaning we can connect to each other in one integrated model and not lose track of the different ideas that we pass around in our mental model. In some sense, our brain is making simulations of the world and we do this, that we understand our own mind, and maybe understand physics. And at some point, these simulations become so intricate, that we need to take them out of our minds and put them into computer models so we can track what's going on. And to build these computer models is very hard. So we need to have computer programs that help us building these models. So it starts to automate our own thinking. And this is also something that is deeply interesting to me, how can I extend my own mind into machinery that has fluid connection to my own mind? So fear that still my motivation that goes, is controlling all this, and it's still part of me, but it extends beyond my human brain about beyond my human capacity in a seamless way.

Unknown 39:13
Though, just the last question, maybe if there's no other ones from the audience, there's a lot of talk about generation, a algorithm and generation COVID I guess now we are experiencing the world through simulations through these zoom calls that we're in, and I'm connecting with someone in California right this second. And I would like to hear a bit more about whether you think this actually makes any difference in our perception to kids who grew up through these screens, that channel and different sorts of realities or situations to the same place diff. Like make a difference. And what kind of perception they will have as grownups maybe,

Joscha Bach 40:04
definitely, I think that every generation builds their own model of reality. And the big problem is that our future is changing faster than our models of reality can track it. And this means that our civilizational hivemind, has lost the plot, if you don't have a very good model of the future anymore, our projections mostly end in 2100, when we know that climate change has become so bad that we don't know how to deal with it. And we don't make projections beyond that. And most of our institutions of society do not plan further ahead than a few decades. And the pandemic has shifted this time horizon to much, much harder. So basically, in the very rich, we organize our economy, and make plans of the future is mostly just a couple of years at the moment. So this is terrifying. And the current generation is, from our perspective, the Generation X, called the generation that and we don't really know if something comes after that, right. It's it's not as if we have left a lot of letters after that. I think that in a way, the VAR generation, for generation of World War Two still had the intellectual continuity from the previous generations and ways in which they made sense of reality were shared. And after modernists meant this perspective that built the big societies of the 20th century, which mostly crashed and failed, the communist societies and the fascist societies and the capitalist societies, which are all now either crashing or muddling through. This is all over now, right? And ever since every generation has lost the plot even more and has less of a plan, what to do with the future is we made a very strong intuitions and moral movements. But he probably need to build a new idea of how to deal with reality if you want to stay around as a species. And that task is on the next generations.

Unknown 42:11
Thanks, Russia. This is actually I think, a perfect ending point and thank you very much for your presentation.

This transcript was generated by https://otter.ai