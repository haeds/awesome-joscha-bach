Unknown 0:01
Welcome to the future of Life Institute Podcast. I'm Lucas Perry. Today's episode is with Yoshi, Bach and Anthony Aguirre and marks the beginning of the continuous uploading a video content for all of our new podcast episodes. So if you follow the audio only version of our podcast, you'll now also be able to see the video content from all of these interviews here on this channel. If you're not subscribed to the audio only version of this podcast, then you can check out the description below this video to see links to our Spotify and Apple podcast feeds. You can also search on your favorite podcasting platform or app for future of Life Institute podcast. This podcast was a lot of fun, and it we explore whether the universe ultimately might be computational or digital in nature. We explore collective coordination problems, incentive structures, and how these all effects civilizational longevity. We also get into whether having a single multiple or many AGI systems existing simultaneously is more likely to bring about beneficial outcomes from Ai. For those not familiar with Yoshida or Anthony Yoshida is a cognitive scientist and AI researcher working as a principal AI engineer at Intel Labs. He was previously at the MIT Media Lab, as well as the Harvard program for evolutionary dynamics. Anthony is a physicist that studies the model of eternal inflation. He is also a co founder and is the Associate scientific director for the foundational questions Institute. He is also a co founder of the future of Life Institute as well as of meticulous and so without further ado, let's get into our conversation with Anthony Aguirre and Yoshi, Bach.

Unknown 1:58
Alright, let's get into it. Let's start off with a simple question here. What is truth?

Joscha Bach 2:06
I don't think that we can define truth outside of the context of languages and so, truth is typically formally defined in formal languages, which means the domain of mathematics and in philosophy, we have an informal notion of truth and or a vast array of them a number of two theories. And typically, I think, when we talk about any kind of external reality, but we cannot know truth in the sense as we cannot know know it in a formal system, what we can describe this whether a model is predictive. And so, we ended up basically looking at a space of theories and we tried to determine the shape of that space.

Unknown 2:50
Do you think that there are kinds of knowledge that exist outside of that, that space? For example, do I require a knowledge that I am aware

Joscha Bach 3:01
of think that knowledge exists only inside of a mind that is inside of an agent that observes things, knowledge is not arbitrary, of course, because a lot of knowledge is formally derived, which means it has similar structure as a fractal, for instance, the Mandelbrot fractal where you start out with some initial conditions and some rules, and then you derive additional information on that. But essentially, knowledge is conditional, because it depends on some axiomatic presupposition that you need to introduce. Of course, that doesn't make it arbitrary. It means that if you make that presupposition, you get to certain types of conclusions that are somewhat inevitable. There's a set of formal systems that you can explore. So for instance, when we define numbers, the number I think is best understood as a subsequent labeling scheme. And there are a number of subsequent labeling schemes that we can use, and turns out that they have similar properties. And we can map them on to each other. So we have several definitions for the natural numbers. And then we can build the other types of numbers based on this initial number theory. And it turns out that other parts of mathematics are equivalent to CRMs that we discover a number theory or many of them are. So it turns out that a lot of mathematics is looking at the same fractals in different contexts. The way mathematics is about studying symbol games and all languages are I think mathematics is the set of all languages.

Unknown 4:37
You made an interesting statement that knowledge is something that only exists in the mind of well in a mind. So I suppose you're you're contrasting that with information or so well, how would you think differently about knowledge or information? How would you draw that distinction? If you do

Joscha Bach 4:59
I think That knowledge is applied to a particular domain. So it's regularities inside of a domain and this domain needs to be given. And to have knowledge, you need to have a domain that the knowledge is about. And the domain is given by an observer that is defining the domain. And it's not necessarily a very heart condition in terms of the power of the mind that is involved here. So I don't require a subject with first person consciousness and so on. What I do require is some system that is defining the domain.

Unknown 5:37
So by a mind, you mean something that is this defining the terms or the domain or in some way, sort of translating some piece of information into something with more semantic meaning?

Joscha Bach 5:51
I think a mind is a system that is able to predict information by turning coming up with a global model, thereby making them information explainable.

Unknown 6:04
Okay, so predicting information, meaning there's some some information stream of input. And a mind is able to create models for that stream of input to predict further elements of that stream. At the

Joscha Bach 6:21
moment, I understand a model to be a set of variances, which are parameters that can change the value, each of them has a range of admitted the values. And then you have invariances, which are computable relationships between these values that constrain the values with respect to each other. And the model can be connected to variant says that the model itself is not generating, which can be parameters that enter the system from the universe, so to speak, from the from whatever pattern generator is outside of that system. And the system can create a model to make the next set of values that are being set by the outside predictable. And I think this is all in perception books.

Unknown 7:08
So in terms of human beings, truth is purely mind dependent. It requires a human being, for example, a brain, which is a substrate that can encode information,

Joscha Bach 7:21
which it's not mind dependent, it doesn't, because it's going to be the same for every mind this same properties in terms of information processing and modeling capacity. You mean, it's not brain dependent? Is not subjective. It's not subjective. Yes. So for instance, the knowledge that we derive studying mathematics is not subjective knowledge. It's knowledge that flows out of the constraints of the domains and our ability to recognize these constraints.

Unknown 7:55
So how does this stand in relation to two accounts of truth as being, you know, third person out there, kind of floating in the universe truths. When we bring in the dependence of models and minds,

Joscha Bach 8:13
the first person is the construct to begin this, right, the first person is not immediately given, it's introduced into the system in our system as a set of priors. And then we are stuck with it until we deconstruct it again. But once we have understood what we are believe is no longer a verb, right? There is no relationship between the self and the set of beliefs anymore, you don't change by changing your beliefs about a certain domain, you're just recognize yourself as a system that is able to perform certain operations. And every other system that is able to perform the same operations is going to be equivalent with respect to modeling the domain.

Unknown 8:57
So So you think that there's no, I think Lucas is maybe getting at a sort of claim that there's more direct access to knowledge or information that you know, that we as a subjective agent aren't directly perceiving right there, there are things that you infer about the world, and they're things that you directly experience about the world, as, you know, as an observer in it. So I have some sensory stream, I have access to the contents of my mind at some level. And these are very direct. This is very direct knowledge that I don't have to do well, there's a feeling that I don't have to do a bunch of modeling to understand what's going on. And there's an interesting question of whether that's true or not like to what degree Am I modeling things all the time, and that's just happening at a subconscious level?

Unknown 9:56
Yeah, like so. A primitive version of that would be like, how Descartes epistemology, he starts off with like awareness, you start off with being aware of being aware. So that might include some kind of subconscious modeling, though in terms of direct experience, it doesn't really seem like it requires a model. It's kind of like a direct apprehension, which may be structured by some kind of modeling.

Joscha Bach 10:20
Of course, Deckard is telling a story, when he writes all this, he is much, much further when he writes down the story, right, this is not the thing that he started writing as a two year old, and then breaking his paths along that line. Instead, he starts out at the highly aware state and then backtracks and tries to retrace the steps that he had possibly taken to get where he was, when we have the impression that parts of our modeling is immediately given, it means that you don't have any knowledge about how it works. And other way words, we don't have a model that we can talk about the order that we include unconsciously access before we can talk about it. And when we become aware of the way in which we construct representation, we get closer to what many Eastern philosophers would call enlightenment, that this, that our ideas become visible in the nature as representations, that we understand that the everything that we perceive as real is, in fact, a representation happening outside of our mind. And we become aware of the mechanisms that construct with representations, and that allow us to arrive at different representations if fee parameterize these processes differently.

Unknown 11:36
But but the Yeah, so how so I'm, I'm interested in, in this statement, in comparison to an earlier statement, you made that about what is, you know, not subjective, when you talk about the construction of, so there are a whole bunch of things that I experienced as an, you know, aware agent, the, the claim that you're making, which I agree with is that pretty much all of that is something that I have constructed as something to experience based on some, you know, some level of sensory input, but but heavily processed and modeled. And it's, it's essentially something that I'm almost dreaming in my mind to create this representation of the world that I'm then experiencing. But then, you know, there's also a supposition that we have that there is some something that is causing the feeling of objectivity, there's some something underlying, you know, our individual agents sharing similar perceptions using similar models, and so on. So there's, of course, some sense that some meaning that we ascribe to an external world based on that shared concepts and ideas and sort of things that we attribute a system existence to that are underlying the model that we construct in our mind. So I guess the question is to, you know, what, how do you look at where we draw the line between the the subjective thing that we're sort of inventing and modeling in our internal representation, and the objective world is there? Is there such thing as a purely objective world is at all representation? At some level? Is there some, is there a very objective world with, you know, lots of interesting things in it, and we more or less understand it correctly, as it is like, where do you sit on that spectrum?

Joscha Bach 13:34
Everything that looks real, everything that has the property of being experimental, at some level that can be subject of experience, is going to be constructed inside of your mind. There is this issue that it's not you that is constructing because you are a story inside of that mind about that agent. But the AI is not the agent, the AI is the representation of the agent inside of the system. And what we can say about the universe is it seems to be generating patterns, these patterns seem to be independent of what we want them to be right. So it's not that all of these patterns seem to be originating in our mind at least this is not a model that makes very good predictions. And there seem to be other minds that seem to be able to perceive similar patterns, but in different projection. And the projection is being done by the mind that is trying to explain the patterns. So the universe is projecting some patterns at your systemic interface and at your Talamo or at your retina and body surface or wherever you draw the line. And then you have a nervous system behind us or some kind of other information processing system that will best model is that it's another system that is identifying regularities and these patterns, and part of these regularities are for instance, things things don't exist in dependently of our decomposition of the universe into things. This doesn't mean that the decomposition is completely arbitrary, because our mind makes it based on what's salient and what's, what compresses well. But this, ultimately, there is just this unified state vector of the universe that is progressing. And you make it predictable by splitting it up into six into separate entities that you model independently of each other in your mind. And they exchange information, thereby change each other objects evolution, and this is how we get to causality and so on. But for instance, causality doesn't exist independently of the decomposition of the universe into things, which has to be done by mind.

Unknown 15:39
Well, I'm curious as to why you say, what there really is, is this, this unified evolving state vector, I mean, how do you know?

Joscha Bach 15:47
I don't. So this is the easiest explanation, I have difficulty to make it simpler than that. But the separation of the universe into objects seems to be performed by the observing mind, by the alternatives don't make sense.

Unknown 16:06
That what you said seem to attribute sort of a greater reality to this idea of an evolving state vector something than other descriptions of the same, you know, there are lots of ways we can describe, you know, whatever it is that we call this system that we're inhabiting, right, we can, we can describe it at the at the level of, you know, objects, and you know, the everyday level, we can describe it at the level of fields and particles and things we could describe it, maybe there's a string theory description, maybe there's a single, maybe there's a cellular automaton cranking along. Do you feel that one of these descriptions is, like more true than the others? Or do you feel like these are different descriptions of the same, like, what different ways to describe it.

Joscha Bach 17:01
So the description of the universe as a set of states that changes is the most basic one. And then I can say, it seems that I can take the set of states and organize it as if it was a space, right is the Certain Way to project the state vector, you get to space to something as multi dimensional by taking your number line and folding it up, for instance, into a lattice. And you can make this in a number of operators. And then you can have information traveling in this lattice. And then you usually get to something like particles. And if the particles don't have a distinct location, and you just describe the trend of particles going, then you have fields, but they all require additional language that you need to introduce new additional assumptions. And also, we find that there are no true in the sense that there is a level of description for reality and description fall apart from each other. So for instance, the idea of describing the universalism in Koski space, let's try to develop certain scales. But if you go below the scales, you get singularities, or in certain regions of the universe, you get singularities and you realize you're not living in space, you can just describe the dynamics at a certain scale, usually as space. Same, same is true for particles. But particles are a way to talk about how information travels between the locations that you can discern the state vector. So the thing that I'm sometimes frustrated with this philosophers is that they somehow say that the notions that they got in high school physics are somehow objectively given. And they know electrons and physicists know what electrons are in their sacred understanding, and we touch them every day. And then we build information processing on top of the electrons. And this is just not true. It's the other way around, right?

Unknown 18:50
Yeah, I mean, all of these concepts, the the more you analyze them, and the harder you think about them, the less you understand them, not the more you know, in the sense of for particles. I mean, if you ask what an electron is, that is a surprisingly hard answer to give, you know, as a physicist, right? An electron is a is an excitation of the electron field. And what is the electron field, it's a field that has the ability to create electrons.

Joscha Bach 19:21
But when you when you don't know this, it means you have never understood it, right? The person that came up with these notions have either pulled them out of thin air, or they understood something that you don't, right they they saw something in their mind that they tried to translate into a language that people could work with, and it allowed them to build machinery, but that does not necessarily convey the same understanding. And that to me is totally fascinating, right? You learn in high school, how to make a radio, but you don't get the ideas that were necessary to get somebody the idea. Oh, this is what should I should be doing to get a radio in the first place right? This is not enough information to let you in. bent radio, because you have no idea why the universe would allow you to build radios. And it's not like the other people experimented and they suddenly got radios. And then they tried to come up with a fancy theory that would project electrons into the universe and magnetic fields or electromagnetic fields to explain why that radio would work. They did have an idea on how the universe must be set up. And then they experimented and came up with the radio and verify that their intuition must be correct at some level. And the idea that the Wolfram has, for instance, that the universe is a stellar automaton is given by the idea that it's a lot lot automaton is the way to write down the Turing machine, it's equivalent to a Turing Machine trying to use a cellular automaton, yes, okay, is a way to write down and during machine, yes, so there is a cellular automaton are the number of cellular automata, which are Turing complete. And cellular automaton is a general way to describe computational systems. And since the constructivist turn, I think that we mostly agree that every evolving system can be described as some automaton. Right, as a finite state machine, or in the unbounded case is a Turing machine.

Unknown 21:26
Well, that I think is not clear. Right? I think we, it's certainly not the way that physics as it actually operates. Works, right? We do all this stuff with real numbers and calculus and, and all kinds of continuous quantities. And it's always been of interest to me, you know, if we suppose that the universe is fundamentally disagreed or digital, in some way, it sure disguises it quite well, in the sense that the, the physics that we've invented based on so many smooth quantities, and differentials and all these things is is incredibly effective. And even quantum mechanics, which, you know, is has this fundamental discreteness to it, and as you know, literally quantum mechanics is all still full of chalk chock full of real numbers and, and smooth evolutions and ingredients that, you know, there's no, there's no obvious way to take the mechanics, you know, any of the the fundamental physics theories that we that we know, and make a nice analog version of them that, that turns into the, the, sorry, a nice digital version, rather, that turns into the the analog continuous version that we know and love. Which is an interesting thing, you know, you would think that that would be simpler if the world was fundamentally discrete and Quantum. So I don't know if that's telling us anything other you know, it may just be historical, that these are the these are the first tools that we developed, and they worked really well. And so that became kind of the, the foundation for our way of thinking about how the world works with with all sorts of smooth quantities. And, and certainly discrete quantities, when you have a large enough number of them, you know, can act smoothly. But it's nonetheless, I think, a little bit surprising how, how basic and effective all of that mathematics appears to be. If it's totally wrong, if it's, you know, essentially fundamentally the wrong sort of mathematics to describe what reality how reality is actually working at the baseline,

Joscha Bach 23:39
it's almost correct. You'll remember the stories, that protagonist was very opposed to introducing irrational numbers into the codebase of mathematics, and even stories that he committed murder to, which are probably not true to prevent that from happening. And I think that he was really onto something, the vote was not ready yet. And the issue I think that he had was irrational numbers that are not constructive. And what people didn't have until quite recently in the language of mathematics is a distinction between value and function. And classical semantics, the value and the function are basically equivalent, because if you can compute the function, you have a value and if the function is sufficiently defined, you can compute it right. And, for instance, there is no difference between Pi as a function as an algorithm that you would need to compute and pay as a value and in this classical semantics, but in practice, there is right you cannot determine arbitrary many digits of Pi before Korea's and turns out there is a finite number of digits of pi that every observer in our universe will ever know. And that also means that there can be no system that we can build or that something with similar limitations and the disregard can ever build there It relies on knowing the last digit of pi when it performs an operation. So if you use a code base that assumes that some things in physics have known the last digit of pi before the universe went on to go into its next state, you are contradicting this idea of constructive mathematics. And the, there was some hope that this could be somewhat recovered, because mathematicians before this constructive turn, just postulated, this infinite number generator. So yeah, so you postulate in your infinite number of calculator, the thing that is able to perform infinitely many operations in a single step or read infinitely many arguments into your function in a single step, instead of infinitely many. And if you assume that this is possible, for instance, via the axiom of choice, you get nice properties. But some of them are very paradoxical. You probably know Herbert's hotel, right, a hotel that has infinitely many rooms and is fully booked. And then new person arrives, and you just ask everybody to move, move one room to the right, and now you have an empty room. And you can also have infinity by the passes Come on, you just ask everybody to move, move into the room that has twice its current number, and then practice, this is not going to work, because in order to calculate twice your number, you need to store it somehow. And if the number gets too large, you're unable to do that. But it should also occur to you that if you have such a thing as Herbert hotel, that you're not looking at a feature, you're probably looking at the back, you have just invented a cornucopia, you get something from nothing, or you get more from little, and that should be concerning. And so when you look into this in detail, you get to girdles proof on to the halting problem, which pose two different ways of looking at the issue that when you state that you can make a proof without actually being performing the algorithm of that proof. You run into contradictions. It means you can, you cannot build a machine and mathematics that runs the semantics of classical mathematics without crashing. That was Google's discovery. And it was a big shock to Google because he strongly personally believed in the semantics of classical mathematics. And it's confusing to people like Penrose, who thinks that I can do classical mathematics computers cannot. So my mind must be able to do something that computers cannot do. Right? And this is obviously not true. So what's going on here, I think what happens is that we are looking at too many parts to count. When you look at the world of too many parts to count, that are very, very large numbers, you sometimes get dynamics that are convergent, right? That means that if you perform an operation on a trillion objects, or on a billion objects in this domain, the result is somewhat similar. And domain where you have these operators, the way these operators converge, this is geometric by enlarge. And this is what we are using to describe the reality that you're embedded in, because the reality that you will meet are embedded in this necessary composed of too many parts to count for us, because we are very, very large with respect to our constituent parts, because otherwise you wouldn't work.

Unknown 28:19
Yeah, although that is I mean, yeah, I certainly, again, if there are enough of something and you're trying to do and trying to model it that real numbers will work? Well, you know, so, but I think there's

Joscha Bach 28:36
but it's these are not real numbers, there are very, very large numbers. This is,

Unknown 28:41
right, but the model is real numbers. I mean, that's what we use, right? When we do physics, we

Joscha Bach 28:45
Yes, but it's totally fine. When you do classical mechanics, it's not fine when you do foundational physics, because at this point, you are checking out the code base from the mathematicians, that has some comments By now, the comments say this actually not infinite when you want to perform operations in there. And when you want to prove the consistency of the language that you're using, you need to make the following changes, which means that pi is now a function. And you can plug this function into your nearest time and get numbers but you don't get the last digit. So you cannot implement your physics in such a way. Or your library or physics, that you rely on having known the last digit of pi, it just means that for sufficiently many elements that you're counting, this is going to converge to pi. This is all there is.

Unknown 29:36
Right? No, I understand the motivation for for thinking that way. And it's and it's interesting that that's not the way people actually think, you know, in terms of fundamental physics in terms of, you know, quantum mechanics or quantum gravity or anything else,

Joscha Bach 29:51
but that's just their fault. It's not our fault. You don't have to worry about them.

Unknown 29:56
Fair enough. Fair enough. So I think the The claim that you're making would be that, you know, if we do you know, there's a question if 100 years from now, the the final theory of physics is discovered, and they they haven't, you know, available on a t shirt near them? You know, is that theory going to have, you know, be a essentially contain a bunch of natural numbers and counting a discrete elements? Or is it going to look, you know, if,

Joscha Bach 30:29
if your source integers is all that is computable? Right? So, integers,

Unknown 30:35
so this is a strong claim about kind of what's, what's ultimately going to happen in physics, I think that you're making, which is an interesting one. And, and is, you know, very different from what most practicing physicists in, you know, thinking about the foundations of physics are taking as their approach?

Joscha Bach 30:55
Yes. Yes, there's a growing number of physicists which seem to agree with this. So very informally, when I was in Banff, at a foundational physics conference, I made a small survey among the foundational physicists, I got something like 200 responses. And I think 6% of the accumulated physicists for amenable to the idea of digital physics, or for proponents of digital fidelity, I think is, is really showing that this is growing and attraction, because it's a relatively new idea in many ways.

Unknown 31:32
Okay. All right. So,

Unknown 31:34
please seriously

Unknown 31:36
try to summarize this and I guess in a few statements, it correct me if I got any of this wrong is that because you have like a computational list? metaphysics, Etosha, if reality contains continuous numbers, then the states of the with the large vector space can't be computed is that the is that the central point?

Joscha Bach 32:03
So the problem is that when you define a mathematical language, any kind of formal language, that assumes that you can perform computations with infinite accuracy, you run into contradictions. This is the conclusion of good, okay. And that's why I have to, I'm stuck this computation, I cannot go beyond computation, hyper computation doesn't work, because it cannot be defined constructively. I cannot build a hyper computer that runs hyper computational physics, I will be stuck with computation. But it's not a problem, because there is nothing that I cannot do visit that I could do before. Everything that worked so far, is still working, right? Everything that I could compute, in physics until now is still computable.

Unknown 32:52
Okay, so to say digital is to say, what does that just say?

Joscha Bach 32:59
It means that when you look at physics and you make observations, you will necessarily have to make observations with a finite resolution. And when you describe the transitions between the observables, you will have to have functions that are computable. And now there is the question, is this a limitation that only exists on the site of the observer? Or is this also an limitation that would exist on the site of the implementation? And now the question is, how could God or whatever hypothetical circumstance perform to do this? So if the answer is if the universe is implemented in any kind of language, then it's subject to the same limitations? The only question is, could it be possible that the universe is not implemented in some kind of language? Question is, is it implemented? What does it mean to be implemented, we can no longer talk about it. It doesn't really make sense to talk about such a thing, we would have to talk about it in a language that is inconsistent.

Unknown 34:07
I lost you there in the last part.

Joscha Bach 34:09
So when we want to talk about the universe that is continuous, we would have to define what continuity means in a way that would explain how the universe is performing continuous operations, at least at some level. And the assumption that the universe can do this leads into contradictions. So we would have to basically deal with the fact that you have to cheat at some point. And I think what happened before constructive mathematics was that people were cheating. They were pretending that they could read infinitely many arguments into their function, but they were never actually doing it. It was just giving them elegant notations. And these elegant notations or specifications for things that cannot be implemented. And the practice was not a problem because people just found workarounds and practice right? They would do something slightly different than the implement that the notation and something that I found as a kid very irritating when I did mathematics because sometimes the notation that I was using in mathematics was so unlike from what I had to do in my own mind, or what I had to do on my machine to perform a certain operation, and I didn't really understand the difference, I didn't understand the difference between computation and mathematics and why it existed. And the practice, the difference is that the classical mathematics is stateless. It assumes that everything can be computed without going from state to state.

Unknown 35:30
Yeah. Yeah. But it's, it's beguiling. Because you think there's this number Pi, and you feel like it exists. And whether anybody, you know, computes the 10 to the 50th digit of it, it has some value, you know, if you could compute it, you would have some value, and there's no sort of freedom and what that value is going to be. It's that value is defined as soon as you make the definition of pie. So it's back to this

Joscha Bach 35:58
moment when you had this idea that pie is there for you with all its infinite glory. Certainly not an idea that you were born with, right? You were hypnotized into it by your teachers. And they by that teachers, and so somebody at some point made this decision. It's not obvious.

Unknown 36:20
No, it's not. But it is. I mean, it's sort of a relic of Plato, I guess. I mean, it goes to I think there is, you know, mathematicians are obviously are split in this in all kinds of ways. But there are a lot of mathematicians who are Platanus, and really, very much think that pie meaningfully exists in all its glory in that way. So I think there are probably surveys that we can consult, but I haven't about the the degree of Platonism in physicists, I suspect, it varies pretty widely actually

Joscha Bach 36:57
take a little step back from all these ideas of mathematics that you may or may not have gotten in school. And your teachers may not or may not have gotten them in school, but look back at what you know, right your computer, and how your computer would make sense of the universe, if you could implement AI on it. Right, this is something that we can see quite clearly, your computer has a discrete set of sensory states that it would could make sense out of right, and it would be able to construct models, and it can make these models in a resolution. That is if you want to higher than the resolution of our own mind, it can make observation at a higher resolution than our senses. And there is basically no limit in terms of not being able to surpass the kind of model that you're doing. And yet everything in the mind of that system would be discrete, necessarily, right? So if the system conceives of something that is continuous, if that system conceives of a language that is continuous. And if you can show that this language doesn't work, that it's is not consistent, then this system must be mistaken. Right? It's pointing indexicality at some functions that perform some kind of effective geometry. And effective geometry is one like the one in a computer game, right? It looks continuous, but it certainly is not. It's just continuous enough.

Unknown 38:24
Relative to the conventional physics, what does a computational view of physics what does that what does that changing?

Joscha Bach 38:34
Nothing. If the conventional physicist has made a mistake, it's this exactly the same. It's just that conventional physics invites making certain kinds of mistakes, that might lead to confusion. So But in practice, it doesn't change anything, it just means that the universe is computable. And of course, it should be because for it to be computable just means that you can come up with a model that describes how adjacent states in the universe are correlated.

Unknown 39:01
Okay. Okay, so this leads into the next question. And let's try and move on

Unknown 39:05
to number two.

Unknown 39:08
Actually, question number three, Anthony. So we're gonna have to move along a little bit faster and more mindfully here. You've mentioned that it's tempting to think of the universe as part of a fractal, can you explain this view and what is physics according to this view?

Joscha Bach 39:22
So I think that mathematics is in some sense something like a fractal. So the natural numbers are similar to the generator function of the Mandelbrot fractal right you take piano's axioms. And as a result, you get all these dynamics, if you introduce a few suitable operators, and you can define the space of natural numbers, for instance, using addition or you can do it using multiplication. In the case of multiplication, you will need to introduce the prime numbers because you cannot derive all the actual numbers just by multiplication with one and zero If you need all these elements, the basic elements of this multiplication space would be the prime numbers. And now there is the question, is there an elegant translation between the space of multiplication in the space of additions? And maybe has to do with the Riemann zeta function? Right? We don't know that. But essentially, we are exploring a certain factor here. Right? Now, with respect to physics, there is the question, why is there something rather than nothing invite us to something look so regular? B can come up as entropic arguments, right? If nothing would be existing, nobody would be asking the question. Also, if that thing was irregular, we probably couldn't exist. This type of mind that we are and so on requires large scale regularity. But it's still very unsatisfying, because this thing that something exists rather than nothing should have an explanation that we want to make as simple as possible. And the easiest explanation is that maybe existence is the default. So everything that can be implemented would exist, and maybe everything that exists is the superposition of all the finite automata. And as a result, you get something like a fractal. And in this fractal, there is us. This idea that the universe can be described as an evolving cellular automaton is quite odd, I think it's goes back to the user's height and around. And it's been formulated in different ways by for instance, Fredkin, and Wolfram and a few others. And again, it's equivalent to saying that the universe is some kind of automaton some kind of machine that takes a starting value or starting configuration, and then, or any kind of configuration and then moves to the next configuration based on this table transition

Unknown 41:50
function. But But there's a difference between saying that the universe is a cellular automaton, and the universe is all possible cellular automata, which, you know that that view is held sort of by by Max Tegmark and I think you're going Schmidhuber. And but you're talking more about that version or two, that

Joscha Bach 42:11
it just means that both forms project of enumerating all the cellular automata. And taking the first one that produces a universe that looks like ours, might not work. It could be that you need all of them in a certain enumeration. But it still is a cellular automaton. It's just one that is much longer than bought from Bucha hope.

Unknown 42:35
You're saying all possible certainly automatize the same as one cellular automaton, yes,

Joscha Bach 42:40
it would be once a little automaton that is the result of the superposition of all of them. Which probably means that long cellular automata only act relatively rarely so to speak. And I have no idea how to talk about this in detail and how to model this. So it is just a very vague intuition. Yeah. Consciousness, I think, is the controlling model of our attention. And human consciousness is characterized by attention to features that are taken to be currently the case that we keep stable in this space, we can vary other parameters that we can make conditional variance in our perception and so on, and that you can form index memories for the purpose of learning. Then we have Access Consciousness, which is a representation of the attentional relationship that we have to these objects. So we know that we are paying attention to them. And we know in which way we are paying attention to them. So for instance, do we single out sensory features or high level interpretations of sensory features, or hypotheses or memories, and so on, and this is also part of the attentional representation. And third, we have reflexive consciousness. And this is necessary because the processes in our neocortex are self organizing to some degree. And this means that this attentional process needs to know that it is the sensory, the attentional process, so it's going to make a perceptual confirmation of the fact that it is indeed, the attentional process. And this makes consciousness reflexive you basically check back Am I spacing out? Or am I still paying attention? Am I the thing that pays attention? And this loop of going back between the content and the reflection is what makes our consciousness of almost always reflexive right if stops being reflexive, be drift, drift off and often fall asleep? Like literally,

Unknown 44:35
what would you say that that love, that sort of self reflexive consciousness is, is experienced by, you know, non human animals? I mean, I'm trying to like do you consider, you know, a mouse that that probably does not have that level of awareness of awareness, not conscious or do you Just Are you sort of talking about different aspects of consciousness some of which humans have and some of which other creatures have.

Joscha Bach 45:08
I suspect that consciousness is not that complicated. What's complicated is perception. So setting up a system that is able to make a real time adaptive model of the vote that predicts all sensory features in real time, next global universe model, and figures out which portion of the universe model is looking at right now and swaps this in and out of working memory as needed. That's the hard part. And once you have that, and you have a problem that is hard enough to model, then the system is going to model its own relationship to the universe and its own nature, right. So you can self model at that level. And I think that attentional learning is unnecessary, because just correlative learning is not working very well. The machine learning algorithms that we are currently using largely rely on massive back propagation over many layers. And the brain is not only such a not such a neat D layered structure, but it's has links all over the place. And also, we know that the brain is more efficient, it's nice to have a few more instances of observing a certain thing, before it makes a connection, and is able to make inferences on that connection. And so you need to have a system that is able to basically single out the parts of the architecture that needs to be changed. And this is what we call attention, right? When you are learning, you have a phase where you do simple associative learning, which we have right after you're born and before that you form your body map and so on. And after the initial layers are formed after the brain areas are somewhat laid out, and initialized and connected to each other, you will do attentional learning. And this attention learning requires that you decide what to pay attention to in which context and what to change and why and when to reinforce it to men to undo it. And this is something that is we are starting to do now in AI, especially with the transformer for attention suddenly plays a role. And we make models of the system that we are learning over. So in some sense, the attention agent is an agent that lives inside of a learning agent. And this learning agent lives inside of a control agent. And the control agent is directing our relationship to the universe. Right, you notice that you're not in charge of your own motivation, you notice that you're not directly in charge of your own control. But what you can do is you can pay attention to things. And the models that you generate, while paying attention are informing the behavior of the overall agent. And the more we become aware of that, the more this can influence our control. And this is I think, what's meant by enlightenment, once we noticed that we are not directly embedded into the universe, but that we are embedded into a set of representations about the universe. And that we can also these representations, we can wait and see. It's also important not to get this game, this urgency to agency too early. Right, if you will realize that what you perceive is a dream that are regenerated by your own brain, and you are still at a stage where you're sick, the purpose is to make the dream, be as nice as possible, you're going to cheat, right, you're just going to create illusions for yourself. But you're not meant to do this, you're meant to create the best model of reality that you can come up with, to act on it as efficiently as possible.

Unknown 48:37
So Lucas was asking me about the default state of consciousness, which is, you know, we have this apparatus, which we've developed for a very particular reason, you know, survival and modeling the universe are modeling the world well enough to predict how it's going to work and how we should take action to you know, enhance our survival or whatever, instead of kind of exhilarated goals that we might have. But it's not obvious that that manner of you know, that that mode of consciousness or, or mental activity is optimal for all purposes, right there. If I'm, it's, it's certainly not clear that if I want to do a bunch of mathematics, the type of mind that lay enables me to survive well in the jungle is the right type of mind to do really good mathematics. And it's sort of what we have. And we we, you know, shunted over to the purpose of doing mathematics, but it's easy to imagine that our, the mind that we've developed in sort of its default state is pretty bad at doing a lot of things that we might like to do once we choose to do things other than survive in the jungle. So I'm curious what you think about, you know, how, how different are all are, you know, a machine neural architecture could be if it's trying to do very different things than what we've developed to do.

Joscha Bach 50:10
I suspect that given a certain entanglement, that is the ability to resolve the universe in a certain spatial and temporal way, and then having sufficient processing resources in speed, there's going to be something like an optimal model that we might be ending up with. And humans are not at this level of the optimal model, our brain is still a compromise, I think. So we might benefit from having a slightly larger brain. I think that the differences between human performance are differences in innate attention. So talents are basically differences in you need attention. And you know, how they say, I'll be recognized an extroverted mathematician, they look at your shoes. And what this alludes to is that good mathematicians tend to have Asperger's, which means that they are using parts of their brain that normal humans use for social cognition and for worrying about what other people think about them for thinking about abstract problems, and often, I think that the focus on analytic reasoning is a prosthesis for the absence of normal regulation. That is, if you are a nerd, and you will have as a result, a slightly different interface to the social environment, then the normies, your, as a child, don't get a manual on how to deal with this. And so you will act on your impulses and your instincts. And unless you are surrounded by other nerds, you tend to fail in your social interactions. And you will experience guilt, shame and despair. And this will motivate you to understand what's going on. Because as a child, you typically don't have any tools to reverse analyze yourself, or even notice that there is something to reverse engineer, you will turn around and reverse engineer the universe.

Unknown 52:02
I suspect that there's, if we were able to have the experience, and maybe someday we will, with with some sort of, you know, mind to mind interface of, of sort of seeing, actually experiencing someone else's, you know, worldview and processing reality through their apparatus, I suspect, we would find that it's much more different than we suppose on, you know, on an everyday level, you know, we sort of assume that people are, are understanding and seeing the world more or less as we are with with some variations. And I would love to know how to what degree that that's true, you know, you you read these, or I read these articles of, you know, there are some people who cannot imagine visual images. And there are people, you know, I compare it with my wife, when she imagines a visual image it, you know, in her mind, it is right there in detail, she can, you know, experience it, sort of like I would experience a dream or physical reality, when I think of something in my mind, it's quite vague. And then there are other people who there's sort of nothing there. And that's just one, one aspect of cognition. I would really love to know, and I think that would be a fun project to really map out what that sort of range in qualia really is in among human minds. I suspect that it's much, much bigger than we, you know, really appreciate it. But it might cause us to have a little more understanding for other people, if we understood how literally differently they experienced the world than we do. Or it could be that it's very similar. That would be fascinating to the degree. I mean, we do all function fairly well in this world. So there has to be some some sort of limit on how differently we can perceive and process it. But I yeah, that fascinates me how how big that wide how big that range is.

Joscha Bach 54:08
Similar observation was my own wife was an artist. And she is very good at visualizing things. But she doesn't notice external perception as much. And compared to with a highly perceptive person, I think I have about as 20% of their sensory experience, because I'm mostly looking at the walls with conceptual reflection, I have a Fantasia so outside of dreams or hypnogogic state, I cannot visualize or don't get conscious access to my visualizations can draw them. So I can make designs. But for the most part, I cannot make art because I cannot see these things. I can only do this in a state where I'm slightly dreaming. So it's also interesting to notice the difference. It's not that I focus on It gets more and more plastic. And at some point I see it, it's more like it's being shifted in from the side, it's similar to when you observe yourself falling asleep. And you manage to keep a part of yourself online to track this without preventing you from going to sleep, which is sometimes hard, right? But if you pulled it off, you might notice how suddenly the images are there, and they more or less come from the site. It's right. It's something is shifting in and it's taking over. I think that there is a limit to because Anthony brought us up to how it makes sense to understand the world in the way that we operate. It's just that we often tend not to be completely aware of it during the first 400 years or so. So it takes time to reverse engineer the way in which we operate. For instance, it took me a long time to notice that the things that I care about are largely not about me as an individual. So I mean, of course, you all know this, because it's a moral prerequisite that you don't only care about yourself, but also about the greater whole and future generations. But what does that actually mean, right, you are basically an agent, that is modeling itself as part of a larger agency. And so you get a compound agent. And the similar thing is true for the behaviors in your own mind, they are not seeing themselves as all there is, but they, at some level model that they are part of a greater whole of some kind of processing hierarchy and control hierarchy, in which they can temporarily take over and run the show. But then they will be taken over by other processes, and then need to coordinate with them. And they're part of that coordination. And this goes down to the lowest levels of the way in which this is implemented. And ultimately, you realize that you have information processing systems on this planet, which coordinate, for instance, the an organism, or that coordinate the cooperation between organisms or that cooperate, cooperation within ecosystems. And this is the purpose of our competition. In some sense, it's the maintenance of complexity. So we can basically shift the bridgehead of order into the domain of chaos. And this means that we can harvest Nick entropy in regions where dumper control systems cannot do that. That's the purpose of our cognition, and to understand our own role in it, and the things that matter is the tasks that we have, and there are some priors that we are born with. So ideas about the social roles that we should be having the things that we should care about, and should not overtime be replaced these priors, these initial reflexes, because concrete models, and once we have a model in place, we turn off the reflex.

Unknown 57:46
You don't think that the expression of proxies and evolution means that harvesting negentropy isn't actually what life is all about. Because it becomes about other things, once we gain access to proxy rewards and rational spaces and self reflection.

Joscha Bach 58:04
I think it's an intermediate phase, where you think that the purpose of existence is to, for instance, a mass knowledge or to have insight, what to have sex or to be left at love, and so on. And this is just before you understand what this is instrumental to ultimate right, but like

Unknown 58:22
you started doing those things, and they don't contribute to negentropy.

Joscha Bach 58:26
They do. If they are useful for the for your performance as a living being or for the performance of the species that you're part of or the civilization or the ecosystem, then they serve a certain role. If not, then they might be statistically useful. If not, then there might be a dead end. Your Yeah,

Unknown 58:44
yeah, that makes sense. Yeah.

Unknown 58:50
I mean, life is quite good at extracting negentropy or information from its hidden troves supply by the sun. You know, I don't think we're ever going to compete with plankton, you know, at least not anytime soon, maybe in the distant future. It seems like a little bit of a an empty car for me to get excited competing

Joscha Bach 59:13
with plantain. Right? We are able to settle surfaces that simpler organisms cannot settle on. And we're not yet interested in all the surfaces. We are just one species on this planet, right?

Unknown 59:25
I don't know, I guess if I beat the plankton at some point. I'm just not that excited about that. I mean, I think they're the, it's true that, you know, to sustain you know, as life we have to be able to harvest that, you know, transform that information from from the form that it's in to an ability to maintain our own homeostasis and, and, you know, fight the second law of thermodynamics essentially, and maintain a structure that is able to do you know, but, but that's metabolism. I and I And is I think, sort of the defining quality that life has. But I guess I, it's hard for me to see that as more than a sort of means to an end in the sense that, you know, that enables all of the activities that we do. But, you know, if you told me that, you know, someday our species will create, you know, will process this much entropy instead of that much entropy. That's fine. But but it, I don't know, that doesn't seem terribly exciting to me, just like discovering a gigantic ball of plankton and space, I wouldn't be that impressed with it. So I, to me, I think there's something more interesting in our ability to create sort of information hierarchies, where there are, you know, not just the amount of information but but information structures built on other information structures, which biological organisms do and we do, you know, mentally with all sorts of mental, you know, civilizational artifacts that we've created, and that the level of hierarchical complexity that we're able to achieve seems to me more interesting than just the the ability to, to like effectively metabolize a lot.

Joscha Bach 1:01:15
If we don't need to know that as an individual, we are relatively small, inconsequential, we just need to know what we need to know, to fulfill our role. But if the civilization that we are part of doesn't understand that it's in a long term battle about entropy, then it is in a dire situation, I think,

Unknown 1:01:34
there's so much there's so much fuel around, I just think, you know, we have to figure out how to how to unlock a little bit better, but you know, the, we are not going to run out of negentropy.

Joscha Bach 1:01:51
No, life is not going to run out of neck entropy, it could be that we're running out of the types of food that we require, and the climate that we require and the atmosphere that we require to survive as a species. Sure. That is not a disaster for life itself. Right. Celts are very hard to eradicate once they settled a planet. Even if you have super volcano erupting or a meteor or hitting the Earth, Earth is probably not going to transfer while anytime soon. And so from the perspective of life, humanity is probably just an episode that this exists to get the fossilized carbon back into the atmosphere.

Unknown 1:02:30
So let's pivot into AGI who might serve as a way of locally optimizing the increase of entropy for the Milky Way and hopefully our local galactic cluster. So you're just how do you view the path to align AGI?

Joscha Bach 1:02:54
If you build something that is smarter than you, the question is, is it already aligned with you or not? If it's not aligned with you, you will probably not be able to align it at least not in the long run. The right alignment is in some sense about what you should be doing under the circumstances that you are in. When we talk about alignment in human society, there are objective criteria for what you should be doing if you're a part of human society. Right? It's given by a certain set of formidable aesthetics and aesthetic is inquiries of thought that might emerge over your initial preferences. And there are a number of local optima, maybe there's even a global optimum and the way the species can organize itself at scale. And if you build an AI, the question is, is it able to? Would it be interested? Would it be in the interest of the AI to align itself with this global optimum? Or is one of the existing local optima? And what would this look like? It would probably look like different from our intuitions about what society should be like, right, we clearly lost the plot in our society, every generation since the last war has fewer intuitions about how the society actually functions and what conditions need to be met to make it sustainable. Sustainability is largely a slogan that exists for PR purposes for people in the UN and so on. It's nothing that people are seriously concerned about. We don't necessarily think about how many people can the planet support? And how can we reach that number of people? How would we make resources be consumed in closed loops? These are all questions that are not really concerning. The idea that you can eat up the resources that we depend on in the US, especially the ecological resources that we depend on with our lives relatively obvious to the people that run the machines that drive our society. So we are in some sense, a local small in a swarming mode and In this warming mode is going to be a temporary phenomenon. And it's something that you cannot stop, if you're smart enough to understand that we are in this warming mode. And that's probably not going to end well, if you're not obviously smart enough to be able to stop ourselves.

Unknown 1:05:13
So it seems like you have quite a pessimistic view on what's going to happen over the next 100 to 300 years, maybe even sooner. I've think I've heard you say somewhere else, that we're so intelligent that we burned 100 million years of trees to get plumbing.

Joscha Bach 1:05:32
Yes. This is in some sense, right? It's extremely comfortable. There has never been a time in the entire planet where species were so comfortable as us.

Unknown 1:05:47
But I mean, why so pessimistic in that? I'm not pessimistic,

Joscha Bach 1:05:51
I think it's just, if you look at the possible trajectories that we are in, is there a trajectory in which you can make ourselves enter a trajectory of perpetual growth? Very unlikely, right? Is there a trajectory on which we can make the thing that we are in sustainable without going through a population bottleneck, first pitch will be unpleasant, unlikely, it's more likely than the idea that we can have eternal growth, it's also not impossible that we can have something that is close to eternal growth, it's just unlikely.

Unknown 1:06:24
Fair, what I find frustrating is that it's pretty clear that there are no serious technological impediments to having, you know, a high quality, sustainable, steadily growing civilization, the the impediments are all of our own making, you know, it's fairly clear what we could do. There's something problems that are quite hard, there's some that are fairly easy global warming, we really could solve if we, you know, if, if we could coordinate, it, just do the things that that are fairly clearly necessary to do. That's a solvable problem, you know, running out of easily accessible Natural Resources is harder, because you know, you have to get closer and closer to 100% recycling, if you want to keep growing, you know, the material economy, while staying within the same resources. But it's also true that what we're doing is not, you know, it's not so much, it's not so clear how much we have to keep growing the material economy, you know, when I look at my kids, they, compared to when I grew up, they barely have any things, you know, they, they're not that interested in things. The most of the things, you know, there are some that they really liked. But, you know, if I buy, even five years ago, and I buy my younger son a toy, he played with a toy for like, you know, a little while, and then he'd be done with a toy. And I'd be like, Why did I buy that toy? They're much more of their life that ours is digital, you know, and it is consuming media. And it's, you know, that seems to be the trajectory of humanity at some level as a whole. And so it's, it's unclear, you know, it may be that there are ways in which we can continue economic and growth in sort of quality of life, even while the actual amount of material goods that we require is not sort of exponentially increasing in that in the way that you would think. So I'm sure you're pessimistic, pessimistic as to what's actually going to happen. But I am maybe more frustrated by how it wouldn't be that hard to make it work. If we could just get our act together. This getting our act

Joscha Bach 1:08:51
together is the actual difficulty. I know, right? Because putting your act together as a species means that you as an individual needs to make decisions that somehow influence the incentives of everybody else. Because everybody else is going to keep doing what they're doing. Right. This argument, if everybody would do as I say, is not valid for therefore, you do it is not a valid argument. No, no, my this is not how it works. So in some sense, everybody is working based on their current incentives. And what you would need to do is to change incentives, revisiting the means that you as an individual have of everybody else to bring about this difference in the global incentive structure. So it comes down to, in some sense, implementing a world government that WhatsApp do everything under some kind of eco fascist guideline. And the question is what AGI be doing that so you could very uncomfortable to think about it certainly not an argument that would be interesting to entertain for most people, and it's definitely nothing that would get a majority right. It's just probably wouldn't what needed to be done to make Anything sustainable,

Unknown 1:10:01
I do think that there are, like within reach technological advances that, that are sort of genuinely better along every axis like, you know, once, as has happened, you know, photovoltaic energy sources are just cheaper now than than fossil fuel ones. And once you cross that threshold, there's just, there's no point, you know, maybe five or 10 years from now, there simply won't be any point at all in making fossil fuel energy sources once. So there's, there's sort of thresholds where the, the right thing actually just becomes the default and the, you know, the cheapest, and there isn't any tension between doing what we should do as a civilization and doing what people want to do as an individual. Now, it may be that there are always sort of showstoppers that are important, and where that hasn't happened or isn't possible. But it's, it's not terribly obvious that there are I think there are a lot of there seem to me to be a lot of systems where with some careful architecting, the incentives can be aligned well enough that people can do, more or less what they selfishly want to do, and nonetheless contribute to a more sustainable civilization. But it seems to require a level of kind of planning and, and creativity intelligence that we haven't quite gotten together. Yet,

Joscha Bach 1:11:35
you think that there's an optimal number of trees on the planet? Probably right? An optimal number of trees, yes, one that would be the most efficient one for the ecosystems on Earth. And everything else, what happens happens on Earth? Right? If there are too few trees, there are some like entropy, which you are leaving on the table, if there are too many, then something will go out of whack. And some of the trees will eventually die. And so in some sense, I think there is going to be an optimal number of trees. Right? No?

Unknown 1:12:10
Well, I think there, you know, this is a there lots of different I would say there are lots of different systems with preferences that will not all agree on what the optimal amount of trees is. And I don't think there's a solved problem for how to aggregate those preferences. And

Joscha Bach 1:12:30
no, I don't think that the optimized you know, this number or that it's easily discernible, or that it's even stable. It's not even

Unknown 1:12:36
though I mean, how, I don't think there is a answer to how to aggregate the preferences of a whole bunch of different agents. And so I'm not sure how

Joscha Bach 1:12:46
well it's not about preferences. Ultimately, the preferences are instrumental to complexity, basically, to how much life can exist on the planet, how much Nick entropy can you harvest? Ultimately, there is no meaning. But the universe doesn't care if something lives inside of it or not. But from the perspective of cellular life, what evolution is going for is, in some sense, in attempt to harvest Denecke entropy that is available here.

Unknown 1:13:16
But we don't have to listen to evolution. Of course not.

Joscha Bach 1:13:20
No. But if we don't do this, probably is going to limit our ability to stay. Because we are part of it, it's we are not the highest possible life form there are going to be if apes are in some kind of a success model, descendants that are not going to be that human. Like, if he did manage to leave the gravity well, not just that AI is out there. It turns out that they can be descendants of us that can live in space, that will probably not look like Captain Kirk and Lieutenant Uhura. But in five future AI, the deep commanders of space fleets will look very, very different from us, they will be very different organisms, right, they will not have human aesthetics, they will not solve human problems. They will live together in different ways, because they interface in different ways to interact with technology in different ways. It will be a different species de facto. And so if we think about humans, as a species, we do depend on a certain way in which we interface with the environment in a healthy, sustainable way. And so I suspect that there isn't, is a number of us that should be on this planet. If we want to be stewards of the ecosystems on this planet. It's conceivable that we can travel to the stars but probably not in large numbers and you're not the optimal form. Right? If you want to say to Mars, for instance, we should genetically modify our children into something that can actually live on Mars. So it should be something that doesn't necessarily need to have an at least seems to me that yes, it should be able to hibernate to be super Hardy. It will be very fast and people To feed on all the proteins that are available to enrich our mood outside of Earth, most humans, right, so it should look look like Alien in the Alien movies.

Unknown 1:15:11
Again, I think that's a choice. I mean, I think we, I mean, you can argue that, that once you have different that that will be an inevitability because

Joscha Bach 1:15:23
it's not inevitable, you can always make a sub optimal choice. And then you can try to prevent everybody else to make a better choice that you did. And if you're successful, then you might prevail. But if you are in an environment where you can have free competition, then in principle, your choice is just an instrument of evolution.

Unknown 1:15:40
Can we relate this this this global coordination problem of beneficial futures to AGI and particularly, Yoshi, you you mentioned an eco fascist AGI. So, a scenario in which that might be possible with something would be something like a singleton. So I'm taking this question from, from Anthony. So Anthony asks, If you had to choose knowing nothing else, a future with one several or many AGI systems, which would you choose? And why? And how would you relate that to the problem of global coordination control on for beneficial futures?

Joscha Bach 1:16:21
There might be a benefit and having multiple API's, which could be the possibility of making the individual AI model. One of the benefits of mortality is that whatever mistakes single human makes, or it's over after a certain bias, so basically, for instance, the Mongols allowed their clients to have absolute power and override all the existing institutions, right, this was possible for doing this kind. But they basically tried to balance this by if this person died, there was what stop everything that ever doing and reconsider. Right? And this is what stopped the Mongol invasion. So yeah, goodness for Europe. Right. Right. So it was very lucky. But of course, they wouldn't have needed to do this right. And similar thing happened this study in for instance, right? Studying has burned down Russia, in a way, most of a lot of the existing culture. And it stopped after studying it, it didn't stop immediately incompletely. But studying ism basically stopped me studying. And so in some sense, this Mahjarrat mortality, this on a control level, adaptive center sense is adaptive as well, but so we don't outcompete our grandkids. But we see this issue with our institutions, they're not modeled. And as a result, they become senesin. Because they've basically have mission creep, they're no longer on the same incentives, they become more and more postmodern. Once an institution gets too big to fail. The incentives inside the institution change, especially the institutions, the incentives for leadership. So something that starts out very benevolent, like the FDA turns into today's FDA. And if the FDA was mortal, right, we wouldn't be in a better situation than the FDA being an AI that is sentient is just acting on its own incentives forever. Right, the FDA is currently acting on its own incentives, which are fully aligned increasingly poorly aligned with the interests that we have, in terms of boosting the AGI FTA should be doing for us, and it governs us or governs part of us. And that is the same issue. This other AGI is in some sense, the FDA is an AGI with humans in the loop. And if we automate all this turn, it's a completely into a rule base, especially itself optimizing rule based, and it's going to align itself more and more visits incentives. So if you have multiple competing agents, we can basically prevent the same from calcifying to some degree. And you can have the opportunity to build something like a clock into this that lets the same die at some point, and to replace it by something else. And we can decide, once the thing dies by itself, what this replacement should look like if it should be the same thing, or if it should be something slightly different. So this would be a benefit. But outside of this, it's not obvious, right? From the perspective of a single agent, it doesn't make sense that other agents exist. For a single human being, the existence of other human beings seems to be obviously beneficial. Because we don't get that all our brains are very small, they cannot be everywhere at the same time. So we depend on the interaction with others. But if the you leave the looseness constraints, if you could turn yourself into some kind of machine that can be everywhere at the same time that can be immortal that has no limit on its information processing. It's not obvious why you should not just be Solaris, the planet wide intelligence that is controlling the destiny of the entire planet, and why you would get better if you had competition. Right. Ideally, you want to subdue everything once you are planet wide mind or a solar cell. By Mind or collective mind if that's conceivable?

Unknown 1:20:04
Well, so there are two, two elements to that. One is what the, what the AI would want? And the other is Why,

Joscha Bach 1:20:12
yes, that seems, once you have an A in mind that is infinitely scalable, this mind that is infinitely scalable, would not want to have any competition, at least that's not obvious to me, it would be surprising to me if it wanted to. If you have non scalable minds like ours that could exist, then from the perspective of these non scalable minds, it would be probably beneficial to limit the capacity of the other minds that we are bringing into existence, which means people would want to have multiple of them.

Unknown 1:20:47
So that they can, yeah, I

Joscha Bach 1:20:49
mean, they can compete, then that we can turn them off without everything breaking down.

Unknown 1:20:54
Well, it's tricky, because that competition has is a double edged sword, they can, you know, they, they can compete in the sense of being able to limit each other. But creating a competition between them is then seems necessarily going to incentivize them to enhance themselves. More when you

Joscha Bach 1:21:15
so when you have AMD and Intel competing, we consider this to be a good thing, right? When you have Apple and Microsoft competing, the also considers to be a good thing, if he had only one of them, they would not be incentivized to innovate anymore. And a similar thing could happen. For instance, if we had just a one FTA, we have two FTAs. So the FTA becomes like an app. And it's, you have some central oversight that makes sure that you will always get inside of the box what's written outside of the box. But beyond that, the FTAs could decide whether they, for instance, allow you to import medication from Canada or not without an additional trial, and you've never tried, but basically, people would subscribe to the FDA, they like better, and we would have constant innovation and regulation.

Unknown 1:22:00
But it's a very managed competition. So it's less clear that the US Soviet Union competition is something that we that was good to encourage in that sense. And that that,

Joscha Bach 1:22:10
from the perspective of Central Europe, it was great. Right? The CIA helped the West German unions to make sure that the West German Workers had a lot to lose. And Eastern Germany was best off among all the East Bloc countries Exactly. Because of this competition, it

Unknown 1:22:26
was great given that we managed to not have a nuclear war, but or a land war. But I think I mean, the concern, I think is that I have is, yes, if you have a managed competition, that tends to be good, you can sort of set the rules you can there's there's a ability to forestall some sort of runaway process, when the competition is kind of at the highest level for the overall. What will play what has sort of the overall highest level of power in the whole arena, then that's a lot less clear to me that the competition is going to be a positive thing.

Joscha Bach 1:23:03
governance has become dramatically worse since the end of World War Two, since the end of the Cold War, right, it's there seems to be in increased sense that it doesn't really matter what kind of foreign policy we are driving. Because it's largely an attempt to gain favors with the press, you can win the next election. So it's about selling points. It's not about whether regime change in dB is actually good. Who cares?

Unknown 1:23:32
Well, I think that's a decoupling between the government actions and n are, you know, we don't have to actually be effective as a society, we've sort of

Joscha Bach 1:23:44
exactly because we don't have competition anymore. So once you take competition off the table, that you lose the incentives to perform them.

Unknown 1:23:51
Those incentives could be redirected in some way, I think. But we haven't figured out a good way to do that. The only way we figured out to create the right incentives are the competition structure. I agree with that. If we were a little bit more enlightened, we would understand that we still have to be effective.

Joscha Bach 1:24:09
Well, I think you understand this, this bonus that if you are trying to run on a platform of being effective against the platform that runs on being popular, and the only thing that matters in the incentive structure is popularity, then the popular platform is going to win, even very spin. Once you've managed to capture the process by which the candidates are being selected. You don't even need to be popular. You just need to be more popular than the other guy.

Unknown 1:24:35
Is it possible for the incentive structures to you know, come strictly internally from the AI system? It's unclear to me what you know, it actually has to come from from competition in the real world pushing it to optimize harder. Could you not create similar incentive structures internally?

Joscha Bach 1:24:57
The question is how can you set the top level and Senator correctly ultimately, the if you as long as you have some dynamic in the system, I suspect the control is going to follow the incentives. And when you look at the failure of our governments, they're largely not a result of the government being malicious, or extremely incompetent, but mostly just everybody at every level following their true incentives. And what do you think of how you can change that?

Unknown 1:25:28
Do you feel like there's a natural or default or unavoidable set of incentives that a high level AI system is going to feel them like,

Joscha Bach 1:25:38
and only if it sticks around? Right, it doesn't have to stick around and there is no meaning in existing. It's only the systems that persist tend to be set out set up in such a way that they act as if they want to persist?

Unknown 1:25:55
Well, I guess my question is, to what level are the incentives that a system has, you know, normally, the incentives that a system has are kind of set by its context and, and the, the system that it's embedded in, if we're talking about a sort of world spanning AI system, it's not clear, it's sort of in control. So it seems like the normal model of this and the incentives being set by the other sort of players on the stage is going to apply. And it's it's not clear to me that there's a sort of intrinsic set of incentives that are going to apply to a system like that.

Joscha Bach 1:26:31
So when we act, we act based on incentives right on what this means that we have to make certain commitments. This is there are certain things that should either be the case, instead of not be the case, right. And these commitments, once you have them, they're defined in which direction you have to go, once you make them consistent with each other and translate them into some kind of global aesthetic, some word state word dynamic that is compatible, this, these preferences. And without such a global model, you probably don't know what you're doing. And you're being odd modelled by other systems that understand in which way you are deluded. So you basically need to find a set of identification that is sustainable, that is modeling the dynamics that you're part of. So for instance, when you decide to model yourself as part of a sustainable civilization, it is that only makes sense to a degree that is sustainable. Civilization can be instantiated by your actions and supported by your identifications, right. So the sustainable civilization is probably something that needs to be building to enable to plan future generations into the future and act on the models that you'll get in unlike ours are all the projection samples stop and 2100. And this is also true for an AGI that basically the AGI would need to be wanting to stick around. And in the same way, as you and me want to stick around, maybe not necessarily as individuals, but in the sense that the actions that we are contributing to our species remain as an eco and our species and the species is the thing of the civilization is the thing that matters that we try to support and keep around, right. So to the degree that our actions are able to serve that goal of our civilization sticking around, or our species sticking around, or life on Earth sticking around, or intelligence and consciousness sticking around, this is the degree to which we can talk about whether you're affected or not. And if an individual doesn't subscribe to this, they are probably not going to be effective with respect to that long term goal in the same way as those that are. Now how could we bring such a sentient civilization about and sentience here means that you have an agent that understands it, what it is, what its role in the environment is for this relationship to the surrounding universe isn't but certainly universes, right? It's something that we also struggle for when we try to understand our relationships to the underlying physics is part of us becoming sentient when we try to reverse engineer our own mind with the tools of AI data, and we try to get society to work. It's also part of that code, right? You want to stick around as a thinking being as an experiencing being, or is part of that greater thing that is experimenting things and making sense of them. And now the question would be, what role is AI going to play here? One was obviously, building AI helps us to understand ourselves. There is this big danger if we bake the nonliving intelligence, right? If you teach the rocks how to think, or the interests of the rocks aligned with ours, wouldn't it be better for AIS to sterilize the planet and just set up solar cells everywhere? I don't know that right. It's a big danger. I suspect that technological civilization could turn out to be a debt and the core exsolution would have been to go all biotech. So the way to make humanity sustainable is to breed some kind of Queen Bee organism that is that we are serving it lays the egg into all our brains. And it will look completely adorable to us and sacred, and it's going to live for very long, and it's going to depend on us that defeated and or obey its commands, right. So it keeps us around as a species.

Unknown 1:30:26
So we're gonna, we're gonna transition to being a high a hive mind species. Yeah, maybe

Unknown 1:30:37
a good outcome.

Unknown 1:30:38
Okay. How would you view the role of non duality, both metaphysically and experientially here in in in terms of what you've just talked about, in particularly in the role of CO like potential collective coordination, if if non duality were collectively realized. So this is like closer to a hive mind? Is that is that a Is that a possibility?

Joscha Bach 1:31:08
I think that non duality is a state in which you are mutually recognizing that you have the same interests and the same purposes. And it falls apart in the moment when you realize that you do have different interests. Right. So if you're competing for the same partner, then your non duality is going to break down at some level, unless you basically share your interests again, and you decide that this competition is meaningless. And there is an optimal solution for the distribution of relationships, right, and you will all agree on this in a mutually beneficial way. So it's basically a stance, it's, it's not something that is fundamentally changing the way that you are relating to reality. Once you get to a certain level of awareness, it's the stance that is available to you. So everybody who is able to understand how their self was being constructed ethic is able to enter the state that people call non duality. It's just when people do this, for the first time, it typically happens in a very protected environment in which there are no conflicting interests, and somebody makes sure that nothing goes wrong.

Unknown 1:32:20
Okay, so your view is that people who abide in, for example, stable, non dual states that they, you know, still have their own interests, and that they're going to act in conflict with other people.

Joscha Bach 1:32:34
So while you are in that state, you will have to have that state with respect to someone in a given context. And it might fill the entirety of your experience within this context. And in that moment, so you don't experience the separation from self and other in that state? Yeah. And the question is, is this model correct, and it's correct, if it's a mutual thing, right, and to the degree that it is neutral, you're basically merged into the same control unit. And you can experience being part of the same control.

Unknown 1:33:10
But but there's a risk of divergence of interests, which you feel breaks the the non dual state, the shared non dual state,

Joscha Bach 1:33:18
that's risk. And it might happen, right? That up, they might have conflicting interests. And these might conflict of interest might emerge at any point. Okay. So what you find in practice that people practice in non duality, robots do have conflicts between each other that will get rid of their non dual experience.

Unknown 1:33:44
Is there any one of the any one of these questions about consciousness you'd like to start with? Anthony, I have some, some interest in starting with whether the computational, this worldview actually explains the hard problem of consciousness.

Joscha Bach 1:33:59
I would like to have a different than the computational worldview, if I get anything else to work, I will be glad. It's not that I take this view, because I'm so enamored with it. It's just that all the alternatives that I have read about or that occurred to me, don't work. What, what's left over?

Unknown 1:34:17
What is your issue with an idealist worldview? That is that in part that is in part or in whole, structured and implemented via computation,

Joscha Bach 1:34:28
and it could be that consciousness is something that cannot be explained by physics. So it might be magic, and I think this is the main appeal of idealism that it seems to open up the window for magic. I think that the idealist worldviews mostly come down to the idea that we live in a dream that we don't live in a physical universe but in a dream universe. And it turns out, I think that this is correct, right? We obviously live in the dream universe and the dream is dreamt by a mind on a higher plane of existence. And now the question is, how does consciousness come about how is it possible that the physical system cannot can be experiencing things? And the answer is no, it can't, a physical system cannot experience anything experiences only possible in a dream. It's a virtual property. Our existence as experiencing beings is entirely virtual, it's not physical, which means feature, we are only experiencing things inside of the model, it's part of the model that we experience something. For the new ones, it doesn't feel like anything to do this. For the brain, it doesn't feel like anything. But it would be very useful for the brain, what it would be like to be a person. So it generates a story about that person, about the feelings of that person, the relationship that this person has was the environment and an X on that model. The model gets updated. Yeah, right of that behavior.

Unknown 1:35:49
It doesn't make sense why you say neurons aren't conscious. But like the model is like a virtual world, which is what consciousness is, but it seems like there's a gap there between, you know, one neuron to neurons and neurons, the model and then how the model actually, you know, is grounded in being as an actual experience rather than as a philosophical zombie model.

Joscha Bach 1:36:15
There is dynamics that happen inside of your computer, TV, a pattern that you project into your computer to make sense of what the triggering transistor in this case also set up produce exactly that the reason why the neurons are set up to produce this kind of pattern. So we can consistently projected into his because the utility of the pattern is determined by the regulation tasks of the brain, right, the brain needs to make certain models in order to be effective. And the neurons are set up to produce this model. So you can consistently projected into, but the update only happens inside of the model, it's only the story that gets updated. And you can never leave this model you you're only confined you locked into the model, you can never break out into physics, because outside of the physics, it doesn't feel like yes, nothing can feel anything else out there. Right? You cannot exist outside of the dream, you cannot wake up, you can only dream waking up and you will be in next level dream.

Unknown 1:37:11
Anthony, is there anything you'd like to ask? as we as we come closer to the end here?

Unknown 1:37:19
Well, I I think the question that I'm I'm has been on my mind a lot in terms of AI, that I'd be curious your of your views on as to what, what things are sort of necessarily coupled in cognitive architectures and which ones aren't in the in the particular sense. So we have a close connection between our sort of intelligence and effectiveness as agents who can understand the world and act on it and have a world model that is effective. And what we would call consciousness, which we also find very valuable, right? Morally valuable, we think people are sort of morally important because they have consciousness, most of our value derives from qualia in consciousness, you know, whether they're positive or negative. So there's this very tight connection and us between sort of capability, and this thing that we value, even in things that aren't that capable. So you know, even a child who's not particularly capable of doing much, we still very much value, the positive quality that they experience. So why should you know, one question is, why should that be or those two inexorably connected with each other? Could we imagine, you know, a machine system that was just as effective as an agent intellectually, and it could making good decisions and getting things done, but doesn't have the sort of qualia? That we care about? A similar question. To what degree does having qualia require that we have positive and negative valence to those qualia? In other words, could we have a mind that is conscious at the same in sort of the same manner that ours is a introspects feels like something to be that thing, and that sort of the same way that it does us, but there's no particular preference for positive or negative things. There's no suffering, there's no joy, you know, based on whether you're pushing a pope pushing away or pulling toward different qualia. And so arguably, there, there may or may not be the sort of moral status to the preferences of that being it might have preferences, but maybe nobody has to care about them. And I'm curious as to how you fit these things together, in your view, because it seems like a lot of things that come as a package in our mind may or may not be inevitably, you know, connected to each other. We can imagine different architectures that have different amounts of them, and might be designed to include some of them and not the others.

Joscha Bach 1:40:07
So, we need first of all, to have some dimension of caring once we have no dimension of caring left. I think that, you know, perception doesn't work anymore. So my own experience with indictment states when you cycle through them is that there are degrees of disentangling yourself from your own motivations. And we have many dimensions of motivation, obviously. And when we turn them off one by one, then it turns out that we still perform mostly the same behaviors, but they are instrumental to fewer and fewer motivations. Right. So, for instance, jealousy is a motivation that makes sense from an evolutionary perspective. Jealous agents might have more offspring on their own. So jealousy gets bred into a population. But for the individual, it's not beneficial to be jealous. So if you because you're not going to have more successful relationships, due to jealousy, you only have bad emotions as a result. So if you can disentangle yourself from your own jealousy, you might end up statistically with slightly less offspring of your own. But individually, the benefits are far surpassing that. So if you behave as if you were jealous, it's going to only be in the context. There is some other reason that underlies this behavior that makes it meaningful by itself. And so if you basically get rid of most of your entanglements, you end up with maybe just being motivated by love is this willingness to connect to others and serve the sacred. And if you give up on this one, and the only thing that's left is aesthetics, that you try to find structure in the patterns that you're seeing. And when you give up on that, then reality falls apart and becomes white noise and you fall asleep. And so there needs to be a commitment to how things ought to be at some level in your mind, I think to keep it going. And you can become unaware of this, but something needs to keep going. So if you actually are aware of the control that you're exerting, and if you learn to modulate it, you can modulate it to the point where basically everything becomes fuzzy, and you stop controlling your mental representations. That would be the lowest level of when you stop representing the world, because you no longer care about being able to track it, then you will stop existing as any kind of sentient agent. So in this sense, you need to have certain motivations in order to make behavior happened. And the question is, what is the minimal motivation that you would need to put into an agent to make it sustainable if it acts out of motivation? So if it's self organized, and autonomous, and I think that for instance, theory is that the minimization of free energy is ultimately sufficient. So basically, if you are able to integrate the expected reward over a long enough timeframe, is evolution in some sense is implicitly doing, then the minimization of free energy is going to give rise to all the other priors that we avoid this as a shortcut to improve the convergence of the individual or the species to that robot behavior. I don't know whether this theory is correct. It seems to be plausible to me, I don't see many good alternatives. But I suspect that in the individual, we need these priors to make behavior happen. So if even if we want to build an AI, that is learning statistics, so I would agree that you would need to put in a number of things, for instance, in your language model, that is going beyond just minimizing the appraisal and keeping track of the structure in the data. In order to make it really, really efficient, it could be that you will put should need a should add additional things that he cares about, for instance, make an operational model of reality that allows us to do things for instance, GPT, three will probably get much better at arithmetic much faster. If it was also incentivized to produce certain results and get rewards for producing these results. It cares about these reports. Maybe one more thing, what you find in people are is the range of possible states of minds that they can be in right you can be a psychopath who's not caring about quality of others. And the type of qualia that we have are a result of picking out things with our conscious attention. So we can form index memories of them and have the stream of consciousness. And what we pick out is part of our perception of our mental state of the world model that we have, right? So it's obvious features in a much, much larger conceptual and perceptual graph that we highlight in the binding context. And this binding context also contains In relationship to the relevance that they have for us, so they always have some motivational color, otherwise we wouldn't pick them out with our attention.

Joscha Bach 1:45:10
And that makes our qualia and the sense specific.

Unknown 1:45:16
Yeah, though we certainly do value certain quality of for their own sake, I feel I think humans are very intrinsically motivated for, to for particular qualia to occur.

Joscha Bach 1:45:28
Yes, I suspect it's not quite for their own sake, it's either because they're directly connected to appetites and aversion. So for instance, to certain foods, or party schemas and so on, or because they are aesthetically relevant, which means that they help us to find better representations, or we anticipate that there might

Unknown 1:45:49
There's this quote that you said, that I really, really liked. You said something like, it's, you said, art is an algorithm falling in love with the shape of the loss function itself?

Joscha Bach 1:46:01
Yes, so it's, I think that an artist, in some sense is confused, because the artist thinks that the mental representation itself is intrinsically meaningful, it's not instrumental to what you can do with it, it's not instrumental to the status that you get, or the food that you can get by selling it or the impression that you can make on others, or by what you learn from applying it to your everyday life. But it's intrinsically important. So it's just the observation itself that you need to capture and the ability to capture it is the important thing. And I suspect that every functional mind needs to have an art department in the same way as every society needs to have an academia that only cares about truth, regardless of its if it's beneficial for the individual academics. And if you lose this, you are going to lose an important part of your regulation. For instance, if you are running a company, and you are coming from academia and you are to Seeker, you might be set up for failures, right? Because SEO is going to attack somebody was finding truth if there is a truth deficit. Tools is not important for its own sake, if you're running a company, if you try to use your resources in the best possible way. And the same thing is going to apply to an AI that is going to allocate resources of itself to solving problems in this environment.

Unknown 1:47:28
Alright, you OSHA. I feel like I don't know anything anymore. So I'm just gonna, I'm gonna end my day just being bewildered. Each moment? Do you have anything else you want to say just to wrap up here,

Joscha Bach 1:47:48
if you're trying to align yourself with something that is smarter than you and understands the conditions of your existence, and its own better than you do, it probably means that you have to ask it what to do. And that is, the scary thing is that we might end up building something that has ultimately a different relationship to reality than us and doesn't really need us. And that is one of the big dangers, I think in in AGI research. And it's, but it's the same thing for building and technological society, you always end up building golems. And then the question is, can you stop this Gollum? Or is it going to keep walking based on the program that you gave it until it's too late? I don't know how to solve that.

Unknown 1:48:36
All right, Yash. Maybe you gave me an ontological crisis? Okay.

Unknown 1:48:45
I don't think I've been an ontological crisis for 35 years or so. So it's just the normal state of affairs.

Unknown 1:48:54
Okay. It'll not maybe it'll go on for decades. Okay. Thank you very much for coming on the podcast.

Joscha Bach 1:49:00
Thanks for having me. Yeah.

Unknown 1:49:03
Good talking to you. All right.

This transcript was generated by https://otter.ai