Unknown 0:01
Hello everyone. Can you Can everyone see my screen?

Unknown 0:07
You can see your screen. Yes. Excellent.

Unknown 0:11
Great. So, my name is Daniel Greenberg. Today we're going to be talking about self organization. biological and social agents are very different from our present approaches to design artificial agents, technological systems are structured constructed from outside then they extend the part of the world with known functionality by 14 is deterministic substrate into record functions. This is however, this is true whether we are building a bicycle in a workshop. We're learning algorithm in a software development environment. However, biological systems are growing from inside out the organized an indeterministic substrate with unreliable properties into a structure that converges to serving the required function and which will even self heal and regrow when they are being damaged or disturbed. Today we will be exploring this dichotomy and how it applies to technological systems especially artificial intelligence. So, our first presenter today will be Professor Christopher fonder Wallaceburg. Today professor from the funder malzberg is a senior fellow at the Frankfurt Institute for Advanced Studies, and a visiting professor at the Institute of neuroinformatics neuroinformatics at ETH Zurich. Previously, he served as a research scientist at Max Planck Institute in Copenhagen, and professor of computer science, neuroscience, physics and psychology at the University of Southern California. And as director of the Institute of neuro Informatics at Bocconi University, he has founded two successful companies and has received many awards, including Pioneer Award of the neural network Council, IEEE, and the Hab award of the International neural network society. Christoph The floor is now yours.

Unknown 2:03
Okay, thank you, can I share my screen?

Unknown 2:08
Yes, it should be. I will stop my show.

Unknown 2:15
Continue. Okay. We go. So first, I would like to discuss the how to determine the information content of the brain and of the environment with which the brain is dealing. And the right way of going about that is Kolmogorov complexity. The information content according to the information content of the structure is measured in terms of the bit length of the shortest algorithm that creates that structure can create a structure. So let me give you a simple example that Julia set is a very complicated thing, in order to describe it as is you need a literally an infinite amount of information, you can blow it up as long as you want. And it still continues to create more contain more structure. But in order to create it, it needs a few line algorithms, the guts of which are shown on the lower left. The flip side of low Kolmogorov complexity is that the structure it is describing is highly structured, it has high structural regularity, which is again displayed here you can see there is a lot of structural regularity, which never repeats, but you can see the inner coherence of the whole thing. So what about our natural environment? A climate has very low Kolmogorov complexity, otherwise, we couldn't perceive it and science wouldn't work. And I think virtual reality is a very good tool to show that

Unknown 4:15
ordinary looking environments, including the dynamical interaction with a viewer can be created with very little information. So the basis of that is computer graphics. In computer graphics, that's an amazing field that has developed over 20 or 30 years the ability to create very realistically looking scenes and also dynamic scenes. They have created something like an ontology of our visual environment. And I guess you all know how it is done. It is a is a compositional game you start with a representation of a shape In terms of shapes in terms of wire frame models, then you give them surface markings and reflectivity, you transform them by noun roles into a scene in position them in the scene, you're you your project the scene was projective geometry into a virtual camera you illuminated. So, that is something that can be done with a few gigabytes of program code. Now, we all learn in a very deliberately designed, simple environment and nursery. And although this nursery is very limited in terms of numbers of samples and complexity, we later walk out into the world and can reflect it represented in our brain. Now, as I said, to generate this kind of to simulate if one cared to do that, that kind of environment including the social interactions, it would take a few gigabytes of a program like a computer games program, virtual reality program. So, the Kolmogorov complexity of our environment as far as is needed for learning is gigabytes only. Now, let me remind you that at least two psychologists the speed or the rate at which we pick up information into our long term memory is a bit of so per second so that over your whole lifetime you pick up a gigabit if when I first heard that, I found that offensive to the rich the richness of my inner life, but turns the other way around and say it takes a gigabyte to create the world as I know it to to represent it. Now, the brain is a very complicated thing, a simple estimate of the amount of information you need to describe the wiring is a petabyte and is 15 bytes is a little computation on the screen arrived at that by but as they come the Kolmogorov complexity of it must be very low, it takes one gigabyte of genetic information to create an organism like mine, including the brain, and as we saw, it takes a few gigabytes to train it to at least some level of competence. So, the Coronavirus complexity of the brain is very low. So, that means the brain is highly structured and I think this is the quarry theory has to shoot for to describe the particular kind of structure that is dominating the brain. The question arises what is the Kolmogorov algorithm by which the brain is actually created

Unknown 8:22
Okay, the as I said, the brain is dominated. Now, here's my slide, the brain is the result of self organization of course, where the genes play the role of parametric control and and likewise the sensory signals they just influence this process of self organization, which however, is totally dominated by the structure that we just concluded must be structuring it. So, the rain is dominated by attractor patterns. And see that in in analogy to crystals or to touring patterns, if you have heard of them to soap bubbles are the Golgi apparatus that is in all the eukaryotic cells, all the cells of your body, those those structures arise by the more or less chaotic interaction, dynamic interaction of the building elements of those systems. These patterns emerge as one as one called Seven speaks of emergence, they just arise because they can self stabilize, they can prevail in a dynamic game. So that poses the very important question what are the emerging patterns in the brain? There is, thank goodness, a very good paradigm for that, that has been studied for two years ago very intensively. I must say it was the middle of this with dozens of different types of experiments done on frog and fish. And the question is How come that the fibers that grow out in at some stage in the embryo from the from the retina on the left on the left and the grow out to target structures in the brain, the optic tectum for instance, here on the right, how come that these fibers, which at least in some species stand out in a rather random pattern, order themselves in over some time till at the end, you have a beautiful picture

Unknown 10:51
appearing here and the tectum when a picture the sun into the retina, and a conic connectivity pattern when neighboring ganglion cells in the retina connect to neighboring cells in the tectum. How come these fibers know where to go, there was a handful of theories, all of them died, given the enormous flexibility of the system, its resistance to experimental interventions and quirks of natural development. And the one that survived and I was one of the people who proposed it with my friend David Wilshaw and Alexander Heisler is network self organization. So the claim is that is the Kolmogorov algorithm of the brain. And it was like so in network and initially more or less random network creates signals, the signals act back on the network by synaptic plasticity, and this loop is initially unstable, continues until a network structure is reached, that stabilizes itself via the segments that create signals that stabilize that same network and ready not to pay is just one example of that. So by some leap of faith, one has to see or if you don't take it as a logical conclusion, one has to see the structure of the brain as an overlay of lots of self organized network patterns. These attractor networks are characterized by two properties one is the consistency of different pathways, a single pathway can only grow if it gets co operative help from other pathways coming from the same source going to the same target cooperativity. And this is bridled in by a sparsity constraints versus remaining limited number of inputs to the same neuron or outputs from the same neuron. That's a simple characterization of attractor networks. So the idea is that the brain is an overlay of lots of attractor nets, each having its own support as a set of, of neurons. And each time that sort of neuron is active, it works a little bit on its connectivity until it has reached attractor structure, and you're on can be part of a number of attractor nets.

Unknown 13:40
So the central thesis towards I have been driving is the emergence nets, self organized nets are the brain spires. And this is a very bold, it took me a while to sort of put my belief behind this. This is a very bold statement of course, saying that the mechanics or networks of organization is at the base of the structure of our mind, the structure of our brain, that is one half of that hypothesis and the other one is the structures that arise by this mechanics are a powerful bei bias to understand the environment. Any statistical learning mechanism needs to have a very strong bias, It tunes it to the phenomenon that is to be learned from and so the idea here is the conclusion here is that the bias in our brain is network SOC self organization. The Attractor nets are the data structure of the mind they they form a construction kit for mine states that are the Lego blocks of the mind the chunks of cognitive theory, and the syntax the rahmah under which they combine into each other is any combination of of CO active networks has to form a stabilized a a self organized a a attractor net, that would be given enough time this table on the self organization is in principle a very simple system. Let me just give a simple illustration to make it more concrete face recognition that was the base at the base of two companies I've co founded in the past in California and in Germany successful companies. So, the idea is the image of an object or a phase enters primary visual cortex as we all know, as a 2d array of local feature detectors, which are as we also know, connected laterally connected by short range connections. So, it is a tiny step from there to assuming that what the input image activates is local connectivity fragments fragments of connectivity, which seamlessly blend into each other to represent a whole phase one order to record in in order to recognize it, you need a model of that phase in another part of the brain fusiform complex. And in order to establish the relationship the similarity relationship you need fiber projections between primary visual cortex and the the inferior temporal context which links corresponding paths to each other. These projection paths, networks have to switch as quickly as the images change in the primary context. They're called shifter circuits by child's endless and by David finessing. Now, let me just point out the whole structure here that arises in a fraction of a second when you look at a phase is an attractor network is composed of lots of little net fragments that had been previously prepared and that fuse into each other to form this representation. So, let me let me go one step further and submit the idea that we comprehend objects by linking them sensory objects by linking them to schematic description there are kinematic description that are put together by network fragments that have been trained before. So let me come to my end and repeat my central thesis. Emergent nets are the brains buyers. Thank you.

Unknown 18:09
Thank you very much, Christophe, that was an excellent presentation. So

Unknown 18:17
you want me to stop sharing I suppose.

Unknown 18:20
Ah, yes, you could do. I think the share will be interrupted when Giri starts. So our next presenter is Professor Urich was Jackie. YouTuber. Jack is the big professor of neuroscience at NYU School of Medicine, and is among the top 0.2% of most cited neuroscientists. His work has contributed to the emerging under emerging understanding of the dynamics of hippocampal system and the recognition of the importance of temporal firing properties in the formation of neural Coates is overarching hypothesis is that the numerous rhythms that the brain perpetually generates are responsible for segmentation of neural information and communication across brain regions. He proposed how these rhythms support a brain syntax, a physiological basis of cognitive operations. His most influential work is known as the two stage model of memory trace consolidation, and has been adopted as a framework at several leading laboratories around the world. You're the floor is now yours.

Unknown 19:27
Thank you, Tatiana. Let me use this opportunity to ask a few questions. And then then I go to my real presentation. The first thing that I like to ask is that what makes us so successful as a species? And the answer is that we are the, perhaps the only or very exceptional species that was capable of externalizing brain function. being spread, expand the body and expand the brain. We make machines, clocks, rulers, computers, to help us and obey us not to suffer Judo compete with us. Now, if you take this position and you can ask, you know, how is AI? And and why do we call it artificial intelligence in the first place that always bugged me now what if we are talking about artificial smartness, artificial creativity, thinking artificial consciousness, they just happen that AI survived. And because that was a community agreement, you know, what if, for nine months, named a computer an artificial brain, then we will be having a branch sponsored by governments and we will be all researching artificial brains. Now, what is so special about intelligence? Intelligence in biology is typically defined as the ability of the species to survive and prosper in its own niche. And the emphasis to me is on niche, because it would be unfair to put the human on the water for 10 minutes and then conclude that the fish are more intelligent, that we all all species survive and perform in their own niche. And the question is, then what is the niche for AI? If every intelligent agent requires a, a environmentally, what is AI is defined environment. Now where do we would like to do a artificial version of something anything, we hit need to give it have a good definition of the real thing first. And let's see how it works with intelligence. Like space and time, intelligence is an abstract deduced idea, ideas become scientific only then we begin to measure them measuring these scales, time and space became scientific terms were big began to measure duration and distance by clocks and rulers. Intelligence also became a scientific term that we made up a scale for measuring IQ. Historically, this was introduced as a tool for selecting soldiers during the first fall First World War, for particular goals, you know, goals is a very important thing this was classification can happen only only in the presence of a goal. But today, the goals of AI are very different, you know, different groups of people come up with their own creative definitions and relate them to their own rulers. Unfortunately, there is no agreed common ruler against which we can measure intelligence of humans or the animals, machines and computer algorithms. So when it comes to defining AI, one may wonder this is a fantastic system or a field that can leave alone. or, indeed, as some people say, Don't AI should be inspired by the brain, over the brain scientists like myself should be looking out for AI people like you guys, to see how much we can steal from you to understand the brain. So in order to do that, though, we like to see is what kind of, of of aspects or hypotheses or statements AI is using currently, from brain models. Now, I have to share the screen here. And

Unknown 23:30
there we go. Is interview. And let's go. So we can distinguish basically three extreme versions of how we think about brains in general. One is, I would say is still dominant. And is based on the TiVo is like random organization, he egalitarian have rules, the eye balance, noise, and sleep plays no importance whatsoever. You know, we create robots so they can work 24 hours a day. And we create algorithms to work 24 hours a day, but the humans and other animals sleep also. Now, the whole idea here is that you start with a simple brain and make it more and more complex and the complexity scales with experience, you can call this model tabula rasa and writing in and Christophe very eloquently already pointed out that this is not the kind of brains we are most brain scientists look at. Imagine brains have eternal dynamics, and it's a common word, but we don't really explain what it is. So I give it a try and explain it like this. So the alternative of the the AI like the the tabula rasa, or the blank slate model would be a alternative, which is a autonomous system, a self organized system, which has very different rules instead of egalitarian, it says strong, skewed rules. And sleep is essential feature that is necessary to maintain its own dynamics. And instead of the clean paper, no brains can be pre configured dynamic. And that pre configured dynamic dynamic gives you a enormous realm of possibilities, typically sequences. And learning in this under this model is not a synthesis, it's not putting something into the brain, but I'm masking and matching an existing pattern with the experience. Now, the way how we can summarize these two models in just very simple sentences, you know, this is the famous short summary of of habits that neurons that fire together wire together. In the other end, you can say that neurons that are bound together will wire together, therefore, they will fire together with a much higher probability that neurons that are not bound together. Now, this is a, a very simplified view, of course of the brain. And I have a checkbox here saying which side I prefer. And of course, you would like to know whether there are supports for any of these things. You know, I've never met anybody in my neuroscience community will say, Oh, the brain is a tabula rasa. But there are famous people such as this guy here, who said exactly that, you know, there is not so long ago that there is a notebook then that you have to fill it up with, with experience. He was another giant, John Hopfield, not so long ago said, you know, large number of simple equivalent components. So, this is exactly where a majority of AI people live on. And I'm happy to hear the no contradicting me. And of course, there are new areas of AI that are different than they are more brain inspired. But I think, large and, by and large, even neuroscience is, is following these principles. In contrast, you know, if you are looking for fundamental laws or fundamental rules in the brain, and not too many, this is not like physics, but at least we have one overwhelming rule in the brain. This is called the wave of Fechner law, which describes our subjective perception as a law rule. And there were many, many attempts to show why this is the case. And it's also not only for our perceptions, but it applies to almost everything is, such as short term memory, long term memory, space, duration, perception, and so on. The reason, the fundamental reason, I think, why this log rule occurs, is because the brain has a dynamic range, extraordinary wide dynamic range, all in almost everything from synaptic weights to firing arrays, population synchrony, and so on. They also show a lot of log levels, they show a log normal distribution, or log normal like distributions. And this dynamic is based by a skewed system, which is, as as

Unknown 28:25
Christopher already pointed out, this is not from random or not random organization at all. But connectivity can be described by a log rule, which means that one area of the brain is connected to a handful of other areas in the brain very strongly 50% of these connections are to handful areas, but the other 50% is to a very large number of other areas with weak connections. And this is what it's caused by the Bob rule. So of course, these are interesting observations with all these statistics, but the question is whether these are statistical curiosities only, or they serve something interesting. And I think what they serve is exactly what the brain has to solve, which is a fight it's a a continuous struggle of war between vi dynamic range, stability, resilience, homeostasis, redundancy, degeneracy, and you know, this is one end, the other end if you want will be plasticity and robustness. So, if these are fundamental rules of the ways, then we know that there are there are small brains and large brains and well how are they how are they? They react in their niche where they live? And the answer is that not the answer, but my hypothesis is that the main goal of the brain is to maintain maintain its own dynamic. Second, is to generate an output To see the consequences of its outputs, and predict the consequences of its outputs. So this simple creature is generating an output. It interacts with the body and with its own nature and the environment, and then events sensors to make the prediction better. And the goal, of course, is to predict this, it's the consequences of its own actions. Now, brains grow, they get larger, there are many, many loops added to this. But the entire goal of this is exactly the same. But now, this organism, such as your brain, and my brain, can predict the future at a much longer time scale. And in a much larger, much more noisy, complex environment. Now, this is not the condition, there is one more trick here. Namely, we have to disengage the brain from the world. The reason why I see is not because there are photons on my retina, I can see and I close my eyes, and the screen does a debate, I can still see that Jana and and everybody on the screen, in my mind, is because what we see is actually the brain computation. And if that is true, then we can temporarily have a longtime disengaged or removed from the environment and keep going on with the computation and do and compute. what if scenarios. What if I didn't wake up this morning, early enough to come to this talk and what will be the consequences of this therefore, I put my alarm clock and so on. So these are the kinds of things that these complex brain can do. Now, there is one more bug that is is complicated because all you see is here is loops, loops, loops and complicated loops and interactive loops. And this was like a, a Talamo cortical system. But besides our cortex, and the thalamus, there are two tricks here. One is that the the brains event is side loops, there are two side loops here, the cerebellum in the basal ganglia, they are first cousins, they like each other, they compute similar things, and they complement each other. And the third loop is the hippocampus. So though, you may wonder if you would like to make a system, you know, why are this side loops, what they are good for, and how they work. So the rest of my time, I'd like to show you some examples how they actually work. So my first claim was that the number one goal for the brain is to maintain its own dynamics. Is it expensive? Or is it does it come for free. So recently, Dan Levinson, a grad students in my lab devoted his five years here and calculated, what we did is that what you see on the left is

Unknown 32:52
the distribution of interspike intervals, that is how regular spikes spike work. And we know that they are pretty irregular most of the time. And in the x axis, you've got this interspike interval and every single line there are few 1000 euros here in the hippocampus, every line is the interspike interval distribution of a neuron and you can see is that that there is this nice shift that is different from neuron to neuron. So, there are fingerprints that are neuron individual neuron characteristic firing patterns, which is on the low end of the firing, this can be zero to 0.01 0.001, very low frequency firing, which bordered many people for a long time, you know why those neurons fire at such a low rate that doesn't make sense, you know, they cannot do anything, except they have this charging their partner in 10 years, but they don't have any information value. Now, it turns out that there are other regimes such as here you can see a band here that all neurons are in the same band, this is in the hippocampus, this is the theta band, oh there is another band here, but but gamma there is another one here is a bursting pattern and so on. So, by analogy to physics, we call this state here the individual specific state, the ground state, and then the other states that are common to all euros or most of the euros is are the activated states. So this is shown here in a cartoon manner, that every neuron can have its own ground state and is activated state activate the states means they are working together with many other neurons for a purpose. Now, what fraction of the Euros pan in the ground state to do nothing or to maintain urodynamics? Nothing meaning the no communication, no perception, no thinking and so on. And the answer is astonishingly high. This is A figure that shows the hippocampus, the Piriform cortex, basal, lateral amygdala, frontal cortex, visual cortex, the thalamus doesn't matter where you go, and what state but it's sleep waking, most of the spikes everywhere in the brain are devoted to maintain the brain dynamic. Okay, so I made my first point. My second point is that there are many years that are silent, or they are firing these scattered spikes, such as the ones I just showed you that they are they on the ground state. So, for example, if you are a place urine, you can see my cursor here probably, if the animal is running in an environment and they are recording from a poor campus, then then there are places that this is placed cell number one place, and number two, place number three, four, and so on. But there are half a million euros that I like this yellow cells that they don't do anything. Without, are they part of this attractor that Chris was talking about talking about? What they are this thing from from each other? So how do we know that the way how to do it is do a trick manual Valeria did is is optogenetically, activate the cell for a short period of time and again, a short period of time periodically 20 milliseconds for 1000s of times, that doesn't pick up the system and ask, you know, how are you and then the neuron fires a spike, and then it fires a spike another spike. So now this neuron, the same neuron that you have seen before, that doesn't have any place with all of a sudden down does have a place. So we can we show that and this place field is married to a particular position, just like normal places. And here's another one. And then there are many of these. In fact, most of them, if you have the probing done, right, so the middle one would be the noisy one that we wouldn't see otherwise, because the firing rates are too low compared to outside the field. And we don't know where the field is. But if you probe the neuron, then we can unmask place fields from every single, say, one pyramidal neuron in the hippocampus. It is part of the same exact attractor, it checks except it doesn't spike, it doesn't have an output. So unmasking is as effective as making. So remember that they don't on the one hand, you have to sympathize, you have to make neurons and make them the fire the way how they would make them fire or the other one is that it just happens when you are searching into something, there is a high probability that a particular pattern occurs and that pattern can be associated or linked to something meaningful. So where do these

Unknown 37:45
pre configured lists of sequences come from? And the answer is perhaps, buy from either evolution or evolution or embryonic states. So now we are doing a little bit of neuro archaeology. And we asking is that if you are recording from an adult brain? How would we be smarter to know how this neuron should behave? If we don't know that this urine and another neuron were born in the same day, on a different day, and to do that, Romain Husar in my lab, he labels neurons at different stages of development, such as embryonic stage 1314 15 and 16 days, mark them permanently. So when animals grow up, then we can combat the adult animals as and and know which neurons were born on the same day and which neurons were not. And the answer is, even if you go to those neurons that that were born together, they will fight together the same data cycle, the same shockwave cycles, at the population level, they like to be together they form cell assemblies, and even at the very extreme level, this black neuron was born on on 14 days, if 14 days and it has one field and it has another field. The blue neuron was born on the same day and it has a similar field and the red neuron was born at a different day, the dissimilar field and if you do the statistics on a large number of neurons, we find that neurons that are bound together, they do many things similarly, and they vie together and fight together. Well, this brings us to the the new brain picture which is my spaghetti brain, which was what suggests that we are not making complex brain from simple Brains. Brains are devoted devoting the enormous resources to maintain the dynamic. That brain dynamic does not change. scales with learning or experience, mind brain, your brain or that have a, a totally unexperienced brain or the brain of Albert Einstein are not necessarily different in complexity, because learning is not a not adding. But it's a matching process, the, the in the spaghetti, the thicker ones that have already been associated or linked to experience. And so, with a bit of analogy, it would be like a Chinese dictionary, where there are many symbols, all the symbols are there for communication, we just don't understand them, but we have to ground them by knowledge, such as knowledge of English words, or in our cases is experienced. So the interesting challenge to di, if you are interested in brain inspired system, maybe we should be looking at the right end of my first slide, which is this slide here, that we can create a system that already has a realm of possibilities for matching. But another requirement that that system should be supporting a goal, it has to live in a niche, it has to be embodied, it has to have a thing that is deciding or constraining the features that it can support with itself organized complexity. And, you know, I have a few more things to say. But if you're interested in just read this book, thanks a lot.

Unknown 41:37
Thank you very much. That was an excellent presentation. So next up, we have Professor Dave Ackley, let me quickly create a spotlight okay. So David directly is emeritus professor of computer science at University of New Mexico. David received his PhD from Carnegie Mellon University. Before starting his academic position at the University of New Mexico. He was a member of the cognitive science research group at Bell core is ongoing research interests center on artificial life models and real artificial life. Grind research emphases include genetic algorithms, and programming, distributed and social computing, robust, self aware systems, and computer security. Dave, the floor is now yours.

Unknown 42:39
Thank you, Tanya. I wasn't exactly sure how I fit in here. Christoph is an incredible legend. I mean, I started doing computer neural networks in the 80s in graduate school, and I was already reading his papers. And, and jordiz talk was just an incredibly perfect setup for what I want to say, you know, my interest is making computers do new things by themselves, because that's cool. And so I've been doing that my entire career. And I, the big problem is, of course, is that once I've gotten them to do it, it's not cool anymore. So I have to kind of keep moving on, keep feeding them off with new cool stuff. So I went from neural networks to genetic algorithms, the artificial life started doing in the 90s started doing biological approaches to computers, security, trying to do automated diversity generation to try to make it so that you know, if there are going to be bugs in software, and there were going to be bugs in software, well, then maybe the attacker would have to solve a different problem for each copy of Excel rather than just being able to kill all of them at once. And you know, by the late oh, I was depressed about computer security, I was depressed about the impossibility of fixing computer security, you know, and the problem wasn't that we couldn't get the, you know, users to change their passwords or apply patches, or that programmers were incompetent, or that managers ship crap, although all those things are true. The problem is, even if those were all fixed, we still would have incredible computer security problems that are just getting worse and are going to continue to get worse, as people figure out how to exploit the incredible fact that the way we've designed computers is one bug is all it takes to take over the entire machine. And you know, physical systems, living systems, brain systems are not like that. I mean, except in very, very rare circumstances. And so I said, Well, you know, what is the actual problem here? And the problem is, I've concluded the underlying architecture of computation, the CPU and random access model is broken. I mean, it's fine for small systems. But as the system gets bigger and bigger and bigger, it's terrible. And so my, my goal is to say, well, how can we come up with a new architecture which will be more inherently robust, much more like the attractor networks, the overlapping attractor networks that Christopher was talking about, much more like the brain spaghetti, that JoJo was just showing, and yet still be able to engineer with it somehow? And my answer is, Well, number one, we have to stop eating the glass sandwich. And this is the glass sandwich. The idea is, the purpose of a computation is to connect physics to value to connect matter to money, to put it not too fine a point on it. And the way we do that is we build hardware, we build these digital electronic circuits that in fact, have tremendous redundancy in them. A wire that we use to carry one bit could easily carry dozens or hundreds or 1000s of different values with some degree of error. But we don't do that we send one bit data and we stick amplifiers everywhere to squish that one bit back over and over and over again. And that heroic act of redundancy in digital circuitry is what makes the hardware so reliable, that the software level can just assume that it's perfectly just assumed interest to present a synchronous unit.

Unknown 46:29
The best way to learn math and science. Okay. I'm not sure who I heard that. The circuitry of electronic circuitry is incredibly redundant. And therefore software can be incredibly non redundant. And that's bit baked into the DNA of computer science. The whole idea is, you should never you know, don't repeat yourself. That's a mantra in software engineering, you should use caches, if you've computed something you should remember it don't compute it again. And all of that is built on top of the idea of, we have to trust the the hardware is perfect. But that guarantee that hardware provides always has an asterisk because of course, there is still some probability of failure, some probability of an undetected error coming up from the hardware level and reaching the software level, we just engineer it so that it's low enough that we can finish playing solitaire, or doing whatever program we wanted to do with having the data shown with a low chance of anything going wrong. Similarly, once the computations get really, really big, like data, seven data, center level 10s of 1000s of these machines all owned by a single organization, they start seeing them failing, because that remaining level of failure is there. And they start applying robustness features. But for everybody else, there's basically, you know, electronic circuit robustness, and then this fragile and incredibly efficient, which equals incredibly non redundant, incredibly fragile, non robust software built on top. And the claim is, the suggestion is we have to stop eating the glass sandwich. And here's my conclusions. 12 STEP program for inventing a new architecture that, in fact, almost completely inverts the design assumptions that underlie deterministic execution with CPU and RAM. And I won't any have anywhere near enough time to go through all of these, but several of them have already been mentioned, self stabilization was mentioned. Number seven, look at life for lessons. That's what I take from both URI and Christoph using, they're studying the brain and studying the nervous systems have animals and people and everything, for understanding about how these things work. And the fact that for example, brains aren't just sitting there, they're doing stuff all the time. If you want to do something with a brain, you have to work with the dynamics that it's got that's very different than a computer with memory just sitting there empty, you loaded up with a program and then it does whatever you wish. So it begins with step one, admit we have a problem. And for me, that is driven by computer security. I think, you know, 50 years from now, hopefully less, our great grandkids will not believe the world that we've lived in as far as computer security goes today. Of the computers we have today are so unbelievably gullible. I mean, one mistake, I mean, they're like complete idiot, you know, you just talk to them, and they they become zombies. It's like a horror movie where all you have to do is say the thing and then they start sending spam to Russia for you or whatever it is that they do. And that is not The way it has to be, that is the way it is because the way we've designed the glass sandwich, but we could do something else. And so you know, the idea is instead of thinking about correctness and efficiency only at software, we have to think in terms of robustness. First, think robust first, and admit we have a problem. We can sing the whole song, pick new metrics, and so on. But I won't do that. I just want to get a little bit more unpack the idea, show a few demos, and then stop there. And let's go with discussion for it. Okay.

Unknown 50:34
So so here's the answer, the answer to how to stop eating the glass sandwich is go for structure at all scales. And rather than saying, We've got physics, we've got hardware that produces universality as close to the physics as possible. And then it's all just software, we're going to say no, actually, we want to delay universality, and have that happen much closer to the value. And we want instead, just like Jordan was talking about, just like talking about have attractor nets, things that sell stabilize things that have their own internal goals. Other than get the credit card number? Yes, we have to get the credit card number at the end. Otherwise, we can't pay for the whole operation. But we want to do it with things inside that are worrying about their own goals. You know, am I still is everything all cleaned up? Do I have enough room to work? Do I have enough copies or enough cousins and brothers and so forth that are available to do it in case something happens to me, and so forth. And they themselves are made of even smaller systems like that. So rather than saying, you know, It's turtles all the way down, we want to build bottom up and say, you know, it's thermostats all the way up, made out of more and more and more complicated ones layered on, and I want to engineer that I want to actually build that. Learn by implementing them. You know, we can learn by studying the brain, we can learn by studying animals. That's great. But that's not what I do. I want to do it by building it and seeing cool new things happen. All right. So

Unknown 52:02
I've already said this, don't blame the users, the programmers, the managers, blame the architecture, in particular, blame random access memory, you know, which is this wonderful thing. And it's far, far too wonderful. Because the instant we managed to knock a program off, its kilter. Once you have this huge field of of opportunities, you can find anything, you need a little bit here a little bit, there's some Timothy's carry loop, make a thing, don't worry about what you're doing whatever you wish, how do you stop that? What we have now all the stuff that we're doing now, the people doing computer security work, you know, it's there, we got to do it, because here's the engineering field that we're currently living, and we got to play it as it lays. But it's patch, patch patch, I mean, not just for the users, but for the whole idea. It's a glass dam that is going to spring leaks, we have to keep patching it up, it's gonna go to hell. But we could if we wanted actually start to build another dam a little further away at a sterner stuff at of stuff that's gonna build out a ripstop nylon instead of out of brittle glass. And in order to do that, we have to ditch random access memory, and what are we going to replace it with? If we get rid of random access memory? Well, the suggestion I make is, it's going to be some kind of cellular automaton. Now, if you're not familiar with cellular automata, it's the idea of instead of having one big central processing unit, and one massive RAM, you have a whole bunch of teeny little processors with little teeny bits of RAM, and they only talk to nearest neighbors are nearest two or three neighbors or whatever it is some limited neighborhood, that is all that they can get to. And there's no general purpose pointer. They cannot go whoa, I need that little bit in this little bit. So does that mean everything's guaranteed to be fine? No. Does that mean everything is safe? No. But it does mean that if an attack is going to be mustered, in the most critical moments, when you first knock the system off kilter, you have a very little bit of stuff to work with. And it's all very delicate, and you have to do a land war, you have to take over the next step and the next bit and the next bit and spread it, rather than going to whom I want. Now, most people are familiar with cellular automata. They're familiar with things like Conway's Game of Life. And that has a two characteristics that I don't like. And in particular, number one, it's deterministic. So it inherits that exact same flaw that believing in perfect hardware that CPU and RAM inherits from, and if we're trying to get around the problems that CPU and RAM and deterministic execution are causing, we have to give up on deterministic execution, we have to admit that there will be flaws, and they have to be handled software can't just say reliability is a hardware problem. And number two, it can't be synchronous. The whole thing can't go could chunk a chunk chunk at once. But because the whole point of cellular automata is that it can get bigger, we can add more, we can grow the thing out. And the bigger the thing gets, the worst synchronization becomes, there's a bunch of tricks you can do that people keep discovering every decade or two about ways to kind of lay a synchronous thing on top of an asynchronous thing. But they all rely on deterministic execution. If there's a possibility of errors, that means the synchronous overlay, it actually locks up the entire universe grinds to a halt. Not a good outcome for having one big flip. So we have to embrace asynchronous fallible hardware, and say, How can we program on that? And wow, that's harder than programming on CPU and RAM. But hey, we know a little bit more about software now than we did when we first invented the Von Neumann machine and all the subsequent CPU and RAM stuff. So that's the idea how do we make a cellular automata got it, that's can be indefinitely scalable, we make it by making an individual pile a chunk of cellular automata that can connect with others of its own kind, and we can just keep plugging it out. So here, this is a T two tile, this is the specific tile that I've been working on for the last decade or so. It's a small project. So it's going slowly. But in fact, we had an earlier version called the iluminado Ex Machina back in 2008, that similarly, it's a 2d thing that you plug them together and so forth. Those were actually briefly marketed. And now in more recently, we have the T two tiles, the one that I just showed you. And these things are, you know, ridiculous, huge, heavy, hot, $100 expensive each, because they're a research prototype. And, you know, the key is to figure out what we want to figure out a new deal between hardware and software. And then yes, the hardware guys can come in and figure out how to do this beautiful. But we have to know what we want first. So that's it. There's a the T two title project has bi weekly videos on YouTube. There's also a T two demos, which just shows examples of the stuff running. And you know, we've got a new programming language called LOM, which is a procedural language for coding up transition rules for these things. We also have a spatial programming language called splat, where you actually can make these little these little diagrams, you know, little ASCII pictures, saying this 2d pattern goes to that 2d pattern and so forth. And that, you know, it's very simple, but it made stuff possible it made stuff work like that I had been trying to get to work forever. Now, I'm just going to show you this one. And then I'm going to guess I'll stop because my 15 minutes are up. One of the big problems with a synchronous cellular automata is how do you move a big thing? How do you move something that's bigger than you can move all at once? If it's synchronous, you kind of imagine going chunk in one step. But when it's asynchronous, you can't, you have to somehow break it down. And that's what this example was doing. It's the little blue guys that go through, they create swap lines that come up and pass through the rectangle. And each time they pass through the matrix, that matrix moves one step in the opposite direction. That's what a swap line does. So a swap line is designed so that it never gets more than 45 degrees down the line. So it's a limited amount of synchronization, the passing of the line is a certain degree of synchronization. So that's just one example of Learn by Doing this is another example, I'll just let this run I guess, and we'll end.

Unknown 58:36
This is taking a plate, a grid of sites that communally say let's create a common spatial origin, let's create a 00 and a 2020, or whatever it is, there's no overall grid coordinates in the underlying architecture, there's no 00. Because it's indefinitely scalable. There's no beginning. Everything just thinks it's the center of the universe, and it goes from there. But that doesn't mean we can set up our own private little one. And once we do that, we can do all kinds of things with it. So this is more stuff with plates. Oh, and I'll just jumped to this last one, if I can. There it is. This is an incredibly lame neural network kind of encoded in an Moveable Feast machine written in law. And here it is actually running. So the two blocks that you see on the upper side are crossbar matrices that connect inbound inbound wires and outbound wires, and they each have a weight at the connection, and then down. So it's actually doing a simple function optimization where the one on the upper left represents the function. The one on the upper right represents the knowledge that the algorithm is gaining. And then it actually had a little, a little data readout on the screen to produce human output. So that's it Uh, I will stop there. And it's going incredibly slow. But hopefully, some folks will be inspired, you know, step, step 11 is you know, it, we have to make it happen, we have to get organized and so forth. And this is not going to be running excel in a year. This is a long term fundamental research project to kind of go for a mulligan to kind of do a do over instead of having determinism at the bottom, we have determinism at the top instead of having data center software reliability at the top, we have it at the bottom, and so on. Thanks for listening.

Unknown 1:00:41
Thank you, David. I from the chat. I see this was an extremely inspiring presentation. Okay, all right, I'll switch to Russia. So our final presenter today is Dr. Yoshua. Yoshio, Bach is a cognitive scientist and AI researcher with a focus on computational models of cognition and your symbolic AI. He has taught and worked in AI research at Humboldt University of Berlin, the Institute for cognitive science and Osnabruck, the MIT Media Lab, the Harvard program for evolutionary dynamics, and is currently a principal AI researchers researcher at Intel Labs California, your show the floor is now yours.

Joscha Bach 1:01:35
Thank you. So the machine that builds the machine is a very interesting topic when we think about the brain because our mind is something that is not just designed as a technological system from the outside in. But this biological and social systems are from the inside out. The free look at this difference. When we design a system in our lab, we start from a deterministic environment. And we take a substrate into this environment that is not structured yet in the way in which we want it to be structured, but if you can fully control it, and we extend our determinism into this new part of the universe to basically extend our deterministic world into this particular thing. So we are coming from the outside in and technological design. And if you look at a biological system, you do not have this deterministic environment to start this instead, you have an indeterministic environment and to start out with some seed that needs to colonize the environment to branch out to subdue it, to turn it into something that proceed knows how to do this. And then gradually turn its own structure. And then you will go beyond simple organic roles, you look at organismic roles, where you already know the structure around you because you have created it or you're part of something that had shared destiny at some point. And so now you have known units around you this which you can collaborate and organize. And so you are colonizing the outside internally, you are organizing from the ground up from local units inside out. And we can ask ourselves what an organism is, does an organism actually exist, right? We sometimes think of organisms as things, but the organism is a good thing. It's a function that describes the coherent pattern in the activity of many cells. Right, so the individual cells are all serving that function. And by making them coherent, due to evolutionary pressure, and the design constraints that are built into the cells as a result of that, you see a coherent pattern emerging and this coherent pattern that we see emerging, that is the causal structure that we call the organism. And the organism, like every other thing that exists to exist is to be implemented, is implemented to some extent. But it's not implemented in the way in which a computer chip is implemented. But the degree of approximation is much more vague. And it's the organism exists to the degree that the patterns in the interaction of the cells of the organism procurement. So in some sense, we see a pattern of this organization, a software that emerges over this information processing that looks as if there is a coherent agent that is inhabiting this thing. And traditionally, the word for this emergent operating system for an autonomous robot in nature is called Spirit. And so in this sense, the emergent agency that we see in organisms is actually what was called spirits by the previous civilization. And the spirits also happen to be in our own minds, and they also happen to emerge in groups of people, nation states, and ecosystems and so on. These spirits are virtual machines that possess agency that is they play a controlling war by being able to model the future have their own place in the universe to some degree, and they're approximately implemented. And so in this sense, the spirit is a very high level of an organization that is required to see the emergence of such a spirit. And then we look at the hierarchy, of course, IT systems at the lowest level, we may have something like our automata, like the game of life, and the these automata, they can already be Turing complete, it's not that they are limited in any way, because if you give them some memory, and so on, they can implement arbitrarily complex structure if you set them up in the right way. But you need to do this from the outside where some kind of design process, the only automaton that might be able to do this without it was a random starting state is our universe itself. That might be a big automaton at its bottom level, if you just happen to inhabit a region that has interesting enough complexity to contain us. If you look at a mechanism that is slightly more complicated and costly than automaton, that's usually a stateful thing and is entwined with a substrate. Here, I used as an example the famous machines by sorry, my brain is blinking out.

Joscha Bach 1:06:28
Sorry, Kenya University theory and some theory and strength piece. He is and has been building these amazing machines that are driven, usually by wind power, and they are completely mechanical things that are fully coupled with the environment that don't have an existence that is the sense independent of the environment. And if you look at feedback systems, you can have open loop systems that are coupled. For instance, in oscillators, you add in synthesizers, you produce interesting patterns that are the result of some static coupling. And if you make this coupling dynamic, for instance, in the regulator for a steam engine, you can have seven attic control system. And the controller in a cybernetic system is built by having a system that cares about the target value and wants to minimize the distance to the target value. And if you extend this controller, with computation, you can get an agent. And to have this decoupling of this ability to model the future you need to have a system that is a computer or a Turing machine, in some sense, is a mechanism that is disentangling itself decoupling across the structure from the underlying dynamic of the universe. The interesting thing about our computers is that they do the same thing. Regardless of what the environment is doing, they work the same way, whether you are carrying them to America and New York, or whether the temperature is a few degrees higher or lower, whether you're climbing a mountain or go down, or whether the wind is blowing or not. And the same kind of computer also exists inside of our scouts. It's a slightly different one. But the principle of the computer is that enables an arbitrary causal structure. And you need to have this arbitrary causal structure to be able to make models of the future, right, because you want to look at different futures. Regardless of what the universe is doing right now, and the simple system that we know and nature that is in the sense, Turing complete and has the powers of function approximation, that organization to achieve that is to say, so the car basically is able to perform computations that are decoupled from its immediate substrate that enabled the cell to make models that predict the future to so the cell can regulate against future disturbances and keep itself stable against these disturbances. So that's why the cell is such a complex system is able to exist. So the cell is an agent. And an agent is basically controller, combined with the internal setpoint generator, and the ability to model the future. So the agent is not just acting like a thermostat on the next frame, and tries to optimize the state of the next frame, but it's integrating the expected setpoint deviations over the future and tries to minimize them. And if the modeling capacity is sufficient, then this agent is able to model different branches of the universe and the effect that its decisions will have on these branches. And as a result, you basically get beliefs, desires, and intentions all emerging from a simple controller that is able to model the future. So this is basically a minimal concept of agency. And agents can start to collaborate with each other and groups for agents and groups, agents that typically have individuals Motivation and a reputation system among the agents that makes sure that their actions are harmonious and beneficial to the members of the group.

Joscha Bach 1:10:09
And slightly different extension of the group agent is a state building agent. A state putting agent is one that scales beyond reputation system, it means that the individuals do not have to know each other individually to have to maintain a model of their reputation and that transaction and synchronize this reputation system somehow, like a tribe as a state is fundamentally different from the tribe. Because the members of the State become interchangeable, they have functional roles now. And this stapling, agents can grow very large. But the size of the state learning agents depends on the size of the effective colonial structure that you can maintain. So basically, the logistics chain to build such a colony of units such as synchronize, the state needs to have a way to impose administration on its substrate and extract more neg entropy from the substrate, then the administration costs. And this limits the size of the design of state building system, especially once you have such a state building system and evolution, it's going to compete the similar systems for the same like entropy. So you are basically the set of principles that has out competed all other systems from extracting entropy from your volume of space. And to do this, you need to impose or coordinated patterns of organization, on to your volume of space. And this, because you're competing with others limits the size that you can have, there are very few organisms that have cracked the code and have become infinitely scaling scapegoating agents, right. Most state building systems have a limited size, that design is limited by the stable logistics chain that they can use to impose their colony onto the environment. And this here, for instance, is the panda forest, it's ash trees, and you tap, it's one of the largest organisms that we have on Earth, all these trees are the same tree. They're not just genetic clones of each other, but their wounds are connected. This is basically one big tree that can grow as large as it wants. It's very old. And it didn't mutate very much since its growth, right. So it needs to be evolutionary stable, so it doesn't drift. Another example of why it isn't up scaling, stapling aging is a linear PC value mirror, it's Brazilian, and that has spread around the world. And all members of this end of these ant colonies do not attack each other, they will all treat each other as part of the same cohesive colony, with the exception of a few drifted colonies. For instance, in the US. When they get in touch with the other colonies, they will attack each other. So they had some kind of genetic drift after the colony was established, that makes them appear to be strangers to each other, but the species has cracked the problem of becoming an infinitely scaling skate state. There is no limit to the size of this colony apparently, if you look at the design constraints, for such systems, the mechanical component needs to have an outside and designed by some external agents. So it is not going to exist by itself, and it's not able to adapt by itself. And then you build a controller controller gets resilience that can be larger than the mechanical component because it's able to adapt its states to a slightly changing environmental circumstances and maintain an attractor state by itself via dynamic control. And if your controller is able to model the future via decoupled computation, then it's able to integrate future reward. And it's able to not just adapt itself to the environment, but it's also able to adapt environmental itself. And in group agent, you can do this on the next level. So you're basically built an agent that is composed of multiple sub agents, and each of these sub agents has its individual motivation at the reputation system to coordinate the group and an estate building agent, you

Joscha Bach 1:14:21
change this reputation system or extended by a hierarchy of governance and distinct needs an immune system. So the individuals are submitting to this governance and are not building their own government that is competing with the main government. And you will have limited autonomy of the sub agents. So they will be set up in such a way that they per default, most of them will want to submit to the state building group rather than doing their own thing. And you can see this in humans, we are basically a domesticated species of the planet. And as a result, you're not just tribal homosapiens is statebuilding because the Yeah, most of the individuals and in our species are willing to submit to the group before that with their own thing. And if you go to an infinitely scalable Stapledon agent, you can do at some level less than you can do and these other groups, because the you need to be static, you cannot have an evolutionary drift, you cannot adapt to the environment beyond the mechanisms that are built into the system. Because if you were to drift, then this, this infinite scale would break, and you would no longer be consistent. So, if you think of hierarchies governance as a principle, we have a trade off there, between adaptivity and coherence in the system, the more adaptive it is, the harder it is to maintain coherence. And the individual agents here are incentivized to defect from the system of very often. And you might have to limit this by having an agent that imposes an offset to the payoff matrix. So the individuals and this is what we call the government. And the need for government comes not from political constraints or from the desire to exploit people or something else, just game theoretic thing that you can derive from first principles. And the purpose of this government is to integrate the total reward which can happen from bottom up, and to top down to credit assignment to make sure that the individual behavior is adjusted in such a way that the Nash equilibrium of the individual agents become compatible with the common good. And this is something that also needs to happen in some sense in our brain and humans are autonomous reinforcement learners. And the interaction between the neurons needs to be coordinated into a coherent structure. And Jerry Edelman has suggested that the organization that happens in our own mind is something that evolves in every individual in some kind of what he calls evolution, because Neural Darwinism. And so maybe the top down process that is harmonizing about bottom up perception is something like a governance colonizing agents. So our brain is not just playing free jazz, which it does, to some extent, but it also plays a coordinated symphony. It is serving coherent goals, it is as an emergent coherent agent that is forming inside the organization of the cells that makes our organism more efficient, by giving it a coordinated spirit. So how is this relevant to AI, current machine learning representations all have an outside in design, and organisms, the representations are different, the organisms are coupled to the environment. So the features are not static. They are functions that basically your operators on your current mental representation to give you the next state, and they are tuned in such a way that they track the sensory patterns. And the features are kept stable and coordinated via individual controllers. So every feature is probably some control structure that maintains its stability, and its coordination with the environment. And the entire thing goes beyond just by having some kind of emergent governance that harmonizes it and instantiates individual features or results. I mean, they're no longer necessary to surprise the attractor states. This some governance vents that the level of the scene that you currently use to interpret the world. And you have multiple systems of interacting agency, and they're visiting the scene agent that is trying to predict how the world continues. You also have a self agent that is driven by the motivation of our organism. And you have an attention agent that is figuring out which features or features to select and harmonize and to instantiate or to dissolve at any given moment. And in this way, organisms can happen. It's centralized causal structure. But the centralized causal structure is not like a CPU and a computer rather, it's an it's more like decentralized causal structure in a society of people that emerges as a result of an evolution that makes the society more efficient and better at competing with other societies. So this is where I am for today. Thank you. You're right,

Unknown 1:19:17
so now we are to the discussion part of the session. Let me see what's what we have in the chat for questions. So first of all, please feel free if any of the panelists has comments about each other's presentations. Please feel free to voice them. And in terms of questions, so first question is from Thomas McGee, and it is not on it was posted, I believe during a URI citizen presentation but it may have been to anyone what are some examples of multi stable and metastable neural attractor dynamics with the slow fluctuation of externally oriented delta theta non dominated oscillations and internally oriented alpha beta oscillations be an example of an endogenous, multi stable attractor dynamic in the brain. also curious about some examples of neuro hetero clinic cycles?

Unknown 1:20:25
Well, it's a charged question and there are many components to it. One of the most beautiful things in in brain evolution about scales is brain rhythms. Now, what you would like to know, in general about scaling is that, what do you want to preserve? And what do you what do you what are you allowed to sacrifice? So brain rhythms are extremely useful on this because they are pretty much the same in every single brain in at least in mammals from the mouse, the human. And the mechanisms are the same, the pharmacological sensitivity is the same. The second interesting thing is that they form a, just just finish this line, which means that the most important thing for the brain is to keep timing preserved. And the reason why timing is so important is because we control muscles, and the muscles are the same in all species, and the speed of the muscle hasn't changed in evolution at all. So other creatures have pretty much the same speed. So that's probably one of the evolutionary pressures that allowed or a force to keep timing the same, and then you sacrifice a lot, you sacrifice a structure, you put a lot of lines, there is axons in a larger brain that are much more much faster conducting, because you have to deliver the information in the same time to a more distant target. So then the calibers of the axons grow and so on. And these are beautifully demonstrated by comparisons of the fibers in the corpus callosum and in the in the retina, and the optic tract and so on. Now, these oscillations or writtens, that this question asked about, form a beautiful hierarchical system. The hierarchies organization is simple, which is called phase amplitude coupling, which means that the lower oscillations phase modulate the amplitude, or the magnitude of the first one and the phase of the first one modulates the amplitude of the even faster one, and so on, and so on, and so on. So, the consequence of all this is that, when you have a short period of time, and you've got a short period for the oscillator or short waveform, then only events can occur locally, when you have more time and then you have a slow oscillator, that it engages all the other ones in a larger neuronal space. The consequence of this very different from Ai probably this is if I, if I understood it right from from, from David, he alluded to this that, that we try to deliver stuff to distant architectures rather than just to the neighbors. Now, this is what the brain does in both ways, namely that most of the organizational patterns is local. But the large oscillation is allowing that local computation is broadcasted locally, but globally a little bit. And the global computation that is the global oscillations constrains what goes on in any local situation. So this allows this hierarchical system allows you to have a brain syntax to package information in short chunks and longer chunks. So you asked about various oscillators various names, but for the audience, it doesn't matter. Let's just call the faster ones gamma oscillations, which are about 2030 millisecond, this could be the content of this is a bunch of neurons firing together with the one and only purpose is to discharge a postsynaptic target neuron. This can be called a neuron ladder. Now a theta and an alpha oscillation can contact concatenate several of these slots become oscillations to a neuronal Word, and the neuron word can be combined into a longer segment. So, this is the way I think it was, was a case of already mentioned that without a generative rule, a syntactical rule you cannot really grow the information content infinitely but if you have such a syntactical rule, such as the brain or Is military hierarchy, then it allows the brain to generate infinite number of sequences from limited number of elements. So this is a complicated answer to the brain rhythms. If you're interested in first of all, I had a previous book, but that's the short answer.

Unknown 1:25:18
Curious if I can follow up on that? Is it the case? So you're saying these brain rhythms are extremely conserved across mammalian species at least? And does that mean that the size of the brain doesn't affect the rate of a given class of isolation? Elephants are going no faster, no slower? Even though they have much more distance in just raw centimeters to cover? I mean, why the hell would that be? I mean, why? Because you just stretch the axons out, and that makes hardly any difference in the propagation time.

Unknown 1:26:00
So I think the idea of physical systems was, was discussed a couple of times here. Now physical, this physical systems are different from, from theoretical creations with unlimited speed and so on, in order to, to keep the if you if you look at my mark, here, it has color and all sorts of features, as has been studied. And for multiple studies about dividing issue, all these things have to come together. But they have to come together somewhere in a small bay and the large brain in the same time in order to perceive it. And they do not understand

Unknown 1:26:38
why same time, why couldn't it be a little longer in the big brain?

Unknown 1:26:43
Because we are? Well, not because but this is the speculation, I'm interacting with another species, and another species and another species and another species, all of this, if there would be a tremendous, you know, order of magnitude advantage, then in speed, for example, I would be that

Unknown 1:27:00
I would think the short cycles I could expect could be preserved or forced chemically, or something like that. But it's the long ones that I would expect could have more variation.

Unknown 1:27:10
This is the interesting kick. brains do this for a goal. And we can talk about the goal a little bit later. Because this, if you're interested in what is preserved in the brain throughout evolution, then my answer is timing and the brain oscillation, it's not because the brains cannot do something else. Breathing, which is also an oscillation, a very regular thing is organized by by about a few 1000 neurons, that can have several orders of magnitude difference. In rhythm, you know the ways and the heart rate. So they are very, very different. So if you want, you can do it. But all the other oscillations that are used for condition and controlling the body seems to be preserved, everywhere. Thank you. And as I mentioned briefly, that there is there are beautiful, full anatomical data showing that the connection between this part of my brain and this part of the brain is about 100 times smaller in a smaller brain. And the conduction velocity is 10 times more in my brain. Because it's needed, that you get the cost is about the size, the cost is enormous, because you have to put myelin and energetically, it's so costly to maintain to deliver electricity from one place to another. But this is what brains do.

Unknown 1:28:33
Oh, that's the same in digital manufacturing computers, the more metal you have to run, the more energy you pay, the more layers you pay, the more area you pay. It costs a ton. If you want to crank this clock, the same speed on a bigger

Unknown 1:28:48
physical system, the brain is just like your chips. And it says thank you.

Joscha Bach 1:28:54
For the question two too dirty? The if you look at the organization of the neocortex, how much of that you think is the result of deliberate Secretary building and how much of it is just a stochastic substrate? So you point out that the complexity doesn't very much change during learning, right? It's not that the brain starts out with no structure or the neocortex starts or there's no structure after the initial setup of course, and then it forms all this intricate structure after interacting with the environment, it tweaks the structure, but the complexity at which a child perceives the world is probably not that much different from the complexity at which an adult perceives the world even though the functions that are being learned are slightly different. And how much of that is basically reflected via the circuitry and how much is the circuitry just a result of, of the learning of for instance, RNA based memory that is stored in the activation pattern, or propensity of the individual itself?

Unknown 1:30:02
Well, propensity of the individual cells seems to be preserved throughout much of lifetime. So the firing rate of neurons is almost like a fingerprint, that you can perturb it, you can do lots of things that need to be the same. Now you take a conical unit a cortical module, it's called the color. And then you can grow it. And then many people are very much interested in how these different columns compute something differently in the visual system versus a thinking system such as the prefrontal cortex. But the if you look at the connectivity of these two systems, they are not very different. So the commonality is much stronger, so much, so that experiments have been done 20 years ago, when you when then either a newborn or a prenatal animal is taken out and you take a piece of tissue from here, and you put it here and you change it, there will be a relatively normal brain because the system can tolerate that kind of discrepancy. Now, when you look at a small brain, a large brain and you say, how many different types of neurons that are there, then today are these days, people celebrate, if they find one neuron that in the human brain, or in a primate brain that looks a little bit different, or genetically looks different than in the brain of a mouse, because the component diversity is relatively limited throughout the mammalian evolution. Now, having said that, the neocortex is a modular system, it can just grow because you can add elements. And then you need the agent that you talked about the controller that brings this together, that maybe the calibers that allows all these things to be modulated together work together, there is this different type of organization called the hippocampus, which is a single giant cortical module. It is the same structure, there is no modularity in it. It just grows from the three shrew to the way that this gets larger and larger, because it is, quote, unquote, designed as a random graph, that you would like to go from anywhere to anywhere else in just two steps. And that may be an interesting thing. We know why. And I don't have a good answer. Nobody does. Why do we have this this accident loops? Why does the neocortex cannot solve the problem of the of the what the hippocampus can do. But what I learned today is that even in computer science and everywhere, architecture is the primary thing that determines form defines function. And then rain is not an exception from this. In fact, it's I think, the prime example.

Unknown 1:32:52
Thank you. You're so so we have a question from Winnie Shroff to to Christoph and Yuri, looking at your insights is the current architectural paradigm for artificial neural networks still stuck in an architecture, ignoring the endless loop with environment paradigm of real organisms? So despite? Despite the deep learning advances, will we continue getting more stuck? This question has a postscript saying some alternatives like cellular automata still totally missed the feature of being massively looped, or massively parallel, in my opinion, also a dead end street?

Unknown 1:33:37
And I answer to that, I take it as asking, is deep learning the end of the story, so to speak? And can that be continued indefinitely by just enlarging the system or enlarging the, the training sets, in my opinion, here is that deep learning is stuck. The main problem being that it's a priori assumptions. It's it's fundamental data model is not tuned to our environment. It may be tuned to some particular application fields, but as far as we are, after animal type, human type intelligence, deep learning doesn't have the right data architecture. That is the reason for it. Being very poor in generalizing, you know, if you show a new kind of object to a three year old child, that child gets it after the inspection of a single sample of that object and recognize it in under massive changes in color and exact shape. and so on. So what deep learning is poor in is its feed forward architecture, which is forced on it by the necessity to back propagate the error. This is a very poor data format. And as I've tried to point out self organized networks, which differ from what we have today in deep learning structures, fundamentally, by having cycles of of connectivity, you know, lateral connections between it within a layer is speaking about the layer system. So I think the enormous efficiency with it was which animals learn or, or humans learn is something which is beyond reach of the deep learning paradigm.

Joscha Bach 1:36:07
Christophe, I have a question about Kolmogorov complexity. If you think of physics, the Kolmogorov complexity of the universe might be very low in the sense that it could be a fractal, which has a simple generator function. But the complexity of the particle universe is extremely high. Right. So if you try to describe the detailed, fine grained structure of the universe around us, we would need enormous amount of code because we cannot compress it very well, because we don't have access to the underlying function and our position in the fractal. But the description that we are making of the world was Newtonian physics. And basically, the game engine that our mind and habits, again, has much much lower complexity. So there's basically an emergent causal structure that we use to predict the world that fascinatingly works by, and that can be described efficiently in what you describe as a gigabyte of code, probably a lot less if you write the code done more efficiently than we do. And now an interesting question is what is the actual Kolmogorov complexity of our mind where the complexity of building a brain by setting up self organization process between the cells is probably a relatively No, it's not the entire gigabyte of genetic information, but probably more on the order of kilobytes or megabytes that are required to basically form out the brain as the self organization process. But what is the Kolmogorov complexity of the emergent system? If we were to design the brain as an engineering project from the outside in? Is this going to be similar to the Newtonian world where you have a relatively efficient structure could we come up with classical AI architecture describe the brain efficiently or do you have to deal with the fact that the effective structure of the brain is going to be very complicated, so, you will need to have a self organization to understand it.

Unknown 1:38:12
My argument was of course, that the brain is of low Kolmogorov complexity, because it can be built with so little genetic information, as you said, Some people claim or have computed that the 3.3 billion note nuclear bases can be compressed to something like 50 mega mega bit. So the the complexity is very low. And the in order to build the brain, you need a process of self organization that's as we know, started with a single fertilized cell and goes through divisions and goes through a sequence of attractor states. That's the way the brain is built. Now, our way of building outside in completely ignores such constraints, as our inputs implicit in the organic growth from one state to the next, we can sort of when when putting together a blueprint, we can we have the full the full universe of potential patterns we can throw on to our blueprint and the only constraint that we are observing is the design ideas we have in mind. So I think, of course you can by by knowing the the exact the procedures of Sir of organizations the mechanism of self organization, you can let them play in your computer that you use for the design and get the final result and then that impose that final result outside in on a piece of hardware, but I find it pretty against the nature of things to do that. So, I think complex, complex brains, artificial brains will be built inside out. And if only they are reconstructed on digital computers, at the present time, I'm simulating all my systems of course, on a digital computer, what can I do even on a digital computer, you will rely on an organic growth process, it turns generating the final structure as a sequence of intermediate states. So, I think you're stuck with self organization.

Joscha Bach 1:41:05
By the way, the reason why I wanted to have Dave on this panel is I thought that it would be interesting to see if there is an interaction between the ways in which he is designing computers via self organizing principles and the way in which we think and neuroscience and cognitive science about self organization for information processing, I can

Unknown 1:41:28
comment on that and he made it very clear that reliability in our digital computers is is solely on the on the hardware level very meticulously by by forcing the signals to decide either for one or zero with you know, these these self interaction loops driving the signals to saturation and and building on that very brittle as you present software. Now, this has two floors, number one, the software needs to be designed outside in there is no way the computer prefers more functional strategies and software prefers more functional structures, less functional structures by itself. So all the functional structures must be brought from the outside in and number two, the unreliability he talks about. So, if on the software level, you have something that is built on redundancy, multiple pathways is built on attractor dynamics, you can work with you can live with underlying hardware neuromorphic hardware for instance, which is analog, which is prone to a noise noise that is braided in by the if you if you want to refer to that as such, by the software level bridled in by the by what we now have as software. So I'm completely in tune with David, actually, I love his way of looking.

Unknown 1:43:16
Thank you, Christophe. I mean, you know, this was such a big aha for me, because I was raised as a computer scientist, I was raised to be all about efficiency, all about correctness. And then to realize that that was all just purchased on this phenomenal act of redundancy at the amplifier digital signal level. And you know, we were just sort of cruising on that ever since. And yeah, so the question is, is how can you build bottom up in terms of software, and the idea, all that I come up with is that we build simple agents. And then we build more complex agents and bigger, slower and more complex agents by combining collaborations of smaller, simple ones. And you know exactly how to do that depends on what the actual hardware you're trying to deal with, if you're trying to deal with analog neuromorphic stuff that has one set of affordances that you now have to figure out how to work with. And if you're working with, you know, I work with, you know, stuff that's a little bit more traditional, like cellular automata, except, you know, fat best effort only and asynchronous only, and so forth. But there's clear set of problems, like control of space, and how to reduce variation around space, so that you can now do something more specific. And if I could take one, one minute, I could show a little demo that I wanted to show because it kind of shows the idea maybe. So, you know, One approach is to just make everything big and rigid. Right. So So here is a block of wall so to speak. And the idea is well, but you know, instead we want to do something more adaptive more Uh, reactive. So this is a, a simple cell membrane that's kind of knocking around, and oops, and I think I may have just killed it, let's start a new one. So much for robustness there, you know, if God is going to mess it up, you know, it's not really his fault. But the point is, is that, you know, the existing stuff that we have tries to be rigid, and it counts on the, the underlying hardware remaining rigid, and so forth. Okay, there's a rigid thing. And but one of the things that we do, because there's this terrible problem, you know, if you try to be robust, but there actually is nothing challenging the robustness, the robustness looks like waste. So there's this inherent tendency to start chipping away at the redundancy, because if there's no actual problems, then it doesn't matter, you can get away with it. So it can happen in natural evolutionary processes as well. So one of the things that we do in what we build is we build stuff into deliberately challenged the system. So one of the things we've got as an element called drag, it stands for Dynamic regulator. And what it does is it just wanders around and randomly erases stuff that it's next to every so often, not all the time. And every so often, it just creates a new sort of food particle that can be used for anything. So I'm going to flood the world with dreg right now. And so you know, what we see happen is the the rigid structure gets eaten up, right? But the, the celled cell, I want to call it a cell membrane, it's not a real cell membrane, obviously, this is so abstracted away, it actually does active transport to bring the little food particles inside and it grows. So this is my suggestion and example, you know, a thought experiment? Well, it's, it's implemented, not exactly a thought experiment of how you can actually start building up that you builds first you build small, fast structures, then you build bigger, slower structures out of multiple units of these things. And we just try to keep going up. And at each stage of the operation, we're going to have data sheets, saying, you know, this thing is good for this, it'll work at this, it'll do badly at that. If you go outside these parameters, behaviors, it's your fault, and so on, just like real systems always have data sheets, but computer science never did. And it was again, because of that same damn. determinism that the hardware guarantee was supposedly providing.

Joscha Bach 1:47:46
Whatever you'd like about your work is that you don't try to imitate brains. It's beautiful work about spiking neural networks, but why you spikes if you can set arbitrary messages. And so you have the self organization from a completely different angles. And I wonder, have you thought about learning systems in this way? Could you build a structure that is learning new functions? How would a meta learning system look like because you have to design eventually the meta learning right?

Unknown 1:48:13
The last example that I showed this, the function optimizer, as a simple example, that was actually implementing the CI algorithm that I did my dissertation on in 1987. And here it is coming back. And one thing that was interesting to me when I was implementing it in the Moveable Feast machine in this architecture, is that it was really hard to do a bipartite graph, where everything was supposed to connect everything by equally length units. And I ended up not doing it, I ended up doing a crossbar switch and putting, you know, mate weight matrix weight weights at each intersection. But then, since it's all a synchronous, that means that the stuff that's close to the crotch where they meet is much faster. And it's a lot like a Yorkies picture where he showed the simple brain, and then the bigger brains wrapped around it with the bigger loops, the slower loops that just fell out in the sky algorithm in the site implementation that I did on a Moveable Feast. Because once again, we still had space, there is no random access memory, you can't just pretend everything is next to everything. So yeah, I think so I think it's going to impact the structure of learning systems in a fundamental way. And it's going to be a pain. Because right now, you can just throw around matrices, you can tensor them up and just do the deep learning things the way people are doing and they're having great fun. If I was younger, I would totally be doing that. But you know, I did my version of it in the 80s. And I moved on like that. But all of that all put together is still under the scene, as Christophe was saying outside in where you pick the architecture. I've got 10 layers and a concentrator and a convolutional layer and then a transformer attentional thing that's all done by the human, and then it's fixed. And I want to have something that's underneath all of that, that says, you know, we can do these things, but then we can reprogram them. By sending down new software, rather than saying, we have to throw out the machine and build a new one.

Unknown 1:50:20
Maybe that's the brain goal is to put a lot of effort into making the system resistant to catastrophic interference. And that's the primary goal, probably your brain and my brain never experienced this catastrophic injury, interference showed up, you know, a car accident or something like that. I liked a lot of statements you had Dave, my favorite one was this, we have to know what they want. First, which is an interesting statement, because this is exactly what the AI is about, it has to have a goal. Now, on the other hand, you your mind is very fascinated about self organization. And there are two interesting things here, you know, one is that it just grows and we don't know what the end product will be. The other one is a goal. Now, the funny thing, and this is, I think what most of the people don't understand out there, the difference between evolution and intelligent design is that evolution can be explained best with a goal. But that's just a convenience. And of course, evolution has been tremendously,

Unknown 1:51:34
tremendously misleading, sometimes convenience, but virtually irresistible. Because and, and we think that says something to Christakis point about low order structure in the environment, so that there is some specific thing to want. It's not just like every possible environmental input is equally likely, there is structure there that our brain is trying to latch on to. And once it finds it, that feels like a goal, I want to get better at doing that. And then we'll then we go off to the races, then we can do deep learning. Once we've got something that says, you know, I want this this is a good mapping, then boom, go Hill, climb and be married.

Unknown 1:52:17
I like that. And you know, there's a whole big field, it's called decision making. But it's, it is the nature of Intelligent Design kind of have, it sounds like it yeah, St. Augustine's definition, but in the real brain decisions are made post hoc. Most of the decisions that I made in my life I justified and it looks like decision after the fact, rather than

Unknown 1:52:43
make is that intelligence. Intelligence likes to think it's the captain but really, it's the historian

Unknown 1:52:53
there's a there's an excellent question from Kevin to all the panelists. So what are the panel panel's thoughts on artificially creating the phenomenal aspects of our existence? For example, consciousness. For example, there is a what it is like to recall an episodic memory while basal ganglia learning and memory can operate outside of awareness, connecting to the ideas of chunking and attractor slash complexity, rhythms of the brain and hardware software considerations. Would we need anything different to go from artificial intelligence to artificial consciousness and qualia? Potentially metabolic or biochemical universalities? Or perhaps artificial conscious computing can already be accomplished without the bits of info at the molecular level, like for an artificial hippocampus, medial temporal lobe system to create what it is like to encode and recall an episodic memory? Well,

Unknown 1:53:53
can we give it a shot? Go ahead. You know, I, to me, at least, the state of consciousness in my brain is one where a large number of modalities like seeing and hearing and wanting and feeling and motion and the aims i After at the present time, where all these modalities are in sync with each other, they speak of the same thing, they understand each other they one response to the other in a useful way. Like when you drive your car, a signal coming into your peripheral vision immediately lets your your arm turn the steering wheel or your your foot hit the brake. So the phenomenon of consciousness is one of, of integration of all subsystems into one coherent state. And I see that as a An example of, of different fragments, connectivity fragments in the different modality is being activated activated by activating the participating neurons, of course, activated such that they all fit together into one brain spanning coherent network and networks that, if it was given time, would just recreate and stabilize itself by the exchange of signals. That's how I see the the generation of conscious states.

Unknown 1:55:42
Just to add to that, you know, they organizer is the brain rhythms, the system abraded, those, they are the ones that bring all this together. So probably that's why it is so important. And of course, you can see the evolution of brains and you can study your questions. The question is more complex. I don't think anybody can give a one sentence explanation about qualia. But I can give you an explanation about the role of the hippocampus, for example. So I take out my hippocampus, and I will probably still no, I'm uribl, Jackie, I can do a lot of things except that I will be missing my past, I will missing with the Skoda no Tadek consciousness that is, I don't know whether I was an agent or face episode or not. I don't remember anything about my life as being a participant of this, this is done entirely by one system, this side loop of the hippocampus now, what kind of consciousness is this? It's a good question. Because the USA, well, you are awake, fine, you know your name, and you know that you are distinct from others, but I don't know who I am, in terms of my history. So I'm just a zombie that lives in the environment, and responds, according to the socially agreed knowns, this is the kind of thing that I think I can do not so long from now. But the feeling of it or being you and putting you, as the first person experience it. This is the big question is that when a AI system can be saying that I am the viewer, I'm the first person experience, rather than the third person describer of the events out there.

Joscha Bach 1:57:41
A bit more optimistic than you you're basically our model of reality is a model of what the world is like, right. And our model of the South is a model of what our interaction with the world is like. And the model is written for us and informs our future behavior. So basically, it's the historian that is helping the emergent captain that makes a decision based on the model contents. And as a result, the story is continued with the consideration that the emergent captain is making my take entire system is virtual, the captain is spiritual, the, the agent that lives inside of the world that we observe as being asked is a virtual construct that is getting causal power, because it would be very useful to know what it would be like for the brain, if such a person existed, and coordinated the behavior of the organism, right? It's a spirit that is being controlled by the interaction of the cell. And the filament experienced if you have this feeling of what it's like. And the content of what it's like, is a model of what it is like to attend to our model of reality. And the purpose of modeling is control. So the purpose of our modeling Fairman experience in our own mind, and being able to access it and reflect on it is to control the attention that we are paying, and the way in which you're coordinating our inner reality. So the issue is that you have to grasp that the consciousness is not physical. It's not something that exists at the level of neurons or physics. It is entirely virtual, it's a story and we live inside of that story. The story is being accessed by this loom that weaves the story to continue the weaving and the contents of the weaving when we reflect on it that is the reflection that we have that he experienced as our phenomenology.

Unknown 1:59:34
Yeah, consciousness is not in one brain. Now the word conscious this is joint knowledge, knowledge of yours and mine, and in Russian is called Cessna Ania. This is for for Tatiana, which also means knowledge mirroring from you, without you, I have no idea who I am. If I'm the only person in my own niche I'm surrounded only by alligators, I would have a very interesting opinion about myself, certainly very different than living in New York.

Unknown 2:00:10
Interesting, you know, you could interpret consciousness also by saying that different parts of your brain know together.

Unknown 2:00:22
It's exactly the first view, because now you are you looking at yourself, but looking at yourself is your past experience, which is Yeah.

Unknown 2:00:30
I wonder URI why you think that this particular function of knowing your own history of being conscious of your own self in as you just said, in a social setting, couldn't be modeled in artificial intelligence? Why would that be a barrier?

Unknown 2:00:53
I don't think there are limits. Because I've heard that there are no limits in our world, right? I just say this is the most difficult thing to do. Okay, looking at the kind of consciousness which is just mirroring that are I know that I'm separate, it's a relatively easy one, because the the way how I would approach it as a biologist to say, what, how can I study these things in an animal, and when I say, first person, second, or third person view, then I can study an animal of low organization such as a mouse, because in every animal, the most important distinction is the self from everything else, you know, there are boundaries and so on this is this is a biological thing that has to be internalized, very early on in evolution, because that's the important thing. And so this is the egocentric world. And then then the allocentric kind of thing that comes much later. Because that requires that you generate something that is transferable to the other organism, which is one of your species. This is the social this when it comes up. So all these complicated things, such as socialist and individual needs can come down to the ego versus ILO.

Unknown 2:02:16
I mean, as a, as an engineer, I approach consciousness with how can I build it? Or what would it take to make a crappy little substitute for it and say, maybe it's something like this. And I think there, I can get a little bit I mostly I don't talk about this, because I think the appropriate level of implementation is so much lower than that. And consciousness is something that is kind of architectural and structural, that is going to be much less mysterious once we earn our way up to that level of architecture. But I do have a thought about it. And, you know, one of the things is, is Okay, so we're willing to by Dave's pitch that we have to have more redundancy, in software software is going to have to start taking over some of the reliability work, which we had said reliability is a hot hardware problem for the first 70 years. And so what that redundancy look like, and I think the best example of or it's the most obvious wonderful example, is in software is unit tests, that having tests for code is a redundant representation, the format of the test and the procedural code that it's testing are getting set similar dynamics, but they get it in a completely different way. One does it the other one checks to see if it was done. And so that, you know, it used to be in computer science, when I was young tests were like, oh, because you're too stupid to prove it's correct. You know, but now we live in a different world where if you don't have tests, then you're essentially negligent. So that is a kind of software redundancy right there. That is, you know, you can bite it, you can eat it, people love it, because it's good. And so to cover go dot, dot, dot way past anything that I can actually cover with an implementation right? Now, the sense of qualia, the sense of consciousness, the guts of it is going to be that we have these redundant representations. One sort of procedural thing that is we're doing that's actually running our sequencing control what we do move the hand do this. And the other one, that historian that folks have been referring to, that is describing what we've done, and we're going to get around kind of matching between those two representations. That's going to be like the test going green thing. And that ultimately is going to turn out to be the contents of conscious experience that that green blew up when the test has passed. We now have told the story. Oh, that's my engineer story.

Unknown 2:04:46
Thank you, Dave. So one last question from the audience. I'm sorry, we couldn't get through everyone's question. So this one is from Paul Cassidy. To everyone which think There's theories and concepts are you currently finding most fascinating and stimulating? These can be either directly related to the discussion topics or not highly creative and interesting people are the best to get recommendations off off in my experience

Unknown 2:05:21
thinkers, theories concepts, most fascinating and stimulated, geez. You know, the funny thing is, for all the engineering and science I tried to do, I really don't have that much time for nonfiction. So, you know, I see I feel like I learned a lot much more about the world from fiction. I don't know how to say. So all I can say is, at the moment I'm reading, walk away by Cory Doctorow and I'm finding it fun.

Unknown 2:05:53
You know, two authors who are often cited these days in circles that discuss consciousness are Giulio Tononi, and Bernard Barrus. And both of them actually talk in different ways about coherence of the state, brain spanning coherence of the state. In Tononi, the basic idea is, the space of all possible states of neurons in the brain is reduced by connection. So if if you cut the brain in half, then the two halves are free to think, to create states, they wouldn't be able to, to create in the presence of the inference from the other half. So that is the kind of, you know, he talks about, of course, entropy and such things. Whereas Bernard Barr's thinks consciousness comes to, comes into existence by there being a central Blackboard, a kind of exchange medium in the middle, the virtual middle of the brain, to which all the different ages or different sub modalities can put stuff and from which they can read stuff. So again, a kind of a means of creating order of creating a key coherence in the whole thing. In many of the discussions I've seen, these are referred to as domain theories. Whether you like it or not.

Unknown 2:07:38
So Christoph, what do you think of integrated information? Tognoni stuff due to buy in?

Unknown 2:07:45
Yeah, I agree with his basic idea. But I mean, you can't make a whole career out of this idea with a five function, you cannot measure it, you cannot compute it. You cannot deduce anything from it. It's a nice thought, share the thoughts. But so to narrow the different modalities, my brain cannot speak the same language, they cannot communicate in the same language on the blackboard, so they speak different pairs of languages. And so I find that too narrow.

Unknown 2:08:26
Yeah. To me, it seems it's metaphorical at best. And even if it's a metaphor, I don't know if it's a good one. But it's, well, it seems popular. I mean, just like the Markov blanket stuff seems popular, but it seems, I don't know. I have trouble buying it. Thank you.

Unknown 2:08:48
I'm an activity that I read a lot. But I cannot make a shortlist of whom I would recommend because every single time I find some great idea, what fascinates me most is that how far I have to go back in history to find the same idea. You always do. So I buy my favorite books are always old. Okay,

Unknown 2:09:10
I remember do you mentioned in the during the prep session, you mentioned prepared unprepared counter counter prepared concepts who was the bike

Unknown 2:09:23
Seligman, I can send you the reference right away. So, for example, you know that one is a extraordinary person when we talk about, you know, in my book inside out, I go back in time, and I realized that you know, maybe I have to go all the way to plateau. Because that was the ultimate inside out but then Seligman and many others, the umbrella member Allen that we discussed that the before the meeting, they are great thinkers, you know, ideas come by every 50 years. No small additions scum by heavy day.

Unknown 2:10:04
So the brain cycles do continue to lower Hertz.

Joscha Bach 2:10:11
Indeed, one of the most interesting current assets, Ted Chang, I think and Greg Egan thing, Greg Egan is probably the most interesting philosopher of mine was currently and I felt Dr. Ed. And his last name is Egan, e g, a n.

Unknown 2:10:31
I certainly will pitch permutation city to anybody.

Joscha Bach 2:10:34
Yes, yes, sir. There's books to read. And yes, it's also very beautiful, mathematically inspired short stories. He's he's a very mathematically inclined and physically physicist, inclined person who plays a lot business ideas in his mind. And it's not story driven, the things that he writes and stories are vehicles to explore ideas and metal fractals. It's quite quite beautiful, the intricate, but I do agree with your statement that most of the good stuff is actually quite old. I learned a lot by reading Ken and I also, besides that, I never found them that exciting. I grew up with him. And now I realize he's very good. He just was not exciting because he was just the intellectual ground zero where I grew up, it was just so normal, but it's still very good stuff.

Unknown 2:11:39
Excellent, thank you your shot. So with this new wrap up, we would like to thank into labs for allowing us to host this event. And we would like to thank all of the presenters for participating and for delivering these amazing presentations and the lively discussion afterwards. The meeting has been recorded and will be posted on our YouTube channel. The link can be found in the chat and the chat log with all the references will also be posted on our website. So don't worry, you don't need to copy paste anything in a rush. It will be there. With this, thank you everyone. It was great meeting you all. Thank you the audience for participating and enjoy the rest of your day.

Joscha Bach 2:12:30
And thanks to all our guests this was amazing and thank you Tanya for helping with the organization and during the moderation today. Thanks everyone. Thank you, Tanya. I speak to you guys. about am I slightly is great.
