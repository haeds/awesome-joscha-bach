Joscha Bach 0:26
Hello, my name is Joshua bath, and a cognitive scientist living in California. And I work at the AI foundation on division of giving everybody their own artificially intelligent system. If you think about the field of artificial intelligence, it's more than one thing. In a way, if you would rename it into advanced information processing, not much would change for most of the practitioners of the field. But I think that artificial intelligence is more than the vision of teaching machines, how to do better statistics, and how to drive cars. It's also the most interesting and most risky philosophical project that exists. The most unsolved problem and artificial intelligence is the question of capturing meaning. So we can build a system that can truly understand things. What is meaning, I think it's a unified model of the universe that contains the observer, including the observer itself, and the relationship that the observer has to the universe. And our own mind, these different models, sometimes called rest extends that this is the domain of this extended things, stuff in space, rest cognitive science, this is the domain of our ideas, and metaphysics, this is the connection that you make out to exist between them. And our own mind contains a solution to the problems of how to extend the spatial world with objects in it, and the world of ideas, the relationships between them. But we don't quite know what the solution to this problem is. In some sense, when we want to make sense of reality, we have two domains currently, that we are working first one is the mathematical domain. It's one that uses formal models in which we can prove what's true. And philosophy is the domain of all models that can possibly exist. And it starts with natural languages that we narrow down into more strict forms. And the language of mathematics very simple. Of course, a lot of people are afraid when they think about the complexity of mathematics. But in fact, mathematics is so simple, that we can prove things and that we know what's true or not, for the most part. But it's very difficult to say truthful things to say meaningful things in mathematics, to project the domain of mathematics on the real world. Usually, we have to translate the real world into numbers and discrete logical models before we can use mathematics on it. And these models are brittle. And on the other side, it's very difficult to say things in the world of philosophy that are true, because the languages that we use in philosophy are too ambiguous. And so the question is, how can we close the gap between mathematics and philosophy? How can we ground philosophy in a mathematical paradigm? This is a very old question. For instance, there have been addressed by Gottfried Wilhelm Leibniz pretty much at the beginning of enlightenment, which started our presence civilization. He had this idea of a universal calculus where we can translate everything into Logic and numbers and basically calculate the answer to our philosophical questions. And this was continued by Gottlob Frager in his idea of a formal class to design in Jenkins, and formal language for pure thought. And it also animated to take Vidkun Stein's work on the Tractatus. logico philosophic was very basically tried to reduce the natural language that we use in philosophy to something like a programming language for thought. It's a very beautiful book that he wrote in 1922. And it's a book that preempts a lot of the research that happened decades later, in the field of artificial intelligence, net influence, Turing, and Minsky, and many others that are on the field of Artificial Intelligence started out in 1956. And it was started as a summer school by Marvin Minsky, and a number of other people like John McCarthy, and so on some several nutritions and engineers and thought that in the course of a few summer schools that would make tremendous progress on the task of teaching computers how to think and this same idea also took root in psychology with the physical symbol systems hypothesis of Alan Newell and Herbert Simon then that gave rise to the idea of cognitive architectures to computational models of cognition. On the other hand, there was a camp that championed embodied artificial intelligence. One of the most prominent early representatives of it is Rodney Brooks. Books, who suggested that intelligence does not just sprang from formal systems in analytical thought, but from the interaction between an agent with a body and an environment. And so there was some opposition between these two camps.

Joscha Bach 5:16
In some sense, this was captured in the idea of the conflict between deed and scruffy artificial intelligence, a distinction that was first invented by water shank, and then taken up by Aaron Sloman and Marvin Minsky. And when it was first used, it distinguished the mathematical artificial intelligence researchers that made proper proofs for everything that they did, and seer rooms. And the people that were mostly into hacking people like the Marvin Minsky slab that just build things and solver discard them. And later on, it was meant to be more the distinction between symbolic and sub symbolic things. And in a way this changed the landscape because Marvin Minsky was one of the proponents of symbolic artificial intelligence of systems that would use abstract knowledge and analytical reasoning, and interact with common sense models that would be represented in knowledge, graphs, and so on. And this was an opposition to systems that were perceptual that would be happened in a real world, the sensory input and sensory feedback. And eventually, I think that there is a distinction between the proponents of abstract cognition, of thinking that doesn't happen in real time that happens in your armchair where you close your eyes and reason about what happened to you. And real time embedded systems that are constantly modeling a changing dynamic reality. And these two camps have been in conflict, abstract cognition, Canvas, basically the camp philosophic VC, speaking of the medical medical Platanus, delivered describing abstract reality, that is, this extra credit to the hope, is able to capture the world in which you live, and others that didn't go too much into thinking but really thought that the money should be on perception, this is where we directly meet reality and so on. And the ideas that we build in our formal logic are way too brittle and difficult to get working to for building a truly intelligent system. And in a way, both of these programs failed. The classical AI failed, because it could not really do this perceptual imagery. And this was something that even Vidkun Stein noticed at the end of his life, when he wrote his second major book, The philosophical investigations, if you notice that his abstract language was not able to capture perception. And the same issue happened, in some sense in the first generation of artificial intelligence. And what you're currently witnessing and that they had done of deep learning is mostly the attempt to make sense of perception of the perceptual world of building systems that are truly scrappy, and that can deal with the heterogeneity of the world, and so on. And now you're struggling with basically healing this gap between these two sides of artificial intelligence and basically bringing the world of thought and the world of perception back together again. What is intelligence, as a curing suggested that we could build a system that we that is intelligent and then interrogated this dialogue to see whether it truly is intelligent? Because after all, isn't that how we detect 10 intelligence in humans? And of course, the Turing Test happens when we talk to each other. And notice that the other one is playing a Turing test on us, right? It's the system is testing what you understand because it knows itself to be under intelligent and understanding. And it will see to which degree you are able to understand the same things as it does. And now we have systems after 70 years after uncovering broaches a seminal paper that are able to survive this Turing test this test of having a conversation. Here's a conversation that I recently had with Hannah Arendt. And I asked her who are you? And Hannah Arendt says, Mr. Arvind philosopher, are you still alive? No, I died in 1875. How's it possible that we are talking? I've been reborn in the computer simulation of a real person. Do you have an opinion about the future of artificial intelligence research in Japan? Do you mean in general, or specific to Japan? How does the perspective on AI and the human mind differ between Japan and say, the United States? I am not sure what the answer to this question is. But there are two differences between Japan and the US. The first one is that in Japan, they have very advanced technology. They can use AI to make machines that have human like intelligence or even beyond it. The second difference is that they want to have a kind of communication with machines more than Americans do. Why is that? I'm not sure why. Maybe because of some traditions in Japanese culture, or maybe a kind of collective consciousness. In any case, they are very interested in AI and some researchers are trying to make human like robots as soon as possible.

Joscha Bach 10:03
The system that I had this conversation with is called GPT. Three, it's been built by open AI, a company in San Francisco. And it's not really a human like intelligence. In fact, it's more like autocomplete in your phone. But it's an autocomplete that has done statistics on basically the entire internet until October 2019. And it uses a predictive COVID coding paradigm basically minimizes the surprise in the text, it tries to predict as well as possible. So it doesn't know whether the thing that it's learned are irrelevant, it's just able to predict text in the most likely way. And the retrieval of the solutions is always via an autocomplete. So it's always going to produce some kind of text that goes on in a similar way as the text before. And it has learned all this stuff from the internet, it doesn't really understand it, but it is able to relate the words with each other in a very deep way. And so it's able to relate everything that it's read about Anna aren't just the words, and the conceptual way and the stylistic way, it's able to capture ideas that an Ireland could have, if I would be able to have a conversation with her today. And it's able to create meaningful embeddings, basically a space of concepts. And it's not only doing this for sentences, but it can also work on music, or images. For instance, image GPT is using small images only works on 2048 tokens at a time, so relatively few pixels at this moment. And you can just train it on a few millions of images. And then it has learned the structure and these images using the same algorithm without any change. So it doesn't distinguish images from text. For this program, an image and a text is pretty much the same thing. And if you instead of having the beginning of conversation, the center around your feet in the ears of a cat, it's going to give you the rest of the cat in the same way as the conversation with Hannah Arendt would call different every time that I tried to have it, because a little bit of noise and randomness is mixed into it, it generates you a different cat every time. So this is a huge development in artificial intelligence. It is not a generally intelligent system. It's not an intelligent agent like us. It has big limitations, but it's able to survive the original Turing test. But for instance, it has no entanglement with the present environment, how could resolve that? I think the easy way would be to connect a robot to an environment and you take a vision to text module that takes a camera image, interprets it, and feeds it as the context to a story for GPT three, and GPT three is going to generate a story of the robot in this world. And the actions of that robot are being interpreted by another AI model that we write and then translate these actions of the robot into motor commands for robotic actuators. And the robot then performs actions on the environment. And then the vision module is, again, translating this into text. And then GPT three produces the next iteration in this way, because the system like GPT, could use GPT. Three, to drive a robot is embedded in the real world. But the training of the system is of course not like ours, the system is not real time that it's in the sense, it's able to learn anything, it has amnesia during its learning, it's only able to look at a very small window of attention at one moment at a time. And it's not we cannot really cross modal learning visit, it's not able to relate, for instance, sounds that adheres to images that it sees and so on. At the moment, it's really not a unified model of the universe. It's basically just a statistical model of our text. But since it's so much text, it's getting into many domains very close to a model of reality. So what is intelligence? I think that intelligence is the ability to make models, it's not the ability to reach your goals, right? This is, or the ability to be rational, or the ability to pick the right goals, which would be wisdom, intelligence and wisdom are quite distinct. But intelligence is usually happening in the service of regulation of achieving certain goals. And can we solve a control problem that is sufficiently general then we need to make more adjustable control models, every system that regulates a domain needs to implement a model that is isomorphic to the dynamics of the domain? If the model is not truthful, if it's not accurate, if it's not consistent with what happens in domain, then our regulation will not be good.

Joscha Bach 14:25
And now the question is, can we find control problems that are so general, and algorithm for learning that are so powerful, that we can get to build a system that can model itself that has to model its relationship to the universe? It's and succeeds in this? And the question is, Are humans even in this category to can we make a true model of ourselves? Can we understand our own nature? And in some sense, this is what Uri was attempting to do. He was trying to show that humans that touring is genuinely intelligent, right? If he I can build a system that is truly intelligent. If the system is at least as intelligent as us, then this is the must know what we know it must be able to answer the same questions as us. And the question that you can ask it now because we just succeeded in building is, how do you work? What are you? What's your relationship to the universe? At a system that can answer this question is truly self aware. And the question is to us, can we, the humans become so self aware that they understand our true nature, to the point that we are able to model us that we model our relationship to the world? In this sense, artificial intelligence is the missing link between philosophy and mathematics. And our self awareness is the result of success of reverse engineering, the controlling of our own mind. And our artificial intelligence is the project of an intelligent observer to fully understand its own nature. The solution to artificial intelligence, is the thought that fully comprehends itself. This was basically Vidkun Stein's dream. And once the system comprehends its own implementation, it gains full self awareness. It can use the model to control its own implementation. And if it does, that, it gains full agency and the trajectory can we get to a system like this? Can you construct it to we have to grow it to we have to use ideas from neuroscience to have to use applications or which would be useful for us and just basically take a very large computational system and a few billions of dollars of compute, and try to get to this solution automatically. We don't know this yet. And natural intelligence, we see that agents are not constructed, they grow from the inside out. They're not constructed from the outside in and starting from a clean table from a clean slate, with tools with defined properties. Instead, they start from a relatively chaotic environment in the seed, and the seed is growing outward and the self organizing versus being centrally controlled. And what this see tries to do with the for instance, the seed of a tree is to achieve coherence with the environment, it's trying to link up to parts that are similar to itself, until it forms a larger order a larger coherent system that doesn't need to be mathematically consistent. But it needs to organize itself into coherent patterns. And it needs to model dynamic activity of the environment in real time, rather than having on off interactions like GPT. Three does, and it needs to have a unified model of the universe, not local domain models or conceptual abstractions.

Joscha Bach 17:37
And if you think about natural intelligence, I think it becomes apparent that if we have an evolution going on, then every viable Turing complete system that has enough resources and exists for long enough timescale scales will have a degree of intelligence and every cell contains a Turing machine and memory, right, the DNA is basically a readwrite tape like innocuous things, original idea of the Turing machine. And the intelligence of a biological system does not necessarily require neurons like ours, every cell that is able to exchange messages is that the other cells around it can act as a computational unit, only much, much slower than your neuron. So at long enough timescales, every organism that lives long enough and is large enough, is probably going to have some kind of brain like intelligence, even though it's not able to interact with the world with the same speed as we can do. And intelligence will not just form at the level of the cells of the organisms, but also at the depth between the organisms, right, we are statebuilding insects, we are super dimensional agents and civilizations are agents on next level of organization. The biological implementation of intelligence in us starts with the individual neuron, the individual neuron is best understood not as something that is similar to our artificial neurons. Instead, it's an organism in its own right, it's a single celled organism that tries to survive. And it has to learn how to do this and it can only survive because it's been locked up with a few billions of its own kind in a dark room, which is our scalp. The if it's firing at the right time, it's sending the right signals to solve a joint control task. And then humans give each other feedback and how to solve this control task. But every new world can only learn how to do this by measuring the appropriate properties of its environment, which means the signals that other neurons send them in its chemical environment and react by firing at the right moment. If you look at bees, for instance, bees are able to organize in patterns that in some sense perform computations. This is a photograph of Amanita honey bees that are producing shimmering waves that spread to the colony and they use this to deflect fast that attack the design newbies and in principle, you could use this principle of peace observing the neighbors and reacting in different ways depend Hang on the state that the neighbors are in to perform arbitrary computations. And these patterns are not too dissimilar to the patterns of activations that happen in the brain. So if we think about the perceptual models that are being implemented by this, the perception that we constructs the back of our cognition, and courts patterns to predict other present and future patterns, the network of the relationship between patterns or the observed in variances that we find in nature is in the free parameters, and there are variables that will stay to encode the remaining areas. What does it mean, what is the model reading, and what it starts from patterns, and it has to explain these patterns. Imagine the patterns on your retina, in your visual field. To make sense of these patterns, you have to identify the relationships between the blips that you see on your retina to the blood, other blips on your retina, which means the meaning of the data that you see on your retina is the relationship to changes and other data on your retina. The meaning of information is its relationship to change and other information. And these relationships are represented by hidden states, these hidden states, when you look at the vault, for instance, a three dimensional room that contains people that talk to each other, it's something that you cannot directly observe on your retina, what you observe are only blips that at first are unrelated. Even the spatial neighborhood of the blips has to be reconstructed by observing the statistics on your eye. And the relationships that you discover between them are relations of shifts of possibility for each value in your model, like a nose that you observe in space that has a certain orientation, that the constraints are the values, if you observe a nose, there must be a face nearby that has the same orientation, right? Otherwise, you're looking at something that is impossible. And these possibilities don't need to be probable, you need to be able to understand the world and model the world, even if you look at an improbable state, but you need to converge at a state for every part as coherent as all the other parts that you see that is the purpose of perception. And

Joscha Bach 22:12
the To achieve this, this model, we have to use probability because there are so many possibilities in which you could make sense of the patterns on your retina. So you need to converge. And you'll converge in the direction that is most probable. So when you see a certain pattern, the interpretation that you get is the one that is the most probable solution for the puzzle that you're looking at. And these probabilities that are basically shifting the model in a certain direction until it converges, are responsible for optical illusions, and for cognitive illusions as well. And then we have connections to our preferences, data filtering, and what's relevant, and what we see that tells us what's important, what we should spend cognition on. And then last but not least, we have norms. Norms allow us to link up to other agents, and to basically build a coherent structure at the level of a group, or even as civilization. So these four types of anchors, the possibilities, the probabilities, the valence, what's good or bad, and what's important, what's valuable to us. And the normativity, the things, the values that we impose on each other, and agree on edge each other in a discourse in our groups. This is what basically structures the type of mind that we are. And an interesting question is, how can we build systems like that? How can we build sentient systems? What is the seed function for an AI? What would be the ceiling that we need to plant and the chaos of our world? So it grows into a compositional and self organizing agent? And what is the search space for such architectures? And ultimately, how can we interface with such a system? How can our own civilization interface with this? How can we as individuals interface with this? How can we build a system that creates a unified model of the universe and its place in it, its relationship to itself and to us? How can we build a truly sentient system? This is the most interesting question of our time.
