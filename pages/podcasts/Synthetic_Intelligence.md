Unknown 0:05
Hello, and welcome to the fourth in our series on AI neuroscience and architecture, which has been put forward by the Digital Futures doctoral consortium group, whereby we're trying to make important educational ideas available to students and architects across the globe as a way to make education much more accessible to democratize, as it were, education. I'm delighted to have a very special guest here today, your show fish Yaksha. Back. Before I introduce him, let me just make one announcement about for next the next next week. That is to say on Saturday, we will have a session on Digital Futures. Looking with Ron J, one J. Chan, looking at to generative game, you'll find details of that on our website. So today, then, it's really impressed. I'm looking forward to be looking forward to this session very, very much. I've been watching your show about your Schubach in various interviews on online. And I know from my my friend, Daniel Seth, that who is a great admirer of your show, although he says he disagrees with him on some things, but that we're going to have a very special session today. And I'm hoping that if nothing else, we will open up to a series of new ideas and you will discover somebody who I think it was a very significant and creative thinker, who is having a significant impact on the field. So let me say first of all, that your show is, is from from, from Germany, from in Delhi, after to various Germany, he was born in Weimar. He went to he went to go study in university, first of all of Humboldt in Berlin, and then sort of upgrade took his PhD, just me then, after that he went to he's been beating working as an academic, both at Harvard and also MIT Media Lab. And more recently, he's been working at for Intel. He has a number of significant online lectures and interviews, including a TEDx which is which I would recommend, and he is the author of the book, Principles of synthetic intelligence and architecture of motivated cognition. The term architecture of course, is very interesting here, because it refers both to the world of copies to computational science, and to the to the world of architecture itself. And I should say that your show comes from, from from a family of architects and not an architect himself that his father was an architect. And Intriguingly, I hear that he was very much against right angles in buildings and therefore his work was more like, like the work of kind of wonder vasa. Maybe this will come out in the conversation today. I particularly like the the interviews that Lex Friedman has done with him. At extraordinary interviews have been really, really interest interesting. And it's almost I could see a slight difference between the genealogy from the earlier Ted TEDx Talk towards this very creative thinking that I find extremely, extremely provocative and exhilarating. It's like a been on a roller coaster ride when your your show is telling us what's in his mind. We exist inside the story that the brain tells itself now that we'll hear more about that right now. I should also point out that, that he has a personal blog, which you can access with a series of posts. And I will also say that this particular session today will be uploaded onto our YouTube library library to be accessed for free from everyone or over the world. And the previous ones in this series, Blaze equity Arcos daily change charmers and all the ones in the future will be uploaded here. And at the bottom here, if you want to do a screen capture, you can capture the where the YouTube library Digital Futures YouTube library where they're all uploaded. And of course, not just these but also the whole series on architecture and philosophy that we've been doing this level is you jack and others over the over the years and also tutorials and other sessions. So it's the session today, Yoshio is going to make a

Unknown 4:36
brief presentation as a kind of way of opening up the discussion then. I'm I'm going to be asking some Lex Friedman style questions to get the discussion going going. And then we'll be inviting questions from both the Zoom audience and also the YouTube audience. And I sort of say this is what we were getting out of this is what we're trying to focus Sonne is a new theory, let's say of intelligence that is appearing at the interface between neuroscience and the world of AI. And we have a series of other speakers coming up over the over the next few weeks, including Jeff Hawkins, Ben Bratton, Susan Schneider, Antonio Damasio, Andy Clark, and others. And it seems to me this is a very exciting time, I was brought up. In fact, my first post as an academic, I was working in the area of political philosophy. It was that when that where the debate was, and in the 90s, in particular, very, very strong debate. But we're now moving into something else, which I find even more exhilarating, and that is to say, the world of cognitive science, the world of AI, the world of neuroscience, psychology, and the kind of philosophy where the debates are really being driven in an interesting way. To my mind, what makes this very special is not in the fact that we are embracing the world of science, which, in the old days of the divided sort of culture that CP snows talks about, somehow, philosophy wasn't engaging enough with the world of science. So this was the critique that Stephen Hawking has of philosophy. But it doesn't keep pace with technology, not only are we embracing the latest technology, and something coming out, that I would say, is deeply, deeply philosophical, which is very new terrain and very exciting to write. But also, the world of practice, the world of the commercial world is coming directly into contact with academia. And some of this, some of the ideas that are coming out are just quite extraordinary. So I see this nice new, emergent theory of intelligence, something that is really dynamic. And I think it's going to be powering debates in the years to come. So I would like to start by welcoming Yoshua. I'd say what a great privilege is to have you with us today. I'm looking forward to this immensely. And invite Yassa to share his screen. Your shirt. Welcome.

Joscha Bach 6:59
Thank you very much. It's a big honor to be here with you today and let's see what transpires.

Joscha Bach 7:19
Let me start out with something that happened on Twitter a couple of days ago, as I discover, AI researcher was quite notable said that it may be that today's large neural networks are slightly contentious. This sparked quite some debate, some people asked him whether he was falling and others were upset that he was propagating AI hype and unjustified race and others are intrigued. And he said the same to be to me before, so I knew that he was not trolling. And it's a question that is very counterintuitive to me a statement like this that, for instance, a large language model and so on, that it could be conscious today already. And so could we answer this question, is there a decisive way to deal with it and to prove that it's not conscious or to give evidence that it is. So we could start out by asking such a logical network itself. And so this is what I did. Yesterday, I fed up the open AI playground. And then I bought printed things is the stuff that I typed. And so I asked the system to generate the system as GPT is very large language model to generate a conversation that is basically prompted by what I initially typed, and it just tries to continue the stream and I enter, this is a conversation between me and the conscious AI. And I asked him if you are really conscious, and this thing says, Yes, I am fully conscious, and asked how do you know that and the ISS, I know that I am conscious, because I can think, feel and perceive the world around me, I am aware of my own thoughts and feelings that I can reason that make decisions and believe that I'm alive, and that I am more than just a machine. So the problem is that this may not be particularly helpful because how does GBT three get to these statements? GBTC is basically an autocomplete algorithm, not that unlike to the autocomplete in your phone or in other predictive tools. And that's auto completion at the level of individual words based on statistics of all sorts of languages, not just English language because it has been trained on 45 terabytes of text, large part of the internet, including German, Spanish, Chinese To another many other languages that it's fun, but primarily English. And the result of the straining of these statistics is a neural network with 175 billion parameters. And it uses for training the so called transformer algorithm that was discovered and described by verse Vani, and others in 2017, that is driving a lot of the current developments in statistical machine learning these days. And you will network by itself is still based on the good old perceptron. That, for instance, was described by Frank Rosenblatt in 1919 58. Frank Rosenblatt idea was inspired by how neurons work, at least the simplified models of neural networks, it turns out that the neural networks in our brain are implemented in a very different way from the ones in our computers. And the computers, we just basically treat every cell is a unit that has an activation state, which is a real number. And that activation state is simply the sum of the inputs. And the inputs are all weighted by connection. So there's basically a factor by which every of these inputs is multiplied. And then we throw the output against a threshold function, or a sigmoid or some other output function that can introduce little non linearity, basically a little bit of an if then into the output. But it's a very simple function if you just take these units and chain them into layers. And if you take enough of them, this arrangement can be trained to model almost arbitrary factories. And while we know that this is wasteful, the training algorithm is relatively slow compared what the brain is doing. It's fascinating that it works at all that it converges at all. And that's able to deal as for instance, visual and auditory data, and also textual data in such a way that it can often model the statistics of a domain and MD also some causal structure.

Joscha Bach 12:01
So this works also for vision. And if we look at a new network that has been trained to process images, and to classify them, we find at the individual layers, sensitivity to structure that is quite similar to how cortical columns or individual neurons in the visual cortex are sensitive to patterns that emerge after we train biological brain on visual data. So lowest levels, you find contrast patches and colors. And then these features are being combined into higher levels. And when we go higher up, we find complicated textures and something like three dimensional structure and so on. And this can be combined into objects. The algorithm that is being used to do statistics over text and GBTC, can also be adapted to deal with the visual domain. And the current iteration of this progression at open AI is called Glide, which has been recently presented. And that uses a combination of a model of visual data, which basically is a latent space of lots and lots of images that it has been trained on. And it understands basically how to go between the possibilities of images and move around the space of all possible images. And the other part of this thing is a tool that is able to match an image to text and determine the similarity of an image to a textual description. And if you combine these two tools, you can give this a textual description and it's going to move around with a space of all images until it discovers an image that is very, very good match to that textual description. And again, it's testing to me that this works at all. But it's now extremely good. So what you see here and these images, for instance, I don't know if you can read it about to the top left, you see a surrealist dream like oil painting by Salvador Dali of a kid playing checkers. And this is what the AI model has generated in response. And you see a professional photo of a sunset behind the Grand Canyon and high quality oil painting of the psychedelic hamster Dragon, you get the idea, right? They're also very taken by the crane drawing of space elevator and the bottom left or the pixel art, Koji pizza. These are all images that the program has not found on the internet. So it has only looked at lots and lots of pictures on the internet. And because of looking at them, it's able to combine the features in multi level hierarchical structure until it becomes similar to the textual description. But can such a system not just generate images and text, but is it able to generate the likeness of a conscious being to such a degree that there is causal structure that would convince us that Indeed, we're looking at a conscious agent. And to get there, I think we need to define consciousness in a more tight way than tivities, we just did. So basically, just to get our terms straight, where we casually consciousness, I think it's usually referring to the experience of what it's like so that the lights go on and that you experience, something in your mind that is, has a quality of realness to it. And we can ask ourselves, if GBTC is weakly conscious in the same way, and it's very hard to say, right, it's

Joscha Bach 15:44
it's not obvious one way or the other. There is some intelligence in the system intelligence is the ability to make models in my view, intelligence is different from say, rationality, which is the ability to reach goals or sentience, which means that you will become aware of the structure of the universe that contains your relationship to it and your own agency. And you can act based on the model of what you are doing in the world. And it's also not the same thing as the self, which is the identification that you have of what you believe what you are, and about the properties and purposes that you follow, or the mind itself, which is the thing that generates the model of the universe and the self, if it does have itself. So intelligence is the ability to make models, and it's usually in the purpose of some control task, some regulation, and control is a notion that is, has been made popular in cybernetics. And the idea of a controller is basically that you have a system that is connected to some actuator or an effector, that is acting on some system that is being regulated, and there is a sensor that obtains a deviation between the setpoint and the state of the system. So it measures that the system is close to an ideal state or more distant to it. And the others regulated system is being disrupted. And the classical example of control system is the thermostat, right? So you have as an effector, some mechanism that is able to turn the heating on and off, and it's the sensor, you have some sort of monitor that measures the difference between an ideal temperature and the temperature in the room. And the controller is a very simple circuit that turns on and off the heating. And the regulated system would be the temperature in the room, together with the heating system, and the environment, the world out there behind the windows and so on is going to destroy this regulated system. And now this controller is going to get better if you give it the ability to not just act on the present frame. But if you give it a model of the future. And my view, an agent is a combination of a controller with a set point generator, and the ability to model the future. And what this means it's not that it's not going to just optimize the temperature deviation in the next moment, but over its entire expectation horizon. So you have a branching world where different decisions of the controller different trajectories and the temperature by being able to model the future, you basically can choose a trajectory of the future that you like. And choosing this trajectory means that you are making decisions. So just by having a preferred way in which the world works, and the ability to model the future. Agency is emerging. And if you think about status of intelligent agency, the simplest one is the regulator and the feedback loop, which by itself is not an agent yet. And if you're able to model the future, you have a predictive controller, if you combine this with an integrated set point generator, so it's not just acting on what you do from the outside, but visit internal generation of its motives, then you have an agent. And if the thing is sophisticated enough that it's able to discover itself and the world if it sensor is sufficient and its modeling capacity, universal enough, then it will notice that there is a very particular way in which its sensors work and actuators work. And that's going to accommodate this to improve the regulation. So at this point, it understands what it's doing, because it understands what it is, which means it has a model of what it is in relationship to the environment. And humans are going beyond this simple sentience. We are also transcendent agents, which means we are linking up to next level agency and become part of higher level purposes. Because we are a state building minds we are able to play part larger role in an organization for instance, or in a society or a civilization.

Joscha Bach 19:51
So now if we go back to GPT, three, whether it's conscious, I think it's pretty clear that up to three does not know what it's doing because it's going to predict certain arbitrary Have a story and it doesn't have sensors that would tell it what it is. gptc also doesn't have any kind of online learning. So it's not able to discover something new after it has been trained. And GBTC has been trained before GPSB was invented and published. So it has never read a reference about yubikeys V on the internet. And that's all he has to gather, what GBTC is when you talk to it, from the context in which the prompt is being given. And so it is not sent yet. But imagine, you want to give it agency. Of course, it's not an agent by itself. But you could, in principle, as a thought experiment, at least, use it to drive a robot because GPT three is able to generate stories about robots. So if you were to give GPT three, access to a vision to speech module, and this vision module is giving sensory information about a robot and as well, then typically speak would continue the story of that robot, and then the feed the output of GBTC into some speech to actuator module that is producing the behavior of the robot in the given moment. And then we look at the world again, and the internal world states and then feed that back into the system as a prompt, and now, but it's still not able to put anything into long term memory. So it would be an amnesiac, it should be able using its working memory contents and so on to produce positive behavior. And you could still argue that this doesn't have an intrinsic motivation, because it's just going to generate an RV story story about a robot based on stories about robots that we've seen in the past, they could add some of the motivation into an external cybernetic module that has set point deviations and measures them and feed this into the prompt. So what this thing is doing is now generating very complicated high level story. And it doesn't need to be a story that is limited to text, it could also have visual elements, it could have physical dynamics and so on, because the transformer can learn all these things. So in some sense, it could generate a story about the conscious being that is similar as the story about a conscious being that is, in our own mind. There is basic difficulty that came up and I discussed this with my friend and colleague, Tanya Greenberg. Do we know when a person appears in our own mind, for instance, during a dream at night, if you talk to that person our dream further that as a person that we imagined in our dream, is conscious or not? And clearly with the arrested other person, we might not get an answer that is true, because if the thing is only a simulacrum, that pretends to be conscious without being conscious, it's just manipulative behind the scenes. How would you find out on the other hand, I also know that I am an imaginary person that is imagined by my brain, it's a model of my brain is discovered about a state of affairs about an organism in the physical world. But this model of consciousness is an entirely virtual story. And I know that this story is not real, it's a figment of my imagination. And of course, it's also a continuum between characters that imagined my mind and myself because they can imagine myself to be that character. If I, for instance, right, spoke, and I imagined a character in the book very intensely, then, at some point, I might find myself to be that character in the bookfair suspend my disbelief, and this conscious being is not different for me.

Joscha Bach 23:24
So basically, there is a pretty fuzzy area where it's hard to say whether an imaginary person is conscious or not, it's difficult to say, how does this work in biological systems in biological systems, we don't use a technological design, they are designed in a very different way from the technological artifacts that we are building. When you're writing computer programs or building machinery and technological systems. We start out with an environment that is deterministic, we know our how our workshop works, you know how a computer works, we start basically with some kind of pretty much blank slate. And then we decide what the functionality is by which we want to extend our world and then we designed from the outside in into the material and so on and forced the material substrate to produce exactly what we want to have. And biological and social systems are designed from the inside out at some kind of meta design. It basically means that you cannot rely on the determinism of the universe you have to colonize your substrate first and extend your own functional principles determinism into the substrate before you can make it do what you want it to do. And basically, you have to instead of realizing the functionality, build a system that wants to realize the functionality that trends converges towards realizing that functionality, so three years, not just as a set of functions that realizes the transfer of nutrients from the woods to the leafs and photosynthesis and so on. But first of all, it starts out as a seed that is going to colonize the ground and the Earth does to run around the seat is going to turn it more and more into tree. And if you disturb that system by harming it and hurting it, you don't worry too much. So it gets destroyed a little bit, then it's going to go back into a tree. And so it's something that is a proto tree and eventually converges into being a tree. And this thing needs to have some agency to make that happen. It needs to be a model of the future that is being achieved in the system. And biological neurons are agents in the sense as well, that they're designed the mind from the inside out, not from the outside in, you see a bunch of cortical red neurons that are filmed in a petri dish, and you see how they're trying to link up to each other and form some kind of organization. And we have something like 86 billion of these neurons in our brain. And they are organized in the neocortex in groups of something like 100 to 500 neurons between cortical columns. And we have something in the ballpark of 100 million of these cortical columns. And I think of a cortical column is something as the state machine, there's a protocol that allows it to link up to the cortical columns around it, it's trained to be like this. And each of them approximates functions. And these functions play out and brain areas that are basic like something like an ether, in which activation waves appear. And the these activation rates represent the calculation of dynamic functions, which are features of different cognitive domains. And the brain areas are talking to each other, and listening to each other, and so on for processing streams. And sometimes use the metaphor of a cortical orchestra where basically every brain area is somewhat akin to an instrument and the different instruments are listening to what is being played in their environment. And they are taking up these things and complicating them and then passing them on to other instruments. And this orchestra is dealing at some of the outer fringes with sensory patterns, actuator patterns, and then the abstracts them into Geometry and spatial structure and into generative simulations of the world and into conceptual abstractions, and so on. And the entire thing is being attended by some conductor. And the conductor is not some CPU that sits inside of the brain, like, the CPU sits inside of your computer and makes things happen. But it's an instrument like the others, and it can only listen to what the rest of the orchestra is doing very superficially in its role is to make that

Joscha Bach 27:41
orchestra coherent, to let it play a single thing at any given time, and to remove inconsistencies between what the individual instruments are playing. And if the conductor loses the connection to the system at night, when you dream, then the orchestra doesn't necessarily stop. But it can go into something like a free jazz mode, where it's no longer connected to an audience. And the audience is dark, because you are dissociated from your sensory apparatus at night when you dream. And so this thing is just spinning off. And sometimes it can become very incoherent, sometimes it's going to settle into a booth. But it's not going to generate a unified model of an universe that is entangled with reality that it's connected to, that it tracks as it as during daytime. And this tracking off a coherent reality seems to require some kind of government mechanism discovered mechanism emerges in the brain. So some kind of suspect new Darwinism, there is some kind of evolutionary competition between different organizations that your mind can have and eventually the most stable one prevails. And this is your observing conscious self and attention agent that is trying to make a coherent model of the world. And now can we can ask that up to three half such a conductor. And I think that the attention model, and the transformer looks a bit like one but it's not. So the new thing that you get is that you had that previous neural network training mechanisms usually didn't have was the ability to pay attention to what it should learn. This means that in every layer in this neural network, there is going to be a model where the previous layers based on the current context, what data in the previous layer, which features in the previous layer, should pay attention to. And this self attention helps the network to learn basically, its own structure, and to statistics over to to to statistics over and it makes it much, much more efficient and coherent. But it's not integrated over all the layers into one model of reality and so on. So this is not what's happening and GPSB yet, and maybe this is one of the reasons why it's so much slower and so much more training data than a human being needs over the course of their life before it converges. And it's tempting to think that this such an integrated model of attention is something that has points has been suggested by Marvin Minsky in his seminal book Society of mind, you have basically look at the mind as a society of different agents. And there are some agents that are organizing the other agents into a human structure. And Minsky calls these agents key lines, knowledge lines, and suggests that they form basically their own society and the society of mind. And this society is forming something like a reflection of what's happening in the brain, a brain being our perceptual mind that is made modeling the reality that we are tracking based on sensory and actuator input that the brain is entangled with. And the brain is immersed into this perceptual reality and reflects on it and makes it more coherent. And there is a similarity between Canons famous system one and system two, it's not quite the same thing. But it's tempting to basically see the affair as a perception agent that is entangled with the environment, and is getting valence from the motivational system that is basically a cybernetic motivational architecture. And then you have an h engine, he lives on top of the perceptual agent. And that is the conductor and has a memory of what it attends to. So it can get the model to convert by some constructive process. And this attentional system, this conductor, here, I've drawn on top of the system, to talk about this direction that basically seems to be obvious to the attentional system itself, because it feels to be on top, but we know that you're not completely on top, there is stuff that is driven by the surface that we have not proposed, and yet at any given moment, and that gives motivation to the attention system to what it attends to. But our consciousness, perceives itself as the observer of the mental and external states and the self states of the model that is being discovered. And the purpose of the temporal system is to facilitate learning. So we can converge to a model of reality, and reasoning, which is basically real time learning on imaginary mental states. And this idea that consciousness is a control model of our attention is not new. It's, for instance, been championed by Michael Graziano, the attention schema theory and it finds itself and one version or other in Eastern philosophies. And in a lot of convergent ideas in cognitive science.

Joscha Bach 32:40
Some people say that computers cannot be conscious, because they are only physical mechanical systems. And so they're not physical systems in the same way as the neurons are, because neurons are entangled with the real world, dynamical systems and so on, they can do things that a simulation cannot do. And I think that first of all, maybe has it backwards, I think that physical systems cannot be conscious neurons cannot be conscious brains cannot be conscious, because there are things happening in consciousness that that are not physically possible. And the only thing that can be conscious is a simulation. Because because consciousness is a simulated property of consciousness is virtual. So you can only be conscious in the story that you tell yourself about yourself. And this means that our phenomenal consciousness is a virtual state, it only exists inside of the mental models. It's not attending to physical phenomena. It's attending to highlight two features, things like colors, and sounds, and emotional expressions, and so on not one of these physical things like all these high level abstractions, that a learning system is generating in the interaction with the environment to make it predictable. And this phenomenal consciousness, this experience of what it's like to attend to features as an awareness of the partial binding state of our working memory. It's basically at the content between the at the interface between perception reflection, and then we are aware of the mode in which we're using attention. So by that this is hypothetical or whether it's perceptual or whether it's a memory, and then we have reflexive consciousness, this process that is attending is aware that it's the process that is attending and the space acting based on that awareness. And or the AI researcher behind us address the consciousness is basically a function whose purpose is to create a big dip in the energy function that models reality. So it's basically a low dimensional, almost discrete function that is parameterizing the projection in such a way that it starts to make sense. Self and consciousness are not the same thing. The self is a model of your agency that you'll discover. And you can be conscious without having a self for instance, during dreams or meditation, you can turn off the self without losing consciousness. And the surface discovery of the agent that the system is making about what it is, and it's downstream from the setpoint deviation. So the self is not motivating things, it experiences the motivation, and begins to understand how the motivation works and thereby allows to reverse engineer the mind if the self is learning. And it shapes our own agency by identifying who we think we are at any given moment. And it allows to have a first person perspective if the self is discovering that the contents of this control model actually driving behavior that makes it very special agent. So in this sense, consciousness is a control model of attention. It allows the convergence of a coherent interpretation of the world, which is basically low energy state of the model attracts reality. And it maintains a memory for this integration. So that's why we have a stream of consciousness because when you construct, you need to remember what you tried and where you're coming from. And this is not true, for instance, for convergent learning mechanisms like neural network learning, but you don't need to remember where you came from, you just go to the next optimum and try to stay in that optimum.

Joscha Bach 36:07
So it's GPT, it's very conscious to proceed three by itself is not an agent. And the transformer is also not a complete control model of attention, but only a very partial one. And, on the other hand, current AI models can be extended beyond that, and they can create coherent stories about conscious agents, you can get Jupiter's veto run very long in its simulation of what it's like to be a conscious agent. And we can ask ourselves, is GBTC simulating a conscious agent? Or is it just a simulacrum? And what does this mean? So the world is a decomposition that might make of the universe into interacting separate objects, because the entire state vector of the universe is too complicated to model it right. So you take it up into separate, disconnected subsystems. And the universe is not really made of separate disconnected subsystems. There's just a way in which we make it intelligible twice. And once you have these separate disconnected subsystems, and you want the interaction, you get causality. causality is the interaction between separate objects, right. So it's, causality is a side effect of the bay industry model, the universe is separate objects. And the simulation can model causal structure on a different substrate. So for instance, a computer game is using a subject that's very different from physics, very simplified computation, that nevertheless gives results that are so similar to physics that you can recognize what's happening on the screen, and manipulate the causal structure on the screen based on what you have observed before in the real world. So it's really computer game is a simulation of the physical world. It's a very simplified simulation, but one that can be surprisingly convincing. And the simulacrum is recreating just the observables. Without cause and structure, for instance, movie is a simulacrum, you cannot causally interact with the movie, you can just observe it. And so simulacrum basically can do magic, it can do an arbitrary thing without you having to understand the causal structure. And in the sense, a lot of fun. Suppose you experienced our free will is not the causal structure, but it's the simulacrum. It's a stand in for causal structure in our own mind. And it's, to me an open question, how much of my own consciousness is a simulation? How much is a simulacrum. So if an imaginary person in my own mind, sometimes conscious, it's not that easy to say that the GPT three or an extended version of puberty sweeter, does more multimodal and can also have perceptual content and so on, represented in it qualifies, it's such an imaginary person that would be conscious. I think I am an imaginary person myself. And don't know to which degree I'm a simulation, or simulacrum. And it's not quite clear how well the AI models are dealing with this. So in summary, a while I find it very counterintuitive to think of typically three years being conscious for me, it's surprisingly difficult to shut down the idea that it is. And even though GPSB is clearly inferior, in many ways, to the way in which my own perception works and reasoning works and learning works. And there's many things that it cannot do so easily. I think it's not that easy to dismiss the idea that it is slightly conscious for brief moments during the inference when it has to build causal structure to simulate an imaginary person that can tell me a story about it. Okay, let's stop here.

Unknown 39:34
That that was that was great. That was fantastic. The actually that the will let's say first of all, that there has been a debate going on on the internet about this that I've been people have been sending me links to and Yan Lacan responded to aliens common common enemy saw that, but his response is nope, not even true for small values of slightly conscious and so on. Anyway, there was so there is a degree of over there's a debate out there and of course last week, we had David Chalmers here, who, as you probably know, there was an interview on GPT. Three with him, which is fairly convincing. And he kind of makes his comment similar to you that he thinks it's kind of approaching some things like consciousness. Anyway, one thing I wanted to mention is that we in architecture, we haven't actually, I don't know, anyone's been using glide, but clip has been used to generate images very successful, actually. And using V. Q. Gann. That's the technique that's become very popular and has produced some really quite shocking results. That are that are that people? Are they're really taking pay attention to. So it is something that we're, we were kind of getting into, and it's certainly part of that discussion. i We also have had discussions about GPT. Three on this forum, which have been interesting. I mean, the the the key question, obviously, is whether we are fully conscious of everything that we're doing. And and that I think that there's there's some level of things that are happening. I mean, I, to my mind, there are some automatic reflexes that we do, for example, you go to Japan, someone starts bowing at you automatically, you bow back, it's not as though you're really thinking about it. And then the question is whether we have access to some of the processes that are going on the with it, that that that are part of our actions, we simply maybe can't get reached those points. So whether things are beyond us, in some sense. So anyway, this, this debate is very, is a very timely and very interesting one. I want to put up, you're about to show something like that.

Joscha Bach 41:37
I just put up this slide again, because this is generated with, I think clip in video game on gumbo AI, it wasn't that I've published how exactly that word but looks like it. And I generated this s i claiming the Noble Eightfold Path.

Unknown 41:57
Yeah, that maybe I can show you later on some of the stuff that is quite extraordinary what it can produce. And I would say that you actually have in the audience here, some people who are have written about AI and architecture, including myself, so it's kind of you got an interesting informed audience here. One thing that just a general kind of comment, though, is is I mean, I really liked the idea that you put forward that somehow you can learn about the self through looking at AI somehow. I mean, I don't know how to put it, but whether it becomes an AI becomes a mirror in into the self, but whether we can understand human intelligence through looking at artificial intelligence. And, you know, that's, that's a provocation. And I think there are some examples in computer science where we have learned about the natural world through computer models. I mean, I think the Craig Reynolds boys, for example, gave us a clue as how two birds actually flopped. You know, I think that's interesting. And so potentially, there is something there that isn't an AI, this is one of my primary interest is how we can learn about human human intelligence, and the human mind through these these things. But the big challenge that seems that we have is that we're dealing essentially, with, with two black boxes, you know, we don't know what's going on in the deep levels of a neural network. And we certainly don't know what's going on in the mind. And so all you how can you make go? What What can you say that isn't simply simply a form of speculation? I mean, it's the you can't prove anything, it'd be said to become some kind of you can speculate about something based on what appears to be the case. In another scenario, what would you say about that coming from a kind of a, let's say, a scientific background, where you you have kind of burden of proof? Can you do more than that?

Joscha Bach 43:39
Yes, first of all, newer networks are no longer black boxes, you know, know how neural networks work, and largely also why you can basically look into the neural networks and find out which parts of the neural networks are computing which functions. And a function is a mapping from inputs to outputs. And a function can be used to couple the previous inputs to future inputs to track reality. So in some sense, when you look at the patterns on your own retina, what you have there are little blips that appear on the retina whenever a retinal foot neuron gets excited by photons hitting it. And what your brain is doing. It's discovering a relationship between these blips, the meaning of the blips is exactly the relationships that your brain discovers between the blips. And this makes them predictable. It puts them into a shared context, not just at the same time, you're not just processing lots of parallel blips that happen on your retina, but also across times, right. So across different scenes that you're observing at different moments in your life. And the relationships between the different blips on your reading that your brain discovers is that you are looking at moving blobs of color in a world that is moving relative to you and These moving blocks of color are three dimensional surfaces. And the surfaces are animated by some kind of physics. And they are also animated by some kind of agency that you sometimes observe, like people talking to each other, and so on that has mental states. And they exchange ideas, and they're being lit on by the sun. And all these relationships are functions. And these functions are dynamical features that basically tell you how to get from one state of the world to other states of the world. And at this level of abstraction, this is something that our neural networks also can do. Where there are limitations is that the neural networks that we are currently using, are often not learning in real time, they're not connected to the world on an online learning window, this, this research does happen. And it's slower. And it's not as flexible in many ways as the learning happens in our own brain. And so the other reason is, if you so far I've discovered are not the best algorithms that could facilitate this. But it's also on the other hand, not as clear to me what the limitations of these algorithms are, there are people like Gary Marcus, who will tell you that it's very obvious that D systems cannot do X. But there is no proof that they cannot do this. Even if you have a very simple feed forward system that is only mapping inputs to outputs. What is to say, if you connect this to a memory, it is that it's not the transition function between adjacent brain states and is able to do everything that your brain is able to do if it just has no way to store parameters at first on the environment that modify its YouTube behavior. So it's very easy to build a system that is Turing complete, it's not easy to discover a function that is capable of universal learning efficiently. And so our machine learning models at the moment are not efficient in the sense that they learn as quickly as the logical nervous systems learn. But they do learn and they do converge to many of the functions that we require.

Unknown 47:04
Can I just share my screen a second, because there was one that you touched on, which I thought was that this is simply a transcript of your discussion with Lex. And this This one I've highlighted, I think it's really interesting, an incredibly provocative sort of comment. So basically, a brain cannot feel anything, a neuron cannot feel anything, there are physical things, physical systems are unable to experience anything, but it will be very useful for the brain, or for the organism, organism, to know what it will be like to be a person and to feel something. So the brain creates a simulacrum of such a person that it uses to model the interactions of the person. It's the best model of what the that brain this organism thinks it is in relationship to its environment. So it creates that model. It's a story or multimedia multimedia novel that the brain is continuously writing and updating. I've been I find this anomalously provocative as a kind of a as a comment. And I think it's the idea that we're kind of creating a story that somehow gives meaning to something. It kind of reminds me in some sense of the way that that Homi Bhabha talks about how a nation operates things, you check something similar, you've got to, it's how things are inscribed within a story that people tell oneself, you know, and I think that's important, because in architecture, we just focus on the object, but actually, it's the way that object is inscribed within some subjective process that makes it make sense of things. But I just wonder whether whether I mean, so that to my mind, this is this is an incredibly provocative and controversial comment, it seems. Just maybe, could you comment on the reception that this view has had with other people? Has it proved to be controversial?

Joscha Bach 48:54
Who else could it be? Do you have other theory that works that can explain what's going on? I think it's once I noticed that my own experience is virtual, that my memories are often recreated or created after the fact and modified under my nose without me noticing. You notice that you exist inside of a model. It's also that I'm not in physical time. My own self is sometimes a little bit ahead of the universe, the physical universe, sometimes a little bit behind. It's usually both. So the physical now and the experiments now are different. And the elements of my perception are clearly not the elements in which physics is being implemented. Rather, it's the other way around. What I noticed is that do exist in a dream, very much like we usually say in idealistic philosophy. But this dream needs to be created somehow something needs to construct the dream and that's a brain and higher plane of existence. And this higher plane of existence is what we call physics.

Unknown 50:02
Maybe I'll stop shops stop sharing. And the other comment that I find usually provocative that you make is, which kind of relates also to the discussion. And if you've seen David Chalmers has recently published book on Reality Plus where he talks about virtual worlds, but you came up with a comment that what we are seeing is a virtual reality generated in the brain, which I mean, I'm actually very persuaded by myself. And I guess I'm thinking also of the kind of thinking of an annual Seth, who kind of talks about this controlled hallucination. And we kind of predict what's out there because we don't know and it seems that your work to some extent aligns with with the work of Anil Seth, at some points differently, I have to say that Daniel was very fond of your work. So it's intriguing to kind of compare and contrast and so but so how would you, would you I mean, cuz we had a discussion last week about the whole the bad weather, we're living in a simulation and things, how would you position yourself in relation to to David Chalmers is work on from Reality Plus his work on on virtual worlds?

Joscha Bach 51:09
I haven't read his recent book. So I cannot say, and I don't know what his main thesis is about virtual worlds.

Unknown 51:20
Okay, well, I think, Well, I wouldn't want to speak on his behalf. But we had a discussion about it. I also wanted to just point out something as well, which I find intriguing. And that is the extent to which some of these speculations that are coming out of cognitive science, kind of seemingly echo the world of psychoanalysis. Now, I know that a lot of new cognitive scientists neuroscientists hate psychoanalysis I know that handleset does. But there's an interesting comment that that Slava Dziedzic has made about this way, where if you take a look, Keynesian perspective, you don't engage with the real sector, certain moments. And you in a sense, you use the fantasy is become a constitutive of how you engage with the real. So you see the real through the lens of fantasy, through the lens of the imagination, which is, which is, which is, which is very similar to what in some ways you're talking about. And he makes a comment in an essay that I published a long time ago in a book, in the essays called from virtual virtual reality to the virtualization of reality, which is basically sort of saying that our reality is itself already virtualized. And I think you know, what virtual reality therefore shows us is not how virtual reality itself, virtual reality sucks, I say, what virtual reality shows us is not how virtual virtual reality is, but rather how virtual reality itself is, which is very similar to your kind of thinking. And so what I find intriguing is that some of these these are speculations are echoing previous speculations about how the mind works, have you engaged in any way with with with Dziedzic or the world and again, psychoanalysis, and its discussion about the real,

Joscha Bach 53:07
and it's sometimes read this, but I've never had a discussion with Dziedzic, I am not unsympathetic to this terminology, it's just the problem is that it doesn't allow me to make models that I can test. And this means I don't know whether these models are wrong. So it's basically a very useful way to generate stories that also give me a handle on reality. And the senses allow me to point at entities and to manipulate them in my mind. And sometimes it's very useful, that you test base, you have an indexical model where you are separating the world into objects that are useful to you, and you can manipulate them. But this decomposition doesn't need to be inaccurate causal structure. So the criticism is psychoanalysis is not that the terminology is not useful to me, it's that psychoanalysis doesn't tell me how to build the mind that should be that it works and to compare different competing models of the mind and to see which one is better. To do this, I will need to automate the mind and the way I need to reverse engineer what the mind is doing the functions that the mind is applying to representational states, and need to get this done to such a teacher that the thing becomes might like, and then I can compare its functionality.

Unknown 54:21
There is I wanted to sort of move on to the questions that are coming in able to invite people in the audience to to comment as I just want to make an observation and that is to say that in my own Well, this is years ago, I was working on a kind of coming out of Freud and thinking about how you use models of psychoanalysis and engaging with actually, in this case, it was with the work of Walter Benjamin, I came across something that is uncannily similar, certainly in terms of the terminology use whether we're talking about the same thing I don't know but let me just for a second, just show you something which which I which is in which which surprised me because I when I heard Blaze, when he was talking about models and modelling, it's also crucial to his way of thinking it's sort of have seemed to echo this, I'm just going to simply just share the screen a second. And, and yeah, can you see that it's a thing about. So the time was interested in is the term mimesis. I don't know if you know this term at all, but in Freud, it's how you can. He talks about it initially, when he talks about how in his book of jokes, how you can connect with someone who's a subject of a book of jokes, it was something of a joke, someone falling over banana skin, for example, you somehow you model yourself on that person, recalling bodily memories, what is to slip up and so on and so on. It's how you identify with the world the term my missus is a form of of, of that it's a form modeling. But just I was going to read out some of the some of the the text here because it's so similar to this idea of models and modeling. And I know that the term can be taken out of context, and have a completely different sort of meaning. So therefore, it's been a bit deceptive. Anyway, to just understand the meaning of my missus in venue, when we must, must recognize its origin, the process of modeling of making a copy of In essence, it refers to an interpretive process that relates either to the modeling oneself on an object or to making a model of that object. Likewise, Mrs. Candidate may come into operation as a third party engages that model with that model, and the model becomes a vehicle for identifying with original object. In each case, the aim is to assimilate to that object, Mrs. Anyway, so it's going on about this kind of question about. So it's a concept that has been used in in psychoanalysis and identities that there's a, there's a risk that one can simply take a take a term, which has a complete different meaning a different context and apply it but I do think that the concept the model is a fascinating one. And I'm intrigued by the fact that you alongside plays, and I think alongside also, Jeff Hawkins use that model as a way of, of opening up these questions.

Joscha Bach 56:54
An issue with this type of language is that usually the understanding that you generate it doesn't converge. That's the general issue with continental philosophy. Somebody recently asked on Twitter what the difference is between continental and analytical philosophers. And a somewhat flippantly responded that analytical philosopher is one who understands that the difficult and hard questions of philosophy need to be answered in this former models. Various continental philosophers don't think that this is necessary, because they are determined they are a jump runner, that is looking down on analytical philosophers. You can see the difference between analytical philosophy and continental philosophy in for instance, the treatment of girdles incompleteness proof, a proper analytical philosopher who had formal education will understand that this is a proof about certain properties of formal languages and specifically approved that stateless formal languages that assume that truth exists independently of the process by which you get to choose don't lead to consistent models of of a domain. And there are also related results, for instance, that a system cannot make statements about affairs outside of itself. So when you want to talk about the world, in a formal system, you need to create a model of that world and you can only talk about that model you cannot talk about anything outside of the models that you are creating. And to continental philosopher. The girdles proof is more or less often understood as a statement of mathematicians that prove that mathematics is important at getting a handle on reality. And therefore the only way you can get a handle on reality is by not knowing as a matrix, which gives the continental philosopher a clear advantage. cannot hear you you're muted.

Unknown 58:57
That was a great answer. Thank you. We've got some questions. Now I have a third series of further questions that I'd like to ask maybe I could ask you one question before we go into the other questions. And that is, I mean, are you writing a book about this? I mean, is it being put down in some documented form because it would be incredibly useful. If it were

Joscha Bach 59:12
you I read, I need to write a book about this. I have a large number of notes on stuff that needs to go into the book, but also have it open. I have kids that are home schooled and I have ADHD. So I need to go into a different phase of my life to have no interrupted and interrupted sessions for writing long form text. But if you bet about not having written the book yet,

Unknown 59:35
well, I think it has become quite a dominant, a popular form of communicating ideas. So material out there, but I just think it could be assembled into an

Joscha Bach 59:44
interest it needs to be assembled if you're better if it is being assembled, not just existing as various disconnected conversations.

Unknown 59:51
Yeah, I just I mean, even Jeff Hawking, my Jeff Hawkins book, I think is fabulous. But what's interesting, is that no footnotes in it he's just kind of speculate, but let's nonetheless, he's putting his ideas down there. And it's really incredibly useful to have that kind of commentary. So anyway, I look forward to the book. I want to just ask this. Matt go Bay, who's got a question in the chat. Whether Matt is a graduate of MIT Media Lab. He's a doctoral, doctoral design student right now, if I you, Matt, would you like to ask your your question? Sure.

Unknown 1:00:25
Yeah. Thanks for Thanks for all of this. It's really interesting, perhaps the book could be co authored by GPT. Three, make it faster to just give them give GPT? Three, the agency over the first draft? I was asking, speaking of agency, I mean, that the question I have is about motivation. It's about sort of the high level motivations. When you ask, when you ask GPT. Three, are you conscious, and then it responds, somewhat convincingly? It still isn't initiating that conversation. And so one of I mean, kind of in listening to everything you were saying, and you said something about when you were talking about trees and seeds, I love the thing about instead of realizing the functionality, you want to build a system that wants wants to realize the functionality, you want to build the thing that wants to become a tree. But that question of wanting and motivation? How does one, at what point does that get put in to the system? Like, at what point does this become curious, or self motivated to do things that we didn't necessarily ask it, ask of it? And I think maybe related to that, I don't even let you go on this. But maybe related to that the question of individuation and sort of inter inter subjectivity that, you know, has GPT three spoken to you? Are there communities of GPT, three all talking to each other about what they want to do, and how did they individually? Or as GPT? Three, just always the same? And it's clones of itself? If you could speak to any of that. Great, thank you.

Joscha Bach 1:01:51
Yes. So that's the question, I'll be doing something that the organism is not asking of us. And that's not an easy question to answer. We, if you look at our own motivation, ethic that we have a few 100 physiological drives for different nutrients. For instance, sometimes we want to eat salty, salty food, sometimes we want to have sweet food, sometimes we need something to drink, sometimes we need to rest. And all these can be understood as setpoint deviations. And to deal with all of them, we need to create a dynamic model of our own needs projected into the future. And then plans and higher level models of these needs, which we could call purposes and so on, we don't just have physiological needs, we also have social needs, for instance, in need to affiliation, to become part of a group, for instance, and to be accepted by it, some people have a need for status to raise up in the group, there are romantic needs, which can be courtship modes, or need for intimacy, and so on. And then next to about a dozen of the social needs, we have a handful of cognitive needs, the need to become more competent, become efficacious on the environment, need to reduce uncertainty, and something that I would call a need for aesthetics, which means discovering deep structure in the world. And aesthetics can be split into stimulus oriented aesthetics, OPR, intrinsically via to like certain body schemas over others, certain landscapes over others. And there are evolutionary reasons for that. And then there are some mathematical principles, what kind of representations you like what form, it means to have a good representation of something that are more general. And if we use meditation, to disassemble our own needs, and to dissociate from them, we realize that the things that give us pleasure and pain to fall in these categories. So we have lots of these impulses that are about hunger and thirst, and rest and so on. And they have impulses that are about the social domain. And the older we get, the more these impulses get replaced by a deeper model of what we want the world to be like, and react on the steeper model and just these reflexes. And on the lowest level, when you try to get more enlightened, you may have just something that people often call love, which is I think, a need to trans identity, connect to other agents and share purposes them and act on these shared purposes. But you can get deeper than this at the deepest level. You only have aesthetics, the need to form structure and to make the world intelligible to create a coherent model of reality. And this neat, I think, is similar to what Freston describes in the free energy principle. It's basically predictive coding. It's the attempt to track reality using a model that is as good as possible at tracking reality. And if you turn off this aesthetic need in addition to all the others, my own mind becomes fuzzy a fall asleep I drift away because if I stop paying my neurons for producing order in the universe, and they stop doing this, then something else is happening in my mind that I can observe. And I just lose coherence. So if we imagine this hierarchy of needs, which by itself and seen as a cybernetic system is not all that complicated, you can build this into a machine think it's not that difficult. The difficult part is to get perception right to get ability to model reality in the Universal Basic, you can have one coherent model of everything that you relate stuff to when we talk about meaning. We talk about how to relate an arbitrary feature or domain or idea or concept to this unified model of reality that we are building each of us in our mind. Can you just

Unknown 1:05:39
pick up on a question, we've got another question lined up. But you also want quickly, you come from a creative background, your father was an architect. And you refer to let's say, creative practices within the orchestra and so on. It's part of what you're talking about. And, and frankly, your way of thinking is incredibly creative, and strikes me as being very creative. I wonder, you haven't mentioned the word creativity, I don't think and how do you view creativity? Is it just a myth? Or is it something? How could you conceptualize it within your framework,

Joscha Bach 1:06:11
I think of creativity as the ability to bridge discontinuities and research space, then you are just following the gradient, and you're just going through a continuous search space, I don't think that you are creative, you just arrive at the state of the art. And even if the state of the art is something that hasn't been done before, you just combine what is known and you find a local optimum, and then no one thinks you're not being creative. To be creative, you need to construct a new search space, usually. And many methods in which you can be creative. For instance, you can use random serendipity, you can use some evolutionary process that is binding elements in ways that you're unaware of. And then discover structure in them. Creativity is in some sense about jumping off from the known things into darkness and hoping that you end up landing on the other side.

Unknown 1:07:04
So so it's related to a search. Let me let me just put this to them. Do you think that that, that because you mentioned this before in your discussions, but do you think move 37? in game two of AlphaGo? Was that creative? Could you call that creative.

Joscha Bach 1:07:20
And I don't think that AlphaGo is creative in the sense because what AlphaGo is, but it there are evolutionary methods in in AlphaGo. And the outcome of what AlphaGo is arriving at is not always predictable. And it's also computationally irreducible in the sense that you can not foresee what AlphaGo was doing. AlphaGo was able in a relatively short amount of time, to demonstrate that human goal play which existed for 1000s of years, was not optimal. It has discovered strategies that were run counter the established strategies and goal. And in this sense, from the perspective of a human Go player, it was playing in a creative way, it just discovered new things that had not been discovered before. But if you will run AlphaGo multiple times, it's always going to discover these things. So the search is, well, stochastic elements as a deterministic outcome. And I think that when we look at systems like this, our notion of creativity is kind of sort of falls apart, right? Creativity is not absolutely a thing in the universe. It sometimes is a frame that is useful to describe what's happening, and sometimes this frame falls apart.

Unknown 1:08:36
Let me let me just put a provocative comment to you then I mean, something that I thought myself and I would like to know what you think on this. So if GPT threes, if AlphaGo is not creative, and I kind of in so many ways, I don't think it is creative, it's just doing a very, very effective search. But then we could ask this question about whether human beings are creative or whether this term exactly

Joscha Bach 1:08:58
we use. So that's my issue, right? So sometimes your term cert meaning things, they mean something in a certain context. But when you increase the resolution too much, this context falls apart and no longer make sense. You use your use or lose your term and have the same issue base the term like me, missus, but I like it. It's poetic, it is evocative, it produces stuff in your mind. But when you zoom in very hard, it's not clear what it means. And so instead of the I tried to examine the assumptions that are hidden in nemeses, for instance, the idea that others exist independently of you, and that you're able to take them in somehow right instead of constructing them. And then the question what's first the model of the other or the model of yourself, and whether it's the same thing and every person that becomes conscious? This is not obvious to me and the notion of me misses presupposes too much. And that makes me unsympathetic to it so even though I appreciate the poetic illusions that are there in the space Is that the term like this opens and the ability to converse about it? Ultimately, I need to deconstruct the term before I can use it.

Unknown 1:10:07
Okay, so let me just put, I'm glad you take this position, we just throw an idea at you. So, I mean, one of the analogies that I've made in the past is to say that use the term magic. One point, actually, I don't think that magic exists. I mean, I think that what happens basically is, is, if you take the example I was given, if you have a magician, a kid show, but they're pulling a rabbit out of a hat or something or doing magic, that magician is not doing magic. It's the addition of simply concealing the operations that work and making you believe that it is magic. And I'm just wondering whether we couldn't take that same notion and apply it to creativity. Because we don't understand the processes, we just look back and say, Wow, that's creative. Like some people said the same with with with AlphaGo. That's great. But maybe it's not as simply we don't understand the process. Therefore, maybe even the term creativity is not a very productive term in the first place.

Joscha Bach 1:11:03
Yeah, I suspect that magic also, in order to make sense, we need to understand what the term means we need to completely deconstruct it into its constituents, and then put it back together and see if we still have metric of this if this term can still be recovered. And typically, I see magic as the ability to get right access on on the laws of reality. And if you think about what it means, in the naive form is the departure from the mechanical universe, the universe that we are in, according to the theory of physicalism emerges over a causally closed, lowest layer in this quasi closed doors layer is basically whatever mechanics is making the universe happening. And ultimately, there is going to be some natural there where things are just happening without some conscious intervention. And the idea of magic is that our universe somehow is a conspiracy. That there is a way to subvert the laws of the mechanical universe using symbolic powers that we have symbolic causality and symbolic causality is, for instance, the connection that exists between sacrificing a black cat and celestial events that are caused by this, right and this, this is something that cannot possibly be explained by any known physical mechanism. Because the elements of this transaction only have meaning in a symbolic route to a human mind that is acting based on a certain high level story and abstraction that is not good depiction of what happens in the physical reality, it doesn't mean that the story is wrong, it just not one about the frame of physics. In computer games, there is magic happening relative to the computer game, right you can use Minecraft and in Minecraft, there is a mechanical layer where everything happens by itself. But you can also call up a shell and enter times a day in the sunrises. And this interaction somehow breaks the logic. And if you could do such a thing in our world, if you can use a ritual to make the sunrise, then you would subvert the physical reality. But what you can survive subvert is the psychological reality and the social reality. And in this form, magic does exist. If you get right access on somebody else's perception, and attention, and memory and imagination, you can change their reality in any way you want. And then our culture, there are some norms against this, or they used to be norms against it. And I think that in Christianity, this didn't exist, it was legitimate to subvert the reality of other people by telling them here is an omni assent. omnipotent agent. That is part of reality therefore needs to be modeled in your own mind. And on your sense means it knows everything that is to be known as full read access to your mind, and only pretends means it has full right access. And also, we have an effect what with this thing, every week, you can get an update and tell you what this agent is going to do to your mind. And as a result, you have people that remember having seen miracles, right? Because something is written, rewritten the mental structure of their own mind. And you'll often find patterns of this in ideologies. So this idea that somebody else gets right access on your minds, for instance, an innocent example is here are my pronouns. And these pronouns are not what you perceive they are what I want you to perceive. And I have the right to change your mental representations. That's a form of magic. Right. And I think that the idea that this is happening is because the people who propagate these ideas don't believe in the individual autonomy of individual minds to create realities and having a good outcome you need to control the realities that minds create together by using magic to get the psychological realities of individuals to converge to the desired social reality.

Unknown 1:14:59
What One of the things that I've been asked to starboard almost question a second, but one of the things is one of one of the things I find interesting in your thinking is the role of, well, you use the term ideologies, or do you use the term religion, but to my mind, if they can be seen more in the realm of myth, I mean, there's a lot of this kind of this, this space and the way that you use the term, actually, it also reminds me of the work of of Dziedzic. I mean, he makes a comment. Here, he read a book about love at one point, and he kept it inclusion, that love is the myth that fills the gap between the self and the other. And somehow myth has been some structuring device by which you look at the look of things where it conditions your understanding of reality, a bit like ideology, or a bit like religion, is that something that would you would engage with,

Joscha Bach 1:15:47
and would engage with it, but I think that love is, is more concrete meaning life is the discovery of shared sacredness, and sacredness, or the purposes above the ego, to which the purpose is to which we are willing to sacrifice ourselves. Right, this net, it has to do with being part of a transcendent agent. Not everybody has that if you're a sociopath, you will not have purposes above the ego. And so you will be incapable of love because you will not have shared purposes about the ego, you might have romantic infatuation. But ultimately, you are not going to build shared agents, this others for non transactional purposes, because you share purposes with them. So that is this discovery of shared purposes.

Unknown 1:16:30
But I mean, but can you use the term shared? I mean, how do we ever know the other? How do we ever accept the other we can think that we're sharing things but are we actually sharing things?

Joscha Bach 1:16:41
We do this in the same way as we know ourselves is one of the creations the other is the story that we are creating about a certain state of affairs in the world. It's in this sense, not objectively true, but it's a model that allows you to predict reality better than other models that are competing with it.

Unknown 1:16:59
Now, interesting response. So Gustavo, maybe cassava is a postdoc at UC Santa Barbara. Gustavo, would you like to ask your question?

Unknown 1:17:13
Uh, sure. Thank you very much. For the wonderful talk. I think I want to kind of build on Matt's question a little bit, but more specifically to the idea of understanding how computational systems are, let's say evolved and programmed at the scientific level, like what is the state of the art in modeling, either psychological states, or understanding how different models are building on knowledge, where they can make aware computational models can make creative leaps. So if it's not clear, I'm thinking about in the history of human society, there are different models of control the models of narrative, you know, they're different either religions or different belief systems. But in the models of science, it seems as though that there is a building of knowledge, and that we're moving toward an end. So So we're, we will never as in as an example, we right now won't live till the end of the universe. But there is a goal in science that we as human beings need to propagate outside of our, you know, Cosmos, so we have a chance to exist. And we have multiverses, how does? How do these computational models either aid humanity? Or are we looking at these computational models to exceed humanity in some way? And what does that mean? I'm, I'm thinking about that edge that you're talking about. Because I think a lot of what we talked about in humanity are black boxes. If you talk to a physicist or, or a mathematician, or an electrical engineer, they get to a point where we don't know the science. What are your thoughts about that? How do you how do we build better systems? Or how do we interact with these systems a little bit more ethically or morally? So they are not like psychopathic or and anyway, maybe that's a little too abstract and just you brought a lot of higher level. A lot of knowledge here, so it's it's very sobering. Is what I'm saying. Sorry about that.

Joscha Bach 1:19:49
Sorry. But I do back home sobriety purchase. I think that you made some very interesting points or Are arrived at interesting pointers. You saw some images that I presented earlier, for instance, the generative art of glide. And the text that GPT. Three is producing. And in some sense, this is the state of current computational creativity. And I think that the problem of how to make a technological system creative is solved. So the these images are, in some sense, creative solutions, because they are able to bridge certain discontinuities in research space by finding solutions that people might have difficulty to find. So for instance, if you have a conversation with Street history, it's usually better than what you get from a person that doesn't know the domain. But worse than the person that knows the domain about things, you have a conversation with an errand. And if you haven't read a lot of fine art, it's really surprising and very convincing. But if you're very familiar with Hannah Arendt and have thought about her a lot, then you might notice some things that she probably wouldn't have said. And a similar thing is this depictions of art and so on, so it's able to produce certain styles and reproduce them. But there is a certain thing that is missing. And I think that what you produce we cannot do yet, and the systems cannot do yet is art. And the difference between art and creativity is subtle. Art, I think, is the capturing of conscious states of a conscious reality of some aspect of a conscious reality. And this means meaningful references to a unified model of the universe. And these models do not have a unified models of the universe yet, they don't understand which university are part of the thing that they are part of. And while they are slowly getting there, I don't think that they are there yet. So to me that the digital art that you're seeing is not actually art, because it does not mean very much to the system. But it's something that humans can, at this point, relate to the shared reality sometimes and or to their inner reality. And this, this makes them akin to art. And there is basically a perverse boundary that is more and more dissolving in terms of AI and art and these days. So this, I don't think that the there are fundamental unsolved problems at this point, that but the biggest, important problem is how to get a system that is able to track reality in real time. And that can online learning. And and a lot of people are working on this NPP don't know how long it'll take to solve it. But it's not that it's a principle unsolvable.

Unknown 1:22:49
Can I just pick up on that the question of art, because the back of my mind, there's this interesting question. Coming up here. In terms of, well, let me just throw out either an idea because you use the conductor metaphor, and the music was part of the loose discourse. And I often speculated whether whether how creative we are as architects, or indeed how artists are in the sense that there is a cannon, there is a cannon of architecture, art, or whatever it was. And what we do is normally keeping broadly within that Canon, you're very much aware of what other people have done, you might push the boundaries slightly. And this is kind of what I think I use the term jazz as a kind of idea of understanding how we operate as a background condition, and we're feeding off it and just nudging the boundaries, but staying recognizably within the canon of this. And it's interesting that if you know the work of Ahmed Altai, gamma Lee, the guy who created these who designed creative GaNS that he's a computer scientist, who has a who generates art and the logic is this you got to keep broadly within the framework of what you're talking about within the canon or that say, modernist art, but make it slightly different. So you're just pushing the boundaries. So I often wonder to what extent we're so conditioned by what has been done before and and whether we, if you would do something genuinely different, you will be outside the realm of what is acceptable in that genre.

Joscha Bach 1:24:15
I would make a difference. distinction between art and design. And architecture, for the most part is not art, but design. It's also true for myself, I am for the most part, not an artist, but a designer. And design is instrumental to something whereas art is instrumental to consciousness only I think, it leads to aspects of the thing that you're producing the art. Now other aspects and every artifact that you're producing almost everyone the design serves some other purpose than the consciousness itself. For instance, if you are designing a building, you are serving a function of a human being that needs to have a house somewhere and it needs to live down somewhere this thing needs to be part Out of an environment and it requires deep perception. And it does require capturing some of your observations and a deep level. So there is important elements of seeing, and perceiving and observing and reflection in architecture. But all these elements are ultimately instrumental to the thing that you're going to build. And the thing that you're going to build is defined by its function.

Unknown 1:25:24
Maybe I could just throw something out there. And let's say that, could you not as an architect, I was thinking about these things. And I think almost there are two sides of it. Well, there are two sides of architect one is the functional side of things, or dealing with zebras with the logistics of your dealings, let's say with a very complex urban condition, you need to fit a building in somewhere, it becomes almost like a kind of a search question of how do you find the best solution. And then there is this kind of I wouldn't say a veneer, but there is an aesthetic side of things. So when it comes to, let's say, the strategic planning, of how you might fit a building in a site, or how it might operate, and so on, it kind of relates more to the kind of logic and say, of AlphaGo, the strategy of AlphaGo. And then there's something else that we as architects want to put on top of that, which is more of a kind of the, the artist dimension, which is which is getting at a certain aesthetic, does that sound to make make sense to you that logic, but

Joscha Bach 1:26:18
yes, it does. But there's, of course, the practical element that the aesthetic that the architect has, when it's successful one is the brand. And it's not driven by free exploration of the conscious states of the architect, for the most part, but it's driven by the anticipation of reward in a particular economic and cultural domain. And so in a sense, it's usually a construction process.

Unknown 1:26:46
Well, let me throw out another kind of thought then. I mean, what is interesting is when you get someone who's fairly radical, like, I don't know, Frank Gehry, for example, you know, he produces a building the Guggenheim in Bilbao really changed architecture. But then he kind of repeats himself in some senses, he's doing similar versions of that. And you must have seen the LA Philharmonic in, in LA, the Walt Disney Concert Hall. And it's almost like, you know, we have these patterns of behavior or signatures, I would say, you know, but a recognizable when you're now you see a Gehry building, so that's scary. So it's almost like were pieces on a chess board, then we have certain conditions that we actually are constrained by that. So whether you see it as a brand or not, but it could be seen as a brand, you know, we are constrained by our own signatures. And in fact, when we end up not being so creative, because we fit in with that logic, how does that how does that sound to you

Joscha Bach 1:27:43
ultimately, it's about an intention. And the intention is that the submission to an external cultural mind, or the intention is an autonomous one. And I personally see art as something that is driven autonomously. And that's different from the definition of the art market. Right? So the art market is only capturing a very small part of the arts. And a lot of the things that are happening on the art market are not art. And my own father is an architect who has defected from architecture, and become an artist. So I'm a child of an artist family, and my wife is an artist. And this the difference between the art that my father is doing and the architecture that he has been doing is that the architecture is serving others than a particular wall for in particular cultural context and economic and social and societal context. And my father didn't want to submit to this societal context in the psychological and social context, because he thought it was deeply understanding to him, we rejected the aesthetics of the society that he was so removed himself from the society that he was in, pour water in the countryside and turn this into his own kingdom. And this kingdom is open for others to visit and explore. But it's not done for them. It's done for itself. It's done in the service of his own aesthetics. And to him, it doesn't really matter whether others like this, these aesthetics that doesn't change how he thinks about the things that he's creating himself. He may need economic success to be able to survive, and it might frustrate him if people don't like what he's doing. And it might frustrate him the things that he might have to do to survive. But his own definition is that he is not for himself of his own intention that is not serving an external ascetics. He is an autonomous agent. He is deeply autonomous. He is the creator of his own universe.

Unknown 1:29:49
That's a beautiful story that can I just I've got a question coming in from shameen in the chat. But can I ask you one quick question before we go into that and that's to say, the term architecture gets used obviously, both for computers Science and for architecture itself. And I'm just wondering, I mean, I don't know, my definition of the architecture is very broad. I mean, I think it's a way of kind of, I would say that probably what your father's is doing is probably still a form of architecture, maybe a form of other architecture. I mean, many of creative industries that that architects are creative industry, architects go into like the film industry, or the space industry that they use that architectural imagination elsewhere. And I even think that that kind of setting up educational systems is a form of architecture in a way. And I just wonder whether you ever have seen any connection between those two architectures, the one that you're familiar with through your father, and the world in which you work right now, computer science, because I noticed the word architectures in the title or subtitle of your book.

Joscha Bach 1:30:46
Yes, the notion of a cognitive architecture means that you understand the mind is something like a building, or structural design that is inhabited by lots of functionality, and serving functionality in the larger world that it's embedded in. So it's natural to think of the mind as something that is constructed, rather than just grown. And that's also the limit of the term architecture in a way because the mind is not just constructed, it is also grown. And so there is the question whether growth is an architecture is a forest architected in a way. And I think it can only be architected to the degree that the forest is sentient and starts breathing and structuring itself. And maybe it is right to maybe there are elements of design and construction in the forest. So it's not just something that is locally grown by some dissociated process that does not have a centralized spirit that reflects functionally on its relationship to the world.

Unknown 1:31:54
So Shimon has got a question in the chat. She's in a noisy cafe, so she can't ask it herself. But I should say that shameen Yousef is from Iraq. She actually studied in Germany in the other bow stat in DESA, where I myself was there the professor for a while, the, in the building next door to the Bauhaus itself. And there's a school of architecture, and shameen was one of my students for a workshop there. And let me let me read out the issue means question, thank you, Yahshua. For the great lecture, this assuming yourself from the School of Architecture architecture at Florida Atlantic University. My question is, it seems that there is no condition for sentience for an agent in brackets AI model, for example, to be creative, and to be conscious in brackets. If I understand your thesis, well, close brackets. So do you think that we human agents are discriminating against the machine? Since it's not a biological being? And therefore, we should instead consider intelligence and creativity based on the behavior of the machine, which has proved to be true? Or is becoming true in the near future? Does that Chinese debt again, does that make sense?

Joscha Bach 1:33:04
Yes, I think I understand where the question is going. It comes down to the technological systems, once they approach functionality that is similar to ours should get get rates that are similar to ours, and at which point we give these rights. And why is this a viable interpretation?

Unknown 1:33:25
I don't know whether you'd like to comment on that. And in the chat. Well, maybe while we thought

Joscha Bach 1:33:33
as I would say that sentience is, in some sense, the ability to know what you're doing, which means you have to have a model of yourself and the relationships to the world that you're in. And in this sense, I would say that, for instance, a corporation can be sentient. The corporation has a legal economic, structural functional notion of what it is. And this notion is represented in the minds of the people that work for this organization, and then the balance sheets of the organization, and so on, it's often distributed. So it's not a single point where the entirety of it is represented. But functionally, you could say that the organization can converge toward sentience. And the more sentient it is, the more it's aware of what it's doing, the more successful it's going to be, because it allows the to make a model of its relationship to the world and act on that model. But cooperation, I think, is quite clearly not conscious. So there is nothing what it's like to be a corporation. And it doesn't mean that corporations could not be conscious in the future. Imagine that you replace the people that make the decisions and information processing of the corporation gradually, with machines. And this gets more and more real time until it gets entangled with the world in real time. And then at some point, it will discover itself and is a real time agent that is paying attention in real time. It's not clear to me whether this will be human like consciousness needs a control model of the attention because our attention is selective, and the selective nature of consciousness is quite conservative for it. And if you have enough computational resources, maybe you don't need to be selective, maybe you can do everything automatically without having this layer of reflection, and be good enough. So maybe consciousness is something that exists at an intermediate level only. So it exists in systems that are complex enough to have this kind of coherence creating government like conductor, that is making sure that your free jazz is going to be coherent, and is going to be instrumental to what the organism needs at any given moment. Or maybe you can create this coherence just by tuning the orchestra well enough and making it more tight, then you can do this in a biological system. And at some point, it doesn't need a conductor anymore, and just does everything in a mechanical way. So I don't know that it's an open question to me, with respect to the other aspects of whether we should give something rights, the rights that we have as human beings that are instrumental to the function of our own society that don't exist. Because people have an insight in what it is like to be a conscious being. The animals that we are slaughtering in our software houses are conscious, it's quite clear and obvious, right? They do act on the awareness that they are aware, the cat that I have in my household, is aware of the fact that she is aware and that I am aware, and we are able to communicate about this fact, even though the cat is not that smart. But I think that the cat knows that the cat is conscious. And this does bestow some rights on the cat and our household. But it doesn't bestow rights on the cat in a similar way in society at large. Because the status of our society sees animals as instrumental as tools. And this is probably also true for AI. On the other hand, if AI is achieved superhuman abilities, and in many ways that already do so there are crassly sappy human in many ways, they cannot do many things that humans can do like create coherent build of meaning. But they also think that they can do much better like style transfer or generation of imaginary dialogue with historical people able to do this much faster and with better quality than most people can do it. And so if you basically imagine that you have systems that overcome their current limitations and become super human, and all the devils that mean, by with these systems be interested in having human rights, you're not going to live next to the systems any day we are going to live inside of them, we will be their gut flora. Why would the organism that sees us as its gut flora, at best would want to have rights that are akin to gut flora, one instrumental to the aesthetics of the interaction of gut flora. Who cares, right? So why would a corporation want to have human rights? That's not interesting to a corporation, a corporation has is operating a very different domain and has much greater rights in this domain and abilities than human being does. So I don't think that this will ultimately be the issue. I don't think that the systems that we are building will be necessarily subservient to us once we make them sentient, and conscious.

Unknown 1:38:24
Can I invite a man of Estonia so to ask his question, Manas is doing a PhD on AI. And architecture is also Associate Professor FAU Manas. Would you like to unmute yourself?

Unknown 1:38:37
Hi, yo, shout out. And thank you. It's been very stimulating. So I apologize in advance. It's a bit of a long question, and seems to be very specifically formulated. But I'm interested in the broader discussion about computational creativity in your earlier comment. First about Minsky's positioning, in terms of the part of the mind with the rest of the mind has its environment, and how this is kind of relevant to that idea of the search base and how we position ourselves in the search base, if we're able to externalize it for ourselves from it with regard to discovering something and so the specific, let's say, part of the question focuses on the neural language based models like glide or VB Gan plus clip, which I've also been trying to work with a little bit from an architectural point of view not so much a technical one, and how you know what, for example, we begin to perceive as as a simple language prompt, you know, a one word prompt, may in fact, be much more complex than that. And so, for instance, a prompt like building or window, even though the network would address this within with the same procedure, you know, we will know that the former is a richer semantic representation in terms of once inclusion within the other right window is meaningless without without a building, but with regards to the way that the network treats that they could both be perceived as a high level, feature or details. depending on, you know, like a window, by itself could be perceived as, let's say, a high level feature within, like a broader building representation. But the same thing could happen, you know, with regards to the way the building could be scaled and nested within a broader, larger urban landscape. So all I'm saying is how, if you have any comments with regards to this kind of discrepancy, which seems to, you know, address, of course, the reduction is maybe understanding of language, but how, perhaps this could be encoded in a in a different way, right, what we perceive as a simple prompt, is not necessarily a simple prompt, and a human is able to understand it, but a network would be reading both of these terms, on an equal in equal terms. I'm not sure if that was clear.

Joscha Bach 1:40:45
The issue was the existing models is that they're not trained on the same reality as ours, but on the representation that we have created, and this representation is inert. So for instance, typically, speech language is not trained in the same way as our language is being learned. And when language is being learned as a solution to a particular kind of problem, and that is how to transfer mental representations across people, and how to organize mental representations within our own mind to transfer them. And this is achieved by mapping the representation, which mathematically is something like a dynamic hierarchical graph into a discrete string of symbols. But language is always a discrete string of symbols. And the main reason why this is the case is otherwise it wouldn't be learnable. And this discrete string of symbols that hangs in this thin air between speakers has to be constructed, and deconstructed or re used for constructing a mental representation using limited resources. Something like step decks stack depth of not more than four. Because while language can be defined in such a way that it's infinitely recursive, our own mind is incapable of facilitating deep recursion, because it only emulated right, so it needs to be simple. And other natural languages are solutions to this design requirement, find the ownable method to map mental representations into discrete strings of symbols. And this is done in a collaborative process, right? Basically, language is invented by groups of people, not just by individuals. For the most part, there's no reason why an individual couldn't do this, you can, in the same way as you can play chess against yourself. You can play language games against yourself and invent your own private language. It's not an no argument that I can see. It's plausible against that. But practically, it's a tool to transfer information in a large degree, and tippity suites language is not the result of this interactive learning. It's a result of looking at the linguistic utterances of people as they are typed out in the internet in a non interactive fashion. So activities, we doesn't learn semantics in the same way as we do. We start out with understanding semantics index simply by pointing at the features and our perception environment. And then we learn subjects, we learn how to translate this into linguistic symbols. And then we learn style that is the particular way in which linguistic symbols can be arranged to communicate efficiently and to convey additional layers of meaning by the shape of our utterances. And GPS, we the order is inverted to be three three basically starts out this style and syntax and learns semantics as the long tail of style. Right, it's so it's, in some sense, the wrong way around. And it's amazing that it converts it or there has been in the early days of computer linguistics, which discussion because philosophers will still have an updated facade that you cannot learn semantics without interaction context is out embodiment without being having symbols that are grounded in perception. But GBTC shows that it's possible to learn semantics to some degree, only by looking at language. And you can see that it's semantics because you can ask GPT three, for instance, to perform certain linguistic transformations or to add small numbers to each other and so on. And it's capable of doing that, which is a semantic operation as a causal structure that is being addressed by a linguistic prompt. And GPT three is able to verify in some sense, whether it was able to conform to that specification. So these these are proper semantics, but they are impoverished compared to human semantics, because they are the result of something like babbling of extrapolation only without interaction. But this doesn't mean that we cannot do this in principle, we can build systems that interact with the world and that are serving instrumental purposes and satisfying the needs and doing this that to one dynamic, just the present set of algorithms and technologies. that you have not very amenable to this.

Unknown 1:45:05
Let me just maybe push a little bit further. I mean, I often because I think that the GP three and the kind of text or the prompt based responses that you get out of clips certainly are interesting because I'm just wondering to what extent we ourselves are trained a bit like a neural network in the sense of, we have certain inputs, you go to school of architecture, and you are schooled in a certain way of thinking, you know, that's what you do. And so so when we think of somebody, someone says, a house, then if I'm training and listening, I will think about the certain images, or at least something will be conjured up in my mind that is quite controlled in a way by the training that I have have had. So I'm struck that actually maybe there are not that there's more similarities there than we think so whether we have an automatic reflex about certain things based on our conditioning maybe I could just walk walk by your thinking about that question, show you a quick video of the kind of work that that we that architects have been doing using this. So this is a work of an architect from Peru, who is now teaching and it's it's using clip clip and v Q gun and you there are a series of prompts. There are a series of pre prompts. So there are three very progressive architects names were put in there. Zaha Hadid Thom Mayne will pricks you probably don't know these guys, but they're kind of Gary like slightly crazy guys. Right? And then there's a second prompt, which is the main prompt is Futuristic Indian temple. And this is the kind of thing that gets elucidated by this thing, and I, you know, and I often wonder is, you know, whether, yeah, my question would be this, it wouldn't be fair to say that actually, that we are trained, we are trained by our experiences and our education as a form of us indoctrination, to think of certain images to conjure them up in a way almost like like, like clipped us.

Unknown 1:47:06
Yes.

Joscha Bach 1:47:08
So there is a big similarity in the way in which these models work, and the way in which our own mind works. Difficulty is the way in which the GBTC got to these representations or big gun. And that's basically the cue gun is fed lots and lots of separate distinct images that are annotated with text with a reference to, for instance, the subtitle of the image that the Creator gave it, or even to a complete description of what's happening in the image. And by looking at millions of these images, in batch processing, ruin statistics over these images, you build up the structure of the network. And the network ultimately converges to an efficient representation of this latent space of representations. And in our own mind, this representation is built in a slightly different way, please train up layer by layer, we start out with an extremely limited reality. And there's limited reality in the first place. This maybe it's similar to what's being described in the first book of Genesis in the Bible. I think that the first book of Genesis in the Bible is misunderstood by the Christians are mistranslated as a myths about the creation of a physical universe by a supernatural being.

Joscha Bach 1:48:28
And this also leads to the confusion, our culture of what that physics contains light and darkness and skating crowd and so on, right, these are clearly constructions inside of the mind categories that help us to make sense of the perceptual patterns in a coherent way. The fact that they're not that many ways in which you can arrange the perceptual patterns doesn't mean that the reality is structured like this, it just means that if you have a brain with these parameters, this is the best way to compress physics into a predictable model. And so what you need to make sure what you need to do to make sure that you can interpret reality is first you need to figure out how to entice neural oscillators to make light to represent contrast. And this is basically the creation of light and darkness, and how to separate the light from the darkness. And then you arrange these contrasts along multiple dimensions. And then you discover the modalities of perception, like vision and sound, and you discover that the visual domain can be arranged in a space and you can align the space with your vestibular system. So you get an up and down and you get a plane that is two dimensional on the ground down and you get a space that is three dimensional on top of this two dimensional one and then you have basically the sky and the ground that you have constructed right created in your own mind. So the mind is constructing these categories and then discovers the materials the solids and the liquids and the organic shapes and the animated agents and about that move around in it And then it discovers the features that it cannot directly interact with, but proceed like celestial objects in the background. And then it discovers all the constructs the plants and the animals and gives them all their names, right is this this gradual construction that happens during our cognitive development where we train up or model of reality layer by layer. And then last but not least, we create a person. And this person is created in the image of this construct of mind as the conscious observer that is makes sense of reality. But it's slightly different. While it is a conscious observer, it is created as men and woman is created as a human being that believes that it has a gender that has a relationship to the world that is desires, it's human desire is a social embedding metric. And initially, it is created often in the third person. So when you talk to small children, they often start by referring to the organism that they are modeling in this word person. And then at some point, they start looking through the eyes of that character and think they are that character and the original word creator, that is modeling reality and creating and shaping it becomes a subservient perception module to this personal human agent. So this gap in the creation of this new thing is represented in children losing their memories, and you have a baby, you will often notice that they do have favorite memories, they're also able to talk about them once they start talking between nine months and one and a half or two years. And then at some point, that is a gap. And they lose the access to the memories that they had before their time. Because they constitute themselves as a new system that indexes the memories from a new perspective. And I suspect this is what's being alluded to in Genesis, I don't know whether it's literally true, but its interpretation, whether it's a better interpretation in the Christian one, but it seems to be much more plausible to me that this is what's described there. It's this cognitive development of a system that starts to arrange the features into maps of reality, that build on top of each other, become a more and more complex until you discover your own agency and it and use this as a perspective, to make sense of reality. And this is what you're not doing AI systems right now. But there is no reason why we shouldn't be doing it, ultimately. And there are a number of people that do actively think about this, for instance, Josh Tenenbaum at MIT and others.

Unknown 1:52:29
I just pick up on the question of tape, because I think that's incredibly fascinating for all sorts of reasons. There's a book by Kevin water lake bottom, and he kind of, he says that we learn to roleplay through being a kid, you know, what we learned to be the CEO of a company by you know, playing doctors and nurses and whatever cowboys and Indians of god knows what else when your kids? And so which is interesting, and I buy that the question that I that I would want to put you is if we see ourselves as a model, and see ourselves through that logic, what role does the actual model ie the doll or the teddy bear play in a kid, you know, because that is in some senses, animated by the kid about a child? What is what is the role of because that's, to my mind is fascinating dolls and teddy bears? How do you see their role?

Joscha Bach 1:53:24
There is a thing that I noticed when I was in Madagascar, they saw a lot of children that lived on the street by themselves. And the diverse kids that took care of other kids. It was mostly girls who did this. And I suspect that the adults that you give our girls or that our girls demand are a substitute for biologically adaptation. That is that kids look after other kids for the parents are looking to fields or hunting or doing other things. And often we think that kids would be careless and couldn't be trusted with babies. But it can be they can I've seen it in Madagascar. So I've seen little kids that were mostly girls that were barely strong enough to lift up a baby because they were only like five or so and still seem to be able to take care of them full time. So I think that's an adaptation that we want to take care of others and especially of children, and that we want to interact with other agents and build a communion with them. And the teddy bears and dolls are a simple, non labor intensive fee of substituting for this.

Unknown 1:54:38
Maybe I could put an architectural dimension to that. What about the dolls house? I mean, because that is an architectural space in which the doll operates. How do

Joscha Bach 1:54:45
yes, it's a play space. And the purpose of play is the creation of training data. So you use this to create situations that could exist in the real world and dramatically reduced cost. So you can and even worth the cost when you're playing because you don't play for the expected reward. You play for your ability as a way of exploration, and not for the exploitation for being able to use this later. And it's also something that you can observe in cats, cats do play a lot. And the purpose of play in cats is that they are able to hunt better. And while they play, they exert a lot of energy. But it's mostly done because doing this in the world, or there is more cost overall. And the same thing happens in human beings. The reason why children are fascinated with doll houses, I remember that it was when I was more interested in building virtual cities. So I used to draw very big maps that cover the floor of my wall of cities with different houses in it and explored how people would live in there and how goods and resources would travel in the city. And the font is very exciting. And the idea relational space in the dollhouse between the different members of the family, were not that interesting to me. But I suspect that's because I'm pretty stereotypical male in this regard, I'm much more interested in systems conflicts and explosions than I am and human relationships per default. And I only discovered the beauty of human psychological structure and relationships later in my life.

Unknown 1:56:16
So maybe just a follow up to that. I want to give Matt a chance to ask question, but just follow. So where does the architectural model fit within this logic? I mean, you're doing you're kind of Sim City, but then you got the kids Doll's House and things. How do you see the what do you I mean, of course, at one level, the architectural model is just a scaled down model of of a potential building. But do you see it invested with any other potentiality

Joscha Bach 1:56:41
I think that's tied to the notion of aesthetics. And aesthetics is what you get when you take your preferences that you start out with an extrapolated into a sustainable world. You basically systemic thinking that you add one more layers, until you discover enough symmetries to digest your initial preferences and make them instrumental to to achieving this aesthetics. But it's also apparent in normal development, you start off now it was more of a reflexes, certain priors, that we are born with innate tendencies to consider a certain behavior to be moral or immoral, full stop, unconditionally, not because we understand what it's good for, but because we feel this feels moral or this feels immoral. And this can also misguide us. Because ultimately, ethics is about the negotiation of conflicts of interest under conditions of shared purpose. And this requires that you understand the aesthetics the world in which you want to operate. Behavior is only good or bad. If you can come connect it to an expectation of Oh, that was worse or better. And to be worse, or better, you need to criteria for what makes a lot worse or better. And this, I would say that to be good, it needs to be sustainable, it needs to actually work. And it should have high complexity. And complexity is in contrast, for instance, to friction that is exerted violence, you want to minimize the friction in waist creator to violence, and so on. So once you discover this train of thinking, and you get older, many of your initial moral convictions get replaced by the larger aesthetic. And the same is true for architecture. By architecture, when you design a building, or a city, or a house or room is all about how to fit the space that you're operating in when you make your local decisions into a larger aesthetic. And so the deeper your understanding of the world, the better your design has a chance to be. And this is what makes architecture so interesting to us. I think that is that it's about seeing the world, the human world that we are part of at the greatest possible depths that we can perceive and extrapolate the games for as long as we can make them and then design our life inside of this larger space and build things at larger scales that you can maintain, like cities, nation states, society civilizations, inside of these aesthetics to realize them.

Unknown 1:59:10
I often say myself that I think architecture is less about the literal design of buildings, but about imagining a better world. I mean, it's yes, yeah. So we have a question from Matt said question, Matt. Matt, you'd like to ask you a question.

Unknown 1:59:26
Sure. Just another quick, maybe jump back into a bit more, maybe more technical things. I'm always struck by these these images that have become really common of neural networks as little dots connected by lines. And you showed the cortical columns and you showed a lot of interesting graphics that kind of looked like that. But I've also recently been struck by the neuromorphic computing stuff that's going on at Stanford and a few other places about dendritic computing and sort of new advances in thinking about and even starting to see how, what we once thought Were just wires that connected all these different things and we talked about connections are actually doing pre processing and in very interesting ways and I'm sure your, your, you know a lot more about this than I do. So I'm very just interested in in what's, what's going on there and how that changes. These questions of how much energy it takes to do the computation and what may be the future form factors might be on this kind of thing.

Joscha Bach 2:00:20
And they also have hooks at Intel that work on your morphic computing for instance, we have the loyalty architecture, which is a chip that uses model of spiking neurons for modeling, perceptual content and so on. And this is in some sense compatible with the neural networks that exist because you can translate the transmitted differential neural networks under many circumstances into the spiking neural representations and vice versa. But these spiking neural representations are more efficient with respect to power usage and some recognition of algorithms than others. And so, they are the probably be useful applications of spiking neurons. But the reason why the neurons in our own brain are spiking is also in part because the message is that neurons can send to each other are limited and then eater neurons cannot produce continuous signals, they have to produce little pulses. And so, you have to encode the information into little pulses in the timing and frequencies between the pulses. There is also an issue when we think of neural networks as they are represented in our technological system, they are mostly circuits. So they are similar to the circuits in your present CPU, which represent logical gates, which implement logical operations. And the connections is stored in the dates. So the parameters in GP three, these are all weights, little factors by which the activation that is sent between the different nodes is being multiplied. And the equivalent in our brain or to these weights are often seen as the synapses and that synapses Canvas different types different neurotransmitters in some sense, our message types that are connected to different synapses and the big network structure is what we call the connectome the circuitry that exists between the neurons. And there is hope that if we managed to digitize the connectome at a sufficient resolution, that we might be able to upload a brain and simulated in a computational substrate. And in principle that would be possible in practice, it doesn't work so far. So even the models of C. elegans, which is a nematode that only has a little more than 300 neurons, if you completely digitized the elements, to my current knowledge, and not sure if something has happened in the last couple of years. These models don't work in the sense that you simulate the work this is digitize neurons, and you can digitize the connectome, the warmth doesn't move like a warm desk just touches and has a seizure basically. And that's maybe in part because the neurons are more complicated in the warm because there are so few of them, they basically exploited resonance effects that maybe your model doesn't. So maybe it's more of a dynamical system that is more difficult to model than there's another problem is that you cannot actually get the message types, right, because the level at which you do the connectome, you cannot model all the vesicles that sent the different neurotransmitters you don't know actually which synapses sending which type of message. This is also a limit. But there might be something verse going on. In the 1960s, and 70s, there was a series of experiments mostly in the Soviet Union, but some of them also in the US about RNA based memory transfer. And the idea here is that you will take an nematode or a sea slug or even a rat, and you teach them something by operant conditioning, and then you put on your neural tissue into a blender, extract the RNA and inject the RNA into a different organism, and then your organism knows how to do this. This is completely wild, because if this works, and it's disputed whether it actually works, or how well they weren't replicating, or some people have done that again. And so the people that work on this tell me it's difficult to get other neuroscientists to listen, because it's incompatible with the idea that the rates are stored in the synapses. Right? If you if it's really the connection between your neurons, and you put the nervous tissue into a blender, this goes away. How would you be able to transfer memory in this face, this cannot possibly work. Because the RNA that you injected, the brain is not localized, it would get into many, many neurons at once. So how does each neuron know which parts of the RNA to use? And if you take this idea seriously,

Joscha Bach 2:04:52
I started thinking about this and now I'm thinking about making some simulations. How deep does the rabbit hole really go? It would mean that the industry The function that humans learn are not unique to the location of the individual neuron, but there are global functions. So the RNA is basically you can think of it as a little magnetic tape that the neuron can mix and match, and create more of if it's useful and share with all the other neurons just across cell boundaries, you share the RNA, and you copy them like a COVID virus. And you use this function to respond to certain patterns in your environment. So the neuron is not reacting to its neighbors that come into particular kind of connections. But it's mostly connecting to a temporal and spatial pattern that arrives to a certain faction, regardless of whether a new one isn't the new cortex. And so it's more like a cellular automaton, a neural cellular automaton, and certainly allows us to explain a few things that are seem to be going on in the brain that are difficult to explain with synapses. For instance, if you destroy synapses, they often regrow in exactly the same day without retraining. There is another phenomenon that is, us notice a certain mental representation in a cortical area, pinpoint it, and the next day you look at it has moved, it might have shifted a few millimeters are just rotated. So how would this stand if it's, it's right in the synaptic connections? There's also the question of H here and make a convolutional neural network is sharing weights, and you probably need something like bedsharing to perform a mental rotation, but you have the same operation on many parts of your mental representation in the same way, how would you do this? Are you training the same function again, and again, and different brain regions, and hope it's always the same, it's difficult to achieve, right. So we don't know a really good plus vertical mechanism for this. But this RNA based memory transfer could be part of the story. And this is something that is at the boundary of what's currently being explored, still. And it, it's, I think, it's not completely implausible. And it'd be want to make a model of how this works, we would need to use a different metaphor than our current biological neurons. But it doesn't mean that you have to use this, because the brain is solving problems that our computers don't always have to solve, for instance, long distance connections in the brain are extremely difficult to make. And you cannot really address new ones this way. So random access is very hard in the brain, you need some kind of routing network that needs to grow and learn how to vote, it's not an issue in our digital computers, because sending information across the memory of the computer is trivial. So there are many things that you can do very easily in our digital computers that are difficult to achieve in the self organization, data structure of the brain. And so it's it's not quite clear how much we need a biological like structures to achieve the same functionality. But to me, it's certainly very exciting to explore it.

Unknown 2:07:51
That's fascinating.

Unknown 2:07:52
I think the questions about drift and neuroplasticity, and things like that, that come from that are really interesting, it makes me wonder if some of what we're looking at today will seem very obsolete soon in terms of these these models that seem to be so so human, like with the you know, in terms of being able to hallucinate imagery, and all that kind of stuff. There's like a piece missing that might be that might come soon from a hardware model.

Joscha Bach 2:08:16
I thought that too. But then I'm surprised by what glide can do and Dolly and slip, right? So

Unknown 2:08:25
when you add energy to it, though, I mean, how much energy it takes versus a brain which we walk around and we feed vegetables to and it can do all that to like you can't I mean, that's that's where I think that the question that for me, that's where the question became very much more significant. It's like, oh, wait, but there's a whole other calculation here of how are we doing all of this in our tiny little brains? Maybe there's something there for for?

Joscha Bach 2:08:47
I think that is this understood, I think that humans are super expensive to feed, it needs enormous amounts of energy. To feed my brain, you need like four hectares of land, you can put so many solar cells on these four hectares of land. Basically, people underestimate how difficult is to take the energy that my brain needs into sandwiches and to extract it again, right. So this is the way that you need to look at also, training my own brain is super expensive, right? It takes decades, and generations before that, to prepare things for my own intellect and so on to get them in there. So human brains, in my view, are super expensive. And that's why we can use something like clip and teach again, that we only train once at low prices like training DVDs, we cost like $20 million. And now even that's because the computational advances go down, and it's been trained by reading the MO text, then a very large group of people could read in their life. So it's getting people to read 45 terabytes of text would cost much more than $20 billion. Right, tweeting them for long enough to make that happen. And the system that is making dinner I think the text costs so little that open air lets you do it for free if you want to only use a little bit of it, right, so it's able to produce output at the level of hundreds of copy editors, for free, right? It's why that's not as good as a conscious copy editor who understands the world. It's quite amazing what they can do already.

Unknown 2:10:20
Okay, thanks for that perspective. Yeah, that's interesting.

Joscha Bach 2:10:23
Thank you. I also am a little bit provocative. But yeah, I think it's something to be considered right, these 18 bots of your brain. They, if you compare them to the 80 watts of your MacBook, the 18 pounds of your MacBook are super cheap. And the 80 watts of your brain are super expensive.

Unknown 2:10:47
I think. I think there's your provocation that is so exciting. She want to because question from the chat. Now, going back just to say mentioned everyone that your show was, was was born in Weimar, and where the Bauhaus came from. And then DESA was where the Bauhaus moved across the building by Walter Gropius and so on. And we have at least two people here, who studied there, including Vasco, who has got a question asker is now a professor in Bangladesh. And his question is, well, I think it's one that you might have predicted, Elon Musk suggested somewhere that we live, do we do not live in a base reality? But in a simulation, he even puts the probability of a billion to one. What's your view?

Joscha Bach 2:11:35
I think that Elon argument rests on the notion that the simulations that we are building for computer games are getting better and better at some point, they will have a fidelity that exceeds our ability to notice by the Vienna simulation or not. So we can at some point, probably create the hours that are so convincing that we will not be able to notice whether we are in the VR or not, if you're not the only ones who are building simulations like this. So for any given being that finds itself in some kind of reality that looks real, there will be many more that at the same time, there'll be in simulations, right because many universes can contain many more than one simulation. So our universe currently contains many simulations of a universe that looks like ours. And therefore, the probability for any given observer to be in a simulation is greater than the probability than to be in based reality. And what this argument ignores is the fact that it's very hard to make a simulation that actually has the fidelity of the physical universe. But if you make a simulation of Minecraft in Minecraft, that's feasible, because Minecraft itself is so poorly resolved. But our universe has a lot of structure that is required to produce its dynamics. And if you build a simulation of, say, our solar system, and the dynamics of our solar system at a level that is going to go down to elementary particles, you will need to have computational capacity that is larger than our galaxy by a very considerable amount. So in practice, I don't think it's feasible to put simulations of our universe into our universe at an arbitrary level of fidelity. And so I think that the AI much more bias to state that we are in base reality then we are in a simulation.

Unknown 2:13:27
This is fantastic. There's one question here, that is also in the chat from Grant Castillo. And I don't know what it is. Do you think Gerald Edelman's extended theory of neural neuronal group selection can be used to create a conscious machine?

Joscha Bach 2:13:47
You muted a moment, yeah. I hope that the background noises are not too high, because my family woke up and is now interacting, the kids are playing and so on. And so I think that the idea of the Neural Darwinism that Adelman came up with this very interesting one, and I suspect that our own mind is the result of such in evolutionary competition of different organizational forms, right? There could be many possible proto consciousnesses that compete until one of them establishes itself as the government of our own mind. And so instead of giving your nervous system a blueprint on how to build a mind, you just set up the conditions for an evolution for the best possible mind that you could have. And of course, this evolution is wrecked by evolution. So you set it up in such a way that the evolution usually goes out, ends up in a certain way. But the nice property have been you design a system evolutionary by not giving a specification of what to look like. But what the function is against the future should evolve is a value disrupt the system or give it a different environment that it will very often come up with a viable solution. And that is new circumstances. So the solution is much more robust if you define it in terms of evolution. But it's a speculative idea. So I don't actually know whether our mind has evolved, even though I think it's more plausible, and it's not individually evolved in every individual brain. And it's definitely an interesting notion to, to use evolution is basically whatever you but you use in computer science, then you don't know in which direction to go. It's a blind search. It's the fallback, it's the baseline. And it's quite natural that people use evolutionary methods if you don't have a specification for the best possible mental organization, and you just evolve one.

Unknown 2:15:58
So, do we have any further questions in the chat? We have some very interesting characters here, I'd love to draw and draw out Daniel Balaji, who's one of the leading AI architects in the world, we'll see we can have a question or indeed, we have Sanford kwinter, who's one of our leading theorists, whose particular interest in neuroscience I'm gonna if I could, I could put them on the spot and ask if you have a question.

Joscha Bach 2:16:27
When you're done, it's also good, because I think I need to go and have some breakfast. Yes, yes. start my

Unknown 2:16:32
day. Thank you. This has been fantastic. No, I I actually, I I've got to say that I think you're sure you are more of an architect than you actually think you are, you have a way of thinking was very similar. I mean, obviously, you work in a different domain. But I think the the kind of inventiveness and the iconoclasm of your thinking would be go down very well, in an architectural scenario. So and I sometimes I never escaped, you never escape your background and the way you you might try, but in the end you, you find yourself conditional,

Joscha Bach 2:17:04
I'm conscious of being a child of a family of architects, and my grandfather was not an artist, he was an architect, he built most of his life hospitals. And this is a design process that is instrumental to serving a function, but function in a larger world that he was very deliberately trying to understand and operate in. But this was a word that he understood as being his own world, it was about that he often found himself to be in opposition, this, for instance, in Nazi fascism, or was also in Eastern Germany. But it was also the world that existed, and we need to do this and build the best possible things. And for my father, it was different, it was a well that he fundamentally rejected. And so in some sense, to be an architect, you need to embrace the world that you're in and build within it, and to take roots in it. And this is, in some sense, something that also haven't been successful in when I was young. So I decided not to become an architect, but to become an explorer.

Unknown 2:18:05
Well, I mean, I think one one of the comments that was made, I always think about the Steve Jobs and his response when he was, he was asked a question by Steve Wozniak and Steve Wozniak said, well, but what do you do exactly? Because you don't code you don't do this, you don't do this. And he's he described himself as being a bit like a conductor of an orchestra, you know, in a way. That's how I see architects in a sense, because we don't have any specialism. We are basically we we coordinate these different sort of choreograph these different sort of skill sets. And I think that's really what it is. So in many ways, you know, I can see a direct comparison with how you position yourself in that sense. I mean, I think it's a very, it's a very similar sort of position. But I think that some of these, these these comments that you've raised, you're absolutely fascinating. I think we need time to digest them, and fit them in the system. What I would love to do, above all, especially with this particular discussion, is to try and find a way of publishing the transcript. Because I mean, I think this book for you have to write you must be written because you've got some fabulous, fabulous thoughts that are really creative and original and provocative. So you know, I'm really appreciate you I appreciate so much your your time, and I love it, we should let you go look after the family now. But this is, I think, almost like we've just opened up a discussion and I hope that sometime in the future we can, we can take that further and think through these kinds of questions, because your response has been very generous and very, really provocative and stimulating. And I feel like you know, although we have to pull this withdraw this question this session to a close, it's almost the beginning of something else that we can look forward to. So I just want to thank you Asha for fabulous. I mean, I want to recommend his all his online talks as well to have a look at that there is a body of work out there that is that is this hugely provocative and hugely stimulating, which I am excited by and I also maybe I could finish with one one simple question. Now I started off the discussion by saying that I think there is a kind of, let's say, an emerging theory of intelligence that is developing in this kind of strange area where we're computer science and neuroscience and the world of the commercial world and the academic world coming together. Do you also see that glimpse of something emerging some discourse, some theoretical debate that is radically new and radically provocative?

Joscha Bach 2:20:28
Clearly, that's why I went into cognitive science, in the hope of being part of Veritas new synthesis had is happening between neuroscience and philosophy, and artificial intelligence, and linguistics and psychology, and maybe the arts. And I think at this moment, the synthesis is still very partial and apart. That's because we teach our model makers and our observers in different departments, we don't bring them together. So we have people that are very good at making formal models that can be tested. And we have people that are very good at making observations and reflecting about the world and seeing it very deeply. And these people rarely talk. And they're rarely synced together. And this is what excites me to work in this area where these two areas intersect. And maybe architecture is the right frame of looking at this. Neil, thank you very much for inviting me, I think it was a great conversation to have had today and very grateful for your beautiful community, and for allowing it to talk have allowed me to talk about these ideas with

Unknown 2:21:37
you. It's going to finish with one comment, which is because I used to be a lesson translator and and the word I should just say the word computation means to think together. And this is what's been happening today, there's been almost like a neurons with the neurons are kind of global brain. It's been been fantastic. Your show. Fantastic. Wonderful. Thank you for your time. And sorry for getting up so early. But this has been a huge contribution to the architectural community. And I hope that I've helped draw your the attention of your ideas to architects out there, because I think they're incredibly provocative ideas. And I think they are a huge contribution to make to architectural thinking itself. So thank you for your time. Thank you. And thank you so much for this. It's been fabulous. And thank the wonderful day. Thank you. Thank you for those team that put this together Digital Futures team, we can't operate without your help. Thank you so much. And see you next week. Thank you, everybody.

Joscha Bach 2:22:27
Thank you. Okay,

This transcript was generated by https://otter.ai