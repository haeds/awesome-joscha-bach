Lex Fridman 0:00
The following is a conversation with Yoshi, Bach, his second time on the podcast. Yoshua is one of the most fascinating minds in the world, exploring the nature of intelligence, cognition, computation, and consciousness. To support this podcast, please check out our sponsors, coin base, Code Academy, Linode, NetSuite and ExpressVPN. Their links are in the description. This is the LEX Friedman podcast. And here is my conversation with the OSHA back. Thank you for once again, coming on to this particular Russian program. And sticking to the theme of a Russian program. Let's start with the darkest of topics. So this is inspired by one of your tweets, you wrote that, quote, when life feels unbearable, I remind myself that I am not a person, I am a piece of software running on the brain of a random ape for a few decades. It's not the worst brain to run on. Have you experienced low points in your life? Have you experienced depression,

Joscha Bach 1:09
of course, we all experienced low points in our life and get appalled by the things by the ugliness of stuff around us, we might get desperate about our lack of self regulation. And sometimes life is hard. And I suspect you don't get to your life. Nobody does to get a get to their life is out low points and result, moments where they are disappearing. And I thought that I let's capture this state and how to deal with that state. And I found that very often, you realize that when you stop taking things personally, when you realize that this notion of a person is a fiction, similar as it is in Westworld, where the robots realize that their memories and desires are the stuff that keeps them in the loop. And they don't have to act on those memories and desires that our memories and expectations is what makes us unhappy. And the present rarely does the day in which we are for the most part, it's okay, right? When we are right sitting here, right here, right now, we can choose how we feel. And the thing that affects us is the expectation that something is going to be different from what we want it to be or the memory that something was different from what you wanted it to be. And once we basically zoom out from all this, what's left is not a person, what's left is this state of being conscious, which is the software state. And software doesn't have an identity. It's a physical law. And it's a law that acts in all of us. And it's embedded in a suitable substrate. And we didn't pick that substrate, right, we are mostly randomly instantiated on it, and they're all these individuals, and everybody has to be one of them. And eventually, you're stuck on one of them and have to deal with that. So you're

Lex Fridman 2:56
like a leaf floating down the river, you're just have to accept that there's a river and you just

Joscha Bach 3:03
don't have the thing is that the illusion that you are an agent is a construct at what part of that is actually under your control. And I think that our consciousness is largely a control model for our own attention. So we notice where we are looking and we can influence what you're looking how we are disambiguating things, how we put things together in our mind. And the whole system that runs us is this big cybernetic motivational system. So we basically like a little monkey sitting on top of an elephant. And we can put this elephant here in the air to go this way or that way. And we might have the illusion that we are the elephant or that we are telling it what to do. And sometimes we notice that it walks into a completely different direction. And we didn't set this thing up. It just is the situation that we find ourselves in.

Lex Fridman 3:52
How much prodding can we actually do with the elephant?

Joscha Bach 3:56
A lot. But I think that our consciousness cannot create the motor force

Lex Fridman 4:03
is the elephant consciousness in this metaphor.

Joscha Bach 4:05
No, the monkey is the consciousness. The monkey is the attentional system that is observing things, there is a large perceptual system combined with a motivational system that is actually providing the interface to everything and our own consciousness, I think, is the tool that directs the attention of that system, which means it singles out features and performs conditional operations for which it needs an index memory. But this index memory is what we perceive as our stream of consciousness, but the consciousness is not in charge. That's an illusion.

Lex Fridman 4:35
So everything outside of that consciousness is the elephant. So it's the physics of the universe, but it's also society that's outside of your

Joscha Bach 4:45
I would say the elephant is the agent. So there is an environment in which the agent is stomping, and you are influencing a little part of that agent.

Lex Fridman 4:54
So can you is the agent a single human being? What's what Which object has agency?

Joscha Bach 5:01
That's an interesting question, I think a way to think about an agent is that it's a controller with a set point generator. The notion of a controller comes from cybernetics and control theory, Control System consists out of a system that is regulating some value, and the deviation of that value from a setpoint. And it has a sensor that measures the system's deviation from that setpoint and an effector, that can be parametrized by the controller. So the controller tells the effector to do a certain thing. And the goal is to reduce the distance between the setpoint and the current value of the system. And there's environment which disturbs the regulated system, which brings it away from that setpoint. So simplest case is the thermostat. The thermostat is really simple, because it doesn't have a model, the thermostat is only trying to minimize the setpoint deviation in the next moment. And if you want to minimize the set point deviation over a longer time span, you need to integrate it you need to model what is going to happen. So for instance, when you think about that your set point is to be comfortable in life, maybe you need to make yourself uncomfortable first, right, so you need to make a model of what's going to happen when this task of the controller is to use its sensors to measure the state of the environment, and the system that is being regulated, and figure out what to do. And if the task is complex enough, the set points are complicated enough. And if the controller has enough capacity and enough sensor feedback, then the task of the controller is to make a model of the entire universe that it's in the conditions under which it exists and of itself. And this is a very complex agent, and we are in that category. And an agent is not necessarily a thing in the universe. It's a class of models that we use to interpret aspects of the universe. And being very notice the environment around us a lot of things only make sense at the level that should be entangled with them, it should be interpret them as control systems, that big models of the world and try to minimize their own set points

Lex Fridman 7:06
over the models are the agents.

Joscha Bach 7:10
The agent is a class of model. And we noticed that we are an agent ourself, we are the agent that is using our own control model to perform actions, we notice we produce a change in the model and things in the world change. And this is how we discover the idea that we have a body that we are situated in environment and that we do have a first person perspective

Lex Fridman 7:30
still don't understand. What's the best way to think of which objects has agency with with respect to human beings? Is it the body? Is it the brain? Is it the contents of the brain as agency? Like? What's the actuators that you're referring to? What is the controller? And where does it reside? Or is it these impossible things? Like because I keep trying to ground it to spacetime, the three dimensional space and the one dimension of time? What's the agent in that? For humans?

Joscha Bach 8:04
There is not just one, it depends on the way in which you're looking at this thing in which you're framing it. Imagine that you are, say Angela Merkel, and you are acting on behalf of Germany, then you could say that Germany is the agent. And in the mind of Angela Merkel, she is Germany to some extent, because in the way in which he acts, the destiny of Germany changes, there are things that she can change that basically affect the behavior of that nation state.

Lex Fridman 8:33
Okay, so it's hierarchies have to go to another one of your tweets with I think you're playfully mocking Jeff Hawkins with saying his brains all the way down. So it's like it's agents all the way down to agents made up of agents made up of agents, like if Angela Merkel's Germany, in Germany is made up of a bunch of people, and the people are themselves agents in some kind of context. And then people are made up of cells, each individual. So is agents all the way down.

Joscha Bach 9:07
I suspect that has to be like this in the world where things are self organizing, most of the complexity that we are looking at, everything in life is about self organization. Yeah. So I think up from the devil of life, you have agents. And below life, you really have agents, because sometimes you have control systems that emerge randomly in nature and try to achieve a set point. But they're not that interesting agents that make models and because to make an interesting model of the world, you typically need a system that is Turing complete.

Lex Fridman 9:42
Can I ask you a personal question? What's the line between life and non life is personal because your life form? What do you think in this emergent complexity at which point does the thing start being living and have agency

Joscha Bach 10:00
Personally, I think that the simplest answer there is that life is cells, because life is what cells, cells, biological cells. So it's a particular kind of principle that we have discovered to exist in nature. It's modular stuff that consists out of basically, this DNA tape was a readwrite head on top of it, that is able to perform arbitrary computations and state transitions between the cell and the, it's combined with a membrane that insulates the cell from its environment. And there are chemical reactions inside of the cell that are in this equilibrium. And the cell is running in such a way that this this equilibrium doesn't disappear. And the cell goes with this egg goes into an equilibrium state it dies. And it requires some things like and Nick entropy extractor to maintain this this equilibrium. So it's able to harvest like entropy from its environment and keep itself running.

Lex Fridman 10:58
So there's information and there's a wall to protect to to maintain this disequilibrium. But isn't this very earth centric? Like what you're referring to

Joscha Bach 11:08
is not making a normative notion, you could say that there are probably other things in the universe that are sell like lifelike. And you could also call them life. But eventually, it's just willingness to find an agreement of how to use the terms. I like sales, because it's completely co extension of this the way that we use the word even before we knew about sales. So people were pointing at some stuff, and saying this is somehow animate. And this is very different from the non animate stuff, and what's the difference between the living and the dead stuff. And it's mostly whether the cells are working or not. And also this boundary of life where we say that, for instance, a virus is basically an inflammation picker that is subverting the cell and not life by itself. That makes sense to me. And it's somewhat arbitrary. You could of course, say that systems that permanently maintain this equilibrium and can self replicate, or always live. And maybe that's a useful definition, too. But this is eventually just how you want to use divert,

Lex Fridman 12:10
is it so useful for conversation? But is it somehow fundamental to the universe? Do you think there's a actual line to eventually be drawn between life and non life? Or is it all kind of continuum?

Joscha Bach 12:24
I don't think it's a continuum. But there is nothing magical that is happening. Living systems are a certain type of machine.

Lex Fridman 12:30
What about nonliving? Systems? Is it also a machine? They are

Joscha Bach 12:35
nonliving machines? But the question is, at which point is the system able to perform arbitrary state transitions in to make representations and living things can do this. And of course, we can also build nonliving things that can do this. But we don't know anything in nature, that is not a cell. And it's not created by cellular life that is able to do that.

Lex Fridman 12:58
Now, not only do we not know, I don't think we have the tools to see otherwise. I always worry that we we look at the world too narrowly, like we have the could be life of a very different kind right under our noses that we're just not seeing, because we're not either limitations of our cognitive capacity, or we're just not open minded enough, either with the tools of science or just the tools of our mind.

Joscha Bach 13:32
Yeah, that's possible. I find this thought very fascinating. And I suspect that many of us ask ourselves in childhood, what are the things that we are missing? What kind of systems and interconnections exist that are outside of our gaze? But the the are looking for it. And physics doesn't have much room at the moment for opening up something that would not violate the conservation of information as we know it.

Lex Fridman 14:03
Yeah, but I wonder about time timescale and scale, spatial scale, whether we just need to open up our idea of what, like how life presents itself, it could be operating at a much slower timescale. Yeah, much faster timescale. And it's almost sad to think that there's all this life around us that we're not seeing, because we're just not like thinking in terms of the right of the right scale, both time and space.

Joscha Bach 14:34
What is your definition of life? What do you understand this life?

Lex Fridman 14:40
entities have sufficiently high complexity. They're full of surprises.

Lex Fridman 14:50
mean I don't know. I don't have a free will. So that just came out of my mouth. I'm not sure if that even makes sense. There's certain characteristics so complex Cities seems to be a necessary property of life. And I almost want to say it has ability to do something unexpected.

Joscha Bach 15:13
It seems to me that life is the main source of complexity on Earth. Yes, and complexity is basically a bridgehead that order builds into chaos, by modeling, by processing information in such a way that you can perform reactions that would not be possible for dump systems. And this means that you can harvest neg entropy that dump systems cannot harvest. And this is what complexity is mostly about. It's a sense, the purpose of life is to create complexity,

Lex Fridman 15:46
increasing money there, there's there seems to be some kind of universal drive towards increasing pockets of complexity. I don't know what that is, that seems to be like a fundamental. I don't know if it's the property of the universe, or it's just the consequence of the way the universe works. But there seems to be this small pockets of emergent complexity that builds on top of each other and starts having like greater and greater complexity by having like a hierarchy of complex like little organisms, building up a little society that then operates almost as an individual organism itself. And all of a sudden, you have Germany, and Merkel,

Joscha Bach 16:27
well, that's not obvious to me, everything that goes up has to come down at some point, right. So every if you see this big exponential curve somewhere, it's usually the beginning of an S curve, or something that eventually reaches saturation. And the S curve is the beginning of some kind of bump that goes down again. And there is just the thing that when you are in sight of an evolution of life, you are on top of a puddle of negentropy that is being sucked dry, by life. And during that happening, you see an increase in complexity, because life forms are competing with each other to get more and more and find out and find a corner of that, like entropy extracted for

Lex Fridman 17:11
that. I feel like that's a gradual, beautiful process, like it's almost no follows a process akin to evolution. And the way it comes down is not the same way came up. The way it comes down as usually harshly and quickly. So usually there's some kind of catastrophic event.

Joscha Bach 17:30
Now the Roman Empire took a long time.

Lex Fridman 17:34
But that's a would that be? would you classify this as a decrease in complexity,

Joscha Bach 17:39
though? Yes, I think that this size of the cities that will be fed has decreased dramatically. And you could see that the quality of the art decreased, and it did so gradually. And maybe future generations, when they look at the history of the United States in the 21st century, will also talk about the gradual decline, not something that suddenly happens.

Lex Fridman 18:05
Do you have a sense of where we are? Are we on the exponential rise? Or we're at the peak? Are we the downslope of the the United States empire?

Joscha Bach 18:15
It's very hard to say from a single human perspective, but it seems to me that we are probably at the peak.

Lex Fridman 18:25
I think that's probably the definition of like optimism and cynicism. So my nature of optimism is I think we're on the rise. I think this is all a matter of perspective, nobody knows. But I do think that erring on the side of optimism, like you need a sufficient number. You need a minimum number of Optimists in order to make that up thing actually work. And so I tend to be on the side of the optimist,

Joscha Bach 18:53
I think that we are basically a species of grasshoppers that have turned into locusts. And when you are in the Locust mode, you'll see an amazing rise of population numbers and of the complexity of the interactions between the individuals. But it's ultimately the question is, is it sustainable? See, I

Lex Fridman 19:13
think we're a bunch of lions and tigers that have become domesticated cats. To use a different metaphor, and so I'm not exactly sure we're so destructive or just softer, and nicer and lazier.

Joscha Bach 19:27
But if you have monkeys, and not the cats, and if you look at the monkeys, they are very busy.

Lex Fridman 19:33
The ones that have a lot of sex those monkeys, not just

Joscha Bach 19:36
the bonobos, I think that all the monkeys are basically a discontent species that always needs to metal.

Lex Fridman 19:42
Or the gorillas seem to have a little bit more of a structure but it's a different different part of the tree. Okay, you mentioned the elephant and the monkey riding the elephant. And consciousness is the monkey And there's some prodding that the monkey gets to do, and sometimes the elephant listens. I heard you got into some contention. Maybe you can correct me, but I heard you got into some contentious freewill discussions. Is this with Sam Harris or something like that?

Joscha Bach 20:16
Not that I know of.

Lex Fridman 20:18
Some people have told me, you made a bunch of big debate points about freewill. Well, let me just then ask you where were in terms of the monkey and the elephant? Do you think we land in terms of the illusion of freewill? How much control does the monkey have?

Joscha Bach 20:38
Right we have to think about what freewill is in the first place. We are not the machine we are not the thing that is making the decisions we are model of that decision making process. And there is a difference between making your own decisions and predicting your own decisions. Yes, and that difference is the first person perspective. And what basically makes decision making under conditions of freewill distinct from just automatically doing the best thing is that we often don't know what the best thing is, we make decisions under uncertainty, we make informed bets using a betting algorithm that we don't yet understand. Because we haven't reverse engineered our own mind sufficiently. We don't know the expected rewards, we don't know the mechanism by which we estimate the rewards and so on. But there is an algorithm we observe ourselves performing, where we see that we wait facts and factors and the future. And then some kind of possibilities or motive gets raised to an intention. And that's informed bet that the system is making. And that making of the upon bet, the representation of that is what we call freewill. And it's seems to be paradoxical because we think that's the crucial thing is about a debt that somehow in deterministic, and yet, if it was in deterministic, it would be random. And cannot be random. Because it was if it was random, if just dice were being thrown in the universe, randomly forces you do things would be meaningless. So the important part of the decisions is always the deterministic stuff. But it appears to be in deterministic to you because it's unpredictable. Because if it was predictable, you wouldn't experience it as a freewill decision, you would experience it as just doing the necessary right thing. And you see this continuum between the freewill and the execution of automatic behavior when you're observing other people. So for instance, when you are observing your own children, if you don't understand them, you will use this agent model where you have an agent with a set point generator, and the agent is doing the best it can to minimize the difference of the setpoint. And it might be confused and sometimes impulsive or whatever. But it's acting on its own freewill. And when you understand what's happens in the mind of the child, you see that is automatic. And you can out model the child you can build things around the child that will lead the child to make exactly the decision that you are predicting. And in under these circumstances, like when you are a stage musician, or somebody who is dealing with people that this you sell a car to. And you completely understand the psychology and the impulses and the space of thoughts that this individual can have at that moment. Under these circumstances, it makes no sense to attribute freewill. Because it's no longer decision making under uncertainty you are already certain for them, there's uncertainty but you already know what they're doing.

Lex Fridman 23:33
But what about for you? So is this akin to like, systems like cellular automata, where it's deterministic. But when you squint your eyes a little bit, it starts to look like there's agents making decisions at the higher. So when you zoom out and look at the entities that are composed by the individual cells, even though the there's underlying simple rules that make the system evolve in deterministic ways. It looks like there's organisms making decisions is that where the illusion of freewill emerges at jump and scale.

Joscha Bach 24:17
It's a particular type of model. But this jump in scale is crucial. The jumping scale happens whenever you have too many parts to count. And you cannot make a model at that level. And you try to find some higher level regularity. And the higher level regularity is a pattern that you project into the world to make sense of it. And agency is one of these patterns, right? You have all these cells that interact with each other. And the cells in our body are set up in such a way that they benefit if their behavior is coherent, which means that they act as if they were serving a common goal and pitch that means that they will evolve regulation mechanisms that act as if they were serving a common goal. And now you can make sense of these all the cells by projecting the common goal into them

Lex Fridman 25:00
So for you, then free was an illusion.

Joscha Bach 25:03
No, it's a model. And it's a construct. It's basically a model that the system is making of its own behavior. And it's the best model that it can come up with under the circumstances. And it can get replaced by a different model, which is automatic behavior, when you fully understand the mechanism under which you're acting,

Lex Fridman 25:19
yeah, but the another word for model is what story? So it's the story, you're telling me? Do you actually have control? Is there such a thing as a you? And is there such thing as you having control? Like, are you manifesting your evolution as an entity?

Joscha Bach 25:41
And some sense the EU is the model of the system that is in control? It's a story that the system tells itself about somebody who is in control. Yeah. And the contents of that model are being used to inform the behavior of the system.

Lex Fridman 25:56
Okay, so it's

Joscha Bach 25:58
completely mechanical. And the system creates that story like a loom. And then it uses the contents of that story to inform its actions and writes the results of that actions into the story.

Lex Fridman 26:11
So how's that not an illusion? The story is written, then? Or a rather, we're not the writers of the story.

Joscha Bach 26:21
Yes, but we always knew that.

Lex Fridman 26:24
No, we don't know. When do we know that?

Joscha Bach 26:26
I think that's what's the confusion about concepts. The conceptual illusion in our culture comes from the idea that you live in physical reality, and that we experience physical reality and that you have ideas about it. And then you have this dualist interpretation, where you have two substances, res extensa, the world that you can touch, and that is made of extended things, and racecar Gittens, which is the world of ideas. And in fact, both of them are mental representations. One is the representations of the world as a game engine that your mind generates, to make sense of the perceptual data. And the other one world, yes, that's what we perceive as the physical world. But we already know that the physical world is nothing like that, right? Quantum mechanics is very different from what you and me perceive as the world, the world that you may perceive is a game engine. Yeah, and no colors and sounds in the physical world, they only exist in the game engine generated by your brain. And then you have ideas that are not cannot be mapped onto extended regions, right. So the objects that have spatial extension in the game engine, res extensa. And the objects that don't have a physical extension in the game engine are ideas, and they both interact in our mind to produce models of the world. Yep. But,

Lex Fridman 27:38
you know, when you play video games, I understand that what's actually happening is zeros and ones inside of inside of a computer, that have a CPU and a GPU. But you're still seeing, like, the rendering of that, and you're still making decisions, whether to shoot to turn left, or to turn right, if you're playing a shooter, or every time I started thinking about Skyrim, an elder scrolls in walking around the beautiful nature and swinging a sword, but it feels like you're making decisions inside the video game. So even though you don't have direct access, in terms of perception, to the bits to the zeros and ones, it still feels like you're making decisions. And your decisions are actually feels like they're being applied all the way down to the zeros and ones. Yes, it feels like you have control even though you don't have direct access to reality.

Joscha Bach 28:36
So there is basically a special character in the video game that is being created by the video game engine. Yeah, and this character is serving the aesthetics of the video game. And that is you.

Lex Fridman 28:47
Yes, but I feel like you have control inside the video game. Like the all those like 12 year olds that kick my ass on the internet.

Joscha Bach 28:55
So far, when you play the video game, it doesn't really matter that there's zeros and ones, right? You don't care about the video of the bus, you don't care about the nature of the CPU that it runs on. What you care about are the properties of the game that you're playing. And you hope that the CPU is good enough. Yes. And the similar thing happens when we interact with physics, the world that you will meet or in is not the physical world, the world that you and me are in is a dream. But

Lex Fridman 29:19
how close is it to the real world though?

Joscha Bach 29:23
We know that it's not very close. But we know that the dynamics of the dream world match the dynamics of the physical world to a certain degree of resolution. Of course, the structure of the dream world is different. So you see waves crashing on your feet, right? But there are no waves in the ocean. There's only water molecules that have tangents between the molecules that are the result of electrons in the molecules interacting with each other,

Lex Fridman 29:50
aren't they like very consistent? We're you're seeing a very crude approximation. Isn't our dream world very consistent, like To the point of being mapped directly one to one to the actual physical world, as opposed to us being completely tricked is this is like what you have like,

Joscha Bach 30:09
It's not a trick. That's, that's my point. It's not an illusion, it's a form of data compression, it's an attempt to deal with the dynamics of too many parts to count at the level at which we're entangled was the best model that you can find.

Lex Fridman 30:20
Yeah, so we can act in a dream world. And our actions have impact in the in the real world, in the physical world. Yes. To which we don't have access,

Joscha Bach 30:28
yes. But it's basically like, accepting the fact that the software that we live in the dream that you live in, is generated by something outside of this world that you are in.

Lex Fridman 30:37
So is the software deterministic? And do we not have any control? To do have? So freewill is having a conscious being freewill is the monkey being able to steer the elephant.

Joscha Bach 30:55
No, I, it's slightly different. Basically, in the same way, as you are modeling the water molecules in the ocean that engulf your feet when you're walking on the beach, as waves and the waves, but only the atoms on more complicated stuff underneath the atoms and so on. You know that right? You would accept Yes, there is a certain extraction that happens here. It's a simplification of what happens and simplification that is designed in such a way that your brain can deal visit temporally and spatially in terms of resources, and tuned for the predictive value. So you can predict with some accuracy whether your feet are going to get wet or not. But it's

Lex Fridman 31:33
a really good, it's really good interface and approximation. Yes, it says equals MC squared is a good equations are good approximation, or what they're much better approximation. So to me waves is a really nice approximation of what's all the complexity is happening underneath. Basically,

Joscha Bach 31:51
it's a machine learning model that is constantly tuned to minimize surprises. So it basically tries to predict as well as it can, what you're going to perceive next are we talking

Lex Fridman 32:00
about, which is the machine learning our perception system, or the dream world,

Joscha Bach 32:05
or machine world is a dream world is the result of the machine learning process of the perception system is doing the compression? Yes. And the model of you as an agent is not a different type of model, or it's a different type, but not not different, as in its model like nature, from the model of the ocean, right? Some things are oceans, some things are agents. And one of these agents is using your own control model, the output of your model the things that you perceive yourself as doing. And that is you.

Lex Fridman 32:38
What about the fact that it's like when you're standing it with the water on your feet, and you're looking out into the vast, like open water of the ocean? And then there's a beautiful sunset? And it will the fact that is beautiful. And then maybe you have like friends or a loved one with you and like you feel love? What is that as the dream world? And what is that?

Joscha Bach 33:02
Yes, it's all happening inside of the dream.

Lex Fridman 33:05
Okay. But see, the word dream makes it seem like it's not real.

Joscha Bach 33:11
Now, of course, it's not real. The physical universe is free, but the physical universe is incomprehensible. And it doesn't have any feeling of realness, the feeling of realness that you experience gets attached to certain representations. But your brain assesses this is the best model of reality that I have.

Lex Fridman 33:28
So the only thing that's real to you is the thing that's happening at the very base of reality, like,

Joscha Bach 33:36
for something to be real, it needs to be implemented. So the model that you have of reality is real in as far as it is a model, right? It's an appropriate description of the world to say that there are models that are being experienced. But the world that you experience is not necessarily implemented. There is a difference between a reality a simulation, and a simulacrum. The reality that we're talking about is something that fully emerges over a causally closed, lowest layer. And the idea of physicalism is that we are in that layer that basically our world emerges over that every alternative to physicalism is a simulation theory, which basically says that we are in some kind of simulation universe, and the real world needs to be an apparent universe of that, where the actual causal structure is, right. And when you look at the ocean and your own mind, you are looking at a simulation that explains what you're going to see next. And we are living in a simulation. Yes, but this simulation generated by our own brains. Yeah. And this simulation is different from the physical reality because the causal structure that is being produced what you're seeing is different from the causal structure of physics are consistent. Hopefully, if not, then you are going to end up in some kind of institution where people will take care of you because your behavior will be inconsistent, right? Your behavior needs to work in such a way that it's interacting with, accurately predict stiff model of reality. And if your brain is unable to make your model of reality predictive, you will need help.

Lex Fridman 35:06
So what what do you think about Donald Hoffman's argument that it doesn't have to be consistent the dream world to the what he calls like the interface to the actual physical reality where there could be evolution, I think he makes an evolutionary argument, which is like it could be an evolutionary advantage to have the dream world drift away from physical reality.

Joscha Bach 35:30
I think that only works if you have tenure, as long as you're still interacting with the ground truth needs to be somewhat predictive.

Lex Fridman 35:39
Well, in some sense, humans have achieved a kind of tenure in the animal kingdom.

Joscha Bach 35:45
At some point, you became too big to fail, postmodernist. Make sense? There's no reality that

Lex Fridman 35:55
man, okay,

Joscha Bach 35:57
yeah. But basically, you can do magic, you can change your assessment of reality, but eventually, reality is going to come bite you in the ass. If it's not predictive.

Lex Fridman 36:06
Do you have a sense of what is that base layer physical reality, you have, like? So you have these attempts at the theories of everything. The very, very small of like string theory, or what Stephen Wolfram talks about with a hyper grass. These are these tiny, tiny, tiny, tiny objects. And then there is more like quantum mechanics. That's talking about objects that are much larger, but still very, very, very tiny, do you have a sense of where the tiniest thing is, that is like, at the lowest level, the turtle at the very bottom, in a sense,

Joscha Bach 36:45
I talk about where it is because space is emergent over the activity of these things. So space, these coordinates only exist in relation to the things other things. And so you could in some sense, abstract it into locations that can hold information and trajectories that the information can take between the different locations. And this is how we construct our notion of space. Yeah. And physicists usually have a notion of space that is continuous. And this is a point where I tend to agree with people like Stephen Wolfram, who are very skeptical of the geometric notions. I think that geometry is the dynamics of too many parts to count. And when there are no infinities, if there were two infinities, you will be running into contradictions, which is in some sense, what girdle and touring discovered in response to what's called so no infinities, there are no infinities fake there is unboundedness. But if you have a language that talks about infinity, at some point, the language is going to contradict itself, which means it's no longer valid. In order to deal with infinities and mathematics, you have to postulate the existence in initially, you cannot construct the infinities and that's an issue, right? You cannot build up an infinity from zero. But in practice, you never do this, right? When you perform calculations, you only look at the dynamics of too many parts to count. And usually these numbers are not that large. They're not Google's or something. The the infinities that we are dealing with in our universe are mathematically speaking, relatively small integers. And still, you're what you're looking at is dynamics where a trillion things behave similar to 100 trillion things or something that is very, very large, because they are converging. And these convergent dynamics, these operators, this is what we deal with when we are doing geometry, right? Geometry is stuff where we can pretend that it's continuous. Because if we subdivide the space, sufficiently fine grained, distinct approach a certain dynamic and this approach dynamic, that is what we mean by it. But I don't think that infinity would work, so to speak, that you would know the last digit of pi, and that you have a physical process that rests on knowing the last digit of pi.

Lex Fridman 39:09
Yeah, that there could be just a peculiar quirk of human cognition that we like discrete, discrete makes sense to us, infinity doesn't. So in terms of our intuitions, no, the

Joscha Bach 39:20
issue is that everything that we think about needs to be expressed in some kind of mental language, not not necessarily a natural language, but some kind of mathematical language that you neurons can speak that refers to something in the world. And what we have discovered is that we cannot construct a notion of infinity without running into contradictions, which means that in such a language is no longer valid. And I suspect this is what made Protagoras so unhappy when somebody came up with the notion of irrational numbers before it was time right. There's this moose that he had this person killed when he blacked out the secret that not everything can be expressed as a ratio between two numbers, but there are there are numbers between the ratios. They go It was not ready for this. And I think he was right, that has confused mathematicians very seriously, because these numbers are not values, there are functions. So you can calculate these functions to certain degree of approximation, but you cannot pretend that PI has actually a value. Pi is a function that would generate this value to some degree. But nothing in the world rests on knowing quite,

Lex Fridman 40:26
how much how important is this distinction between discrete and continuous for you to get to the because there's a, I mean, in discussion of your favorite flavor of the theory of everything, there's a few on the table. So there's string theory, there's this particular, there's loop quantum gravity, which focused on one particular unification. There's, there's just a bunch of favorite flavors of different people trying to propose a theory of everything. Eric Weinstein, and a bunch of people throughout history and then of course, Stephen Wolfram, who I think is one of the only people doing a discrete

Joscha Bach 41:10
No, no, there's a bunch of physicists would do this right now. And like Topher, Lee and Tomasello, and the digital physics is something that is, I think, growing in popularity. But the reason why this is interesting is because it's important sometimes to settle disagreements, I don't think that you need infinities or at all, and you never needed them. You can always deal with very large numbers, and you can deal with limits, right? You're fine with doing that. You don't need any kind of infinity, you can build your computer algebra systems just as well, without believing in infinity in the first place. You okay with limits? Yeah. So basically, a limit means that something is behaving pretty much the same, if you make the number larger, right? Because it's converging to a certain value, and at some point, the difference becomes negligible, and you can no longer measure it. And in this sense, you have things that, yeah, if everyone engages has enough corners, then it's going to behave like a circle at some point, right. And it's only going to be in some kind of esoteric thing that cannot exist in the physical universe, that you would be talking about this perfect circle. And now it turns out that it also wouldn't work in mathematics, because you cannot construct mathematics that has infinite resolution, without running into contradictions. So that is itself not that important, because we never did that, right. It's just a thing that some people thought we could. And this leads to confusion. So for instance, Roger Penrose uses this as an argument to say that there are certain things that mathematicians can do, dealing with infinities. And by extending our mind can do that computers cannot do.

Lex Fridman 42:55
Yeah, he talks about that there's the human mind can do certain mathematical things. The computer as defined by the universal Turing machine cannot, yes. What so that it has to do with infinity?

Joscha Bach 43:08
Yes, it's one of the things. So he is basically pointing at the fact that there are things that are possible in the mathematical mind, and in pure mathematics that are not possible in machines that can be constructed in the physical universe. And because he's an honest guy, he's thinks this means that present physics cannot explain operations that happen in our mind.

Lex Fridman 43:34
Do you think he's right? And so let's, let's leave his discussion of consciousness aside for the moment. Do you think he's right about just what he's basically referring to as intelligence? So are, is the human mind fundamentally more capable, as a thinking machine than a universal Turing machine? No. But so he's suggesting that right.

Joscha Bach 43:58
So our mind is actually less than a Turing machine, there can be no Turing machine because it's defined as having an infinite state. And we always only have a finite tape, but better perform finally many operations.

Lex Fridman 44:10
Okay, I think it can do the kind of computation the Turing machine can. And

Joscha Bach 44:14
that's because he thinks that our mind can do operations that have infinite resolution in some sense. And they don't think that's the case, our minds just able to discover these limit operators over too many parts to count.

Lex Fridman 44:30
What about his idea that consciousness is more more than a computation. So it's more than something that a toy machine can can do? So again, saying that there's something special about our mind that cannot be replicated in the machine.

Joscha Bach 44:49
You issues that I don't even know how to construct a language to express this statement correctly. Well,

Lex Fridman 45:01
The the basic statement is there's a, there's a human experience that includes intelligence that includes self awareness that includes the hard problem of consciousness. And the question is, can that be fully simulated in the computer? In the mathematical model the computer as we understand it today, Roger Penrose has no. So the universal Turing machine cannot simulate the universe.

Joscha Bach 45:32
So the interesting question is, and you have to ask them this is why not what is the specific thing that cannot be modelled. And when I looked at his writings, and I haven't read all of it, but when I read, for instance, the section that he writes in the introduction to enroll to infinity, the thing that he specifically refers to is the way in which human minds deal with infinities. And that itself can I think easily be deconstructed, a lot of people feel that our experience cannot be explained in a mechanical way. And therefore, it needs to be different. And I concur, our experience is not mechanical, our experience is simulated, it exists only in a simulation, only a simulation can be conscious physical systems cannot be conscious, because they will need mechanical cells cannot be conscious. Neurons cannot be conscious brains cannot be conscious people cannot be conscious. As far as you, if you understand them as physical systems. What can be conscious is the story of the system in the world, you write all these things into the story, you have experiences for the same reason that a character novel has experiences because it's written into the story. And now the system is acting on that story. And it's not a story that is written in a natural language, it's written in a perceptual language and this multimedia language of the game engine. And in there, you write in, what kind of experience you have, and what this means for the behavior of the system for your behavior tendencies, for your focus for your attention, for your experience, of Valence, and so on. And this is being used to inform the behavior of the system and the next step. And then the story updates with the reactions of the system and the changes in the world and so on. And you live inside of that model, you don't live inside of the physical reality.

Lex Fridman 47:23
And I mean, just just just to linger on it, like you see, okay. It's in the perceptual language, the multimodal perceptual language. That's the experience. That's what consciousness is, within that, within that model within that story. But do you have agency that we play a video game, you can turn left, and you can turn right, in that story? So in that dream world, how much control? Do you is there such a thing as you that story? Like, is it right to say the main character, you know, everybody's NPCs? And then there's the main character, and you're controlling the main character? Or is that an illusion? Is there a main character that you're controlling? I'm getting to the point of like, the freewill point.

Joscha Bach 48:14
Imagine that you are building a robot that plays soccer. Yeah. And you've been to MIT computer science, you basically know how to do that. Right. And so you would say, the robot is an agent, that's also control problem, how to get the ball into the goal, and it needs to perceive the world and the world is disturbing him in trying to do this, right. So yes, to control many variables to make that happen, and to project itself and the ball into the future, and understand its position on the field relative to the ball, and so on in the position of its limbs, or in the space around it, and so on. So it needs to have an adequate model that abstracting reality in a useful way. And you could say that this robot does have agency over what it's doing, in some sense. And the model is going to be a control model. And inside of that control model, you can possibly get to a point where this thing is sufficiently abstract to discover its own agency. Our current robots don't do that they don't have a unified model of the universe. But there's not a reason why we shouldn't be getting there at some point in the not too distant future. And once that happens, you will notice that the robot tells a story about a robot playing soccer. So the robot will experience itself playing soccer in a simulation of the world that it uses to construct a model of the locations of legs and limbs, in space on the field with relationship to the ball, and it's not going to be at the level of the molecules. It will be an abstraction that is exactly at the level that is most suitable for past planning of the movements of the robot. Right. It's going to be a high level abstraction, but a very useful one that is as predictive as we can make it. And in that side of that story, there is a model of the agency of that system. So this model can and accurately predict that the contents of the model are going to be driving the behavior of the robot in the immediate future.

Lex Fridman 50:08
But there's the hard problem of consciousness, which I would also, there's a subjective experience of freewill as well, that I'm not sure where the robot gets that where that little leap is. Because for me right now, everything I imagined with that robot, as it gets more and more and more sophisticated, the agency comes from the programmer of the robot still, of what was programmed in

Joscha Bach 50:35
the property to an end to end learning system, you maybe need to give it a few prayers. So you match the architecture in the right direction, that it converges more quickly. But ultimately, discovering the suitable hyper parameters of the architecture is also only a search process, right. And as the search process was evolution, that has informed our brain architecture, so we can converge on a single lifetime on useful interaction with the world and

Lex Fridman 51:00
promise if we define hyper parameters broadly. So it's not just this, the parameters that control this end to end learning system, but the entirety of the design of the robot, like, though, there's, you have to remove the human completely from the picture. And then in order to build the robot, you have to create an entire universe. Because you have to go, you can't just shortcut evolution, you have to go from the very beginning, in order for it to have because I feel like there's always a human pulling the strings. And that makes it seem like the robot is cheating is getting a shortcut to consciousness.

Joscha Bach 51:35
And you're looking at the current Boston Dynamics robots, it doesn't look as if there is somebody pulling the strings, it doesn't look like cheating anymore.

Lex Fridman 51:42
Okay, so let's go there, because I got to talk to you about this. So obviously, we're the case of Boston Dynamics. As you may or may not know, it's always either hard coded or remote controlled. There's no intelligence,

Joscha Bach 51:55
I don't know how the current generation of Boston Dynamics robots works. But what I've been told about the previous ones was that it's basically all cybernetic control, which means you still have feedback mechanisms, and so on. But it's not deep learning for the most part it's currently done. It's, for the most part, just identifying a control hierarchy that is congruent to the limbs that exists and the parameters that need to be optimized for the movement of these limbs. And then there is a convergence progress. So it's basically just regression that you would need to control this. But again, I don't know whether that's true. That's, that's what I've been told about how that work,

Lex Fridman 52:31
we have to separate several levels of discussions here. So the only thing they do is pretty sophisticated control, not with non machine learning, in order to be to maintain balance, or to write itself. It's a control problem in terms of using the actuators to when it's pushed, or when it steps on a thing that's uneven, how to always maintain balance. And there's a tricky, like several heuristics around that. But that's the only goal. Everything you see Boston Dynamics doing in terms of that, to us humans is compelling, which is any kind of higher order movement, like turning, wiggling its butt. Like, you know, jumping back, and it's two feet, dancing. Dancing is even worse, because dancing is hard coded in it's, it's choreographed by humans, choreography software. So there is no all that high level movement. There's no anything that you can call certainly can't call AI. But there's no even like basic heuristics, it's all hard coded in and yet, we humans immediately Project Agency onto them, which is which is fast. So

Joscha Bach 53:48
the gap here is doesn't necessarily have agency what it has a cybernetic control. And the seventh attic control means you have a hierarchy of feedback loops that keep the behavior in certain boundaries, so the robot doesn't fall over. And it's able to perform the movements. And the choreography cannot really happen with motion capture, because the robot would fall over because the physics of the robot, the weight distribution, and so on is different from the weight distribution in the human body. So if you were using the directly motion capture movements of a human body to project it into this robot, it wouldn't work. You can do this visit computer animation will look a little bit off, but who cares. But if you want to correct for the physics, you need to basically tell the robot where it should move its limbs, and then the control algorithm is going to approximate a solution that makes it possible visit the physics of the robot. And you have to find the basic solution for making that happen. And there's probably going to be some regression necessary to get the control architecture to make these movements. So those two

Lex Fridman 54:51
layers are separate the thing the higher level instruction of what how you should move and where you should move is

Joscha Bach 54:59
next back there, the control level of these robots at some level is done. This is just the physical control movement, the motor architecture. But it's a relatively smart motor architecture, it's just that there is no high level deliberation about what decisions to make necessarily, right? But it doesn't feel like freewill, or no, no, that was not where it was trying to get to. I think that in our own body, we have that too. So we have a certain thing that is basically just a cybernetic control architecture that is moving our limbs. And deep learning can help in discovering such an architecture if you don't have it in the first place. If you already know your hardware, you can maybe handcrafted but if you don't know your hardware, you can search for such an architecture. And this work already existed in the 80s and 90s. People were starting to search for control architectures, by motor babbling, and so on and just use reinforcement learning architectures to discover such a thing. And now imagine that you have the cybernetic control architecture already inside of you. And you extend this a little bit. So you are seeking out food for instance, or rest, or, and so on, and you get to have a baby at some point. And now you add more and more control layers to this. And the system is reverse engineering its own control architecture, and built a high level model to synchronize the pursuit of very different conflicting goals. And this is how I think you get to purposes purposes or models of your goals, the goals might be intrinsic as the result of the different setpoint violations that you have hunger and thirst for very different things, and rest and pain avoidance, and so on. And you put all these things together, and eventually, you need to come up with a strategy to synchronize them all. And you don't need just to do this alone by yourself, because you are statebuilding organisms, we cannot function in isolation, the way that Homo sapiens is set up. So our own behavior only makes sense when you zoom out very far into a society or even into ecosystemic intelligence on the planet, and our place in it. So the individual behavior only makes sense in these larger contexts. And we have a number of priors built into us. So we are behaving as if we are acting on these high level goals pretty much right from the start. And eventually, in the course of our life, you can reverse engineer the goals that we're acting on what actually are our higher level purposes. And the more we understand that, the more our behavior makes sense. But this is all at this point, complex stories within stories that are driving our behavior.

Lex Fridman 57:34
Yeah, I just don't know how big of a leap it is to start creating a system that's able to tell stories within stories. Like how big of a leap that is, we're currently Boston Dynamics is, or any robot that's operating in physical space. That, and that leap might be big, if it requires to solve the hard problem of consciousness, which is telling a hell of a good story.

Joscha Bach 58:01
I suspect that consciousness itself is relatively simple. What's hard is perception, and the interface between perception and reasoning. That's, for instance, the idea of the consciousness prior that would be built into such a system by Yoshua Bengio. And what he describes nice thing that's accurate is that our own model of the world can be described to something like an energy function, the energy function is modeling. The contradictions that exist within the model at any given point, and you try to minimize these contradictions are tensions in the model. And to do this, you need to sometimes test things you need to conditionally disambiguate, figure and ground, you need to distinguish whether this is true or that is true, and so on, eventually, you get to an interpretation, but you will need to manually depress a few points in your model to let it snap into a state that makes sense. And this function that tries to get the biggest dip in the energy function in your model, according to Joshua Bengio, is related to consciousness. It's a low dimensional discrete function that tries to maximize this dip in the energy function.

Lex Fridman 59:08
i Yeah. I think I would need to dig into details because I think the way he uses the word consciousness is more akin to like self awareness, like modeling yourself within the world, as opposed to the subjective experience the hard problem,

Joscha Bach 59:23
no, it's not even the self within the world. The self is the agent and you don't need to be aware of yourself in order to be conscious. The self is just a particular content that you can have, but you don't have to have that you can be conscious in, for instance, a dream at night or during your meditation state, but you don't have a self. Right? You're just aware of the fact that you are aware and what we mean by consciousness in the colloquial sense is largely this reflexive self awareness that we become aware of the fact that you're paying attention. That we are the thing that pays attention.

Lex Fridman 59:59
We are the thing that pays attention, right? I don't see where the awareness that we're aware that the heart problem doesn't feel like it's solved. They made that there. It's called a heart problem for a reason. Because it seems like there needs to be a major leap.

Joscha Bach 1:00:19
Yeah, I think the major leap is to understand how it is possible that a machine can dream that the physical system is able to create a representation that the physical system is acting on. And that is, spine force and so on. But once you accept the fact that you are not in physics, but that you exist inside of the story, I think the mystery disappears. Everything is possible in a state exists inside the story. Okay, so your consciousness is being written into the story, the fact that you experience things is written to the head of the story, you ask yourself, Is this real? What I'm seeing? And your brand writes into the story? Yes, it's real.

Lex Fridman 1:00:53
So what about the perception of consciousness? So to me, you look conscious. So the illusion of consciousness, the demonstration of consciousness, I asked for the the legged robot, how do we make this legged robot conscious? So there's two things and maybe you can tell me if their neighboring ideas, one is actually making a conscious? And the other is make it appear conscious to others? Are those related?

Joscha Bach 1:01:25
Let's ask it from the other direction, what would it take to make you not conscious? So when you are thinking about how you perceive the world, can you decide to switch from looking at qualia to looking at representational states? And it turns out, you can Yeah, there is a particular way in which you can look at the world and recognize it's machine nature, including your own. And in that state, you don't have that conscious experience in this way anymore. It becomes apparent as a representation, everything becomes opaque. And I think this thing that you recognize everything as a representation, this is typically what we mean was enlightenment states. And yeah, motivational level. But you can also do this on the exponential level, the perceptual level,

Lex Fridman 1:02:16
see, but then I can come back to your conscious state. Okay, I particularly am referring to the social aspect, that the demonstration of consciousness is a really nice thing at a party, when you're trying to meet a new person, it's a nice thing to know that they're conscious, and they can. I don't know how fundamental consciousness is in human interaction, but it seems like to be at least an important part. And I asked that in the same kind of way. For robots, you know, in order to create a rich, compelling human robot interaction, it feels like there needs to be elements of consciousness within that interaction.

Joscha Bach 1:03:02
My cat is obviously conscious. And so my cat can do this party trick, she also knows that I am conscious be able to have feedback about the fact that we are both acting on models of our own awareness.

Lex Fridman 1:03:14
The question is, how hard is it for the robot artificially created robot to achieve cat level and party tricks?

Joscha Bach 1:03:24
Yes. So the issue for me is currently not so much on how to build a system that creates a story about a robot that lives in the world, but to make an adequate representation of the world. And the model that you and me have is a unified one. It's one where you basically make sense of everything that you can perceive every feature in the world that enters your perception can be relationally, mapped to a unified model of everything. And if you don't have an AI that is able to construct such a unified model yet,

Lex Fridman 1:03:55
do you need the unified model to do the party trick?

Joscha Bach 1:03:58
Yes, I think that you doesn't make sense if the thing is conscious, but not in the same universe as you because you could not relate to each other.

Lex Fridman 1:04:06
So what's the process? Would you save engineering consciousness in the machine? Like what are the ideas here?

Joscha Bach 1:04:14
So you probably want to have some kind of perceptual system. This perceptual system is a processing agent that is able to track sensory data and predict the next frame and the sensory data from the previous frames of the sensory data in the current state of the system. So the current state of the system is perception, instrumental to predicting what happens next. And this means you build lots and lots of functions that take all the blips that you feel on your skin and that you see on your retina, or that you hear and puts them into a set of relationships that allows you to predict what kind of sensory data what kind of center of blips your vector of blips you're going to perceive in the next frame, right? This is tuned and it's constantly tuned until it gets it as accurate as it can,

Lex Fridman 1:05:01
you build a very accurate prediction mechanism. That is step one of the perception. So first you predict, then you perceive and see the error as a prediction.

Joscha Bach 1:05:11
And you have to do two things to make that happen. One is you have to build a network of relationships that are constraints that take all the variants in the world of put each of the variances into a variable variable that is connected with relationships to other variables. And these relationships are computable functions that constrain each other. So when you see a nose that points a certain direction in space, you have a constraint that says there should be a phase nearby that has the same direction. Right. And if that is not the case, you have some kind of contradiction that you need to resolve because it's probably not a knows what you're looking at, it just looks like one. So you have to re interpret the data and until you get to a point where your model converges. And this process of making the sense of a data fit into the model structure is what Piaget calls the assimilation. And accommodation is the change of the models, where you change your model in such a way that you can assimilate everything.

Lex Fridman 1:06:07
So you're talking about building a hell of an awesome perception system that's able to do prediction and perception correct? And don't improve wait, just wait, there's more.

Joscha Bach 1:06:18
Yes, there's more for the minimize the contradictions in the model. Yes. And, of course, it's very easy to make a model in which you minimize the contradictions just by allowing that it can be in many, many possible states, right. So if you increase degrees of freedom, you will have fewer contradictions. But you also want to reduce the degrees of freedom because degrees of freedom mean uncertainty, you want your model to reduce uncertainty as much as possible. But reducing uncertainty is expensive. So you have to have a trade off between minimizing contradictions and reducing uncertainty, and you have only a finite amount of compute and experimental time and effort available to reduce uncertainty in the world. So you need to assign value to what you observe. So you need some kind of motivational system, that is estimating what you should be looking at and what you should be thinking about it, how you should be applying your resources to model what that is, right? So you need to have something like convergence links to tell you how to get from the present state of the model to the next one. You need to have these comparability links that tell you which constraints exist and which constraint violations exist. And you need to have some kind of motivational system that tells you what to pay attention to. So now we have a second agent next to the perceptual eight, we have a motivational agent. This is a cybernetic system that is modeling what the system needs, what's important for the system, and that interacts with the perceptual system to maximize the expected reward.

Lex Fridman 1:07:44
And you're saying the motivational system is some kind of like, what is it a higher level narrative over some lower level, it's

Joscha Bach 1:07:52
just your brainstem stuff, the limbic system stuff that tells you Okay, now you should get something to eat, because I've just measured your blood sugar is a

Lex Fridman 1:07:59
motivational system, like the lower levels, yes, like hungry? Yes,

Joscha Bach 1:08:03
when there's basically a physiological needs and some cognitive needs and some social needs. And they all interact. They all implemented different parts in your nervous system as the motivational system, but they're basically cybernetic feedback loops. It's not that complicated. It's just a lot of code. And so you now have a motivational agent that makes your robot go for the ball, or that makes your work, go to eat, food, and so on. And you have the perceptual system that lets it predict that environment. So it's able to solve that control problem to some degree. And now what we learned is that it's very hard to build a machine learning system that looks at all the data simultaneously to see what kind of relationships could exist between them. So you need to selectively model the world, you need to figure out where can I make the biggest difference, if I would put the following things together. Sometimes you'll find the gradient for that, right? When you have a gradient, you don't need to remember where you came from, you just follow the gradient until it doesn't get any better. But if you have a vote, where the problems are discontinuous in research spaces, that is continuous, you need to retain memory of what you explored. And you need to construct a plan of what to explore next. And this thing that means that you have next to this perceptual construction system, and then motivational cybernetics, an agent that is paying attention to what it should select at any given moment to maximize reward. And this scanning system this attention agent is required for consciousness and consciousness. Its is its control model. So it's the index memories that this thing retains, when it manipulates the perceptual representations to maximize the value and minimize the conflicts and to increase coherence. So the purpose of consciousness is to create coherence in your perceptual representations, remove conflicts, predict the future, construct counterfactual representations, so you can coordinate your actions and so on. And in order to do this, it needs to form memories. Memories are partial binding states of the working memory contents that are being revisited later on, to backtrack, to undo certain states to look for alternatives. And these index memories that you can recall, that is what you perceive as your stream of consciousness. And being able to recall these memories, this is what makes you conscious, if you could not remember what you paid attention to, you wouldn't be conscious.

Lex Fridman 1:10:26
So consciousness is the index in the memory database. Okay. But let me sneak up to the questions of consciousness a little further. So we usually relate suffering to consciousness. So the capacity to suffer? I think, to me, that's a really strong sign of consciousness is a thing that can suffer. How is that useful? Suffering? And like in your model we just described which is indexing of memories? And what is it coherence with a perception with this predictive thing that's going on the perception? How does suffering relate to any of that, you know, the higher level of suffering that humans do.

Joscha Bach 1:11:16
Basically, pain is a reinforcement signal, it pain is a signal that one part of your brain sends to another part of your brain or an abstract sense, part of your mind sends to another part of the mind, to regulate its behavior to tell it, the behavior that you're currently exhibiting should be improved. And this is the signal that I tell you to move away from what you're currently doing and push into a different direction. So pain gives you a part of you an impulse to do something differently. But sometimes this doesn't work. Because the training part of your brain is talking to the wrong region, or because it has the wrong model of the relationships in the world, maybe you're Miss modeling yourself, or you miss modeling the relationship of yourself to the world, or you're Miss modeling the dynamics of the world. So you're trying to improve something that cannot be improved by generating more pain, but the system doesn't have any alternative. So the It doesn't get better. What do you do, if something doesn't get better, and you want it to get better, you increase the strength of the signal, and then the signal becomes chronic, and it becomes permanent, without a change inside. This is what we call suffering. And the purpose of consciousness is to deal with contradictions with things that cannot be resolved. The purpose of consciousness, I think, is similar to a conductor in an orchestra. And everything works well. The orchestra doesn't need much of a conductor as long as it's coherent. But when there is a lack of coherence or something is consistently producing disharmony and mismatches, then the conductor becomes alert and interact visit. So suffering attracts the activity of consciousness. And the purpose of that is ideally, that we bring new layers online new layers of modeling, that are able to create a model of dysregulation, so we can deal with it. And this means that you typically get higher level consciousness so to speak, right, you get some consciousness above our pay grade, maybe if you have some suffering early in our life, most of the interesting people had trauma early on in their childhood. And trauma means that you are suffering an injury for which the system is not prepared, which it cannot deal with which it cannot insulate itself from. So something breaks. And this means that the behavior of the system is permanently disrupt in a way that some mismatch exists now in a regulation, that just by following your impulses by following the pain and the direction we did hurts you situation doesn't improve but get worse. And so what needs to happen is that you grow up. Yeah, that and that's part that is grown up is able to deal with the part that is stuck in this earlier phase.

Lex Fridman 1:13:53
So it leads to grow through adding extra layers to Okay, to your cognition. Let me ask them, because I guess take on suffering, the ethics of the whole thing. So not our consciousness, but the consciousness of others. You've tweeted, one of my biggest fears is that insects could be conscious, the amount of suffering on Earth would be unthinkable. So when we think of other conscious beings, is suffering a property of consciousness that we're most concerned about? So I'm still thinking about robots. How to make sense of other non human things that appear to have the depth of experience that humans have. And to me, that means consciousness and the darkest side of that which is suffering, the capacity to suffer So I started thinking, How much responsibility do we have for those other conscious beings? That's where the definition of consciousness becomes most urgent, like having to come up with a definition of cautious because most urgent, is who should we? And should we not be torturing?

Joscha Bach 1:15:24
There's no general answer to this was Genghis Khan doing anything wrong? It's depends right on how you look at it, where

Lex Fridman 1:15:32
he, he drew, he drew a line somewhere where this is us, and that's them. It's the circle of empathy. It's like these, were I have to use the word consciousness. But these are the things that matter to me if they suffer or not. And these are the things that don't

Joscha Bach 1:15:51
matter. Yeah. But when one of his commanders failed him, he broke his spine and let him die, and horrible way. And so in some sense, I think he was indifferent to suffering. Or he was not different in the sense that he didn't see it as useful if he inflicted suffering. But he did not see it as something that had to be avoided. That was not the goal. The question was, how can I use suffering, and the infliction of suffering to reach my goals from his perspective?

Lex Fridman 1:16:23
I see. So like different societies throughout history put different value on the different individuals, different psyches, but also even the objective of avoiding suffering. Like some societies, probably, I mean, this is where like religious belief really helps, that, that afterlife, that doesn't matter that you suffer or die, what matters is you suffer honorably. Right? So that you enter the afterlife

Joscha Bach 1:16:51
seems to be superstitious to me, basically, beliefs that assert things for which no evidence exist, what are incompatible with sound epistemology. And I don't think that religion has to be superstitious, otherwise, it should be condemned. In all cases, you're

Lex Fridman 1:17:06
somebody who's saying, we live in a dream world, we have zero evidence for anything. So it's

Joscha Bach 1:17:11
not the case. There are limits to what languages can be constructed mathematics breaks solid evidence for its own structure. And once we have some idea of what languages exist, and how a system can learn what learning itself is in the first place, and so on, we can begin to realize that our intuitions that we are able to learn about the regularities of the world and minimize surprisal and understand the nature of our own agency to some degree of abstraction, that's not an illusion. So approximation,

Lex Fridman 1:17:44
just because we live in a dream world doesn't mean mathematics can't give us a consistent glimpse of physical of objective reality, we can

Joscha Bach 1:17:55
basically distinguish useful encodings from useless encodings. And when we apply or to seeking to the world, we know, we usually cannot find out whether a certain thing is true, what we typically do is we take the state vector of the universe separated into separate objects that interact with each other. So interfaces, and this distinction that we're making is not completely arbitrary. It's done to optimize the compression that we can apply to our models of the universe. So we can predict what's happening with our limited resources. This sense is not arbitrary. But the separation of the world into objects that are somehow discrete, interacting with each other, is not the true reality, right, the boundaries between the objects are projected into the world not arbitrarily projected. But still, it's only an approximation of what's actually the case. And we sometimes notice that we run into contradictions when we try to understand high level things like economic aspects of the world, and so on, or political aspects, or psychological aspects where we make simplifications and the objects that we're using to separate the world are just one of many possible projections of what's going on. And so it's not in this post modernists sense completely arbitrary. And you're free to pick what you want or dismiss what you don't like, because it's all stories. No, that's not true. You have to show for every model of how well it predicts the world. So the confidence that you should have the entities of your models should correspond to the evidence that you have.

Lex Fridman 1:19:24
Can I ask you in a small tangent, to talk about your favorite set of ideas and people which is post modernism? What is what is post modernism? How would you define it? And why to you? Is that not a useful framework of thought?

Joscha Bach 1:19:49
Postmodern modernism is something that I'm really not an expert on. And post modernism is a set of philosophical ideas that it's difficult to lump together. that is characterized by some useful thinkers, some of them post structuralist and so on. And I'm mostly not interested in it, because I think that it's not leading me anywhere that I find particularly useful. It's mostly, I think, born out of the insight that the ontologies that be imposed on the world, and not literally true. And that we can often get to a different interpretation by the world by using a different ontology that is different separation of the world into interacting objects. But the idea that this makes the world and a set of stories that are arbitrary, I think is wrong. And the people that are engaging in this kind of type of philosophy, are working in an area that I largely don't find productive, there is nothing useful coming out of this. So this idea that truth is relative is not something that has, in some sense, informed physics or theory of relativity, and there is no feedback between those, there is no meaningful influence of this type of philosophy on the sciences, or an engineering or in politics. But there is a very strong information on of this on ideology, because it basically has become an ideology that is justifying itself by the notion that truth is a relative concept. And it's not being used in such a way that the the philosophers that or sociologists that take up these ideas, say, oh, I should doubt my own ideas, because maybe my separation of the world into objects is not completely valid, and I should maybe use the different one and be open to a pluralism of ideas. But it's mostly exists to dismiss the ideas of other people.

Lex Fridman 1:21:37
It becomes Yeah, it becomes a political weapon of sorts. And to achieve power,

Joscha Bach 1:21:42
basically this, there's nothing wrong, I think, with developing a philosophy around us, but to develop norms around the idea that truth is something that is completely negotiable, is incompatible with the scientific project. And I think if the, if the academia has no defense against the ideological parts of the postmodernist movement, it's doomed.

Lex Fridman 1:22:09
Where you have to acknowledge the ideological part of any movement, actually, including post modernism.

Joscha Bach 1:22:15
But the question is what the ideology is, and to me, an ideology is basically a viral meme Plex, that is changing your mind in such a way that reality gets warped. It gets warped in such a way that you're being cut off from the rest of human thought space. And you cannot consider things outside of the range of ideas of your own ideology at post as possibly true,

Lex Fridman 1:22:35
right. So I mean, there's certain properties to an ideology that make it harmful. One of them is that like dogmatism of just certainty, dog had certainty in in that you're right, you have the truth, and nobody,

Joscha Bach 1:22:48
but what is creating the certainty? It's very interesting to look at the type of model that is being produced? Is it basically just too strong prior? And you tell people Oh, this idea that you consider to be very true, the evidence for this is actually just much weaker than you thought and book here that some studies? No, this is not how it works, it's usually normative, which means some thoughts are unthinkable, because they would change your identity into something that is no longer acceptable. And this cuts you off from considering an alternative. And many de facto religions use this trick to lock people into a certain mode of thought. This removes agency over your own thoughts, and it's very ugly. To me, it's basically not just a process of domestication, but it's actually an intellectual quest, castration that happens. It's an inability to think creatively and to bring forth new thoughts

Lex Fridman 1:23:43
can ask you about substances, chemical substances that affect the video game? The dream world, so psychedelics, that increasing have been getting a lot of research done on them. So in general, psychedelics, psilocybin, MDMA, but also really interesting one, the big one, which is DMT, what and where are the places that these substances take the mind that is operating in the dream world? Do you have an interesting sense how this throws a wrinkle into the prediction model? Is it just some weird little quirk? Or is there is there some fundamental expansion of the mind going on?

Joscha Bach 1:24:31
So suspect that a way to look at psychedelics is that they induce particular types of lucid dreaming states. So it's a state in which certain connections are being severed in your mind are no longer active in your mind basically gets free to move in a certain direction because some inhibition some particular inhibition doesn't work anymore. And as a result, you might stop having yourself or you might stop perceiving the world is three dimensional and you can explore that state. And I suppose that for every state that can be induced with psychedelics, there are people that are naturally in that state. So sometimes psychedelics that shift you through a range of possible mental states, and they can also shift you out of the range of permissible mental states, that is, where you can make predictive models of reality. And what I observe in people that use psychedelics a lot is that they tend to be overfitting. overfitting means that you are you using what bits for modeling the dynamics of a function than you should. And so you can fit your curve to extremely detailed things in the past, but this model is no longer predictive for the future. What is

Lex Fridman 1:25:46
it? Well, psychedelics had forces that I thought would be the opposite. I thought it's a good mechanism for for generalization for regularization. So it feels like psychedelics expansion of the mind, like taking you outside of like forcing your model to be non predictive is a good thing. Meaning like, it's almost like, Okay, well, I would say psychedelics are akin to traveling to a totally different environment. Like going if you've never been to like India, or something like that, from the United States, very different set of people, different culture, different food, different roads, and values, and all those kinds of things.

Joscha Bach 1:26:31
Psychedelics can, for instance, teleport people into a universe that is hyperbolic, which means that if you imagine a room that you're in, you can turn around and it's 60 degrees, and you didn't go full circle, you need to go seven and 20 degrees to go full circle. Exactly. So the things that people learn in that state cannot be easily transferred in this universe that we are in, it could be that if they're able to abstract and understand what happened to them, that they understand that some part of their spatial cognition has been D synchronized and has found a different synchronization and there's different synchronization happens to be a hyperbolic one, right? So you learn something interesting about your brain, it's difficult to understand what exactly happened. But you get a pretty good idea. Once we understand how the brain is representing geometry

Lex Fridman 1:27:17
you have it doesn't give you a fresh perspective on the physical reality. Who's making that sound? Is inside my head? Or is it external?

Joscha Bach 1:27:31
Oh, there is no sound outside of your mind. But it's making sense. Phenomenon physics?

Lex Fridman 1:27:39
Yeah, in the physical reality, there's their sound waves traveling through air,

Joscha Bach 1:27:45
okay. It's a model of what happened?

Lex Fridman 1:27:49
Or what happened, right? That doesn't, don't psychedelics give you a fresh perspective on this physical reality? Like, not this physical reality, but this this more? What would you call the dream world?

Joscha Bach 1:28:08
That's mapped directly to dreaming at night, I think is yeah, see documentation?

Lex Fridman 1:28:13
What? Exactly. So that's very similar to

Joscha Bach 1:28:17
change parameters about the things that you have learned. And, for instance, when you are young, you have seen things from certain perspectives, but not from others. So your brain is generating new perspectives of objects that you already know, which means they can learn to recognize them later from different perspectives. And I suspect that's the reason many of us remember to have flying dreams as children, because it's just different perspectives of the world that you already know. And that it starts to generate these different perspective changes. And then it fluidly turns this into a flying dream to make sense of what's happening, right. So you fill in the gaps, and suddenly you see yourself flying. And similar things can happen with semantic relationships. So it's not just spatial relationships, but it can also be the relationships between ideas that are being changed. And it seems that the mechanisms that make that happen during dreaming, are interacting with these same receptors that are being stimulated by psychedelics. So I suspect that there is a thing that I haven't read really about, the way in which dreams are induced in the brain is not just that the activity of the brain gets tuned down, because you are somehow your eyes are closed and you no longer get enough data from your eyes. But there is a particular type of neurotransmitter that is saturating your brain during these phases during the RM phases and you produce controlled hallucinations and psychedelics are linking into these mechanisms. I suspect

Lex Fridman 1:29:49
so isn't an another trickier form of data augmentation?

Joscha Bach 1:29:54
Yes. But it's also data augmentation that can happen outside of the specification that Your brain is tuned to so basically people are overclocking their brains. And that that produces states that are subjectively extremely interesting. Yeah, I just went from the outset very suspicious. So,

Lex Fridman 1:30:13
I think I'm over applying the metaphor of a neural network in my own mind, which I just think that doesn't lead to overfitting, right. But, uh, you're just sort of anecdotally saying my experiences with people that have done psychedelics or that kind of quality,

Joscha Bach 1:30:30
I think typically happen. So if you look at people like Timothy Leary, and he has written beautiful manifestos about the effect of LSD on people, he genuinely believed he writes in these manifestos that in the future, science and art will only be done on psychedelics, because it's so much more efficient and so much better. And he gave LSD to children in this community of a few 1000 people that he had near San Francisco. And basically, he was losing touch with reality, he did not understand the effects that the things that he was doing, would have on the reception of psychedelics by society, because he was unable to think critically about what happened. What happened was that he got into an euphoric state, that euphoric state happened because he was overfitting. He was taking this sense of euphoria, and translating it into a model of actual success in the world. Right, he was feeling better when the limitations had disappeared, that you expect parents to be existing, and you didn't get super power, I understand

Lex Fridman 1:31:30
what you mean by overfitting. Now. There's a lot of interpretation to the term overfitting in this case, but I gotcha. So he was getting, he was getting positive rewards from a lot of actions that he shouldn't

Joscha Bach 1:31:44
have not just this. So if you take, for instance, John Daly, who was studying dolphin languages, and aliens, and so on, a lot of people that use psychedelics became very loopy. And the typical thing that you notice when people are on psychedelics is that they are in a state where they feel that everything can be explained. Now. Everything is clear, everything is obvious. Yeah. And sometimes they have indeed discovered a useful connection, but not always, very often these connections are over interpretations.

Lex Fridman 1:32:15
I wonder, you know, there's a question of correlation versus causation. And also wonder if it's the psychedelics or if it's more the social, like being the outsider. And having a strong community of, of outside and being having a leadership position in and outside a cult like community that could have a much stronger effect of overfitting, then do psychedelics themselves, they actually substances, because it's a counterculture thing. So it could be that as opposed to the actual substance, if you're a boring person, who wears a suit and tie and works at a bank, and take psychedelics that could be a very different effect of psychedelics on on your mind. I'm just sort of sort of raising the point that the people you referenced are really weirdos. I'm not sure exactly.

Joscha Bach 1:33:04
No, not necessarily. A lot of the people that tell me that they use psychedelics in a useful way, started out as squares and liberating themselves because they were stuck. They were basically stuck in local optimum of their own sort of model of their relationship to the world. And suddenly their data augmentation, they basically saw as an experience, the space of possibilities, they experienced what it would be like to be another person. Yeah. And they took important lessons from that experience back home.

Lex Fridman 1:33:36
Yeah, I mean, I love the the metaphor of data augmentation, because that's been the primary driver of self supervised learning in the vision computer vision domain, is data augmentation. So it's funny to think of data Augment, like, like chemical induced data augmentation in the human mind.

Joscha Bach 1:33:59
There's also a very interesting effect that I noticed, I know, several people who are spiritual me that LSD has cured their migraines. So severe cluster eight headaches or migraines, that didn't respond to standard medication that disappeared after a single dose. And I don't recommend anybody doing this, especially not in the US where it's illegal. There are no studies on this for that reason. But it seems that anecdotally that it basically can reset the serotonergic system. So it's basically pushing them outside of their normal boundaries. And as a result, it needs to find a new equilibrium. And in some people that equilibrium was better. But it also follows that in other people, it might be worse. So if you have a brain that is already teetering on the boundary to psychosis, it can be permanently pushed over that boundary.

Lex Fridman 1:34:55
Well, that's why you have to do good science, which they're starting to do on all these different substances of how will actually works for the different conditions that MDMA seems to help with PTSD. Same of psilocybin, that, you know, you need to do good science meaning large studies of large and

Joscha Bach 1:35:11
yeah, so based on the existing studies with MDMA, it seems that if you look at Rick Doblin 's work and what He has published about this and talks about MDMA seems to be a psychologically relatively safe drug. But it's physiologically not very safe. That is, there is neurotoxic CCT if you use too large dose, and if you combine this with alcohol, which a lot of kids do in party settings, during raves and so on, it's very HIPAA hepatotoxic. So basically, you can kill your liver. And this means that it's probably something that is best and most productively used in clinical setting by people who really know what they're doing. And I suspect that's also true for the other psychedelics that is, while the other secretaries are probably not as toxic as say, alcohol. The effects on the psyche can be much more profound and lasting.

Lex Fridman 1:36:03
Yeah, well, as far as I know, so saving so mushrooms, magic mushrooms, as far as I know, in terms of the studies they're running, I think have no overt like, they're allowed to do what they're calling heroic doses, so that one does not have a toxicity. So they can do like huge doses in a clinical setting when they're doing studies on psilocybin, which is kind of fun.

Joscha Bach 1:36:25
Yeah, it seems that most of these psychedelics work in extremely small doses, and which means that the effect on the rest of the body is relatively low. And MDMA is probably the exception, maybe ketamine can be dangerous in larger doses, because it can depress freezing, and so on. But the LSD and psilocybin work in very, very small doses, at least the active part of them of psilocybin LSD, it's only the active part. And the about the effect that you can have on your mental wiring can be very dangerous, I think.

Lex Fridman 1:36:57
Let's talk about AI a little bit. What are your thoughts about GPT three and language models trained with self supervised learning? Came out quite a bit ago, but I wanted to get your thoughts on it.

Joscha Bach 1:37:14
In the 90s, I was in New Zealand. And I had an amazing professor in Britain, who will realize that was bored in class and put me in his lab. And he gave me the task to discover grammatical structure and an unknown language. And the unknown language that I picked was English, because it was the easiest one to find corpus for construct one. And he gave me the largest computer at the whole university, it had two gigabytes of RAM, which was amazing. And I wrote everything in C with some in memory compression to do statistics over the language. And first would create a dictionary of all the words which basically tokenize everything and compresses things so that you don't need to store the whole word, but just a code for every word. And then I was taking this all apart and sentences, and I was trying to find all the relationships between all the words in the sentences into statistics over them. And that proved to be impossible, because the complexity is just too large. So if you want to discover the relationship between your article and the noun, and there are three adjectives in between, you cannot do Engram statistics and look at all the possibilities that can exist, at least not with the resources that we had back then. So I realized I need to make some statistics over what I need to make statistics over. So I wrote some thing was pretty much a hack that did this for at least first order relationships. And they came up with some kind of mutual information graph, that was indeed discovering something that looks exactly like the grammatical structure of the sentence, just by trying to encode the sentence in such a way that the words would be written in the optimal order inside of the model. And what I also found is that if we would be able to increase the resolution of that, and not just use this model to reproduce grammatically correct sentences, we would also be able to correct stylistically correct sentences by just having more bits in these relationships. And if we wanted to have meaning, we would have to go much higher order. And I didn't know how to make higher order models back then, without spending way more years in research on how to make the statistics over what we need to make statistics over. And this thing that we cannot look at the relationships between all the bits in your input is being solved in different domains in different ways. So in computer graphics, the computer vision standard methods for many years now is convolutional neural networks. convolutional neural networks are hierarchies of filters that exploit the fact that neighboring pixels in images are usually semantically related in Distance pixels in images are usually not semantically related. So you can just by grouping the pixels that are next to each other hierarchically together. either reconstruct the shape of objects. And this is an important prior that we built into these models so they can converge quickly. But this doesn't work in language for the reason that adjacent words are often but not always related in distant words are sometimes related by the words in between or not. Right, so how can you learn the topology of language? And I think for for this reason that this difficulty existed, the transformer was invented in natural language processing, not envision. And what the transformer is doing. It's a hierarchy of layers are every layer learns what to pay attention to in the given context in the previous layer? So what to make the statistics over?

Lex Fridman 1:40:46
And the context is significantly larger than the adjacent word?

Joscha Bach 1:40:51
Yes. So the context that is that GPT three has been using the transform itself is from 2017. And it's been using that larger for context. Open API has basically scaled up this idea as far as they could at the time. And the context is about 2048. Symbols, tokens in the language, these symbols are not characters, but they take the words and project them into a vector space are words that are statistically co occurring a lot our neighbors already, so it's already a simplification of the problem a little bit. And every word is basically a set of coordinates in a high dimensional space. And then they use some kind of trick to also encode the order of the words in the sentence, or in the not just sentence, but 2048 tokens is about couple pages of text, or two and a half pages of text. And so they managed to do pretty exhaustive statistics over the potential relationships between two pages of texts, which is tremendous, right, I was just using a single sentence back then. And I was only looking for first order relationships. And they were really looking for much, much higher level relationships. And what they discover after they fed this was an enormous amount of training data, pretty much the written internet, or a subset of it that had some quality, but a substantial portion of the common for that they're not only able to reproduce style, but they're also able to reproduce some pretty detailed semantics, like being able to add three digit numbers and multiply two digit numbers or to translate between programming languages and things like that. So the results that GBT three got, I think we're amazing.

Lex Fridman 1:42:34
By the way. I actually didn't check carefully. It's funny, you just mentioned how you coupled semantics to the multiplication isn't able to do some basic math and to two digit numbers, yes. Okay, interesting. I thought, I thought there's a lot of failure cases,

Joscha Bach 1:42:53
it basically fails if you take the larger digit numbers, so four digit numbers, and so on, makes carrying mistakes, and so on. And if you take large, larger numbers, you don't get useful results at all. And this could be an issue of the training set, when download net many examples of successful long form edition and standard human written text. And humans

Lex Fridman 1:43:15
aren't very good at doing three digit numbers either.

Joscha Bach 1:43:19
And they're not, you're not writing a lot about it. And the other thing is that the last function that has been used is only minimizing surprises. So it's predicting what comes next in a typical text. It's not trying to go for causal closure, for instance, we do.

Lex Fridman 1:43:32
Yeah. But the fact that that kind of prediction works to generate text that's semantically rich and consistent, is interesting. Yeah. So yeah. So it's amazing that it's able to generate semantic consistent text.

Joscha Bach 1:43:50
It's not consistent, or the problem is that it loses coherence at some point. But it's also I think, not correct to say that GPUs VI is unable to deal with semantics at all, because you ask it to perform certain transformations in text and it performs these transformation in text and the kind of additions that is able to perform our transformations in text, right and there are proper semantics involved. You can also do more, there was a paper that was generating lots and lots of mathematically correct text and was feeding this into a transformer. And as a result, it was able to learn how to do differentiation integration, in race that according to the authors, Mathematica could not to which people in mathematical responded that they were not using Mathematica in the right way and so on. I have not really follow these, this resolution of this conflict.

Lex Fridman 1:44:46
This this part as a small tangent I really don't like in machine learning papers, which they often do. Anecdotal evidence they'll find like one example it's some kind of specific use of math Marika and demonstrate Look, here's, they'll show successes and failures. But they won't have a very clear representation of how many cases is actually represented as

Joscha Bach 1:45:10
the first paper, this is a pretty good start. And so the take home message, I think, is that the authors could get better results from this and their experiments than they could get from the way in which they were using computer algebra systems. Which means that was not nothing. Yeah. And it's able to perform substantially better than GPT is V can based on a much larger amount of training data, using the same underlying algorithm.

Lex Fridman 1:45:38
Well, let me ask, again, so I'm using your tweets as if this is like Plato is if this is well thought out novels that you've written, you tweeted, GPT, for is listening to us now. This is one way of asking, what are the limitations of GPT? Three, when it scales? So what do you think will be the capabilities of GPT? Four, GPT, five, and so on? What are the limits of this approach?

Joscha Bach 1:46:11
So obviously, when we are writing things, right now, everything that we are writing now is going to be training data for the next generation of machine learning models. So yes, of course, TBT for is listening to us. And I think the tweet is already a little bit older in the air, we now have Tao and we have a number of other systems that basically are placeholders for GPT. Four, to know what opening as plans are in the CRM

Lex Fridman 1:46:35
error that we in several ways. So one is obviously everything you put on the internet is used as training data. But in a second way I read it is in a, we talked about agency, I read it as almost like GPT for is intelligent enough to be choosing to listen. So not only like did a programmer tell it to collect this data, and use it for training, I almost saw the humorous angle, which is like it has achieved AGI kind of thing.

Joscha Bach 1:47:09
Well, the thing is cofeb Already believing in GPT, five GPT. Four

Lex Fridman 1:47:16
is listening and DPD five actually constructing the entirety of this reality will request

Joscha Bach 1:47:20
be in some sense, the what everybody is trying to do right now in AI is to extend the transformer to be able to deal with video. And there are very promising extensions, right there is a book by Google that is called perceiver. And that is overcoming some of the limitations of the transformer by letting it learn the topology of the different modalities separately. And by training it to find better input features. So the specific feature abstractions that are being used by this successor to GPT. Three are chosen in such a way that it's able to deal with video input. And there is more to be done. So one of the limitations of GPT. Three is that it's amnesiac, so it forgets everything beyond the two pages that it currently reads also during generation not just during learning.

Lex Fridman 1:48:14
Do you think that's fixable? Within the space of deep learning? Can you just make a bigger, bigger, bigger input?

Joscha Bach 1:48:21
No, I don't think that our own working memory is infinitely large, it's probably also just a few 1000 bits. But what you can do is you can structure this working memory. So instead of just force feeding the thing, a certain thing that it can has to focus on, and it's not allowed to focus on anything else, because it's network, you allow it to construct his own working memory. As we do right when we are reading a book. It's not that we are focusing our attention in such a way that you can only remember the current page, we will also try to remember other pages and try to undo what you learn from them or modify what we learned from them, we might get up and take another book from the shelf, we might go out and ask somebody, if we can edit our working memory in any way that is useful to put a context together allows us to draw the right inferences and to learn the right things. So, this ability to perform experiments on the world based on an attempt to become fully coherent, and to achieve causal closure to achieve a certain aesthetic of your modeling, that is something that eventually needs to be done. And at the moment we are skirting this in some sense by building systems that are larger and faster. So they can use dramatically larger resources and human beings can do much more training data to get to models that in some sense are already very super human and in other ways are laughingly incoherent.

Lex Fridman 1:49:45
So do you think so, making the system's like what would you say multi resolution also like some some of the language models are focused on two pages Some are focused on two books, some are focused on two years of reading, some are focused on a lifetime, like, it's like stacks of GPT, threes all the way down,

Joscha Bach 1:50:11
you want to have gaps in between them. So it's not necessarily two years, there's no gaps, it's thinks out of two years, or out of 20 years, or 2000 years or 2 billion years, that you are just selecting those bits that are predicted to be the most useful ones, to understand what you're currently doing. And this prediction itself requires a very complicated model. And it's the actual model that you need to be making. It's not just that you are trying to understand the relationships between things, but what you need to make relationships or discover relationships over.

Lex Fridman 1:50:42
I wonder what that thing looks like, what the architecture for that for the thing that's able to have that kind of model

Joscha Bach 1:50:49
that I think needs more degrees of freedom, and the current models have. So it starts out with defect that you possibly don't just want to have a feed forward model, but you want it to be fully recurrent. And to make it fully recurrent, you probably need to loop it back into itself and allow it to skip connections once you do this. Right. When you're predicting the next frame and your internal next frame, in every moment. And you are able to skip connection, it means that signals can travel from the output of the network into the middle of the network faster than the inputs, do

Lex Fridman 1:51:25
you think it could still be differentiable? Do you think it's still convenient on that word,

Joscha Bach 1:51:30
sometimes it can, and sometimes it cannot. So it can still be a neural network, but not a fully differentiable one. And when you want to deal with non differentiable ones, you need to have an attention system that is discrete and low dimensional and can perform grammatical operations, you need to be able to perform program synthesis, you need to be able to backtrack in this operations that you perform on this thing. This thing needs a model of what it's currently doing. And I think this is exactly the purpose of our own consciousness.

Lex Fridman 1:52:01
Program things that tree colonial networks. So let me ask you, it's not quite program synthesis, but the application of these language models to generation two programs, and this is the generation of programs. So if you look at GitHub open pilot, which is based on open AI as Codex, I don't know if you've gotten a chance to look at it, but it's the system that's able to generate code, once you prompt it with what is it like the header of a function with some comments, it seems to do an incredibly good job. Or not a perfect job, which is very important, but an incredibly good job of generating functions. What do you make of that? Are you is this exciting? Or is this just a party trick? A demo? Or is this revolutionary?

Joscha Bach 1:52:51
I haven't worked with yet. So it's difficult for me to judge it. But I would not be surprised if it turns out to be revolutionary. That's because the majority of programming tasks that are being done in the industry right now are not creative. People are writing code that other people have written, or they're putting things together from code fragments that others have had. And a lot of the work that programmers to practice is to figure out how to overcome the gaps in their current knowledge, the things that people have already done from Stack Overflow. And so of course, we can automate that. Yeah.

Lex Fridman 1:53:27
To make it much faster to copy and paste from Stack Overflow.

Joscha Bach 1:53:30
Yes, but it's not just copying and pasting, it's also basically learning which parts you need to modify, to make them fit together.

Lex Fridman 1:53:38
Yeah. Like literally sometimes as simple as just changing the variable names. So it fits into the rest of your code, yes.

Joscha Bach 1:53:45
But this requires that you understand the semantics of what you're doing to some degree. Yeah.

Lex Fridman 1:53:49
And you can automate some of those things. The thing that makes people nervous, of course, is that a little bit wrong in a program can have a dramatic effect on the actual final operation of that program. So it's one little error, which in the space of language doesn't really matter. But in the space of programs can matter a lot.

Joscha Bach 1:54:11
Yes, but this is already what is happening when humans program code. Yeah, this is the so we have a technology to deal with this.

Lex Fridman 1:54:20
Somehow it becomes scarier. When you know that a program generated code that's running a nuclear power plant. It becomes scarier, you know, humans have arrows to exactly but it's scarier when a program is doing it. Because why? Why? I mean, there's a there's a fear that a program, like a program may not be as good as humans to know when stuff is important to not mess up. Like there's a misalignment of priorities of value. Is this potential that maybe that's the source of the worry? I mean, okay, if I give you code generated by GitHub, open pilot and code generated by a human and say, hear us use one of these, which, which How do you select today? And in the next 10 years, which code do you use? Would you still be comfortable with the human?

Joscha Bach 1:55:25
At the moment, when you go to Stanford to get an MRI, they will write a bill to the insurance over $20,000. And of this, maybe half of that gets paid by the insurance and the quarter gets paid by you. Yeah. And the MRI cost them $600 To make maybe, probably less? And what are the values of the person that writes the software and deploys this process? It's very difficult for me to say whether I trust people, I think that what happens there is a mixture of proper Anglo Saxon Protestant values where somebody is trying to serve an abstract credo and organized crime.

Lex Fridman 1:56:06
Well, that's a very harsh your your I think that's a harsh view of humanity. There's a lot of bad people, whether they're incompetent or just malevolent in this world, yes. But it feels like the more malevolent you. So the more damage you do to the world. The more resistance you have in your own human like it but

Joscha Bach 1:56:34
hard to explain with malevolence or stupidity, what can be explained by just people acting on their incentives? Right, so what happens in Stanford is not that somebody's evil, it's just that they do what they're being paid for.

Lex Fridman 1:56:48
No, not evil. That's I tend to say, No, I see that as malevolence I see. As a even like, being a good German, as I told you, offline, is some it's not. It's not absolute malevolence, but it's a small amount. It's cowardice. I mean, when you see there's something wrong with the world. It's either incompetence, or you're not able to see it. Or it's cowardice the United able to stand up not in not necessarily in a big way, but in a small way. So I, I do think that is a bit of malevolence, I'm not sure the example you're describing is,

Joscha Bach 1:57:28
the question is, what is it that you are aiming for? And if you don't believe in the future, if you, for instance, think that the dollar is going to crash by what you try to save dollars, if you don't think that humanity will be around and 100 years from now, because global warming will wipe out civilization? By what do you need to act as if it were? Right, so the question is, is there an overarching aesthetics? That is projecting you and the world into the future, which I think is the basic idea of religion, that you will understand the interactions that we have with each other is some kind of civilization level agent that is projecting itself into the future? If you if you don't have that shared purpose? Right, what is there to be ethical for? So I think when we talk about ethics and AI, we need to go beyond the insane bias discussions and so on, where people are just measuring the distance between a statistic to the preferred world model, but

Lex Fridman 1:58:27
the optimism Whoa, I was a little confused by the previous thing, just to clarify. It's there is a kind of underlying morality to having an optimism that human civilization will persist for longer than 100 years like that. Like, I think a lot of people believe that it's a good thing for us to keep living. Yeah, of course, and thriving in

Joscha Bach 1:58:54
reality itself is not an end to itself. It's instrumental to people living in 100 years from now, right? Or 500 years from now, right? So it's only justifiable if you actually think that it will lead to people, or increase the probability of people being right. And that timeframe. And a lot of people don't actually believe that, at least not actively.

Lex Fridman 1:59:16
But I believe what exactly so most people

Joscha Bach 1:59:19
don't believe that they can afford to act on such a model. Basically, what happens in the US is I think that the healthcare system is for a lot of people no longer sustainable, which means that if they need the help of the healthcare system, they're often not able to afford it. And when they cannot help it, they are often going bankrupt. It's the I think the leading course cause of personal bankruptcy in the US is the health care system. Yeah, and that would not be necessary. It's not because people are consuming more and more medical services and receiving a much, much longer life as a result. That's not actually the story that is happening because you can compare it to other countries and life expectancy in the US is currently not increasing and it's not as high as in all the other industrialized countries, so some industrialized countries are doing better with a much cheaper health care system. And what you can see is, for instance, administrative bloat the healthcare system has maybe to some degree deliberately set up is job placement program to allow people to continue living in middle class existence despite not having a useful use case in productivity. So they are being paid to push paper around. And the number of administrators in the healthcare system has been increasing much faster than the number of practitioners. And this is something that you have to pay for, right. And also, the revenues that are being generated in the healthcare system are relatively large, and somebody has to pay for them. And the result why they are so large is because market mechanisms are not working at the FDA is largely not protecting people from malpractice of health care providers, the FDA is protecting healthcare providers from competition, right. Okay. So this is a thing that is has to do with values. And this is not because people are malicious on all levels. It's because they are not incentivized to act on a greater whole on this idea that you treat somebody who comes to you as a patient, like you would treat a family member here. But

Lex Fridman 2:01:16
yeah, but we're trying I mean, you're highlighting a lot of the flaws of the different institutions, the systems were operating under. But I think there's a continued throughout history, mechanism design, of trying to design incentives in such a way that these systems behave better and better and better. I mean, it's a very difficult thing to operate a society of hundreds of millions of people effectively with, so do we

Joscha Bach 2:01:40
live in a society that is error correcting is observed that our models of what we are doing are predictive of the future and when they are not, we improve them, our laws, adjudicated with clauses that you put into every law, what is meant to be achieved by that law, and the law will be automatically repealed? If it's not achieving that, right? If you are optimizing your own laws, if you're writing your own source code, you probably make an estimate of what is the thing that's currently wrong in my life? What is it that I should change about my own policies? What is the expected outcome? If that outcome does manifest, I will change the policy back right, or I will change it to something different. Are we doing this on a societal level?

Lex Fridman 2:02:22
I think so. I think I think it's easy to sort of highlight the, I think we're doing it in the way that like, I operate my current life, I didn't sleep much last night, you would say that Lex, the way you need to operate your life is you need to always get sleep, the fact you didn't sleep last night is is totally the wrong way to operate in your life. Like you should have gotten all your shit done in time and gotten to sleep because sleep is very important for health. And you're highlighting, look, this person is not sleeping look, the the medical, the healthcare system is operating poor. But the point is that we just, it seems like this is the way especially in the capitalist society we operate. We keep running into trouble in last minute, we tried to get our way out through innovation, and it seems to work. You have a lot of people that ultimately are trying to build a better world and and get urgency about them. When it's the problem becomes more and more imminent. And that's the way this operates. But if you look at the the history, the long arc of history, it seems like that operating on deadlines, produces progress and builds better and better systems,

Joscha Bach 2:03:36
you probably agree with me that the US should have engaged in mass production in January 2020. And that we should have shut down the airports early on, and that we should have made it mandatory that the people that work in nursing homes have on campus, rather than living at home, and then coming in and infecting people in nursing homes that had no immune response to COVID. And that is something that was I think visible back then the correct decisions haven't been made. We would have the same situation again, how do we know that these wrong decisions are not being made? Again, if the people that made the decisions to not protect the nursing homes been punished, have the people that made the wrong decisions with respect to testing that prevented the development of testing by startup companies and the importing of tests for countries that already had them. Have these people being held responsible? First of all, so

Lex Fridman 2:04:34
what do you want to like, put before the firing squad? I think they are no,

Joscha Bach 2:04:40
just make sure that this doesn't happen again. No, but

Lex Fridman 2:04:42
it's not that. Yes, they're being held responsible by many voices by people being frustrated. There's new leaders being born now that we're going to see rise to the top and 10 years. This moves slower than there's obviously a lot of older incumbent In some bureaucracy, and these systems move slowly, they move, you know, like science one depth at a time. So like, Yes, I think the the pain that has been felt in the previous year, is reverberating throughout the world.

Joscha Bach 2:05:15
Maybe I'm getting old, I suspect that every generation in the US after the war has lost the plot even more. I don't see this development, the War World War Two. Yeah. So basically, there was a time when people were modernist. And then this modern is time, the US felt actively threatened by the things that happened in the world, the US was worried about possibility of failure. And this imminence of possible failure led to decisions where there was a time when the government would listen to physicists about how to do things. And the physicists were actually concerned about what the government should be doing. So they will be writing letters to the government. And so for instance, the decision for the Manhattan Project was something that was driven in a conversation between physicists and the government. I don't think such a discussion would take place today.

Lex Fridman 2:06:06
I disagree. I think this the virus was much deadlier, we would see a very different response. I think the virus was not sufficiently deadly. And instead because it wasn't very deadly. What happened is, the current system started to politicize it. The mask, this is what I realized with masks early on, they were not very quickly became not as a solution. But they became a thing that politicians used to divide the country so that the same things happened with vaccine, same thing. So like, nobody's really the people weren't talking about solutions to this problem, because I don't think the problem was bad enough. When you talk about the war, the war, I think, what I think our lives are too comfortable. I think in in the developed world, things are too good. And we're not faced severe dangerous. One, the danger, the severe dangers existential threats are faced, that's when we step up, and a small scale and a large scale. Now, I don't I that's sort of my argument here. But I did think the virus is I was hoping that it was actually sufficiently dangerous for us to step up, because especially in the early days, it was unclear, it still is unclear because of mutations. How bad it might be. Right? And so I thought we would step up. And even so the masks point is, is a is a tricky one. Because to me, the manufacturer of masks isn't isn't even the problem. I'm still to this day, and I was involved with a bunch of this work, have not seen good signs done on whether masks work or not. Like there still has not been a large scale study. To me that should be there should be large scale studies and every possible solution, like aggressive in the same way that the vaccine development was aggressive. There should be masks, which tests what kind of tests work really well, we're kind of like even the question of how the virus spreads. There should be aggressive studies on that, to understand I'm still, as far as far as I know, there's still a lot of uncertainty about that. Nobody wants to see this as an engineering problem needs to be solved. It's a that I was surprised about, but I will

Joscha Bach 2:08:22
find that our views are largely convergent, but not completely. So I agree with the thing that because our society, in some sense, perceives itself as too big to fail, right. And the virus did not alert people to the fact that we are facing possible failure. That basically put us into the post modernists mode. And I don't mean in philosophical sense, but in a societal sense, the difference between the postmodern society and the modern society is that the modernist society has to deal with the ground tools. And the post modernists society has to deal with appearances, politics, politics becomes a performance. And the performance is done for an audience and the organized audience is the media. And the media evaluates itself via other media, right? So you have an audience of critics that evaluate themselves. And I don't think it's so much the failure of the politicians, because to get in power and to stay in poor, you need to be able to deal with the public opinion.

Lex Fridman 2:09:17
Well, I think it goes in cycles, because the what's going to happen is all of the small business owners, all the people who truly are suffering and will suffer more, because the effects of the closure of the economy and the lack of solutions to the virus, they're going to apprise. And hopefully, I mean, this is this is where charismatic leaders can get the world in trouble. But hopefully, we'll elect great leaders that will break through this post modernists idea of of the media and the perception and the drama on Twitter and all that kind of stuff.

Joscha Bach 2:09:57
But you know, this can go either way. Yeah. When the Weimar Republic was unable to deal with the economic crisis that Germany was facing, there was an option to go back. And there were people which thought, let's get back to a constitutional monarchy. And let's get this this to work, because democracy doesn't work. And eventually, there was no way back when people decided there was no way back, they needed to go forward. And the only options for going forward was to become Stalinist communist, basically, in option to completely expropriate the factories and so on and nationalize them and to reorganize Germany in communist terms and align itself with Stalin, and fascism. And both options were obviously very bad. And the one that the Germans picked lead to catastrophe that was that devastated Europe. And I'm not sure if the US has an immune response against that. I think that the far right is currently very weak in the US, but this can easily change.

Lex Fridman 2:11:05
Do you think, from a historical perspective, Hitler could have been stopped from within Germany, or from outside, or this? Well, depends on who you want to focus whether you want to focus on Stalin or Hitler, but he feels like Hitler was the one as a political movement that could have been stopped.

Joscha Bach 2:11:25
I think that the point was that a lot of people wanted Hitler. So he got support from a lot of quarters was a number of industrialists who supported him, because they thought that democracy is obviously not working in unstable and you need a strong man. And he was willing to play that part. There were also people in the US who thought that Hitler would stop stalling and would act as a bulwark against Bolshevism, which he probably would have done right, but at which cost. And then many of the things that he was going to do, like the Holocaust, was something where people thought this is rhetoric, he's not actually going to do this, right? Especially many of the Jews themselves, which were humanists. And for them, this was outside of the scope that was thinkable, right?

Lex Fridman 2:12:14
I wonder if Hitler is uniquely, I want to carefully use this term, but uniquely evil. So if Hitler was never born, if somebody else would come in this place, so like, just thinking about the progress of history, how important are those singular figures that that lead to mass destruction and cruelty? Because my sense is, Hitler was unique. The, it wasn't just about the environment, and the context that gave him like, like another person would not come in his place to do as destructive of the things that he did. There was a combination of charisma, of madness, of psychopathy, of just ego, all those things, which are very unlikely to come together in one person in the right time.

Joscha Bach 2:13:12
It's also depends on the context of the country that you're operating in. If you tell the Germans that they have historical destiny, in this romantic country, the effect is probably different than it is another country's shot. The stallion has killed a few more people than Hitler did. And if you look at the probability that you survived understanding, right, Hitler killed people if they if you thought they were not worth living, or if they were harmful to his racist project, right if basically felt that the Jews would be too cosmopolitan, and would not be willing to participate in a racist redefinition of society and the value of society and an ethno state in this way, that as he wanted to have it, so they he saw them as harmful dangerous, especially since they played such an important role in the economy and culture of Germany. And it's yet basically at some radical, but rational reason to murder them and starting just killed everyone. scaliness purchase for such a random thing where you said that there's a certain possibility that this particular part of the population as a number of German collaborators or something, and we just killed them, all right? Well, if you look at what Mauer did, the number of people that were killed absolute in absolute numbers were much higher under Mao that there were understanding. So it's super hard to say. The other thing is that you look at Genghis Khan and so on how many people he killed? That when you see there are a number of things that happen in human history. It actually put a substantial dent in the existing population or Napoleon. And it's, it's very difficult to eventually measure it, because what's happening is basically evolution on a human scale, or one monkey figures out a way to become viral, and is using this viral technology to change the patterns of society at the very, very large scale. And what we find so abhorrent about these changes is the complexity that has been destroyed by this, that it's basically like a big fire that burns out a lot of the existing culture and structure that existed before.

Lex Fridman 2:15:39
Yeah, and it all just starts with one monkey, one one charismatic ape, and there's a bunch of them throughout history.

Joscha Bach 2:15:46
Yeah, but it's in a given environment, it's basically similar to wildfires in California, right, the temperature is rising, there is less rain falling, and then suddenly, a single spark can have an effect that and other times would be contained. Okay.

Lex Fridman 2:16:02
Speaking of which, I love home went to Hitler and Stalin from 2030 minutes ago, GPT, three generating, doing programs that this is, the argument was about morality, of AI versus human. So and specifically in the context of writing programs, specifically in the context of programs that can be destructive, so running nuclear power plants, or autonomous weapons system, for example. And I think your inclination was to say that it's not so obvious that AI will be less moral than humans, are less effective at making a world that would make humans happy.

Joscha Bach 2:16:48
So I'm not talking about self directed systems that are making their own goals at a global scale. If you just talk about the deployment of technological systems that are able to see order and patterns and use disease control models to act on the goals that we give them, then, if we have the correct incentives to set the correct incentives for these systems, I'm quite optimistic.

Lex Fridman 2:17:15
So but so humans versus AI, let me give you an example. autonomous weapon system. Let's say there's a city somewhere in the Middle East that has a number of terrorists. And the question is what's currently done with, with drone technologies, you have information about the location of a particular terrorist, and you have a targeted attack, you have a bombing of that particular building. And that's all directed by humans at the high level strategy. And also the deployment of individual bombs and missiles like that. The actual everything's done by human except the, the final targeting, and the the, like, the countries are like was spot similar thing that control the flight. Okay? What if you give AI control and saying, write a program that says, here's the best information I have available, but the location with these five terrorists? Here's the city make sure it's all the bombing you do is constrained to the city, make sure it's precision based, but you take care of it. So you do one level of abstraction out and saying, take care of the terrorists in the city? Which are you more comfortable with the humans? Are the JavaScript GPG, three generated code that's doing the deployment? I mean, that's this is the kind of question I'm asking, is the kind of bugs that we see in human nature, are they better or worse than the kind of bugs we see in AI?

Joscha Bach 2:18:51
That different box there is an issue that if people are creating an in imperfect automation of a process that normally requires a moral judgment, and this moral judgment is the reason why it cannot be automated, often it's not, because the computation is too expensive. But because the model that you give the AI is not an adequate model of the dynamics of the world, because the AI does not understand the context that is operating in the right way. And this is something that already happens. Because XR, right? You don't need to have an AI system to do this. If you have an automated process in place, where humans decide using automated criteria, whom to kill when and whom to target when which already happens. Right and you have no way to get off the kill list. Once that happens, once you have been targeted according to some automatic criterion by people by individual cracy. That is the issue. The issue is not the AI. It's the automation.

Lex Fridman 2:19:52
So there's something about, right, it's automation, but there's something about the there's a certain level of of abstraction where you give control to AI to do the automation, there's a scale that can be achieved that it feels like the scale of bog and scale mistake and scale of destruction that can be achieved, of the kind that humans cannot achieve. So AI is much more able to destroy an entire country accidentally, versus humans, it feels like the more civilians die as a React or suffer as the consequences of your decisions, the more weight there is on the human mind to make that decision. And so like, if becomes more and more unlikely to make that decision for humans, for AI, it feels like it's harder to encode that kind of weight.

Joscha Bach 2:20:47
In a way, the AI that we're currently building is automating statistics, right? intelligence is the ability to make models so you can act on them. And there is a tool to make better models. So in principle, if you're using AI wisely, you're able to prevent more harm. And I think that the main issue is, is not on the side of the AI. It's on the side of the human command hierarchy that is using technology responsibly. So the

Lex Fridman 2:21:12
question is, how hard is it to encode to, to properly encode the right incentives into the AI.

Joscha Bach 2:21:18
So for instance, there's this idea of what happens if we let our airplanes being flown with AI systems, and the neural network is a black box, and so on. And it turns out, our neural networks are actually not black boxes anymore. They are function approximator is using linear algebra. And there are performing things that we can understand. But we can also instead of letting the neural network fly the airplane use the neural network to generate a provably correct program, there's a degree of accuracy of the proof that a human could not achieve. So we can use our AI by combining different technologies to build systems that are much more reliable than the systems that a human being would create. And so in this sense, I would say that if you use an early stage of technology, to safe labor, and don't employ, employ competent people, but just to hack something together, because you can, that is very dangerous. And if people are acting under these incentives that they get away with delivering shoddy work more cheaply using AI, there's less human oversight than before, that's very dangerous.

Lex Fridman 2:22:25
The thing is, though, AI is still going to be unreliable, perhaps less than than humans, but it'll be unreliable in novel ways. And,

Joscha Bach 2:22:35
yeah, but this is an empirical question. And it's something that we can figure out and work with. So the issue is, do we trust the systems, the social systems that we have in place and the social systems that we can build and maintain that they're able to use AI responsibly? If they can, then AI is good news. If they cannot, then it's going to make the existing problems worse? And

Lex Fridman 2:22:57
also, who creates the AI? Who controls it? Who makes money from it? Because it's ultimately humans? And then you start talking about how much you trust the humans?

Joscha Bach 2:23:06
So the question is, what does who mean? I don't think that we have identity per se, I think that these the story of a human being is somewhat random. What happens is more or less that everybody is acting on their local incentives, what they perceive to be their incentives. And the question is, what are the incentives that the one that is pressing the button is operating under?

Lex Fridman 2:23:28
Yeah. It's nice for those incentives to be transparent. So for example, I'll give I'll give you example, there seems to be a significant distrust of tech, like entrepreneurs in the tech space, or, or people that run, for example, social media companies like Mark, Mark Zuckerberg, there is not a complete transparency of incentives under which that particular human being operates. That, you know, we can listen to the words he says, or what the marketing team says for a company, but we don't know. And that's that's becomes a problem when that the algorithms and systems created by him and other people in that company start having more and more impact on society. And that it starts, you know, if if the incentives were somehow the definition and the explainability of the incentives was decentralized such that no, nobody can manipulate it. No propaganda, type manipulation of like, how these systems actually operate could be done, then yes, if not, I think I think AI could achieve a much fairer, much more effective, sort of, like solutions to difficult ethical problems. But when there's like humans in the loop, manipulating this the dissemination of that communication of how the system actually works. That feels like you can run into a lot of trouble. And that's why there's currently a lot of distrust for for people at the heads of companies that have increasingly powerful AI systems.

Joscha Bach 2:25:13
I suspect what happened traditionally in the US was that since our decision making is much more central, a decentralized than an authoritarian state, right, people are making decisions autonomously at many, many levels in the society. What happened that was, we created coherence and cohesion and society by controlling what people thought and what information they had, right? The media synchronized public opinion, and social media have disrupted this. It's not I think, so much Russian influence or something, it's everybody's influence, it's that random person can come up with a conspiracy theory, and disrupt what people think. And if that conspiracy theory is more compelling, or more attractive than the standardized public conspiracy theory that we give people as a default, then it might get more traction, right? You certainly have the situation at a single individual somewhere on a farm in Texas, has more listeners than CNN.

Lex Fridman 2:26:11
Which particular farm are you referring to in Texas?

Lex Fridman 2:26:19
Yes, I had dinner with him a couple of times. Okay.

Joscha Bach 2:26:21
All right. This is an interesting situation, because you cannot get to be an anchor and CNN if you don't go through a complete, complicated gatekeeping process. And suddenly, you have random people without that gatekeeping process, just optimizing for attention, not necessarily with a lot of responsibility for the long term effects of projecting these theories into the public. And now, there is a push of making social media more like traditional media, which means that the opinion that is being projected in social media is more limited to an acceptable range, with the goal of getting society into safe waters and increase the stability and cohesion of society again, which I think is a laudable goal. But of course, it also is an opportunity to seize the means of indoctrination. And the incentives that people are under when they do this, in such a way that the AI ethics that we would need becomes very often something like aI politics, which is basically partisan and ideological. And this means that whatever one site says another site is going to be disagreeing with, right in the same way as when you turn masks or the vaccine into a political issue. If you say that it is politically virtuous to get vaccinated, it will mean that the people that don't like you will not want to get vaccinated, right. And as soon as you have this partisan discourse, it's going to be very hard to make the right decisions. Because the incentives get to be the wrong ones. Ai ethics needs to be super boring, it needs to be done by people who do statistics all the time, and have extremely boring, long winded discussions that most people cannot follow because they are too complicated, but that are dead serious. These people need to be able to be better at statistics than the leading machine learning researchers. And at the moment, the AI ethics debate debate is the one but you don't have any barrier to entry. Right? Everybody who has a strong opinion and is able to signal that opinion in the race is a very frustrating thing, because the field is so crucially important to us. So it's crucially

Lex Fridman 2:28:26
important, but the only qualification currently needed is to be outraged by the injustice in the world.

Joscha Bach 2:28:34
It's more complicated, right? Everybody seems to be outraged. janitors are not always the right one. So basically, I suspect that a lot of people that enter this debate, don't have a vision for what society should be looking like in a way that is non violent, that we preserve liberal democracy, where we make sure that we all get along. And we are around in a few 100 years from now, preferably with a comfortable technological civilization around us.

Lex Fridman 2:29:04
I generally have a very foggy view of that world, but I tend to try to fall and I think society should in some degree, follow the gradient of love increasing the amount of love in the world. And whenever I see different policies or algorithms or ideas that are not doing so, obviously, that that's the ones that kind of resist.

Joscha Bach 2:29:27
So the thing that terrifies me about this notion is I think that German fascism was driven by love. It was just a very selective love. It was a love that way

Lex Fridman 2:29:39
now you're just manipulating. I mean, that's. It's you have to be very careful. You're talking to the wrong person, in this way about love.

Joscha Bach 2:29:50
So let's talk about what love is. And I think that love is the discovery of shared purpose. It's the recognition of the sacred and the other and this enables non transactional interactions, but

Lex Fridman 2:30:03
the the size of the other that you include needs to be maximized. So it's, it's basically appreciation, like deep appreciation of the world around you fully like, including the people that are very different than us people that disagree with you completely, including people, including living creatures outside of just people, including ideas, and it's like appreciation of the full mess of it. And also, it has to do with like empathy, which is coupled with a lack of confidence and certainty about of your own rightness. It's like an open a radical open mindedness to the way forward,

Joscha Bach 2:30:51
I agree with every part of what you said. And now, if you scale it up, what you recognize is that life is, in some sense, the service to next level agency, to the highest level agency that you can recognize, it could be, for instance, life on earth or beyond that, read the, you could say, intelligent complexity in the universe, that you try to maximize in a certain way. But when you think it's true, it basically means a certain aesthetic. And there is not one possible aesthetic, there are many positive statics. And once you project an aesthetic into the future, you can see that there are some which defect from it, which are in conflict with it that are corrupt, that are evil. Right, you will me would probably agree that Hitler was evil, because the aesthetic of the world that he wanted, is in conflict with the aesthetic of the world that you may have in mind. Yeah. And so the thing that he destroyed, we want to keep them in the world.

Lex Fridman 2:31:50
There's a kind of, there's kind of ways to deal. I mean, Hitler's an easier case. But perhaps he wasn't so easy in the 30s. Right to understand who's Hitler who's not

Joscha Bach 2:32:03
was no consensus that the aesthetics that he had in mind were unacceptable.

Lex Fridman 2:32:07
Yeah. I mean, it's difficult. Love is complicated. Because you can't just be so open minded, that you let evil walk into the door. But you can't be so self self assured that you, you can always identify evil perfectly, because that's what leads to Nazi Germany. Having a certainty of what isn't wasn't evil, like always drawing lines of good versus evil. There seems to be a there has to be a dance between, like, hard stances, extending up against what is wrong, at the same time, empathy and open mindedness of toys, not knowing what is right and wrong. And like a dance between us.

Joscha Bach 2:33:01
I found that when I watched Miyazaki movies that there is nobody who captures my spirituality as well as he does. It's very interesting and distinguishes, right there is something going on in his movies that is very interesting. So for instance, Monica is discussing not only an answer to Disney's simplistic notion of Mowgli, the jungle boy was raised by wolves. And as soon as he sees people realizes that he's one of them, and the way in which the moral life in nature is simplified and romanticized, and turned into kitsch, right, it's disgusting in the Disney movie. And the answers to this, you see, he's replaced by Monaka, this wolf girl who was raised by wolves, and was fierce and dangerous, and cannot be socialized, because he cannot be tamed. It cannot be part of human society, and you see human society, it's something that is very, very complicated. You see people extracting resources and destroying nature. But the purpose is not to be evil. But to be able to have a life that is free from for instance, oppression, and violence, and to curb death and disease. And you basically see this conflict which cannot be resolved in a certain way, you see this moment when nature is turned into a garden, and it loses most of what it actually is, when humans no longer submitting to life and death and nature. To these questions, there is no easy answer. So it just turns it into something that is being observed as a journey that happens that happens with a certain degree of innovative durability. And the nice thing about all these movies is there's a certain main character, and it's the same in all movies. It's this little girl that is basically Heidi and I suspect that to happen because he when he did fieldwork for working on the Heidi movies back then the Heidi animations before he did his own movies, he traveled to Switzerland and south western South Eastern Europe. And the Adriatic and so on, and get an idea about a certain aesthetic and a certain way of life that informed is this future thinking. And Heidi has a very interesting relationship to herself and to the world. There is nothing that she takes for herself. She is in a fearless because he is committed to service to a greater whole. Basically, she is completely committed to serving God, and is not an institutionalized God, it has nothing to do with the Roman Catholic Church or something like this. But in some sense, Heidi is the embodiment of the spirit of European Protestantism. It's this idea of a being that is completely perfect and pure. And it's not a feminist vision, because she is not a girl boss or something like this. She is the justification for the men in the audience, to protect her to build a civilization around her that makes her possible. Right. So she is not just the sacrifice of Jesus was innocent, and therefore near to the cross. She is not being sacrificed, he is being protected by everybody around her who recognizes that she is sacred, and there are enough around her to, to see that. Right. So that's, that's a very interesting perspective, there's a certain notion of innocence. And this notion of innocence is not universal. It's not in all cultures, right? Hitler wasn't innocent. His idea of it of Germany was not that there is an innocence that is being protected, there was a predator that it was going to triumph. Yeah. And it's also something that is not at the core of every religion, there are many religions which don't care about innocence, they might care about increasing the status of something. Right. And that's a very interesting notion that is quite unique and not claiming it's the optimal one. It's just a particular kind of aesthetic, which I think makes Miyazaki into the most relevant Protestant philosopher today.

Lex Fridman 2:36:55
And you're saying in terms of, of all the, of all the ways that society can operate, perhaps the preservation of innocence might be one might be one of

Joscha Bach 2:37:06
the best? It No, it's just my aesthetic. So your aesthetic, it's a particular way in which I feel that I relate to the world that is natural to my own specialization, and maybe it's not an accident, that I have cultural roots, which Europe, in a particular world, and so maybe it's a natural convergence point. And it's not something that you will find in all other times in history.

Lex Fridman 2:37:30
So like the basketball soldier units and, and our individual role as ants in this very large society. So he says that some version of the line between good and evil runs through the heart of every man, do you think all of us are capable of good and evil? Like? What's our role in this play? In this game, while playing, is all of us capable to play any role? Like, is there an ultimate responsibility to? You mentioned maintaining innocence or whatever the whatever the highest ideal for society you want? Are all of us capable of living up to that, and that's our responsibility? Or our is there significant limitations to what we're able to do in terms of good and evil.

Joscha Bach 2:38:21
So there is a certain way, if you're not careful, if you are committed to some kind of civilization, or agency, or next level agent, that you are serving some kind of transcendent principle. In the eyes of that transcendent or principle, you're able to discern good from evil, otherwise, you cannot otherwise you have just individual aesthetics. The cat that is torturing a mouse is not evil, because the cat does not envision or no part of the world of the cat is envisioning a world where there is no violence and nobody is suffering. Right? If you have an aesthetic that you want to protect innocence, then torturing somebody needlessly is evil. But only then.

Lex Fridman 2:39:02
No, but within I guess the question is within the aesthetic, like within your sense of what is good and evil? Are we still, it seems like we're still able to commit evil.

Joscha Bach 2:39:17
Yes. So basically, if you are committing to this next level agent, you are not necessarily are this next level agent, right? You are a part of it, you have a relationship to it, like Sal does to its organism, it's hyper organism. And it only exists to the degree that it's being implemented by you and others. And that means that you're not completely fully serving it. You have freedom in what you decide whether you are acting on your impulses and local incentives on your federal impulses so to speak, or whether you're committing to it and what you perceive them as a tension between what you would be doing first respect to the thing that you recognize as the sacred if you do, and what you're actually doing. And this is the line between good and evil, right where you see, oh, I'm here acting on my local incentives or impulses. And here I'm acting on what I consider to be sacred. And there's a tension between those. And this is the line between good and evil that might run through your heart. And if you don't have that, if you don't have this relationship to a transcendent agent, you could call this relationship to the next level, Agent soul, right? It's not saying it's not an immortal thing that is intrinsically valuable. It's a certain kind of relationship, that you project to understand what's happening, somebody is serving, the strengths entered and sacredness or they're not. If you don't have your soul, you cannot be evil. You're addressing a complex, natural phenomenon.

Lex Fridman 2:40:39
So if you look at life, like starting today, or starting tomorrow, when we leave here today, there's a bunch of trajectories that you can take through life. Maybe countless, do you think some of these trajectories in your own conception of yourself, some of those trajectories are the ideal life? A life that if you were to be the hero of your life story, you would want to be like, is there some jasha bhakti is striving to be like, This is the question I asked myself as an individual, trying to make a better world and the best way that I could conceive of what is my responsibility there? And how much am I responsible for the failure to do so? Because I'm a lazy and incompetent too often, in my own perception,

Joscha Bach 2:41:35
and my own worldview are not very important. So it's, I don't have place for me as a hero, in my own world. I'm trying to do the best that I can, which is often not very good. And so it's not important for me to, to have status or to be seen in a particular way. It's helpful if others can see me have a few people can see me that can be my friends. So I

Lex Fridman 2:42:00
want to clarify the here I didn't mean status or perception or like, some kind of marketing thing, but more in private, in the quiet of your mind. Is there the kind of man you want to be? And would consider it a failure if you don't become that? That's what I'm meant by hero,

Joscha Bach 2:42:21
not really. I don't perceive myself as having such an identity. And it's also sometimes frustrating. But it's basically a lack of, of having this notion of father that I need to be emulating.

Lex Fridman 2:42:44
It's interesting, it means the leaf floating down the river. I worry that

Joscha Bach 2:42:51
sometimes it's more like being the river.

Lex Fridman 2:42:59
I'm just a fat frog sitting in the leaf. I know, a dirty, muddy lake. I will wait. Waiting for a princess to kiss. Or the other way I forgot which way it goes. Somebody kisses somebody can ask you. I don't know if you know who Michael malice is. But in terms of constructing sense systems of incentives, it's it's interesting to ask. I don't think I've talked to you about this before malice spouse's anarchism. So he sees all government as fundamentally that getting in the way or even being destructive to collaborations between human beings thriving. What do you think? What's the role of government in a society that that thrives? Is anarchism at all compelling to you, as a system for like, not just small government, but no government at all?

Joscha Bach 2:44:05
Yeah, I don't see how this would work. The government is an agent that imposes an offset on your reward function on your payoff matrix. So it your behavior becomes compatible with the common good.

Lex Fridman 2:44:20
So the argument there is that you can have collectives, like governing organizations, but not government, like where you're born in a particular set of land. And therefore you must follow this rule or else you're forced by what they call violence, because there's an there's an implied violence here. So with government, the key the key aspect of government is, is it protects you from the rest of the world with an army and police, right. So there's this it has a monopoly on violence. It's the only one that's able to do violence,

Joscha Bach 2:45:02
many forms of government. Not all governments do that, right. But we find that in the in successful countries, the government has a monopoly on violence. And that means that you cannot get ahead by starting your own army, because the government will come down on you and destroy you if you try to do that. And in countries where you can build your own army and get away visit, some people will do it, right. And these countries is what we call failed countries, in a way. And you, if you don't want to have violence, the point is not to appeal to the moral intentions of people. Because some people will use strategies if they get ahead wisdom, that feel a particular kind of ecological niche. So you need to destroy that ecological niche. And if effective government has a monopoly on violence, it can create a world where nobody is able to use violence and get ahead, right. So you want to use that monopoly on violence, not to exert violence, but to make violence impossible to raise the cost of violence. So people need to get ahead, because nonviolent means.

Lex Fridman 2:46:06
So the idea is that you might be able to achieve that and just stay with companies. So with the with the forces of capitalism, is create security companies were the one that's most ethically sound rises to the top, basically, it would be a much better representative of the people, because there's less sort of stickiness to the big military force sticking around, even though it's long over lived out little

Joscha Bach 2:46:37
groups of militants that are hopefully efficiently organized, because otherwise they're going to lose against the other groups of militants. And they are coordinating themselves with the rest of society until they are having a monopoly on violence. How is that different form of government? converging to the same thing? So

Lex Fridman 2:46:56
I think it always I, my sources, trying to argue with balance, I feel like it always converges towards government at scale. But I think the idea is you can have a lot of collectives that are you basically never let anything scale too big. So one of the problems with governments is it gets too big in terms of like the, the, the size of the group over which it has control. My sense is that would happen anyway, in this successful company, like Amazon or Facebook, I mean, it starts forming a monopoly over over entire populations, not over just the hundreds of millions, but billions of people. So I don't know. But there is something about the abuses of power the government can have when it has a monopoly on violence, right. And so that's, that's a tension there. But

Joscha Bach 2:47:53
so the question is, how can you set the incentives for government correctly, and this mostly applies at the highest levels of government. And we because we haven't found a way to set them correctly, we made the highest levels of government relatively weak. And this is, I think, part of the reason why we had difficulty to coordinate the pandemic response. And China didn't have that much difficulty. And there is, of course, a much higher risk of the abuse of power that exists in China because the power is largely unchecked. And that's basically what happens in the next generation. For instance, imagine that we would agree that the current government of China is largely correct and benevolent. And maybe we don't agree on this. But if if we did, how can we make sure that this stays like this. And if you don't have checks and balances, in division of power, it's hard to achieve, you don't have a solution for that problem. But the abolishment of government basically would remove the control structure from the cybernetic perspective, there is an optimal point in the system, that the regulation should be happening, right that you can measure the current incentives and the regulator would be properly incentivized to make the right decisions. And change the payout metrics of everything below it in such a way that the local prisoner's dilemma is get resolved. Right? You cannot resolve the prisoner's dilemma without some kind of eternal control. That emulates an infinite game in a way.

Lex Fridman 2:49:19
Yeah, I mean, the there's a sense in which it seems like the reason government, the parts of government that don't work well currently, is because there's not good mechanisms for through which to interact for the citizenry to interact with government is basically it. It hasn't caught up in terms of technology. And I think once you integrate some of the digital revolution, of being able to have a lot of access to data, be able to vote and different ideas at a local level at all levels at the at the optimal level, like you're saying that can resolve the prisoner dilemmas and to integrate AI to help you out automate things that are like, that don't require the human ingenuity. I feel like that's, that's where government could operate that well, and can also break apart inefficient bureaucracies, if needed, there'll be a strong incentive to, to, to be efficient and successful.

Joscha Bach 2:50:20
So without human history, we see an evolution and evolutionary competition of modes of government and of individual governments is in these modes. And every nation state in some sense, is some kind of organism that has found different solutions for the problem of government. And you could look at the all these different models and the different scales at which it exists as empirical attempts to validate the idea of how to build a better government. And I suspect that the idea of anarchism, similar to the idea of communism, is the result of being disenchanted was the ugliness of the real existing solutions. And the attempt to get to topia, and I suspect that communism originally was not a utopia. I think that's in the same way as original Christianity. It had a particular kind of vision. And this vision is a society, mode of organization, vision, the society in which humans can coexist at scale without coercion. The same way as we do in a healthy family, right, in a good family, you don't terrorize each other into compliance. But you understand what everybody needs and what everybody can is able to contribute and what the intended future of the whole thing is. And you, everybody coordinates their behavior in the right way. And it forms each other about how to do this. And all the interaction that happened, are instrumental to making that happen. Right? Could this happen at scale, and I think this is the idea of communism, communism is opposed to the idea that we need economic terror, or other forms of terror to make that happen. But in practice, what happened is that the proto communist countries, the real existing socialism, replaced a part of the economic terrorists moral terror, right, so we were told to do the right thing for more reasons. And, of course, it didn't really work and the economy eventually collapsed. And the mobile terror had actual real costs, people were in prison, because they were morally non compliant. And that is, the other thing is that the idea of communism became utopia. So it basically was projected into the afterlife. We were told in my childhood, that communism was a hypothetical society to which we were in a permanent revolution, that justified everything was presently wrong with society, morally, but it was something that our grandchildren probably would not ever see. Because it was too ideal and too far in the future to make it happen right now. And people are just not there yet morally. And the same thing happened with Christianity, right, this notion of heaven, was mythologized and projected into an afterlife. And I think this was just the idea of God's kingdom of this world in which we instantiate the next level transcendental agent, the perfect form. So everything goes smoothly and without violence and without conflict. And without this human messiness on this economic messiness, and the terror and coercion that existed in the present societies. And the idea of that the humans can exist at scale in a harmonious way, non coercively is untested, or both field tested, but didn't get it to work so far. And the utopia is a built in where you get all the good things without any of the bad things. And you are, I think, very susceptible to believe in utopias, when you are very young and don't understand that everything has to happen in causal patterns, that there is always feedback loops that ultimately are closed. There's nothing that just happens because it's good or bad, good or bad, don't exist in isolation, they only exist with respect to larger systems.

Lex Fridman 2:53:50
So can you Intuit why utopias fail as, as systems? So like having a utopia that's out there beyond the horizon? Is it because then it's not only because it's impossible to achieve utopias, but it's because what certain humans certain small number of humans start to sort of greedily attain power and money and control and influence as they become as they see the power in using this idea of a utopia.

Joscha Bach 2:54:34
Like saying, why is my garden what perfect is because some evil weeds are overgrowing it and they always do. Right? It's about this is not how it works. A good garden is a system that is imbalanced and requires minimal interactions by the gardener. And so you need to create a system that is designed to self stabilize, and the design of social systems requires not just the implementation of the desired functionality, but the next level design also in biological systems, you need to create a system that wants to converge to the intended function. So instead of just creating an institution like the FDA that is performing a particular kind of rule, or wall and society, you need to make sure that the FDA is actually driven by a system that wants to do this optimally, that is incentivize the root optimally, and then makes the performance that is actually enacted and every generation instrumental to that thing, that actual goal, right, and that is much harder to design and to achieve,

Lex Fridman 2:55:30
see if the designer system were English. And communism also was, quote, unquote, incentivized to be a feedback loop system that achieves that utopia, it just wasn't working, given human initially, the incentives were not correct,

Joscha Bach 2:55:47
given. So how do you incentivize people when they are getting called off the ground to work as hard as possible? Because it's a terrible job. And it's very bad for your health? And right, how do you do this? And you can give them prices and metals and status? To some degree, right? There's only so much that is to give for that. And most people do not fall for this. Yeah, right. Or you can pay them. And you probably have to pay them under as a magic way. Because if you pay everybody the same, and they nationalized the coal mines, eventually people will figure out that they can game the system.

Lex Fridman 2:56:21
Yes. So you're, you're describing capitalism.

Joscha Bach 2:56:25
So capitalism is the present solution to the system. And what He also noticed that is I think that Marx was correct in saying that capitalism was prone to crisis, that capitalism is a system that in its dynamics is not convergent by divergent, it's not a stable system. And that eventually, it produces an enormous potential for productivity. But it also is systematically Miss allocating resources. So a lot of people cannot participate in the production and consumption anymore. And this is what we observe, we observe that the middle class in the US is tiny. It's a lot of people think that they're middle class. But if you are still flying economy, you're not middle class.

Joscha Bach 2:57:11
Every class is a menu two. Classes is really like airline class. I, like lost a lot of people, our economy, we really miss class, and very few are first class and some of us.

Lex Fridman 2:57:30
I mean, some I understand I think there's, yeah, maybe some people, probably I would push back against that definition of the middle class, it does feel like the middle class is pretty large. But yes, there's a discrepancy in terms of wealth. So there's a

Joscha Bach 2:57:46
couple of games of the productivity that our society could have. Yeah, there is no reason for anybody to fly economy, right, we wouldn't be able to let everybody travel in style.

Lex Fridman 2:57:57
Well, but also some people like to be frugal, even when they're billionaires. Okay, so like that, let's take that into

Joscha Bach 2:58:04
my mind, you probably don't need to be traveling lavish. But you also don't need to be tortured, right? There is a difference between Google and subjecting yourself to fortress and

Lex Fridman 2:58:14
I love a calm, I don't care why you're preparing a fire academy to torture. I don't although the fight here, there's two crying babies next to me. So that, but that has nothing to do with the carpet as it has to do with crying babies. They're very cute. So

Joscha Bach 2:58:30
I have two kids. And sometimes they have to go back to visit the grandparents. Back means going from the west coast to Germany, that's a long flight.

Lex Fridman 2:58:42
Is it true that when you're a father, you grow immune to the crying and all that kind of stuff like the you know, because like me just not having kids. It can be other people's kids can be quite annoying when they're crying and screaming and all that kind of stuff.

Joscha Bach 2:58:57
When you have children, and you're wired up in the default natural way, you're lucky in this regard, you fall in love with them. And this falling in love with them means that you basically start to see the world through their eyes. And you understand that in a given situation. They cannot do anything but being expressing despair. And so it becomes more differentiated. I noticed that for instance, my son is typically acting on pure experience of what things are like right now is to do this right now. And you have this small child that is when he was the baby and so on where he was just immediately expressing what he felt and if you cannot regulate this from the outside, and there is no point to be upset about it, right. It's like dealing with weather or something like this. You all have to get through it. And it's not easy for him either. But if you also have a daughter, maybe she is planning for that maybe she understands that. You know that she's sitting in the car behind you and she's screaming at the top of her lungs. You're almost doing an accident, you really don't know what to do. What should I have done? Does that make you stop screaming? You could have given me candy.

Lex Fridman 3:00:10
I think that's like a cat versus dog discussion. I love it. So cuz you said that, like a fundamental aspect of that is love that makes it all like worth it. What in this monkey riding an elephant in a dream world? What role does love play in the human condition?

Joscha Bach 3:00:32
I think that love is the facilitator of non transactional interaction. You are observing your own purposes, some of these purposes go beyond your ego, they go beyond the particular organism that you are and your local interests. That's what you mean by non transactional? Yes. So basically, when you are acting in a transactional way, it means that you are expecting something in return for you. From the one that you're interacting with, right, you are interacting with a random stranger, you buy something from them on eBay, you expect a fair value for the money that you sent them, and vice versa. Because you don't know that person, you don't have any kind of relationship to them. But when you know this person a little bit better, and you know, the situation that they're in, you understand what they're trying to achieve in their life, and you approve, because you you realize that they are in some sense, serving the same human sacredness as you are. And they need to think that you have maybe you give it to them as a present.

Lex Fridman 3:01:26
But the I mean, the feeling itself of joy is a kind of benefit is a kind of transaction, I

Joscha Bach 3:01:35
guess. But deep joy is not the point that joy is the signal that you get, it's the reinforcement signal that your brain sends to you because you are acting on the incentives of the agent that you're part of. We are meant to be part of something larger, right? That is the way in which we out competed other hominids.

Lex Fridman 3:01:54
Take that Neanderthals. Yeah, right.

Joscha Bach 3:01:57
And also other humans. Right, there was a population bottleneck for human society that leads to an extreme lack of genetic diversity among humans. If you look at Bushmen in the Kalahari, that, basically tribes that are not that far distant to each other have more genetic diversity that exists between Europeans and Chinese. And that's because basically the out of Africa population, at some point at a bottleneck of just a few 1000 individuals. And what probably happened is not that at any time, the number of people shrank below a few 100,000. What probably happened is that there was a small group that had a decisive mutation that produced an advantage in this group multiplied and killed everybody else. And we are descendants of that group.

Lex Fridman 3:02:46
Yeah, I wonder what the peculiar characteristics of that group? Yeah. How they mean, we never know a lot of people do. And we can only we can only just listen to the echoes in our like the ripples that are still within us.

Joscha Bach 3:03:01
So I suspect what eventually made a big difference was the ability to organize at scale, people to program each other, with ideas that people came programmable that were willing to work in lockstep that we went below above the tribal level that we no longer oops, have a few 100 individuals and acted on direct reputation systems transactionally, but that we basically evolved in adaptation to become statebuilding.

Lex Fridman 3:03:28
Yeah. To do to form collectives outside of the direct collectives, and that's

Joscha Bach 3:03:36
basically a part of us became committed to serving something outside

Lex Fridman 3:03:40
bigger than what we know. Yeah, that's kind of what love is. And it's terrifying

Joscha Bach 3:03:44
because it meant that we eradicated the others. Maybe it's a force, it's an adaptive force that gets us ahead and evolution, which means we display something else that doesn't have that.

Lex Fridman 3:03:56
Oh, so we had to murder a lot of people that weren't about love. So love led to destruction

Joscha Bach 3:04:01
half the same strong laugh as right. That's why I mentioned this thing was fascism. When you see this speeches, do you want total war? And everybody says, Yes, right? This big? Oh, my God be a part of something that is more important than me that gives meaning to my existence.

Lex Fridman 3:04:22
Fair enough. Do you have advice for young people today, in high school in college, they're thinking about what to do with their career or their life, so that at the end of the whole thing, they can be proud of what they did.

Joscha Bach 3:04:43
Don't cheat. Integrity,

Lex Fridman 3:04:47
integrity. So what does integrity look like when you're the river or the leaf, or the fat frog going to like?

Joscha Bach 3:04:54
It basically means that you try to figure out what the thing is. That is the most Right. And this doesn't mean that you don't, that you have to look for what other people tell you what's right. But you have to aim for moral autonomy. So things need to be right independently of what other people say. I always felt that when people told me to listen to what others say, like, with the room, build your ideas of what's true based on the high status people of you in group that does not protect me from fascism. The only way to protect yourself from fascism is to decide is the world that is being built here, the world that I want to be in. And so in some sense, try to make your behavior sustainable act in such a way that you would feel comfortable on all sides of the transaction, we realize that everybody is using a different timeline, but is seeing things differently, and has reasons to do so.

Lex Fridman 3:05:53
Yeah, there's, I've come to realize this recently, there is an inner voice that tells you what's right and wrong. And speaking of reading the room, there's times what integrity looks like, is there's times when a lot of people are doing something wrong. And what integrity looks like is not going on Twitter and tweeting about it. But not participating. Quietly, not doing so it's not like signaling or knots, that all this kind of stuff, but actually living your what you think is right. Like living it.

Joscha Bach 3:06:28
Now, that's also sometimes this expectation that others are like us. So imagine the possibility that some of the people around you are space aliens that only look human. Right. So they don't have the same prayers as you do. They don't have don't have the same impulses, though. It's what's right and wrong, there is a large diversity in these basic impulses that people can have in a given situation. And now realize that you are a space alien. Right? You are not actually human, you think that you're human, but you don't know what it means. Like, what it's like to be human, you just make it up as you go along like everybody else. And you have to figure that out what it means that you are full human being what it means to be human in the world, and how to connect with others on that. And there is also something, don't be afraid, in the sense that you, if you do this, you're not good enough. Because if you're acting on these incentives of integrity, you become trustworthy. That's the way in which you can recognize each other. There is a particular place where you can meet, you can figure out what that place is that you will give support to people because you realize that they act with integrity. And they will also do that. So in some sense, you are safe. If you do that. You're not always protected, there are people which will abuse you and that might that are bad actors in a way that it's hard to imagine before you meet them. But there is also people which will try to protect you.

Lex Fridman 3:07:57
Yeah, this the such. Thank you for saying that. That's such a hopeful message. That no matter what happens to you, there'll be a place there's people you'll meet. That also have what you have. And you will find happiness there. And safety there.

Joscha Bach 3:08:20
Yeah, but it doesn't need to end well. It can also all go wrong. So this there is no guarantees in this life. So you can do everything right. And you still can fail and you can still horrible things happen to you that traumatize you and mutilate you. And you have to be grateful if it doesn't happen.

Lex Fridman 3:08:40
And ultimately be grateful no matter what happens, because even just being alive is pretty damn nice.

Joscha Bach 3:08:46
Yeah, even that, you know, the gratefulness in some sense is also just generated by your brain to keep you going. It's all the trick.

Lex Fridman 3:08:58
Speaking of which, Khumbu said, I see many people die because they judge that life is not worth living. I see others paradoxically getting killed for the ideas or illusions that give them a reason for living. What is called the reason for living is also an excellent reason for dying. I therefore conclude that the meaning of life is the most urgent of questions. So I have to ask what jasha Bach is the meaning of life? It is an urgent question, according to como.

Joscha Bach 3:09:35
I don't think that there is a single answer to this. The nothing makes sense unless the mind makes it so so that you basically have to project a purpose. And if you zoom out far enough, there is the test of the universe and everything is meaningless. Everything is just a blip in between. And the question is, do you find meaning in this blip in between? Do you find meaning and observing squirrels do you To find meaning in raising children and projecting a multi generational organism into the future, do you find meaning in projecting an aesthetic of the world that you like, to the future and trying to serve that aesthetic? And if you do, then life had that has that meaning. And if you don't, then it doesn't.

Lex Fridman 3:10:18
I kind of enjoy the idea that you just create the most vibrant, the most weird, the most unique kind of blip you can give in your environment, given your set of skills just be the most weird set of like local pocket of complexity you can be so that like, when people study the universe, they'll pause and be like, that's weird.

Joscha Bach 3:10:48
Looks like a useful strategy. But of course, it's still motivated reasoning.

Lex Fridman 3:10:56
Your incentives here is still a story we tell ourselves within a dream that's, that's hardly in touch with reality.

Joscha Bach 3:11:03
It's definitely a good strategy, if you are podcaster.

Lex Fridman 3:11:10
And human, which I'm still trying to figure out if I am, hey, there's a mutual relationship somehow, somehow. Joshy the year you're one of the most incredible people I know. I really love talking to talking to you again. And it's really an honor that you spend your valuable time with me. I hope we get to talk many times throughout our though our short and meaningless lives, meaningful or meaningful.

Joscha Bach 3:11:35
Thank you, Lex. I enjoyed this conversation very much.

Lex Fridman 3:11:39
Thanks for listening to this conversation with Josh Bach, and thank you to Coinbase Code Academy, Linode, NetSuite and ExpressVPN check them out in the description to support this podcast. Now, let me leave you with some words from Carl Jung. People will do anything, no matter how absurd in order to avoid facing their own souls. One does not become enlightened by imagining figures of light, but by making the darkness conscious, thank you for listening, and hope to see you next time.
