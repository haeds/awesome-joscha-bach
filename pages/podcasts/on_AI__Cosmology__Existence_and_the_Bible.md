Unknown 0:21
My name is Nicola, and you're watching singularity FM, the place where where we interview the future. If you guys enjoy this podcast, you can help me make it better in one of two ways. Number one is you can write a brief review on iTunes or number two, go to interview the future.com and simply make a donation. Today for the second time, my guest will be your Shebaa Your shirt is probably the best way to describe him, in my view is to say he's a beautiful mind. And if you want a further explanation about who he is, I highly recommend you go check out our previous interview, which is absolutely fantastic. And people loved it so much that I really had to bring him along, even though I'd love to have a conversation with him, even if I wasn't recording it or even if it was not a podcast, just because he's such a rewarding interlocutor on any topic that I can possibly imagine. So without further ado, Yoshua Welcome back to singularity FM my friend.

Joscha Bach 1:27
Thank you, Nicola.

Unknown 1:30
You're shy, it's been almost four years since our last conversation and we kind of discussed it, we will have another one in a few months. But here we are. Four years later, how have you been?

Joscha Bach 1:42
Well, relatively good, considering there was a pandemic in between the homeschool the kids V LIVE in California. Now, currently in the Bay Area. Working for Intel new team, we are discussing in his team the future of artificial intelligence and try to understand what comes after the present developments and how long that will take. So it's an exciting time to be in and VR in the place where I feel it happens. It's basically weird when I think that at some point, I realized as a young kid in Germany, that artificial intelligence was going to happen one day. And I thought about how I could get into this and get closer to this. And now I feel that I'm very close to where all these developments are taking place.

Unknown 2:38
You are indeed very close, you're in the kitchen, in a way. So tell us a little more about because last time you're kind of this in this kind of, as you explained it, zero gravity academic position. And now suddenly, you find yourself working at Intel. And of course, the topic, part of the topic of our conversation is, of course, artificial intelligence, how far we have come and how how far we have to go. And with what's the kind of potential timeline that we may get to get there. So tell us a little more about Intel or the position you're working at or how you got there anything that you find relevant.

Joscha Bach 3:20
I thought that I wanted to spend a few years on the West Coast of the US to get ideas and interact with people and the communities here. And I was offered a position as a Research Leader in a startup company. And I took this for a while. And then I was hired into a different position where I could do more of the things that I wanted to do at Intel. And but it's a in some sense, not very different from an academic research position. We have a team that doesn't feel very different from a team at MIT are so it's so it's not focused on building products. And it's not focused on dealing with customers. It's really basic research unit that allows Intel to do some cognition. And that's why I was able to take this position and quite grateful for the opportunity that I've got that it's it's a really an interesting time our different approaches are being tried around me and people are working on different areas and thought myself visit Intel in a relatively large research community that spans many countries and got new contexts so it into neuromorphic hardware and at the same time into developments of better transformers, which is one of the biggest topics right now in machine learning. And then the combination of a lot of methodologies.

Unknown 4:45
Wow. Well, perhaps you can kind of enlighten us a little bit because to be honest with you, and I'm sure you wouldn't be surprised by that. But Intel is not the first company one would think of when we think of AI Intel might be First company we think of when we think of microchips and CPUs and maybe falling behind Moore's law in the last few years and having to reschedule their launches a few times in a row and all those things. So how would you qualify Intel's approach? Or in other words, what makes Intel's approach towards building AI different or unique or? Or is it maybe it's just the same as anybody else's deep learning and so on, or

Joscha Bach 5:31
I think that Intel is, in an interesting position. Don't feel like making advertisement for my current employer. But this is the start of the new CEO, Pat Gelsinger Intel try to reverse course in many ways, in the perspective of many outside observers, and I think also many inside observers, what had happened in Intel in the past was that they use their comfortable position as the world's leading semiconductor supplier to invest the profits into stock buybacks rather than r&d in this means that Intel came late on a number of crucial developments. So Nvidia and AMD are now having parts of its lunch, indigenous realize this and has tried to turn it around. And this means that they also put considerably more resources into future leading research. And some of that a lot of that is open ended, because we don't know what the future brings. So by putting a few 100 million dollars into research, it's possible to secure a future businesses that are worth many billions of dollars. And this is a thing that Intel can not afford not to do. Personally, I think that Intel should understand itself as an AI company, that is building substrates for AI is this its speciality, and it should maybe become more design centric. And at the moment, I think they said transition happening in this direction. And our own team, emergent AI is one of two major initiatives that have formed in the last year and consolidated one is called emergent AI. The other one is social AI. Both of them are doing future leading research, and basically explore a whole array of technologies that happen in a particular way. So Intel is not making a single bet on this, that is going to happen. But rather it's looking at which things are going to be used, which things are working, which things will be working soon, and what is the hardware that you're going to have to build to support it in the future. So we are looking at what's going to happen in three years from now five years from now 10 years from now, and try to anticipate this by building various things that have to work now.

Unknown 7:51
So overall, is Intel pursuing more than the hardware foundation for AI that other people can build software for? Or is it pursuing software research at the same time that that can be built upon the hardware that they are designing for sure.

Joscha Bach 8:10
I think it's a little bit comparable to what happened at Nvidia when they did the investments in style again, or this was an extremely interesting development where they hired some top researchers in the field to build generative adversarial neural networks that could generate faces. And this was one of the many efforts that NVIDIA has started internally, to get themselves to understand the technology that they would need to build to support us. So in some sense, it's a way of dogfooding your own products to use it as a researcher. And at the same time, they found that this diagun developments were useful for developing technology for Nvidia, for instance, for video compression of faces, and for video games and so on. And at the same time, this is something that Intel is seeing is happening. And we have some efforts that are directly focused on hardware. But the majority of the things that we do are pure software forts or pure open source or purely about how can we serve the community in AI, in identifying things that are currently under researched into which we should put resources. So a lot of the work that we are doing as researchers is very self directed and doesn't feel hardware centric or product focused.

Unknown 9:28
Well, you're kind of in the kitchen of Intel now. So people wouldn't forgive me if I don't ask you about what's the consensus on the inside. There is Moore's Law alive or dead? Because some people would observe that we have gay gotten probably, you know, single or maybe high teens like 15 to 20%. Improvement, generation over generation for the last maybe seven or eight years. And that's not even including perhaps the several deal A case that Intel has had to sort of implement or accept in that development. So what do you think is Moore's Law alive and well are dead?

Joscha Bach 10:10
They don't if you're competent for making such a prediction, and all that there are people which say, there's an intel that it's our mission to keep Moore's Law alive. I also see that there are some developments happening in alternate hardware that could make dramatic changes in the future if they work. But these are interesting bets. And I think what's probably going to happen is that we will have hardware that is specific for particular purposes, like inference for certain applications. And this makes it hard to compare things across the board. Because in some sense, the GPUs that we are building, that seeing the industry are a lot faster than things happen in the past, but they require new programming paradigms. And right, so a direct comparison might not be possible. But also, I think that there is something like a limit in physics, that is theoretically not close. But practically, to get closer to that if you want to build conventional technology, if you want to build deterministic hardware, or don't want to change the architecture of the Von Neumann computer, but you are increasingly approaching limits. But again, I'm not a hardware expert. So I'm not actually competent to have a deep opinion.

Unknown 11:29
You haven't heard any, any of your colleagues making comments on that. Yes,

Joscha Bach 11:33
I do. But I'm unable to judge the entire space of that. So I feel that I would be on thin ice.

Unknown 11:40
Right? Because just to share with you my own personal experience, I was buying my wife a new laptop. So her laptop was a Dell XPS and it was six and a half years old. And I bought her and it costed 2000 years back in the day when we bought it. Now we bought a brand new razor laptop, and it was $2,450. So let's say with, you know, inflation, this and that, let's let's be generous. And let's say it's about the same 2000 price range, I ran a few benchmarks. And the best I could do was about a 60% improvement. And quite often the difference between her six year old laptop was about only 40%. Now, if Moore's law were to be correct, in the last six years, we would have had tool on the power of three. So we would have had to have an eight fold improvement. But as I said, In the best case scenario we've had about 60%. And that's consistent with AMD, by the way AMD supposedly has been eating Intel's lunch, as you said for for the last three or four years with their Zen generation of CPUs. And they've been kind of announcing anywhere from 15 to 20 25%, increase generation over generation, and that's their own internal figures. So it's up for debate whether and how accurate these figures are, you know, and in some cases, they may be overestimating the reality. In some cases, interestingly enough, they can be even a little bit under estimating. So but so that's that's all to say we have to accept it with a grain of salt. And overall, the conclusion between those two examples could be that perhaps at least as far as CPUs are concerned, Moore's law is not doing that great, if at all.

Joscha Bach 13:33
Yeah, I found that when you get a new Mac, there is a significant improvement. At the moment, I think that Apple has the bar a lot higher for the industry, especially with respect to how much compute you get out of a certain wattage and cooling in your system, which is what's in many way limiting what you can build into a laptop today. And I think most of the computers that will consider buying these days are laptops, which for me is a big change. I remember when desktop systems were mandatory for the kind of work that we were doing. And now the systems did shrink. And on the other hand, there is a limitation and what people can build into these machines and this limb factor is subjectively shrinking. And the software, right that is happening in the operating systems that makes things more sluggish, is not disappearing. So that's basically it seems to be a rate at which the compute that we get into our systems and I mean, even 15% per generation or 20, or 30% is not too little if you go for future generations, right? But this, our software gets slower at the same time. And it's an interesting situation that we have such a duopoly on the software front. For instance, I suspect that if you want to get a third operating system launched ever, which has been tried several times it didn't work. It never got served as the operating system That was worth using, despite the developments in Linux and so on, you probably have to move inside of Apple or Microsoft and destroy one of the existing operating systems from prison. Maybe that's already happening. Maybe that's, that's why they're getting so bad.

Unknown 15:16
What about Linux, many people love Linux as a third operating system. Cory Doctorow is a big, big supporter. He's been using Linux for at least 10 years to try

Joscha Bach 15:26
to use Linux from time to time. And I did not like us experiment studying this for months and whitespace, I basically didn't see a single desktop that was consistently designed and was not inciting. And I don't know why this hasn't happened in Linux. And I suspect it's because Linux does not have centralized oversight. There has been individual systems that tried to change this a little bit. But there was no enforcement style guide for the entire application suite. And for me, the inconsistent user experience is one of the issues where I don't think Linux is up to par. And I compare it to Mac OS.

Unknown 16:11
That that's, that's very interesting, because I feel exactly the same way. But you're sharp. I had a few audience questions submitted to me today. And one of the consensus that we got is that perhaps we should try not to get too technical and stay at the bigger picture. So let me ask you with to kind of a personal site questions even if you will, and they both come, or a few of those come from none other than Mark Twain, the good old wit, from American humor. So Mark Twain wanted to know why building a zoo without right angles, was important for your dad.

Joscha Bach 16:56
I think that my dad did not like the my father, the ways in which society was raining people into boxes. He didn't like the brutalism of the Soviet era architecture in Eastern Germany. And he did not like the rectangular ways in which people's lives were planned out in the late modernist era, that was trying to restructure the economy and culture of Eastern Germany and of many of the countries that we live in. And Tifa is subjecting people to this Taylorist approach in which our lives are planned in by people who do not have to live these lives, but want to simplify them is especially cool if you do this to animals, which have no beef and this and he felt that if we want to put animals that we are taking out of the natural habitat into our cities, we should not subject them to the same in human and alien experience that humans had. Of course, a lot of that is also born out of the time in which he studied and grew up, it was the late 60s.

Unknown 18:07
And do you feel that that kind of approach has rubbed on you? Because to me, it looks like it might have rubbed very well on you, you, you, you you tried to kind of round up the angles or or have your own vision about whether or if there should be angles? And what should they be? In what you do? Yes, is that fair to say? It's

Joscha Bach 18:31
true, I think that we, as children were keenly aware of the need to impose our own aesthetic on our life and our surroundings if we want to live a life that is worth living. And the place that we grew up, it was quite isolated and remote. This was in some sense, a different universe. And we looked out into the universe where the people lived. And the people lived in ways that I found disagreeable, and they were obviously disagreeable. I did not see why they would waste their lives like this, producing things that eventually go into landfill, and that are very transitionary and not intrinsically useful. A society that rarely questions what it's good for. And that is not giving people that live and largely a very good deal. And I thought that there is much, much more choice than people are aware that they can have. And our parents were more of the kind that told us, you know, if it doesn't matter whether you're a shepherd or a painter, or whatever you do, but if you don't work hard to do exactly what you want to do, you might end up in a factory or an office, which for my parents was in some sense, the protection of a failed life.

Unknown 19:50
Worst Spanish punishment possible.

Joscha Bach 19:52
It was not the worst punishment possibly, of course, if we were going for such a thing, and do work in an office although it's and home office, that I can staff, myself and other projects that I can pick myself, which I think is quite luxurious for most people, I find that I largely sort of reverse their judgment, it's difficult for me to work on things that I don't think are intrinsically important.

Unknown 20:23
Fantastic. And so I introduced you today for those of our viewers and listeners who may not have seen our first interview, when we went a lot deeper into your background as a beautiful mind. That's always fun to have a conversation with. But if you were to introduce your own self in a sentence, or at the most or in a word or two, how would you do that? Who is your Shebaa?

Joscha Bach 20:47
This depends on the context entirely. I'm a human being that is trying to understand the world. And I think this is true for all of us at some level, and some of us forget it, they basically stop the exploration are limited after childhood and the specialist much more. And of course, I also have to do this, especially once you have children, your role and life changes dramatically. But I still have this childlike need to explore and to observe things and the areas that I studied in and try to understand, we're always in very philosophical, and at the same time, technical, because I thought that we need to be narrow and strict and honest with ourselves to people to understand what's actually going on. And I found that I did not really fit well into the institutions of academia in doing that. And I often had the opportunity to work in there. And it was a lot of fun, especially teaching and working with students and exploring them together. At the same time, the institutions are serving different purposes than they did 50 years ago.

Unknown 21:55
Wow. So let me ask you this, then, as a follow up, if you were to be fortunate enough to have a meeting with God, or an almighty God, like artificial super intelligence, what kind of questions would you ask of them?

Joscha Bach 22:21
found that there are a number of the deepest questions that I had when I was born. Like what is the meaning of life? Not when I was born, but when I grew up, or throughout my life? How does consciousness work? What is the future destiny of humanity? How is it like to be another person? What is it like to be left and connected? How does love work? How do we get relationships to work? How do we get a relationship with ourselves to work and so on? All these different questions were things that I felt I could answer in the course of my life. Yeah, I find that even questions like why is there something rather than nothing can be answered? And

Unknown 23:11
you feel you're closer to getting the answer for those questions today than last time? We talked together four years ago,

Joscha Bach 23:19
constant constantly get answers by asking questions and thinking about them, and discussing them with other people and picking up ideas and combining them and developing them. Yeah.

Unknown 23:34
So which question Do you feel you're closest to the answer to today?

Joscha Bach 23:40
Oh, that's a difficult question. Because I never know how far I am from the answer when I'm don't have the answer yet. Because you don't know what the details are. Otherwise, you'd be directly at the answer. But for instance, one of the things that really puzzled me a few years ago was the question why there is something rather than nothing at all right? What's the existence? I find? That the question what is consciousness? How is it possible as conscious experience is not that hard to answer once you realize that you exist in the dream and how machines can have dreams could work, and how you can entangle them with the universe around them, and how models work in general, and so on, then you get into technical details. And don't think that the algorithms that you could use to that are machine streams are optimal, but they're already starting to become quite good models of what dreams are. So a system that is able to discover an agent that it runs on in the world and develops a first person perspective as a result because it tries to model everything, including the agent that it runs on. And including the attentive observer that seems to be almost within reach, and it's going to happen quite soon. But the question of why there's nothing was pretty shocking to me.

Unknown 24:55
Wow, there's so much there that I want to unpack. Everything is so interesting. Okay. Well, let's just follow that line, and then we'll go back to the, to the AI. But so let's, let's say, one way or another, you have all of those questions answered. Then what? What would that mean to you, as an individual as an identity? Who is your Shabbat going to be? After? All of your questions have been answered?

Joscha Bach 25:31
I don't think that's very important. It's just like, you play music. And you try to compose and you ask yourself, Who am I going to be when I'm done with all the compositions. So basically, as long as I'm curious, I'm going to explore and there will always be more to explore more details to understand about psychology about sociality, about how to raise children about how to not despair, out how to build sustainable interactions with other people and with the world around us. So there's so much to do, this is not the issue as so as long as I don't get jaded or bored or lose all my energy, probably will go on like this.

Unknown 26:13
Yeah, so in other words, you're enjoying the journey, just like in dance, the point of dancing is not to get from one point of the floor to another, or to do so in the fastest way possible. Just like when you're playing music, the point is not to play the fastest way possible and get to the end of the musical performance. The point is to be present there in the moment, and to enjoy that moment, and to be there for it to experience it. So you're not so much like obsessed with the with the final destination, but it's more about the process.

Joscha Bach 26:49
I think that as you observe yourself for a while, you notice that this is always the case, that whenever you have a goal, this goal is instrumental to something else. And ultimately, you can discover how you are driven by some abstract need for transcendence. And for a search for meaning or for integration of yourself as the word or for the transcendence of what you are. So you realize that, at some point, you make a switch from being a particular person to being a vessel for a person that you can create as needed. And your identity changes when you do that.

Unknown 27:31
Yeah. And of course, the kind of questions that we ask. The reason why I'm so curious, always about questions is because questions are like flashlights, you know, they set the, the field of vision for us of, of what's possible for us to observe what's possible of us to consider. And even the realm of the possible answers is being preset by the flashlight, have those questions in a way? So that's why I find it so curious to ask what's the questions that people are going after? Yeah,

Joscha Bach 28:08
for me, it's basically all the basic questions. The questions that I don't see an obvious answer, or things that are attended that need to be resolved.

Unknown 28:22
At the same time, you're very optimistic that you're making progress, which is very interesting observation. And at the same time, now we can maybe narrow it and go back to the AI, you'll think it seems to me, you you made like a couple moments ago, a very kind of an optimistic proclamation that we're not only closer than before, but we're very close indeed, perhaps is that correct of me to interpret?

Joscha Bach 28:51
It's hard for me to say how close we actually are. But the current DC this year is a number of milestones that produce things that surprise many of the experts in the field.

Unknown 29:04
Give us some of those examples of milestone,

Joscha Bach 29:07
I think the most obvious one that people are looking at right now is open AI is development of tele two, which is taking the 2017 transformer algorithm in the realm of images and combines it with a few new discoveries like diffusion models. And there is a deeper understanding of how we represent meaning. The idea here is that there is a multi dimensional space in which we can represent all meanings. And this high dimensional space can be reconstructed in a model by sorting all the things that you came across for us as patrons and data by similarity. And this is an unsupervised mechanism that is just operating on patterns in data by itself. And that itself is sufficient to lead to a convergence of spaces of meaning in different modes. Ladies, and you'll find that the space that emerges when you are just doing analysis of text, like happened in GPT, three and Bert and the other transformer models of text by feeding them basically all of the text that is available by now allows us to make a model that isn't it's a sense just an autocomplete mechanism for text, which says, giving this text that you've seen before the last three pages, how is the text going to continue? This is sufficient to solve many, many problems that existed before in AI. And that couldn't be solved on puzzle, like questions of how to summarize text efficiently and so on, or how to generate new text that is conforming to a specification. And the difficulties with this approach. For instance, how do we get this model to understand the context that it's currently in? How does is two pages of text the sufficient to set the context for any type of problem? And how can we make this real time at any time. But this text space of meanings is almost congruent to visual grammar that we get by analyzing pictures from the internet. So dallied tool has been built by organizing a 200 million images, together with captions, and then combining the images with captions of different captions, which is called contrastive learning, and thereby creating an alignment between text and images. And this was a huge computational effort that was required to get this to work. But it's largely simple algorithms, algorithms that are easy to understand as in takes only a few months to really understand them in depth, and make progress on them. And just scale this up, and the scaling hypothesis that the existing set of algorithms is sufficient with a few tweaks, but with end to end training rather than hand tinkering, new solutions. That is a very powerful thing that has emerged in the last few years. And it's still unclear if the scaling hypothesis itself that is, if you can get two systems that have generality that achieves on surpasses human universality and generality, just by scaling up, it's not clear if that is sufficient. I think that in order

Unknown 32:19
to because that was my question,

Joscha Bach 32:22
to, to get there the full need to build systems that are directly entangled with the world that have real time capability that are tracking the universe that the system is entangled with. And they also need to be continuously learning. Because the world that we are entangled with is an open world, it's one where new objects appear, that we cannot always predict from the past objects. So we will have to be learning all the time. And we have to learn from our own inferences, rather than making them new in every moment. And at the moment, our systems that are getting deployed, have anterograde amnesia, they forget everything. As soon as it escapes their working memory, they forget what they had in their working memory. And we take those things into working memory that are meaningful to store and put commit them to long term memory and build on them. So our world becomes richer and deeper over time, by our own creation. So these are some limitations that don't know if the present class of systems can overcome them just by scaling, or if the need to do something new. And then and most people agree that people need to do a few new new things. But for that, it's also not clear how much of the software stack do we need to rewrite?

Unknown 33:35
Right? Because, look, I'm a non non expert kind of guy. Obviously, I just have had these conversations with a variety of people for the last 12 or 13 years, which I've been very fortunate to have. But at the end of the day, I'm still not an expert in the field developing these things. And I just want to give you a few highlights of things that I have noticed. So first of all, you original Vernor Vinge II and paper from 1992 that the seminal paper that he did for NASA, where he said that within 30 years, the human era would have ended. Well, it's 2022 today, so those 30 years are over, it doesn't seem like the human era has ended or is ending anytime soon. Then you have people like Demis Hassabis two or three years ago. He and I don't know how accurate it is, but I was reading an interview with him where he himself admitted that the exuberance that he felt originally when you know, deep blue defeated the world chess champion, the gold champion of Korea, and so on and so on all these breakthroughs with protein folding and you name it hasn't really paid off at the general AI level at all yet and in that sense Since the progress towards general AI despite all of the narrow AI impressive accomplishments that shocked and surprised many people with their speed, it hasn't been able to translate that into sort of the general AI field. Then you had other people like, for example, Professor Yama, Raman Yampolsky, whom I've had two or three times on my podcast, who is a security researcher in AI, and he said that it occurs to him that for the last 10 years he has been working in the field and stuff and the progress towards general AI has not been as fast as it has been expected. And of course, there's others like Peter Thiel, who have made similar similar proclamations. Of course, Elon Musk is famous for doing exactly the opposite, multiple times. And since 2017, it's always been a year or two, that we would have had, you know, fully autonomous driving cars or full AGI. And yet, that still hasn't happened. So to me, as someone who's been very interested in the field for at least 15 or 17 years, but still not an expert. It looks like we are not moving along the timeline. And it looks like Gary Marcus may be correct and a few others may be correct in saying that, we need 100 Nobel prizes worth of breakthroughs to get from where we are today with our current transformer algorithms to any kind of level of AGI. Is that an overstatement and the wrong impression or where you fall on

Joscha Bach 36:40
that? I don't know that. To me, the issue is that it's so easy to take a sentiment or a gut feeling that you have that is largely the function of the environment that you're in, and try to extrapolate this into the most likely tools. And that's soothsaying, I have the impression that Gary Marquez is an environment that is very skeptical about AI. And at the same time, also very hostile to AI. Because it's seen as an alienating technology that is antagonistic to the interests of the people. Or its maybe this is an echo of the competition between the East Coast media industry and the West Coast technology industry, which are in direct competition for advertising revenue.

Unknown 37:25
You know, I've heard him a couple of times on the podcast, and I asked him specifically if he's a skeptic. And he said, in principle, I'm not skeptical at all, I think it can be done in principle, I think it will be done in principle, I just don't think that we are there yet with the tools or the methods or the methodology or the principles that we need to get in order for us to get there. But in principle, he didn't see any reason why it couldn't be or wouldn't see

Joscha Bach 37:51
that carry through truly believes in his position. And I don't quite understand why he does, because it seems to be the same position as he had in 2003. This was a very reasonable position to have, which means that the end to end train learning approaches are insufficient to get to the kind of AI that we need, and that we need to enhance the models with the combination of symbolic approaches. And now, I think this position is not a very good one, because what deep learning systems are doing is not an antagonism to symbolic systems. Deep Learning is a programming paradigm this program is offering a dime is basically to make space of programs searchable. So you people don't have to write the programs by hand. And the main way of doing that is to express the programs in a differentiable way. Because most of the work algorithms that actually work for search follow gradients. So this requires that you have something like a continuous space of programs and the recasting of the problems that you cannot solve in a symbolic way, which is the majority of them has to happen in such a way that gradients can be discovered. And there is not an obvious thing that you cannot do in this differential paradigm, because it's at the end is just writing programs, you can write arbitrary code using tensor flow, there is no limit to what the deep learning community is doing. There's also nothing religious going on within the deep learning community. It's not like the any lab which says, I'm not going to use this method because it's too symbolic. But most people that work with deep learning fear that all the shortcomings of deep learnings have been solved with more deep learning not as less. So if you really need to use symbols, you can get the system to discover the need to use symbols and find a solution for it. And it seems to be obvious to me that GPT three is able to perform symbolic computation. Right? It's it's meant to carry macrocystis deep does language models do not learn semantics? That's not strictly true. You can obviously ask the system to perform certain transformations like sorting In a string in a particular way, and it does that for you, or it's able to translate for one pole in Anchorage and the other, how is that not semantics? And the counter positions that come against this seem to be often more religious like a notion of symbol grounding. That seems to be superstitious To me that is not borne out by the philosophy that actually works. Gary has announced that he is going to write an article about don't look up in the context of EDI. And I find this curious because he is basically the one who's going to bet the people who think that the video is going to hit that they will be normally mediocre. And I don't know whether that's the case, I just don't know. I think that Gary might be right. And many of his objections that, for instance, they learn language or models, or learning, symbolic operations, compositionality, grammar, analytic operators too little and too late, later than video where they learn them as the long tail of style, rather than at the beginning like we do this. This is correct. And the question of whether this will be overcome by adding more data and tightening the algorithm or tweaking the loss functions? Or by having a completely different approach? This is an open question. I think that most people in the field, not all of them would agree that fundamentally different approaches could be necessary. Or if it may have been helpful, it's possible that you get in a brute force favors the present algorithm to a solution. And let's not forget, once you have a solution that is able to write programs for an arbitrary problem, right? Why would you need people to write the next generation, maybe you just need to specify the range in which you want to search for it. And what we are looking for is systems that can search more efficiently over the space of possible solutions. And in many ways, this is what's happening right now.

Joscha Bach 42:00
So I feel very hesitant to make any bets against certain technology. And what I noticed in when I made a small Twitter survey to us among the people who follow me who are generally quite optimistic about AI, whether they were surprised about the advent of systems like AlphaGo and GPT. Three, and daddy, the vast majority of people who follow me, are as surprised as I am. They thought this would be further out. And to me, this means that these technologies are under hype not overhyped. And this is something that we forget why it is the majority of people who are knowledgeable about the field and follow it are surprised by the pace. Of course, we are taking the scandalous the interesting statements, and like Coatesville predictions of them, we would all be applauding, because they are the one that our cultural chatting points, we take them very much into our public attention. But the majority of people have always been quite skeptical. When I started in AI I haven't met any professor would dare to say that they think that AGI is possible in our lifetime. And the main goal of trying to understand the human mind and consciousness and intelligence by pursuing computational methods was something that was seen as an outlier while I was studying. And while I was working in Germany, and for most people, it still is. So when you ask people, when is AGI going to happen? And you were in Europe? The answer was almost certainly never. And when you were in Boston, the answer was in 30 years. And when you were in Silicon Valley, the answer was in 10 years. And this hasn't changed that much.

Unknown 43:46
I remember I did the last interview with Marvin Minsky, perhaps before he died. And he was one of the skeptics. And the reason why he was so skeptical is he told me that he didn't know a single person almost who worked on AGI in his opinion, all of the examples that I gave him from, you know, deep blue to deep mind to all of those examples that we know very well. He said were nothing more but examples of narrow AI. And he said that in his experience, more people worked on AGI when he was actually actively working in the field. Back in the day, then there are today. And, and to be honest, I was kind of flabbergasted. But when he said that, given that he was referring to the 70s and the 80s. So I couldn't get around to the thought that back then there were more people working in AGI than then narrow AI compared to today. Because he said all the investments we see today and all the numbers and 1000s of people working are all doing narrow AI. And some people have pointed to me afterwards that I did that interview almost like 10 years ago, seven or eight years ago. And many people have said, well, Minsky seems to be right so far, isn't he? And I'm like, I don't know for for a non expert like me, it looks like it. But but maybe I'm missing something. What do you think? Are we putting more and more effort now into general AI? Or is it still all Nero AI with the hope that that would scale as you said, yourself to the level of AGI because one of the criticism I heard from some computer scientists is that there is this presumption that narrow AI would lead us towards general AI. And the example they gave me was like that we presume that presumes kind of scalability or linear linearity between narrow and general AI. And they said, Well, we've made a lot of progress. But we're making progress in the wrong paradigm. So it's like saying, Oh, look, I want to go to the moon. And look, I've climbed all the way to the top of this tree. So if you look at it, objectively speaking, today, I'm so much closer to the moon than I was when I started a few years ago, because this is a 300 foot long, great pine tree. And I'm all the way to the top now. But they're missing the fact that we need a whole other paradigm to get to the moon. Because really, we cannot get to the moon by climbing up this tree of narrow AI.

Joscha Bach 46:32
Minsky was part of a different era, he was part of the modernist era of AI, and also science, which entered arguably for most of the scientific disciplines in the 70s. And when he started out, he started in your discipline. In a time where new disciplines were regularly started, a few doors down. Chomsky started Modern Linguistics and coons invention of normal science also happen at the same time. So when Kuhn wrote this, and invented this concept is poetic multi concept. He did not actually observe this, the normalization of science, where the science becomes the application of methods was something that happened only later. And this paradigm that we have now is that most research happens by being part of a particular team, and a particular environment in which you are taking the methods that you learned during your studies, and you add an epsilon to it, or tweak them. And it's a very different, more technically minded, more application oriented, more publication oriented, more career oriented perspective on how to do science, you largely don't do science because you want to answer questions. You do it because you like the application of methods. And you'll find this deep institutions that are built around this. And maybe that's good, maybe this is the way it has to be. Or maybe that's the way the majority of things has to be. But there are very few Minsky's right now in the field. And that's not because there are no Minsky's in the world. Because the institutions are not welcoming to any new Minsky's that just don't fit in. And just by trying to answer the questions, even in philosophy, you're not going to get tenure. The other thing is that Minsky was very, very smart. And like Chomsky, he was a person who I think did not get to new insights by learning from others, mostly lived in a world where he generated the insights that he needed by himself, and dismiss the objections of others. If they are objections would hold any border, they would occur to him sooner or later, and he would work them into his theories. And he also had a strategic sense that the methods of cybernetics and the methods of neural learning are not the white ones, if you want to build AI, and he actively fought against them. And I think that he felt personally insulted by the success of the deep learning methods. So he told me in his last year that there was no progress whatsoever in the last 15 years of AI. And this means that he deliberately dismissed everything that had been done, for instance, in solving the game of Go and the way it had been done and so on.

Unknown 49:20
Exactly, that's what he said to me to,

Joscha Bach 49:22
if I look at his own theories, like the ones that he has laid out in society of mind, I think what most people do not see is the way in which these ideas are currently being reinvented. And it happens in a way in which the RE inventors of the theories are often not aware of it. If you look at how the transform algorithm is working, transformer is not as complicated as many people might think. It's a relatively simple innovation. The issue with learning is that you when you do this in an unsupervised way you don't know what to pay attention to. So you will look at all the combinations of all the possible elements of the data. And these can be extremely many the more data you integrate the hardest to find the right connections out of the many possible ones. And I remember when I was working on a method to discover grammatical structure and language in the 90s, and research project in New Zealand, I compressed all the text that I had in memory of the computer that I had. And I realized I need a more

Joscha Bach 50:28
principled way to do statistics over what I need to do statistics over. And this is exactly what the transformer is about. It basically learns what to learn. And the method in which it acid is that basically trains an additional neural network for every layer of the neural network that figures out which nodes in the previous layer you have to pay attention to in which context. And it doesn't do this just once. But it has like 96 of these attention hits in every layer that pay attention to the previous layer and learn what to pay attention to in the present context. And this structure is applied in an offline learning paradigm. And so instead of connecting this to the real world in real time, we feed it a big library of images, for instance. And these images are being assembled in random batches, and fed into the system. So it can be parallelized, and then use these attention heads to extract structure for them in a more efficient way. So you can discover structure more efficiently than you otherwise could. But these attention heads are not connected to each other in the same way as they are connected. In our own mind, there is no integrated attention. And the world that we are in is learnable, largely because of information preservation. There are two reasons I think why the world is learnable. Information preservation is one of them, the adjacent frames in the universe that you observe, contains the same information, it just gets transformed by the laws that dictate how adjacent states and physics are correlated, which we call the laws of physics, or there is an underlying regularity in the world that we can discover at different degrees of resolution. So it also works on a coarse grained way. When we look at the built in core samples at that integrate over many features, we still discover loss of information conservation. And this information conservation is a way to make the world learnable. So a continuous world is inherently easier to learn than a static world that consists of disconnected frames, that we have to put together into a story about the universe in our mind. But it requires that our systems are real time that they can actually deal with data that comes in in real time, which we have neglected for the most part research like this happens. But it is not the same one as the scalable models at the moment. The other thing, the reason why the vote is learnable is that the universe that we observe is a hierarchy of controllers. Every structure that is not random, that is deliberate, that is interesting to us, is the result of some control dynamic. elementary particles are in some sense controlled into atoms, atoms are controlled into molecules, very simple, dynamic laws that define some dynamic elasticity in which the molecules are bound from atoms, right, and the cells are controlled atoms. And this is the transition from molecules to cells, something very interesting happens, the super molecule of the cell is extremely more complicated than an organic molecule. And that's because it would not be able to stay stable, it would not be able to anticipate the future to a small degree, which means the cell becomes an agent, and to become an agent to model the future, to have interest over the future states of the world that your own stability, for instance, or the stability of the systems that you're part of. This requires that you are able to model the world with a Turing machine that you have some kind of computer built into you that is able to model an arbitrary counterfactual causal structure such as the future in the cell is the smallest structure in the universe that we're aware of, that encodes such a Turing machine that has one mechanism that allows it to model part of the future so it can prepare for it and prepare itself for the disturbances of the future and do things now to prepare to prevent bad futures for yourself or to anticipate difficult futures and mount a response before that difficulty happens. And this opens up the way for the complexity of life. And then we see more of this complexity happening at higher layers where organisms are controlled sets of cells and societies are controlled organisms. And these control hierarchies is what we are observing. The good regulator theory of cybernetics says that every system that is trying to control something needs to implement a model of what it controls, which says if you do not model the world, truthfully, if you do not model the dynamics of what you're trying to control adequately, for instance, in politics, if you try to not look at the But about really Yes, because makes you uncomfortable, you will not be able to model the world in the right way. Because your dynamics that you want to do that and Alex on the ground. So, in childish utopian view in which you try to exclude the bad from your consideration and so on, is not going to help you, right. And something that you find in everyday life that you in order to regulate effectively, you need to model yourself and the world that you are in truthfully. And if you cannot know the tools, it means you have to model the space of possibilities, but only to the degree that you're able to model the world, you're able to control that efficiently. So if the world is made from controllers, it means that the world is learnable. Everything that is efficiently controlled, has been efficiently learnable. In some sense, this is the other reason why the universe that we find ourselves to be in is learnable, there might be a third reason. And that is there are very few universes that have the properties that allow us to exist in them in the way in which we do. And there are very few types of languages in which such universes can be described and constructed. And we can construct these languages from first principles. So we can also limit the space of universities that you can be in and that are congruent with the observations even further in the survey. And now when we think about these conditions, that we discover that there is limitations to the languages that you can use to describe reality, there are limitations to the universities that can contain us. And that can come up with by themselves and of itself organized. And there are limitations to the structures that you can observe. And there are limitations across frames that you observe, because different successive observations, to which degree are the things represented in the learning systems that we're building right now, it's this is a very interesting question to which degree is the system that you're building able to go in resonance with the world around them and replicate the patterns at some level of granularity that the system can build in some kind of embedding space of meaning that allows us to conceptualize itself and its past to the future of the universe. And when we now look at the present systems, we are seeing that we are getting closer. Now let's get back to the transformer. Imagine we built a transformer to rebuild it to deal with the constraints that we just mentioned. First of all, we want our neural network to or whatever representation mechanism, if you want to use it needs to be more general than the neural network, you want to represent arbitrary kinds of code that runs efficiently on our substrate, we want to have that entangled in real time as the universe. So it's always having to explain a bunch of bits, like we have to explain a bunch of bits and already now every moment. And we do this by going in resonance with the patterns behind the bits. And what we create a certain level of resolution, we can guarantee the best set of functions that we can use to predict future sets of patterns in our retina. And the meaning of these letters on our readiness, the relationship with this car between them. This is what our brain innovate is doing. So how can we do this with an attention based system that is filtering out? First of all, it means that the features in the neural network are no longer just static configurations over the bid configuration in the lower level layer of the neural network that bind them together, a feature now becomes an operator that tells you for given configuration of the world that given state of the world, which changes do you need to make to the world to get to the next state, the features that our mind represents about the world are not static, pattern recognition, they are ways to tell you how the world is changing. And you understand the person is a feature, it says how is this pattern that I observing like Nicola is going to change the next moment while that set of possible changes based on the past that I have observed. Right. And so you are an operator AND operator is composed of many sub operators, operators that describe your geometry, that describe your anatomy that describe your metabolism that describe the ideas that go inside of your mind that describe your motivation. We have all these different layers that interact with each other. And this is all tracked by a system that is trying to establish congruence between all the observations that tries to let reality snap into a single focus a single frame, a connected attention. And this connected attention that binds the features together each of these features with their own controller that enables the interaction between these features of his other features in the world that we are simulating at the same time. This becomes the scene graph. So basically, our conscious attention enables to build a scene graph like in a game engine, that in real time is building a dynamic world that is consistent with all our observations and doesn't glitch that doesn't spin off in a weird way. It stops predicting the vote. And we do this in a way that minimizes the energy that we in information theoretic sense that we require to keep our model in sync with the patterns that we are intending Notice there is a low energy representation of the ad is tracking the contours in the right way. The Minsky had this idea in the society of mind when he said that we have a hierarchy of agents. He talks about a hierarchy of controllers that generate these dynamic operator features that manipulate the internal state of the system. And when he talks about it, we need an attention hierarchy that is truly integrated, not disconnected attention hits on every layer, but a single thing that is consistently trying to make sense of the world from the perspective of an embedded observer.

Joscha Bach 1:00:37
Minsky called that canines it's a different hierarchy of agents, knowledge lines that bind the other agents together, depending on the context. This is what creates the scene graph out of the different parametrized features. And so in a way, I think that future developments of the transformer algorithms are going to rediscover Minsky's ideas of the key lines is just happening because the systems have to go real time. So the next step, when we make these models integrated and consistent with real time, are necessarily going to converge on many of the ideas that Minsky had. And it's beautiful to me that the people that actively work on these things are often not aware of Minsky's ideas that has rediscovered them. It's not, no single nine is required to make these discoveries, what you observe is, if people work in this area, they are weak, discovering the same constraints. And sooner or later, we will get to the same solutions if the solutions were correct. And they do think that society of mind is full of interesting insights. But Minsky assumed that we have to build everything by hand in a way or implicitly, it looks like it's a specification for extremely complicated machinery. And what you're looking for are extremely simple principles for self organization that allow these principles to emerge and stabilize by themselves.

Unknown 1:01:56
Yeah, and I think, in a way, and you correct me if I'm wrong, but in a way, what you described there is sometimes referred to as the framing problem, isn't it? Because we, through millions of years of evolution are born with that frame that you're describing. So we have endless floods of information coming our way. And you have we have learned subconsciously, or instantaneously to discourage the vast majority of it. And just to focus on the most relevant and most important to our survival bits, which create our frame. And we ignore even we even don't even see or become aware of the vast majority of stuff happening around us in data coming our way. And that was one problem that many people have pointed out that those algorithms lacked was that, you know, they're able to get a lot of data, but they're unable to differentiate between relevant and irrelevant one, precisely because they they like this kind of frame that we are evolved with or born with nowadays. And what you're saying in a way is that there has been progress. Some people are rediscovering that Minsky and or otherwise idea about the requirement or the necessity of having that frame, others have called it even being embodied and so on, perhaps. And now we're getting closer and closer to resolving that issue.

Joscha Bach 1:03:27
But I don't think that evolution itself is that important. From my perspective, evolution is an extremely slow and unprincipled search. And we can reproduce the results of that search probably relatively early on, and then automatic, brute force training paradigm. So yes, really, it makes a convergence for us faster. It's true that most human beings don't learn a lot during the life to be largely converge, which means that we already have the dynamics for understanding the social economy of relationships built in our own mind. And then we use that framework, this architecture, this hierarchy of social interactions, to converge this puce from the environment. And this convergence is relatively simple and robust. And what's hard is to be creative to which discontinuities in the search space. That's also hard for the machine learning systems to discover a new architecture. But ultimately, the architecture itself is also just a bit vector that has to be found by exploring the search space. And there are many ways of doing that much faster than creating an organism and waiting until it has children to see whether the creation was successful.

Unknown 1:04:45
Yeah, but but you can't really get out of that mold, I think, because and you you fix me if I'm wrong here again, but evolution is just a function of any entity being in time. So in other words, So let's say you say evolution is kind of inefficient and ineffective and too slow. And we can have all these brute force or other kinds of algorithms who accomplish the same goals much faster and much more efficiently. But they're not outside of evolution, because let's say you create two or three architectures of that type, some of them will survive, and some of them will die, some of them will succeed, and some of them will not. And that's merely of them being a factor of existence within time. So in other words, you don't get and don't, no one, including those algorithms, gets out of evolution. So you have them create it. And then like any other design, that some of them will succeed, and some of them will not. And that's what evolution is about. So maybe you skip a step or two in the beginning, but then eventually evolution catches up with you. And then they either succeed, or fail to adapt and evolve, and some of them will proceed, and some of them will go obsolete, like the dinosaurs. And so in that sense, evolution never stops. I

Joscha Bach 1:06:03
think that the computers that we are building also part of evolution, in the same way as Finch that is building a nest is internet and then is this part of the evolution of technology that defense is using to weave the leafs together as part of evolution, the technology that we're using to weave silicon together and at the crystals, this intricate metrical geometric pattern that allows the crystals to start dreaming, that's also part of evolution, and what evolution is evolving up ways to speed up the evolutionary process. So this is not a big rift that we are discovering now that we have technology, it just means that evolution is taking place on different planes that it's taking place in different realms, and that it has discovered local areas in which it's going to use different methodology to get the results. So wetness, very bite sense, evolution is everything that you're doing. And what I suspect is happening is that the these new technologies allow us to search through the space of possible phenotypes in a more efficient way, then multicellular organisms could do it. The brain is a resonator in a way that is present ating with the world in particular way, using a particular kind of architecture and a particular kind of biological niche. And one of the difficulties with brains is, is many faults. But first of all, the brain is not the original way in which organisms think

Joscha Bach 1:07:35
I suspect that every cell is able to perform most of the functions of a neuron. So an arbitrary cell type is able to send multiple types of messages, chemical and physical messages to neighboring cells. And these images to the organisms, the cells are co evolving, so they can know the functions that the other cells are implementing around them. And this means that they can principle every organism that is multicellular and gets old enough can become like a brain. And they probably are. That means that basically every organism that is made of many cells is going to process information in structured ways, and is going to develop structured agency, but it's mostly going to be very slow, because signal propagation in between arbitrary cells is going to be a few millimeters per second, for the most part. So if you look at plant intelligence, it's probably there. But it's very slow. And given the lifetime of most plants, the plant is not able to extract that much training data from the world to make new abstractions. So ecosystemic intelligence probably takes place on the level of old growth forests or something. And with the advent of animals, particular kinds of innovation where a bunch of cells is wandering about and instead of doing slow photosynthesis, it's eating the organisms that are routed somewhere and do the photosynthesis to drive a much faster metabolism. And then you have the next thing they can enforce, which are wondering about even faster under eating the herbivores. Right, and then you get us at the top of that hierarchy. That requires that you are moving your muscles very fast, you basically want to be able to move the organism at the limit of physics. And this is what our muscles are doing the fastest thing that was possible to implement with the biology that we've got the chemistry that underpins it that is available to it, that needs to be controlled in real time. And for that, the organism has evolved the nervous system, which is a telegraph network. So the brain is not actually just a novel way to compute information and become much more intelligent. It's primarily a way to become much faster. So it's good to telegraph information between cells over very long distances in the organ organism by packing the information into very short high intensity bursts. And that's expensive. So the nervous system takes a large part of the metabolic energy of the organism to make that happen, but it does it now. Will, real time feats that normal cells cannot do. And it also needs to have its own perceptual system. So it's able to perceive the world at the same speed at which the muscles are moving and make plans at the same speed. And as a result, you have now a secondary information processing system exists in the organisms that gets decoupled from the primary from the original one. So we in some sense, probably have two brains, we have a brain that is made out of all the cells in our body that is very slow. And we have a very fast brain that is decoupled from it and cannot really talk to the other one. And that is able to perceive the world at a much higher frequency interact with it at a much higher frequency. This is the situation that we're in. And the technical systems that we are building are, again, magnitudes faster than the newer ones can be. So they also will get decoupled from the way in which we perceive the world like in the movie horror, you will have systems that start out with a frame that is comparable to ours, and eventually leaves the frame in which we exist. And this is because the rate of updates in which you make progress in your models is going to change so dramatically, that you're going to leave the previous system in the dust.

Unknown 1:11:12
You're sure everything that you just said, is absolutely fascinating to me because it connects to the brain and how we think and AI and whether we can learn from one to create the other, or whether we can create the other so that we can learn about the one. And that brings me back to another skeptical neighbor of Dr. Minsky, as you said, a couple of doors back from him that I have had on my podcast. And let me give you a quote from that conversation. And you tell me if you agree with that 10 years later, because this was done in 2013, in a conversation with Dr. Chomsky, that I'm taking this quote from so here's what Dr. Chomsky said, quote, what's a program? A program is a theory. It's a theory written in an arcane, complex notation designed to be executed by the machine. What about the program, you ask the same questions you ask about any other theory? Does it give you insight and understanding? These theories don't? So what we're asking here is, can we design a theory of being smart? And according to Dr. Chomsky, we are eons away from doing that? Do you think that that is correct to be set today? Because based on everything you have told me so far, I would venture to bed? The answer is no.

Joscha Bach 1:12:45
Yes, I disagree with Noam Chomsky, you have great respect for his intellect. I think he's one of the most interesting intellects of his generation, surely, and one of the smartest people of his time. On the other hand, he is a materialist, he deeply believes that something cannot be understood if it cannot be understood Benoit Chomsky, because Mysterion ism. And he is not following the developments of artificial intelligence in any way closely, which is reflected in the way in which he talks about deep learning, or also I think about algorithms, there is a reluctance for him to deeply go into a certain set of ideas that he finds aesthetically disagreeable, at least that's my impression. And that's not necessarily a problem, because I don't think that everything has to be solved by No, I'm talking about other people, too, who have different specialties. And not pointing at myself here. It's mostly an observer, I don't think that I have many ideas that are deeply original. Most of the things that appear to be my deepest insights are ones that I realized that they have been at many 1000s of times, and often 1000s of years ago by people who were smarter than me, and just rediscovered that. And that's delightful. But it's not I don't have any claim to original insights or the creation of new disciplines or anything like Noam Chomsky, so please don't take me to be disrespectful of his tremendous achievements. But to me, and our algorithm is the representation of a set of deterministic transitions, which is everything that a regulation system is doing deterministic transitions in a way that allows reasoning about it. Reasoning is a way in which you can improve the set of deterministic transitions that you perform to execute a behavior including a mental behavior. And to do that, you need to build it in such a way that it becomes systematic and compositional. And this means that you are rhythm gets expressed in language. And this language can be more or less strict. And I suspect that the language in which our own thinking happens is relatively strict. It's a language of thought, if you don't notice the language of thought for the most time, because it's formed before our self as an adult, because ourselves our perception of our conceptualization of our ability to do abstractions, and create a coherent model of reality, rests on this language of thought. And the only notice this language of thought, If it breaks, this language of thought is not English, or German, or Latin. It's much deeper to this is the language in which we write programs. And it's the language in which I observe my children to produce English or German sentences when they carefully construct them, because they don't really know how to express their thoughts in the language yet, and to observe that they know exactly what their thought is, they just need to translate the thought, right. And you see also that this execution of the translation process happens in a language that they have built for themselves. And this is the language of thought, in this structure is, is one of the more interesting things to me right now how to build systems that discover a similar language of thought. Because this language is not learned, it's discovered, which means there are intrinsic constraints in the way in which we can build models across all the domains that allow us to develop a global language that enables the mind to talk to itself about everything into all of its domains. So you can imagine that the mind is, in some sense, like the Roman Empire, that has colonized all the possible information processing in the brain into a single cohesive institution. And this thing is enabled because you are talking the same language everywhere, and you're using the same accounting everywhere. So there has to be a global reward infrastructure implemented in the brain that is rewarding components for contributing to the greater whole in a consistent manner. And there needs to be a way in which information can be transmitted between all the parts, so it can be understood by all the parts.

Joscha Bach 1:17:11
And this is a level at which I would agree with scary Marcos when he says that this is under researched, and current deep learning. But I'm not sure that it does not fall out of the current deep learning as a side effect. So to the degree to which the systems are working to the degree which to which they are learning to do arithmetic, and how to write programs and to translate programs from one language to another, or to translate English into German in an automatic fashion, and to map the linguistic concepts to movement of robots, or to vision model. This is the degree to which such a cohesive language of thought is being discovered in these models. I found that when I played this deli, open AI has, thankfully given me the opportunity to do so that it has a number of interesting shortcomings. Some of those are what you would expect. For instance, if you want to get it to draw upside down faces, it gets into trouble because it hasn't seen enough of them. Another thing might be because of the nature of the diffusion models, it's very hard to produce cameras. So for instance, if you tell it to produce an animal that is the result of merging the torso of a human being with the back of a horse, and it's easy for gptc to do, it's able to describe to you that it has only one head and the head is human. So it's able to construct a center. But for the vision model for Delhi, that's very hard it typically ends up was once you have named the human and the horse, it has already associated the human and the horse, and it doesn't know how to get rid of the parts it doesn't want. So it usually ends up as a horseback rider. It's very hard, if you want to mention the two components of a central otter still converge to the center. That is maybe an issue with the diffusion model, maybe we need a different approach. But I don't know that. But another interesting difficulty is that it's not able to get relations, right. It's able to have objects, so you can ask it for any kind of object, and it's probably going to give you a good rendering of that object. And it's also able to get the context of the object. So if you ask it to render Kermit the Frog, in the movie Blade Runner, you get an amazing result. Basically, every time it's completely able to adapt the style and the context and so on to scenes like this. And if you ask you to render a man pointing at a woman, you get a man and a woman and you get pointing. But it's rarely right. And that's because it doesn't understand binary relationships yet. What it basically does is it treats the linguistic input and it uses for that GPT three, as a bag of words. So it's addressing all these concepts and it knows from having seen all these different concepts of different contexts in which they they usually go to get together. And this is also the way in which it fit them together. And it's at this point, not really able to use the language that you give it a secure to affect this non standard ways. So one thing that people have discovered is that it's easy to render a horse, and an astronaut and an astronaut riding on a horse. But it's very difficult to get the was riding on the asteroid. If you want to do this, you have to tell the system that you want to have a walking astronaut that is carrying a horse. Because these concepts fit together in such a way that it has seen the probabilities before in the images. So there is no deep connection yet between the visual grammar and structure, the semantic structure of the language model. But the visual system is able to render this so it knows how to display this. It's just at this point, the interoperability between those two systems is not there, because the language of thought does not properly translate across the domains. So this is a very exciting development to me. And I'm suspect that under the hood, there are many improvements that open AI and deep mind and Google and Baidu are currently working on to make their respective models because they all have clones of this technology running at the moment. And they're also open source models like Delhi mini from hacking face that you can try, which was a much smaller training set, and let's compute it's still very impressive, that are trying to improve on this and find solutions to these issues.

Unknown 1:21:35
So do you think that those do give us any insight or new understanding of how intelligence works? Because in a way, Dr. Chomsky saying the same thing, which will Dr. Minsky was saying, which was like, you need the theory of mind? Or, or is that correct, and you don't have any new theory of mind that provides that understanding that enhances our understanding and gives new insights into what intelligence is. And according to them, at least, you need that as a requirement in order to get from narrow to artificial intelligence. And as long as you don't have that you won't get there, according to them.

Joscha Bach 1:22:25
This is an area where my own thinking has changed. When I started out and wrote, microsite and the stable. I thought that what we need to focus on is architectures, we need to focus on the detailed architecture of the mind, also, because evolution equips us with such an architecture. And we will be able to develop the understanding of the architecture by thinking about it from first principles like the architects that we are, and it's a very satisfying way to think about it. And it also runs into difficulties where you get at the boundaries between modules or ethical required flexibility or getting all the details, right. And I remember having a discussion Vizio Schmidhuber, I think the first time I met him at an AGI conference in the Googleplex in the early 2000s. And he told me that he doesn't necessarily believe in the need for constructing architectures. He thought that what would get us there would be the focus on learning algorithms. And I think that he's right. And it was a gradual and slow process. For me to get to this perspective, what is a model, a model is a set of regularities that we find in the world, the invariances, the laws of physics, for instance, at a certain level of resolution that describes how the world doesn't change. But it's the same as these other things that remain constant. And the state, the state of the model the state that the world is in. And once you combine these constraints and the non state, you can predict the next state of the world. And this means that the model is encoding a bunch of parameters that contain the state, each of these parameters is one variable that the world can have. And each variable can hold a set of different values that can be discrete or continuous in a certain range. And relationships between these variables. And these relationships are computable constraints that tell us based on what this free parameters are in right now, what is the next state of the world what is the next set of constraints on the free parameters and then in the world, and for this, we need to have a working memory, this working memory holds all the free parameters, and we have a long term memory that holds all the relationships that they can have all the fixed things, and some things that are currently not observable, but that we want to have in the back of our mind and want to swap them back in a state of the world with arbitrary historical events. For instance, right this framework of a world that is represented in the mind as a set of free parameters And computable constraints between them. That's in terms of the Boltzmann machine. And that idea was discovered very early on in the history of computer science. And it turned out that the original Boltzmann machine is very hard to train because finding all these possible relationships between them is an intractable problem. So people started to constrain this Boltzmann machine by making lateral connections impossible and making mostly vertical connections. And then you get to, you will networks in a way that are organized layer by layer, it's simplifying, but there is a intellectual development that you can see when you zoom out in the terms in which these models were built. And then people realized, we need to make these neural networks recurrent, we need to introduce ways to have connections in which you can make backward predictions, and you have circles and circular processes playing out in there. And this is something that we only discovering gradually how to enable the training of these things. And once you build systems like this, they can start to dream, which means that they are exploring the latent space of possibilities. A dream happens at night, when you disentangle yourself from the sensory apparatus, right at night, you dissociate from the constants of your motivational system, have the concept of your organism of the world around you have the sense of the constraints. And instead, what you do is you take all the constraints that you have learned. And you explore the space of possibilities by varying the parameters, probably mostly randomly. And let's say you do a data augmentation, you create new perspectives on the things that you already know, and learn whether that makes sense. And in this way, you discover new constraints. So there might be a use in dreaming the dress by exploring the space of possibilities, or what you have already learned. And in many ways, what a system like delito is doing its dreaming. You give it a few constraints by the prompts. And then it's going to dream this in these constraints, possible solutions, right? It takes all the constraints that are encoded in the model. And then it follows a gradient to an optimum with capturing the gist of the prompt of the text based parameters that tried to pull it into a certain region in the space of meanings. And there is a perspective of intelligence that says that it's the ability to dream in a very focused way, in a way that is very tight and as consistent as possible.

Joscha Bach 1:27:27
And we are closer to building such streaming systems. And I think it would be amazing if if Chomsky would update on this and observe that the systems are multiple generations beyond what she thought predicted to be impossible, because the given approaches?

Unknown 1:27:45
Well, speaking of models, and speaking of intelligence, let me grab that line of reasoning because it connects us to some ideas that you shared with us last time you were here. And maybe we can push it further a little bit this time. So last time, you said that the ability to make models is what we call intelligence. And then you shared with us that, of course, reaching out your goals is being smart, and picking up the right goals is what's called being wise. Now, you also observed somewhere else in a speech that I watch that you gave somewhere that very intelligent people are often neither smart nor wise. Because too much intelligence is often an attempt to make up for the lack of wisdom. So I just wonder, in personal terms, where do you feel you fall on that? Are you the kind of the intelligent one? Are you the very smart one? Are you the wise one? Or are you just the smart and intelligent one that makes up for the lack of wisdom with extra intelligence?

Joscha Bach 1:28:57
I would advise functionally, adequate and smart and well adjusted people to consider from time to time what would your show do, and then laugh hysterically, do the right thing. And neither smart nor wise, nor am I super intelligent. So I know people who are actually smart and to cryptocurrency scams and or that lead companies in an extremely efficient way, structure projects in extremely efficient way I know people which are very wise, and which lead a life that is satisfying and fulfilling to them and don't distract themselves with things that are not conducive to that. And I know people which are extremely intelligent and that are able to solve problems that are extremely hard for me to tackle. And I'm not terribly envious of them. It's because it's just the way it is. And I'm grateful that there are people which can do the actual hard work. of keeping the word going and making the progress that we are seeing. what I bring to the table is a particular combination of things. So it's, I found beyond the point where I able to serve to seep into the idea that my abilities are unique, or that they are healthy or useful to every circumstance. It's just that I project the world in a particular way that not many people in my position projected into. And there's different angles, different projection sometimes brings new insights to the table. I am very stubborn, I have no respect for authority. That's not because I made myself like this. It's because I'm born without it, and there was not able to deduce it. And you

Unknown 1:30:46
don't like right angles?

Joscha Bach 1:30:49
Yes, well, I do like right angles more than my father does. Because I tried to construct things that work in my own mind. And if you want to build a regular structure in 2d, the Euclidean grid is one of the easiest solutions and one of the most straightforward ones. And you can also use triangular, exactly with grids and so on. I like them for aesthetic reasons. But they are sometimes harder to deal with. And in some circumstances, they're not the right solution. So I'm not obviously opposed to them, I just want to I don't want to live on a rectangular grid that somebody else builds for me.

Unknown 1:31:27
Very interesting, and And what about your values? Where do they fit about the unique within that kind of bag of unique contributions that your show brings to the table, because you told me that value is a belief without a prior. And it does not follow from anything therefore. So what are your values, your unique Yahshua values that you bring to the table then.

Joscha Bach 1:32:00
And all of my values are unique, the space of possible values is limited, and I can identify my own coordinates in it. And what I noticed when growing up is that I grew up with certain innate values, so to speak with priors of how I think interactions would work or people's would work. And some of these priors are atypical, for instance, I have a very strong focus on autonomy. They believe that my relationship to the greater whole to what religious people call God agent on the next level that you're part of a network trying to implement with others, is an autonomous relationship. It's one where I have a unique individual relationship. And this individual personal relationship that I have to the sacred allows me to love other people by discovering their own relationship to the sacred and shared sacredness. And there are other people which prefer to have the values of the group over the autonomous values of the individual. And I think that these people are randomly fascists or socialists or communists, because their values will depend on the values of the environment. And they will see the the belonging as the primary value, the loyalty to the group values as the primary thing. So to some people, what I do, that I see the world in this autonomous wherever I individually, try to find out what is the sustainable world and build my alliances, based on the same autonomy to an autonomous relationship to the sacred is alien to people who are parts of pipelines. So to me Love is the discovery of the sacred and the others, so their own agency, and for other people, it's the degree to which they discover that the other is possessed by the same hive mind.

Unknown 1:34:00
Yeah, I can totally associate with that myself, my friend, you know, because I kind of have tried to, you know, when I was in the army I was, my blogging name is Socrates, you might know. But that's not the name I picked for myself. That was the name given to me when I was in the army. And in the army, when you're a Socrates, that's not a compliment. That's a derogatory insult. Because trying to be autonomous, trying to ask questions, is not a smart strategy towards survival. And so, yeah, I can totally associate with that. And I think, of course, this is self serving explanation, but I think most people go for the easy way out, which is to say, they go for the for embracing the hive, the hive mind, and there's many benefits and of course, there's many rewards for doing that, and there certainly is a price for not doing that, but but the paradoxical thing here that you told me is that you told me also last time that while now you're talking about the autonomous search and all of that last time, you told me that you might be writing a book on the hive mind of our civilization. So I wanted to get an update on that, first of all, if you've had the chance, or not to make any progress on that project of yours, and also, how do you square these two things now that you just talked about autonomy, and on the one hand, and on the other hand, you're where you were supposed to be, or you were considering working on a book about the hive mind of our civilization,

Joscha Bach 1:35:39
I do have a lot of material on it. But I think in order to do long form writing, I need to take time off, which I don't know how to do right now. I also have empathy for the experience that you had in the military, I found that my own experiences in a military context and so on which I only had as an adolescent in Eastern Germany, were detrimental because I didn't have the maturity yet at that point to fit into a world in which I myself was a pacifist, and would not be able to understand the need to maintain military and so on deeply enough, and think that it's not that hard to deduce that many circumstances, but obedience is necessary, just to make certain thing happen. And sometimes, it's also necessary to obey the commands of somebody who is less smart than you are, or has less deep understanding than you are, because the drawbacks of the autonomy are higher than the drawbacks of having slightly sub optimal control. And so this coherence is itself of a very valuable thing. On the other hand, we are not the smart home unit, we are the programmable home unit, we have smarter, smaller brains than many of our ancestors. Because I think that they are no longer necessary once you are domesticated,

Unknown 1:37:02
and our brain can shrank by 10 15% Since the last 10,000 years to Yeah,

Joscha Bach 1:37:09
and of course, it would be wasteful to entertain such a large brain of most of your decisions are made by others for you, and you just need to converge into the niche that society opens up for you. And so in a way because I don't didn't fit into the society that I was born into communist Eastern Germany, when you were born in an artist's family, I needed to find my own way to build a society. In my own mind, that made sense to me. And this has continued and many ways as you get older, you arrive many of the things that happen in society around you anyway, and you realize the wisdom of the institution's around you and of other people and of schools of thought. But there are also many ways in which you will still remain independent on autonomous and have your own thoughts. So for instance, it appears to me that if you read the Bible that the Christians have dramatically mistranslated many of the things that are being described in the Bible, like the first book of Genesis, is being interpreted by the Christians in a way that epistemologically makes no sense may be interpreted as this crazy story of the creation of the physical universe by a supernatural being in seven days. And that's a very weird story, because I think even a precocious teenager can discover that it makes no sense. What's the right interpretation? So there can be no evidence for such a story, right? It's the mythology cannot be literally true. And the entities that are being described in Genesis are not entities of physics, there are no light and darkness in physics, they only exist inside of your own mind as a perception of physics. And there are no animals and plants in physics. They exist as patterns here to distill out of physics, there are no names to these plants and animals, there are things that you give to them. So I think what's being described as the creation of the universe, where the universe is created out of patterns inside of your own mind. So this whole thing starts out with this describing that the word Elohim, which is I think it's the creative spirit is hovering over the waters, and the world is too verbal and the formless and void and then it creates a firmament pit that separates the waters above the firmament from the waters below. Just makes no sense, right? It's very weird. And I think what happened here is a translation error. What the borders actually are a substrate. It's basically you have a fluid substrate in which you can create structure and initially there is no structure. And so you have the creative spirit hovering over a dark substrate that is formless and void. And the first thing that the creative spirit over the substrate then you will substrate in your own brain that was not named in the story because the the role of right means was not known and the functionality of neurons was not known is how to create intensity and how to create contrast from the intensity between things that are intense and things that are flat. And then the next thing is that the intensity is associated with light is the color of day. And the lack of intensity is associated with this black was darkness is the color of the night. And this is the first phase is once the creative spirit figures out to spark light out of the neurons how to create intensity and contrast and draw the intensity out of the dark, it's able to represent differences in the world. And the next thing which is covered is to arrange these differences along extensions. So it gets directions, and it gets space. And it discovers two types of space, it discovers the plane, which is associated with the ground later on when it tries to understand the map the world. And you see children building things on the ground at first, right when you have a toddler, even when they can start to walk, they typically don't build towers, they first arrange things on the ground flat. And then you begin to structure the space above the ground, right, this stone, the sky, this thing that reaches to the firmament. And then you separate this domain of space, from this domain of ideas. And you dedicate one of the spaces to describe the physical world around you.

Joscha Bach 1:41:41
If there was stuff in space world, we don't have other spaces in our own mind, for instance, the spaces of our emotions, hypothetical spaces, and spaces of sound, and so on that are orthogonal to the space in which we place things in the world. But this one particular mathematics that our mind is discovering. And once you have this space of the world, the space of stuff in space, this extended world and the realm of ideas, we have rest extends our address cargo tents. And there's reference to these two worlds in Genesis one. And once you have these two worlds, you discover all the materials, we discovered the liquids and solids and the organic shapes. And you use them to construct plants and animals and to give all of them their names. And once that is happening with creative spirit, is discovering that the purpose is control, it discovers the organism it discovers the agent in this world that needs to interact with all these plants and animals and liquids and solids and ferment and so on. And so it creates another agent in its own image. But it creates it as man and woman as something that thinks of itself as a person. And we noticed that around the age of two and a half, three, you have this emergence of a consistent first person agent that no longer experiences itself as the creative spirit that creates the universe in its own mind. But that conceptualize itself as a person that is playing inside of that world. And is not able to leave that perspective for a long time. And until that happens, the creative spirit is happening in the background and is used as a perceptual module that helps you to make sense of the world and solve creative tasks.

Unknown 1:43:28
Wow. So so you're blowing up my mind with this kind of Francis Bacon's bacon esque theology slash metaphysics, if you will, maybe that's how I feel about it. But what's even more fascinating to me is, you know, I'm working on story for the last couple of years and the importance thereof. And this smacks terribly of like my thinking on story in many ways. It reminded me even to the saying that the universe is made of stories, not of atoms. So I wanted to ask you, if, or how story, the idea of story has any relevance to what you just said, and maybe even to AI and to everything that we've been talking about before, because that's what kind of I that's kind of the space, or the frame, within which I've been kind of locked in for the last couple of years, if you will.

Joscha Bach 1:44:31
I think that the story is, of course, a limitation because it is deceiving you into thinking that a particular path to the space of meanings is the only right one. And I think that the stories would be understood as a tool of exploration. And when we use this tool of exploration, we have to realize that the past of the story offers many branches, which we neglect in order to make the story self consistent and round and meaningful. And so the story of becomes a fable or immerse. But there's value in the fables and the myths and VRF. And understand the reasons why the fables and myths are being selected to be presented to us, you should not make the mistake of going for the fable ourselves. So for instance, the idea that we built thinking machines and the Thinking Machines will take over is a very obvious story. Right? And if people and it's meaningful, and it's interesting, and so we ask ourselves, when is the story going to play out. But maybe reality is more complex, there are unforeseen things. When we look at the science fiction predictions of the future, they typically take the same ball that as they were in like in the 1950s. And then they change a couple of variables only. And they get a future that looks completely implausible to us that now live in this future. Because it's very difficult to predict the interaction of all these new objects. That result is the emergence of new dynamics due to changing a couple of variables. So our ability to create stories is a useful tool. It's a useful tool to deal with the overwhelming complexity of the world. It's like playing the stock market, you don't play the stock market all at once you play a few stocks based on a particular narrative. And you try to pick one that the others didn't. But you will, when you play the stock market, you're aware of the fact that your narrative is not reality, and it's only showing you a very small window into reality. So this, for me is a useful perspective, one story.

Unknown 1:46:34
And you know, what's been useful to me is another quote from you, that I'm gonna paraphrase because last time you were talking about meaning, but I'm going to paraphrase this, what you said last time about story. So here's like the paraphrase of yours. To me, story is like the ring of Mordor, you have to carry it, if you drop the ring, you will lose the Brotherhood, that's to say, The Fellowship of the Ring, and you will lose your mission. So you have to carry it, but very likely, if you put it on, you will get superpowers. But if you get what you get corrupted, because really, there is no story. And you will get drawn into a cult, which you will also create. Now you're talking about meaning last time, but I'm taking this and translating it into story. And that's exactly how I feel about it right now. And I find your way of putting it as the ring of Mordor very useful. Because it's super, super, super powerful, is a way of looking into the world. And explaining pretty much everything through story. But of course, you pay a heck of a price for that if you're doing that. And you end up with a story at the end of the day yourself about story. And you may end up being a prisoner within that story. So the question then I'm facing or the dilemma that I'm facing is like, How can I? Or is it even possible for me to even tell that story of the world through story, without paying the price because I want to have my cake and eat it too. I

Joscha Bach 1:48:15
think the best approximation that you can make is to try to tell all the stories, to read all the stories to understand all the stories, not a single one, not a single family of stories. Take the stories that you take to be the most incomprehensible and the most offensive one, but they're still trapped by people who are smart, maybe smarter than you and try to understand them try out to make understand how they make sense try to understand how people at different times made sense of reality and assume that they were not stupid that they were not confused, that they may be telling stories too confused and stupid people but that the underlying theme under the story and the intention creating the story was rational. And once you do this, you will open up a very large zoo of possible stories and possible narratives. If you take for instance, the story of Adam and Eve, there are multiple interpretations that make sense that are very different from the usual Garden of Eden origin story, because there was no Garden of Eden that we ever lived in, in which all the animals were vegetarians, there was no suffering, right? This in this sense, the Garden of Eden never existed. But there is a phase in our life where all animals are vegetarians, and there is no suffering and that's when we are in love. happily in love. And maybe this is describing a period in one's life period in the life of Adam and Eve. After they were a couple after Adam was Hoover's list, which didn't work out she's sometimes referenced as a demon or something strange, or is the first attempt at oh god to create a woman that was unforeseen, not successful. But anyway, this one didn't work out. The thing was it worked out until the thing This snake happens. And it's not Adam's snake. And it creates trouble. It basically drives them out of paradise. The world is no longer unipolar, good. It's now something that is much more complicated. Everything is negotiable, one of their children will end up being a murderer, and not die, but also populate the world. So a substantial fraction of the people on the world are descendants of a murderer. All these things are happening. And in reality, then the reality is the result of this complicated negotiation. It's cannot be eaten, because it is not organized in that way. And the other perspective that we can have on that story is a slightly different. The world in which there is no suffering a world in which there is no unnecessary death, in which there is no pain. That is a perfect factory farm. You only get this garden of Eden, if everything is completely domesticated, even the humans living in it. And what has been discovered by Adam and Eve is the food that you should not taste. It's the insight that you are free to defect from the factory farm that you can choose your own allegiance. If you do not have to belong to the hive, you do not have to submit to the will of the gardener of the owner of the factory farm was planned every process perfectly. So Adam and Eve discover freedom, they discover the ability to choose their own legions, and they escape from the garden, and they're not exterminated. And now they're driven by this mad hope that this was the plan all along, and that we are free to construct an alternative to the factory farm. And there are basically two perspectives on this either Eden is our future, which means the factory farm is our future and we get there by lobotomizing. ourselves

Unknown 1:51:53
as David Pierce's argument for the hedonistic imperative, yep.

Joscha Bach 1:51:57
And it's a perspective that a substantial part of Christianity has. But of course, it's self interested because Christianity was designed as a tool to subdue medieval peasants, and to discipline them is the promise of getting paid for their overtime in the afterlife. And in between that would be meek. It's a tool for Mr. domestication of the vast majority,

Unknown 1:52:18
many transhumanists are of that of that thinking today, especially the vegan transhumanists.

Joscha Bach 1:52:24
Yes, it's a very romantic way of thinking. And I am appalled by the way in which evolution works, I'm appalled by the suffering. But also realize that the suffering disappears once you submit everything under a single will under a single agency, which means you have to give up individuality, this is probably the price that you have to pay. And in a way, this story is hidden in the Garden of Eden myths, I don't know to which degree it was put in there exclusively, it seems to be following it for me if I think about the story for a little bit. So I think that the Bible has a number of very interesting philosophical insights in it that are hidden by a single simplistic, and obviously wrong interpretation that is deeply intellectually and morally dissatisfying if you take it as just the indoctrination of Christians. And I suspect that these stories are basically broken from larger library of insights that people got to by thinking more deeply about reality than Christianity allows it lay people to think about it. And our civilization is the result of that we still in a way, have this null hypothesis of an irrational religion, that builds an ontology that doesn't work, in which we think that we are in the physical world that is possibly created by a supernatural being and have supernatural thoughts, souls, instead of realizing that we live in a dream that is playing out by in the machine in the mind that is existing on a higher plane of existence, that is the brain in the skull of a primate. What's very interesting to me is to see the possibilities for existence at all. That was one of the biggest insights for me in the last year, I think. And that is, if you think about existence, it's so shocking to me, because I used to think that a non existence should be the default, right? I wouldn't be surprised by anything not existing at all. If something exists, the question is what has pushed this Turing machine into the void and implemented the laws of physics on it no matter no matter how liberal they are, right, what is it? And then I realized that non existence is not the default if you don't have any bits to specify it. If existence is possible, at all, which it seems to be, then you have to specify non existence explicitly, in the same way as zero is not nothing To specify zero you need to have a number system first. If you have a complete number system, you have piano's axioms, you can build anything for pianist axiom, because they are Turing complete, right to give rise to computational system that you can use to build an entire universe. So zero itself requires that you build the structure first, into the nothingness. Now, if you are trying to infer structure from nothing from Apery, already, you're looking just as the realm of all tautologies. So existence is possible. And this means that it's possible that universe exists. And maybe it's possible the universe doesn't exist. So the universe is going to have an existence in a non existent branch. You're obviously in existence one, right. But this is what you get. If you have no prior if you cannot specify any rule for the universe, we need to make an assumption being able to construct the universe in the language. If you give up this assumption, then we cannot perceive anything, we cannot think anything, we cannot reason about anything, there can be no structural relationship whatsoever. So it's a relatively mild assumption, because there is no alternative to having languages. So the you have to take the possibility that the universe can be described in a constructive language into account. And now what we can see as a result of the philosophy of the last century, that all the languages that have consistent semantics are computational languages. The languages in which we do have is infinities and continuities, the hyper computational languages don't work, they lead into contradictions and your semantics. So this was the discovery of girdle and Turing, that you cannot build a computer in classical mathematics that runs classical mathematics without breaking, you have to restrict yourself to computation to constructive mathematics. And constructive mathematics is all the finite automata. Now let's make a universe from all the possible finite automata a way to think about finite automata is like lists lists wizard, or lambda calculus, it works by Search and Replace. It's basically a way to describe the world as a set of bits. And in this bit vector, you will define operators that look for certain pit combinations and replace them by different combinations. These operators, in some sense, describe the neighborhood in which the operator fits.

Joscha Bach 1:57:19
Right, so in this view, we'll have a defined operator in which you define which operators are going to be permissible. Because let's wants to build a Turing machine, a Turing machine is a system that goes from one state in exactly one other state with deterministic, right, it has only one possible continuation. Because if you have multiple continuations, which one are you going to take, there needs to be a rule, if you only have finite the many bits available in that you have managed to rent from the universe, because you're exploiting some big entropy gradient. So the computers that we are going to build are largely Turing machines. And if you don't want to build a Turing machine, what you can still build is a non deterministic Turing machine. The non deterministic Turing machine is not randomly selecting one of the branches, it's actually going into all of them. But these branches are not talking to each other anymore. So, if you are embedded in the non deterministic Turing machine, you will go down one of the branches, and you will not know what plays out and the other branches could call this also multi way system. So if you have a set of bits in the universe, where multiple operators fit, the universe is going to branch into multiple variants, right, and this means that the universe is going to pay out and if you are embedded into it in largely unpredictable ways. But if you are a system that wants to control its own structure to wrench dynamics from the ground state of the universe that are orthogonal to it, basically your brain that works differently, even if you carry it around between Berlin and Boston and New York, and San Francisco, it's such a brain require substrate independence, it just requires that you are abstracting from the subsidy to find some regularity, which is the same. And the universe itself is P don't have a limited set of operators. Because as you remember the universe we want to encode your zero bits without any priors, we don't want to have anything that is necessary to bring it into existence, it should just happen by itself. So it's going to be all the operators because you don't constrain them. So every possible matching between big patterns that define and find a neighborhood that the bit pattern fits is going to lead to something else. Now under which conditions we get regularity, something predictable, where all the different branches cancel each other out and you get a merging of branches again, where basically different trajectories lead to the same outcome. This happens for instance, when you look at particles, particles are the set of operators that are self replicating that are reproducing their own neighborhood, but sometimes at a slightly different position, and a different position is defined by by projecting the neighborhood relative to the other neighborhoods in a consistent way. So in some sense, you will get some operators that are periodic sequences of operators that lead to the self replication, and that, by self replicate themselves create metric spaces. So what's the control? Right. And these spaces are created by these particular operators. And only in these regular spaces for your particular like operators. Maybe there's some other dynamics which are able to do this too, but this is primary candidate, you will have structure that is predictable, that is information preserving. And not all of the information is preserved in this way. For instance, you do not know the double slit experiment, which slit the photon is going to go through, because there is not enough information to constrain it. But you know that when you take many of these particles, the statistics over which they will hit the screen. And this is what you can exploit as an agent to predict the future. And in order to exploit it, you have to be classical, you have to be able to come to a deterministic model that allows you to predict the future of the universe from its past, and also your own future from your past. So you can compute otherwise you couldn't write. So you will necessarily need to run on a classical subset of the deterministic Turing machine that is the universe which will look to you like classical observer and quantum mechanics. And it's an important insight that the collapse of the wavefunction is not a particular event in the universe itself. It has something to do with your own epistemology, it's the point in your past, beyond which you cannot pretend that the universe is classical. Right? So you're creating a classical bubble in your own mind, and your own observations to make the universe predictable. And this measurement is the point at which you want you cannot pretend that that's the case.

Unknown 2:01:56
You're sure you're you're blowing up my mind here in in all kinds of biblical and cosmological and quantum mechanical kinds of ways. But I know I promised I'll let you go because 10 or 15 minutes before your next appointment. So let's let's just wrap it up quickly here with two last questions. First of all, what's the best place for other people to find more about you and your work?

Joscha Bach 2:02:26
At the moment, I suspect that one of the best places are the YouTube interviews like the one that you just did. In the meantime, I do hope that I get around to write a book at some point, I use Twitter as an online notebook, which is mostly throw away. So when I have insights that I think are okay to write down, I just write them down in this notebook. And it's a very interactive thing. Because no matter how obscure the idea is, there will be a handful of people which get it and respond to it, or others which ask for clarifications, which also helps. So for me, this is the way to link into an emergent global consciousness that emerges on social media. And that is beginning to form it's a very exciting development, even though it's frustrating and strenuous.

Unknown 2:03:11
Or you're plugging into the hive mind while still keeping your autonomy to a certain degree. Yes. Brilliant. Okay, so we covered so much ground again today. But the unexpected part for me was the biblical end of thing, the cosmology I would have expected, but the biblical cosmology and even some theology, wow, that that part really blew my mind. So I don't know what you've been reading lately, or the Bible and going,

Joscha Bach 2:03:44
it's mostly that I am. Things that I read as a child like the Bible, come back,

Unknown 2:03:50
and why are they bubbling now?

Joscha Bach 2:03:53
Oh, it's largely the inside that the people who wrote these things and the people who deployed religion were rational. I think that starting out with re reading and reconsidering Aquinas, I noticed that the interpretation of the philosophy of Aquinas is often spelled out in such a way that it makes no sense to our essayist and post enlightenment education. But there is a way in which these things made sense because they worked. So under the assumption that the people who wrote this and to build this professional and discovered epistemology, which means you cannot put confidence into things in the absence of evidence, and you cannot exclude possibilities if you have not exclude the possibility of them being true. It is not hard to infer if you assume that people had proper wisdom ology when they did this when they vote these stories, and many of our ancestors probably did, what is the implication? And suddenly you notice when you apply this filter, that these stories reveal hidden content? it. And it could be that this content is projection of mine, I have no certainty that is correct intention or Genesis one to give us the theory of the emergence of cognition in the mind of an infant. But it makes sense, right? It makes sense that you would give a primer to people who tell them, tell them how cognition actually works. And none of the things that I said about Genesis one requires modern neuroscience or AI, to discover them. What it discovers is to unseat the interpretation of Christianity, once you're able to unsee the story and ignore the story, this philosophical interpretation that can be derived by observing infants growing up, and doing introspection and meditation tools that were certainly available to the people who wrote that story 1000s of years ago. This is an interesting consideration that this was an insight that was encoded in a library that we give children to the next generation. And that is still there to be discovered.

Unknown 2:06:01
Absolutely, I think that's one of the most lasting, time tested powers of Story The, the fact that different people can see and unsee different parts and discover and rediscover those parts, and kind of put or reframe, or, or reload the vehicle with a new relevant meaning, if you will, or interpretation, the kind of updates and upgrades in so many ways the carrier. But I just wonder what would that say about the best way of how we can wrap up our conversation should be should we be something about story? Should we should it be something about AI? Should it be something about cosmology, or cognition or consciousness or intelligence? I don't know. Help me.

Joscha Bach 2:06:52
I don't know that to the next conversation. I think this open endedness is a very good way to end our conversation.

Unknown 2:07:00
All right. So what that what that means then, is that we would care far three coming at some point in the future, and I certainly would be up for that.

Joscha Bach 2:07:09
Sure. I enjoyed this conversation very much. Thank you. Nicola, that was fun to discuss. And if it's your wonderful rest of the day,

Unknown 2:07:19
you're Shabak, thank you so much for being with us in the pleasure was entirely mine. It's always a treat to have to have a conversation with you. It's always a pleasure.

Unknown 2:07:40
If you guys enjoyed this show, you can help me make it better in a couple of ways. You can go and write the review on iTunes or you can simply make a donation

This transcript was generated by https://otter.ai