Unknown 0:00
Howdy, this is Jim rut and this is the Jim rut show. listeners have asked us to provide pointers some of the resources we talked about on the show, we now have links to books and articles referenced in recent podcasts that are available on our website. We also offer full transcripts, go to gym rat show.com. That's Jim Rudd show.com. Today's guest is Yoshi Bach. He is Vice President of Research at the AI Foundation. He has previously been a research scientist at MIT and Harvard. He is author of the book principles of synthetic intelligence, psi, that's psi, and architecture of motivated cognition. And he has published many papers, I also have to add this, he has one of the most interesting tweet streams that I follow, you can follow him at at plugins, Pl inz. And only some of it has anything much directly to do with artificial intelligence or cognitive science, but it sure is entertaining. He's certainly in my top handful of tweet streams that I enjoy following. So let's start with understanding sort of your motivation. How did you get into this, and here's a quote from I think from one of your talks, maybe it's from a paper I don't remember, you said, we need to understand the nature of AI to understand who we are.

Joscha Bach 1:30
I think that artificial intelligence is an idea is, in some sense, the missing link between philosophy and mathematics. It's the attempt to make the execution of processes that allow us to use language and make it refer to meaning automatic, and understandable and scalable. And this basically allows us to ground our use of languages that have meaning in machinery that we understand in a mechanical universe. This idea that the universe is mechanical might sound limiting to many people. But it's not a very limiting idea. It simply means that the universe is not magic, that it's not built over symbolic correlations or symbolic causation, but over things that have no conspiracy inside of them. And the other thing is that if you want to think of yourself as a system that has no conspiracy inside of it, what kind of system is it? And AI is the attempt to build a testable theory of what that is. And if we are able to test that theory successfully, we will have built a system that in the race in which it matters is going to be like us, which means it's going to be a system that is able to reflect on its environment and its own role in it and make a model of that understand that and understand its own nature as well. Right? So this project of artificial intelligence, in my view, is something like a capstone of the certain philosophical tradition, or maybe of all philosophical traditions of the question of, what are we in this universe? And what's our relationship to the universe that contains us? What is the observer? All the other questions come from that? And so it's, in my view, the most important question there is,

Unknown 3:17
I have to agree that as I've gotten into artificial intelligence, particularly Artificial General Intelligence over the last, about six years, I've started digging into it in some depth, I found myself being forced to ask just those kinds of questions, which kind of surprised me, right. And of course, we both know that not everybody interested in AI is interested in it at this kind of a level. I mean, there's an awful lot of narrow AI these days, which we'll talk about later, the distinction between cognitive AI and narrow AI, and artificial general intelligence and more applied things. So I take it that you would consider yourself not just an AI guy, but also interested in artificial general intelligence.

Joscha Bach 3:59
I think that artificial intelligence is an attempt to reboot the original idea of artificial intelligence that's basically AGI and the original AI or the same thing. When I started out as a field, it was done by a number of people across disciplines, there were some cyber nutritions there were budding computer scientists, computer science was just getting started. Some information theorists, and even psychologists involved in the whole thing. And the idea was, we now understand how computers work, we understand that everything that we understand you can express as constructive mathematical paradigm. Constructive mathematics is the part of maths that works and it happens to be the same as computation. So let's go and teach the computers how to think and the first generation of people that set out to do this very optimistic. They basically thought this is going to be an extended summer project maybe a couple of years and we will have make made tremendous progress. And as it turned out, they did make tremendous progress. I suppose hindsight. So they did a lot of amazing feats. It didn't take that long to teach computers how to play decent chess, which means chess that is much better than make abilities even before computers became superhuman at chess, and how to get the thing to do very simple language, understanding, simple planning, and so on just didn't take long. The set of programming languages that we use today, almost all of them have been invented and their structure and principles in the first couple decades after AI has started. And the effort was very much connected throughout computer science. So in some sense, almost everything that didn't work in computer science was AI. And when it worked, then it became something boring. And AI has in some sense, has been always the Pioneer Battalion of computer science and very, very productive as a field. But most of the people that worked on it realize that this optimism of building machine that things in a short time, that is, for instance, within the time of a couple of grant proposals or even your entire career, it's very daunting, it's probably not going to succeed. So they're focused on things that were going to give results within the duration of a grant proposal or within the duration of a career. And these were also the things that were going to give you tenure. So AI became more and more applied more and more narrow. And it's always about improving the automation of statistics and developing mathematics around that and theory around that, and so on. And this philosophical project itself has only captured the attention of relatively few people in the field as philosophical projects happen to do. I think in some sense, that's correct. It's the right thing to do. Because philosophical projects are daunting, hard, risky, and often have only marginal benefits. So why not go for this thing that gives very tangible benefits right here right now. And this is what the majority of the field did. There also some political upheavals within the field that happened right when Minsky claimed that cognitive AI was in some sense, the same thing as symbolic AI, I think he made the wrong bet. And Minsky was somebody who was extremely visionary, but he was also somebody who was not so interested in divisions of other people. And so he's basically screamed at people that did cybernetics, and that the neural networks and actively delayed the development of a dynamical systems models of cognition and of machine learning systems for more than a decade, is he will move to funding for neural networks and apparently also impaired the funding of cybernetics and contributor to the ending of cybernetics as a field in the US to get more, I suspect funding and airtime for his own approaches. And in some sense, it's not his fault that he could not see that he was not right that his approaches ultimately would lead to difficulties in grounding concepts and building an understanding that goes beyond symbolic systems. But he inadvertently created a division between cognitive AI that was his his own followers and disciples and everybody else. And so the other people did not read PRG anymore, and that did not think about psychology very much anymore. And this division between artificial intelligence between people to think about cognition and psychology, and people that think about how to, for instance, process images, and then how to interact with an environment. This division lasts until today, in many ways, even though it's, the gap is closing more and more.

Unknown 8:27
And yet, if you talk to people even at Google, they will admit, late in the afternoon, or after several beers that the reason they got into the field was something like AGI.

Joscha Bach 8:38
Absolutely, then I entered university, I only did this because I wanted to understand how the mind works. And that's why I studied computer science and philosophy, and a few other things. And it was very disappointing to me to see that philosophers were completely not into this, mostly didn't understand the ideas that computer science has set developed during the last 50 years at all. And if so, then only in very superficial interest of Fe and the computer scientists were not interested in philosophy. And it was really depressing to me and was not alone on this. So when I was a grad student or not integrated, so basically post the equivalent of a bachelor. Other students would ask me when they entered the field, and it was a tutor, where can I do AI here who's offering real AI classes, even though we had a very large and active AI department or university? And so I decided that I had to offer AI classes right. So as a student, I started doing a seminar on building cognitive architectures and on thinking about the mind and so I got a dozen students who started building things with me and this is the origin of the microsite architecture by the way. This is how I got into working in academia as a student.

Unknown 9:54
Ah, that's a very interesting story sort of reacted against the prevailing trends in academia where as you said earlier, unfortunately, the funding and promotional carrots you know, rewards are focused on, you know, relatively small incremental steps against, you know, known benchmarks, you know, you raise the benchmark by half a percent and you have a paper you can publish, publish seven papers, you get tenure. Right? And that's not the grand question of how do we make a machine that thinks sort of like a human? Are you still optimistic that we can create computer intelligences that are at human level and beyond?

Joscha Bach 10:33
Of course, I It's no obvious reasons why we shouldn't there's nothing magic going on, as far as we know, in the brain. I also don't think that there are. And this might be very controversial to some deep open philosophical questions left, that have to be answered, what's, what needs to be answered is a lot of technical details. And for a lot of these details, I think doors have opened to work on them in the last few years. So even though I don't know how long it's going to take, and whether it's going to happen in our lifetime, I think there's a significant probability that we will see something that is not human like, but in many areas super human like and in other areas, good enough, like visiting our left hand, or maybe even in the next two years.

Unknown 11:22
Yeah, it's hard to say it's one of these damn questions, it could be five years, it could be 100 years or more, right. Of course, it also, as you say, depends on where you're measuring. If you talk about every single facility, it might be 100 years. But if we're talking about superhuman capability in certain domains that could happen. Our practice, frankly, already has happened in narrow domains, like image recognition under certain very constrained cases, and those windows will open larger and larger. And I will also say that one of the things that's made me more optimistic about superhuman capacity across the board, as the more I've learned about cognitive science and cognitive neuroscience, frankly, how limited the human brain is things like working memory, size, fidelity of memory, you know, et cetera, we're not that smart compared to what we could be working memory alone is a huge bottleneck on for instance, the practical level of recursion in language and chunking, size of concepts, etc, you know, the low fidelity of our memory and lack of persistence is certainly a major cognitive limitation. So I'm not one of those people who thinks that the humans are the top of the intelligence spectrum, frankly, I believe we're at approximately the stupidest possible general intelligence, which is not surprising, you know, evolution is seldom profligate with its gifts. And since we're over the line of general intelligence, at least, so it appears, we're probably just over the line. And so I'm one of those who is also very hopeful that we can get not just over the line, but way over the line, at least in some very interesting dimensions, you know, such as language, understanding the ability to read the literature of a discipline, and actually make sense of it, at cetera.

Joscha Bach 13:06
I remember that I've always been very disappointed in the capacity of my brain, as a child, and later on. And I also felt bad about this, because at the same time, I was confronted with the superstitious belief of most people, that if you apply yourself, there's basically no limit to what the brain can do, right? We could have maybe infinite memory, maybe, if people just pay attention all the time, we could read all the books and retain all the books, we could retain all the movie, maybe you could have photographic memory for everything. Maybe there is no limit to our intelligence if we really apply ourselves and meditate enough, right. And there occurred to me that this is probably not the case. I do know, many people that are much much smarter than myself and know much more than myself. But it's often at the expense of other things. So they tend means that they tend to have a much narrower view on on things and know these things much, much more deeply. And apply their attention to exclusively these things and not to others. Of course, there are some people which are way smarter than me across the board. And I'm totally in awe of them. But still, it's just to show the human brain. And this shorter human brain still don't know how much compute we need and how much ingenuity we need to replicate the sturdiness of course, right? So even though we can see the limits of what it's doing, to get this to run, it might be possible that it's doable, or something that you can, as an average person, already buy and put into your basement if you really want to. So something in the order of say 20k of compute. Maybe that's possible. I'm optimistic enough to say that there is a chance that this is the case. Yeah, totally.

Unknown 14:45
I've had numerous discussions with our mutual friend Ben Gertz all about that. Right. And you know, I think we both have come to the view that I think it will turn out to be what is the appropriate level of representation? My home academic this discipline is evolutionary computing. And then evolutionary computing, again, and again. And again, it turns out to be what is the representation on whether a technique will provide traction on a problem. And so if it turns out that the actual right level of representation is indeed the neuron, then probably 20k computers won't do it. If it's symbolic, you know, truly symbolic and the old fashioned AI sense, then probably, you know, 10 computers call it $5,000 Worth will be enough. But as I suspect, if it's some hybrid between the two and kind of messy, and has some very low level stuff, and some very high level stuff, and some transducers between them, it may be on the order, you know, isn't my best guess. And I think Ben thinks my number is high. But he agrees that it's a plausible ceiling, essentially, the equivalent of 1000, powerful desktop computers. So we're talking on the order of a million dollars of hardware, today, if we got the right level of representation at it. And of course, a million dollars with the hardware is no barrier at all, to produce something as valuable as human level artificial intelligence.

Joscha Bach 16:13
If we look at things like, for instance, GPT, two or three models that open AI has recently been working on in publishing, what goes into these models is relatively moderate costs that still will drive academic researchers sweat on the forehead, but it's something like two digit million dollars that go into training these models. And they are trained on a few years of almost a full take of the internet that has been filtered down to something that removes most of the most obvious crap. And then if it's very basic, the common call is a large part of what you find, find a text that's written in a given year on the internet. And then it is able to go through this enormous amount of text that is very, very large library, there's lots of babbling inside, and extract all the meaningful correlations are a significant part of the meaningful correlations from it in relatively short time, right, it's a task that is way beyond what a large group of researchers could do in their lifetime. And it's done in the course of a few days or weeks, these computers and that is a tremendous achievement that you can do, right. And if you imagine you would have something that is only able to process these data at a human level, across all modalities, maybe you try and modify the data. So you get the highest benefits possible in a nervous system that has a capacity similar to ours, that would be a tremendous achievement, if so much data could be processed and extracted in such a short amount of time. And I don't mean that GPT towards we are human like me, the fascinating thing is that they get so far that you have is a relatively simple algorithm, you can produce embeddings over text. And as they should have recently shown images that allow you to make continuations of the text and the images that are basically surviving a type of Turing test where the audience is unable to tell better than chance, whether the text that are looking at has been written by a human, or that the image that you're looking at has been generated by a photographic result. So the words resolution image.

Unknown 18:30
Yeah, that is interesting. I mean, as you say, this is not the way humans do it at all. And I had looked quite a bit at GPT. Two, I haven't looked at GPT. Three yet. And I did some experiments, etc. And wouldn't have fooled me for very long, but apparently could fool some people. But it's essentially, you know, an extraordinarily deep pattern matching system. And is that all human language understanding is, I don't know, seems to me that there's something missing in these brute force, deep learning approaches, when it comes particularly to language that yes, it's amazing what they'll do, you know, the the translation algorithms that Google famously developed GPT, two, and presumably GPT, three and GPT for some day, you know, may well be able to fool us, but do they actually understand language at the level of say, for instance, reading every paper in every textbook in cognitive science, and actually then being able to make some inferences about what's missing in cognitive science and what new theories or experiments are needed. I mean, that's the kind of thing a human could do. Not very well yet. But that's what you know, professional cognitive scientists does. Could GPT for do that? I don't think so.

Joscha Bach 19:43
The thing is that GPT two and three are not sentient, apparently right. So they have no model of a connected unified universe, unto which they match everything that happens in real time and they understand their own role in it and so on. It's not that they have Apart from it, it's just, it's not part of their task, then they haven't been asked to do that this model has not been trained to do such a thing. And yet the capacity that this thing has is tremendous. And there's, a lot of people will say, Oh, this is not grounded and has no connection to reality. The question is, imagine that all you would have access to the world is your own imagination, the only the mental space in which you can produce mental simulations, and lots and lots of books, and a way to parse them. And at some point, you basically try to hash out the space of possibilities in which all the symbols that you're confronting, can possibly make sense and give rise to a universe that contains you. Is this something that you can prove a priori that this is impossible, that something like TPT tours is a three year simple text processor cannot hash it out? based just on the finding one of the possible orders and the patterns after notice there are not that many. And once it figured out the relationship between concepts in some kind of relational space, that is dynamic and producers and evolving world can they start parsing the VPD articles on physics and all the papers on physics that they read and understand the possible solutions to the big puzzles in physics and so on, that allow us how to understand the automata from which our world is generated. I don't know that GPT three is seems to be an incremental extension over GPT two, so basically uses magnitudes more data. And the learning curves are not bending yet. So it seems that you can extend this even further. And the quality of texts that GPT three is producing in terms of coherence. So the illusion that this what it writes corresponds to a self coherent universe. Concepts are consistent for at least the duration of the story. This is much, much better than GPT. Two, so it's up to you we could easily see, when it's a construction fell apart, then last coherence. And this is when the story becomes unbelievable, right? You're willing to entertain a completely fictional story about a completely fictional universe, as long as it refers to a coherent universe. It might be a fantastic universe one that doesn't make sense. But it's one that works by certain rules. Like if you take Buffy the Vampire Slayer is a fictional universe, it's a universe where everything is normal for a sanitized version of normals, suburbia, that doesn't really exist, because it's so perfect and stereotypical. And the only thing that's different from this perfect abnormal and stereotypical world is that every year 20% of the population dies because of an invasion of vampires. And everybody goes on with their life. And this is probably not realistic, right? We know what happens if 1% of the population dies in every given year, political COVID, everything comes to a halt. And so this is a universe that is only meant to highlight things in the stereotypes and the normal interactions, but introducing this new element and deliberately leaving everything else that would be downstream from this unchanged. And this is an interesting construction that our mind can make, it's producing a universe that is derived from our standard universe with all the right constraints. And it's referring to this global meaning and that it literally only changes very few things, but leaving the rest alone. And the people who understand this, understand these layers of meaning that exist. And this would be an interesting benchmark to see how many layers of meaning can GPT three, distinguish between construct versus GPT. Two.

Joscha Bach 23:35
With respect to the complexity of a brain, I think it's possible that the unit is not in urine, but that it's the column, it might be that this is a simplification, and the actual units are somewhat orthogonal to both neurons in columns. So in some sense, you have units that are made from columns, you have some that are made for multiple columns, and a couple of neurons. And you have somewhere the neuron and a couple your column, and a couple neurons interact in a specific way. Or you could have processes inside of the neuron that play an important role that you need to understand in order to model the behavior of that thing. It's similar to understanding the role of people in society, with a certain level of granularity. You don't have people you just have organizations. And yet to understand the interplay of the organization, sometimes you need to look at individual people that played a role in historical developments. And to understand the behavior of these people, sometimes you need to look into very particular things in their own mind, that happened in a certain moment in history. And without that, you cannot understand it. So this simple granularity that that we put on on the model is often too coarse to to make it happen. But if we just entertain the idea that columns might be the thing, because they are somewhat ubiquitous over the neocortex, they are interchangeable you can basically cut out non specialized columns for On the brain of an infant mouse and transplant them to another area of the brain and undertake, they will adapt to fulfilling the role of that part of the cortex. So the columns seem to be pretty general, as far as we know right now. And column is something like tweet. So you know, to find that neurons. So we ended up with something like an order of 100 million units. And if you imagine we have give or take 50 brain areas, it would mean that each of these brain areas has in the order of a million units. And the units can do way more than individual neuron can do. And even an individual neuron would probably need a three layer network to model it is a perceptron. But eventually, what they do is that each of them can link up potentially with a few 1000 Other new units. And these few 1000. Other units are not what they're linked up permanently, it's the address space is what they can talk to. And each of them has a number of states that they can have in dynamics that they can undergo set of functions, they can model. And it's limited what they can do, right. And so if you imagine that you could understand that each column is something like an adaptive agent that is doing local reinforcement learning by some policy, and this by add up into a global architecture versus the others, then maybe this does fit on a few larger GPUs already in real time.

Unknown 26:21
Yep, that could be I just want to clarify something that I in my readings in your book and your talks and papers, you're talking about 100 million columns, as I recall from my reading, and I actually did look it up this afternoon, there's probably more like 100 million mini columns and a million columns, columns seem to be made for multiple mini columns, which one are you talking about when

Joscha Bach 26:44
you're was talking about many columns, and the formation of columns is also different in different brains. So for instance, if you look at a mouse brain, you will find that a large part of the neocortex seems to model the activity of whiskers. Okay, that makes sense. And so the input space of whiskers and the columns formed together into macro columns in a way which are almost like reagents. And the it's not like he could look in the brain, you see very clear cut cells that are, it's just that you have groups of neurons that have more interconnectivity among each other. And you lump them together in a column. And you also find that they coincide usually vertically as well around which they are formed. But it's not by any means very clear kind of architecture, and seems to be possible that neighboring columns that fuse and perform functions together, and so on under certain circumstances. So it's a lot more messy, I think, when we look into this in detail.

Unknown 27:40
So you look at that mini column as the closest thing to a reasonably generic unit. Okay, that's good.

Joscha Bach 27:47
Yes, but it's really something very, I'm already squinting a lot, and possibly too much. Another thing that I wanted to put on my mental stack, when you mentioned it is the question of whether we address the least intelligent thing that is genuinely intelligent in nature. And so I wonder is why there is nothing that is obviously smarter than us in nature. Because ebuyer for a monkey, it's hard to have a brain that is larger than ours, that operates in nature that are larger than ours, right? Whales have larger brains, elephants have larger brains. Why is it that whales and elephants are not smarter than us, because they basically carry these brains around for free, right? They have so large bodies, that they scaled up the brain was the body size. And it's not that they need proportionately larger cortex to control a proportionately larger muscle. This is true for the body map, but only a very small part of the brain is your somatosensory cortex. So what do they do with all this extra capacity? Why is it that they are not that smart? And I suspect that if you make the system too smart, it's very hard to control it. It could be that elephants have massive autism, because if they did, non autistic elephants meditated themselves out of existence, they basically started to understand their role in the universe. Like they're very smart monks. And then, as a result, they decided that doing office politics all day, and having kids and participating in society is just not cutting it. And instead, they just go to do something more interesting was their lives like meditating. These elephants didn't have a lot of offspring. Who knows? That is the question. So I wonder if this is a

Unknown 29:27
crazy idea.

Joscha Bach 29:32
He has a very crazy idea.

Unknown 29:33
That's weird. That's I like that. I'm gonna lay that one on somebody and say, oh, yeah, we only have autistic elephants, because elephants would otherwise be so smart that they would, you know, be too busy philosophizing to reproduce.

Joscha Bach 29:45
I mean, visit dolphins it's obviously it's slightly different that dolphins they live underwater and you cannot really hold a pen underwater, because everything you write down will be washed out. So there will be no life for intellectuals because they cannot read and write on a wall. are so the dolphins only talk about sports and celebrities and sex. And this society is not moving anywhere.

Unknown 30:08
And they have three dimensions to that's another thing, they required a better brain to operate in three dimensions at the speeds they operate at, right?

Joscha Bach 30:16
But navigation is so much easier, right? Because you don't have to solve all these not puzzles, you can just move where you want to.

Unknown 30:23
Yeah, collisions are much less likely, right? When you're stuck in two dimensions, collisions are constantly on our mind three dimensions, it's easier to dodge, right?

Joscha Bach 30:31
Yes, you're probably also noticed that self driving airplanes are completely common and standard for many, many decades now. Well, self driving cars are difficult. Yep, that's a good point. You use the navigation that you need to do on the ground coordinators, all the other things that are limited to two dimensions, and have so many crossing paths are just harder.

Unknown 30:50
Yep. I love that. So your geometry and cognition come together? And that's exactly the right answer. Let's jump back a little bit to a point you passed over rapidly. But I would love to dig into a little bit, which is your statement that, in your belief, the philosophical questions are sufficiently answered to to proceed? What is your take on the nature of the mind? Are you a strict materialist?

Joscha Bach 31:14
I suspect that there is a misunderstanding with respect to what matter means I found that a lot of people think that matter is immediately given somehow that we have seen atoms and touch them and the molecules and the earth on which we stand and the earth of which we move. And while this is exponentially the case for the earth, and the air, it's not so quite true for the atoms and the underlying structure, right. And when we look at this in more detail, it just turns out that what we mean by matter, is a way to talk about information. And what we specifically talk about is the way that we can measure change, and be noticed that you can measure changes, periodic changes in place, which we call matter. And we can see how these periodic changes in place, move between places across locations, and this is what we call momentum. And that is a Crypton of the universe in terms of matter. And momentum is what we call physics. Right? So physics is the set of functions that describes how adjacent states of the universe are correlated. And the idea of physics is that we explore the hypothesis that there is a cause of the closed, lowest layer and the whole thing. This is what foundational physics is about what's the close, causally closed doors layer that describes this entire universe that we are in. And this hypothesis that this layer exists, and it's discoverable to a large degree and can be described or inferred, is a very successful hypothesis. And this hypothesis doesn't have a really good contender. There is not another game in town that is quite plausible. And what would that other game look like? And typically, we are confronted with the notion of idealism. So instead of meta being primary and meta being the way information travels in something like a mathematical space, so a set of discernible locations, and trajectories that the information can take between those locations, we think that the mind is possibly primary. So the conscious experience is primary and subjectively, that's true, right? Consciously experience is affecting and now that we have given here in this moment, and this now is not the same thing as any particular physical now, the physical universe is smeared out and uncertain with respect to that it has a very vague and weird relationship to this exponential now that is immediately given. And if we make the step to say that this exponential now is everything, where the something can be real and experience is real by any observer, in the physical universe, there is nothing out there that can experience something that can be confronted with reality, because in physics, that's just automata. Only unfeeling mechanisms. Everything that is real, is in a dream, it's in here with us in the thing that we perceive that as colors and sounds and feelings and so on, right? So if it make that thing primary, there still needs to be an outside that dreams us. What is the thing that dreams us that produces the dream that you're part of the dream in which physics takes place from our perspective in which we're where we construct our ideas of physics and everything else. And that thing out there, this outside world that you cannot access? This is still physics. If we are drempt by a mind on a higher plane of existence, then it turns out that this higher plane of existence is still the skull of a primate with a brain inside of it. And that higher plane of existence can be modeled with the ideas of physics is not changing anything.

Unknown 34:43
Yeah, but is that necessary? Or when we talk about, let's say, human minds emerging from brains? You know, I'm kind of a naive realist myself. Maybe I'm too naive, but I think there is a physics out there and physics emerges to chemistry and chemistry is very stable and predictable. And from chemistry, we get biochemistry and from biochemistry we get biology and from biology, we eventually get neurons and the neurons, we eventually get nervous systems, eventually, we get brains. And at some point, probably around the time of the reptiles, or maybe the amphibians, we finally got mind, which is the subjective state, then mind is a new, subjective state that is packaged within physics, I think that's the alternative way of looking at it.

Joscha Bach 35:34
I suspect that you don't need to tell the story from this direction, you can spend hundreds of years sitting in your monasteries in Tibet, or whatever forever, and be super smart and have all the time in the world of your hands. Because you convinced the local peasantry to give you free breakfast every morning, because your holy men, you sit together with all the other smart holy men, and you write books and discuss psychology, that respectively at a level that Western psychology still doesn't quite master. And you do understand many parts of the mind and how they interact and so on. And you never ever venture out to describe physics for some reason, right? It's not necessary to do so. Because you do not intend to revolution your society and invent new means of production make everything more efficient, because that would probably destabilize society. So you leave that as it is. And society outside is something like a periodic process that you try to organize as well as you can. So it's somewhat stable, but you don't want to turn it into a runaway probe processes, technological progress. So why would you want to look into physics, you don't need to do that, right? So many cultures, only focused on this mental perspective and the inner structure of perception first, and not at the outer structure that enables it. But if you're not looking into physics, from our perspective, you are leaving money on the table, if you ignore this entire scope of models that work out that do have predictive power, tremendous predictive power, they allow you to build machinery that all these other civilizations could not build, and even think and reason about and did not even start to consider possible, there was nothing that they based any ideas on what you can do in the mechanical universe, it's, it's possible to do that we'll leave all that on the table. And our culture is a little bit weird, because our civilization is not that old. I think it just started 400 years ago. And we are mostly unaware of that civilization break that he had when we got out of the cards. And the Catholic civilization is one that obfuscated the area of the mind because it made it all part of the mythology. So you didn't have the free space to reason about psychology visiting the Catholic society. All this was taken up by gods that interfering with this house on the same brain, people were in some sense discouraged to study psychology, because it might interfere with religion. And the physics that they engage with it was also somewhat crude, because access to rationality needed to use certificates that you will not accidentally disprove religion interfere visit, because it was in some sense and anti rationalist system that people had to live in. And what we did was we freed our rationality, for the first time and 1000s of years. And just you rational society that woke up is the enlightenment, dismissed all the stories about the mind that the Christians had ever told them, and sort of them is superstition. So the less lost many concepts and we are still in the process of restoring them. For instance, I'm fond of saying that spirit is a word that we have dismissed now as superstitious and it's an old word that just means operating system for an autonomous robot. And when the word was coined, it just meant that the autonomous robots that existed, so they were people that were plants, animals, cities, nation states, even possibly ecosystems. But this was it, there were no robots that people had built. And now that we have autonomous robots, and they have operating systems, we understand that there is something like an operating system and that humans must have one tool and plans must have one as well. And obviously societies and civilizations have some kind of operating system, right. And we understand that this operating system of society is is not real, it's virtual. It exists over the coherent interactions of individuals and society, in the same sense, as the mind does not exist as a physical thing. It exists over the coherent interactions of the neurons or whatever are the the constituting parts are.

Unknown 39:31
Where I think that's a very important distinction. And you know, in my study of complexity science, the way I will often say that is reductionist science, you know, let's call it old style. Science is about the dancers, while complexity perspective is about the dance and the dancers, right. So the things that hold together, let's say a business company, they're virtual, they're abstract, you know that you can't put your finger on a particle and say this is the operating system. Have a business. And yet the business is real. It is a series of coordinated actions operating on signals with boundaries and semipermeable membranes. It has feedback loops. I think that's key. And and you make that point as well, in some of your writings that feedback loops are absolutely critical in creating higher levels of complexity and systems, at least they appear to be, you know, for instance, in one of my critiques of our current operating system, is that our current society level operating system is overly driven around the money on money return loop, you know, everything is in the business world, and frankly, in many, many people's personal world is all about optimizing money on money return. And that has produced many of the less than desirable characteristics of our era. But that is a real thing. The flow of money is a information processing modality, which ends up coordinating behavior of actual atoms, and we'll get down to the emergency lists argument about what is top down causality. But one could argue that society organized around money on money return has top down causality and that it requires, you know, Mary and Joe to get up at seven o'clock in the morning, drive for an hour and work in a bullshit job for eight hours, and drive an hour home again. So I think this broader concept of you know, what is real to include complex adaptive systems gets around this false distinction between dead matter and live systems.

Joscha Bach 41:27
The notion of the feedback loop is very old, I suspect that every statecraft that builds societies deliberately had to have this notion of feedback regulation in it, and understanding of nature, you find this already in Aristotle and in our intellectual traditions, throughout the times this notion of the feedback loop, you find it in Dimitri, where he describes that there must be systems of competing springs in the mind that pull and push against each other and keep it in some dynamic balance. And so it's a very classical notion, and it became the core of cybernetics and control theory. And I was very popular paradigm for a long time. But I also suspect that there is a little bit of traditional superstition around the first and second generation of dynamical systems theory, especially second order cybernetics, in the sense that we are tempted to think of these dynamical systems is real. And I suspect that they are just models, they're not real, they are the behavior of too many parts to count in the limit. When we describe how individual things interact, we can often track them and see the low level processes that changed the evolution of one system, of course, the boundary of by another. And if you can no longer do that, because you were looking at trillions of molecules, for instance, you will have to resort to models that look at the statistical dynamics of these to many parts to count. And some of the resulting mathematics have convergent results, and others have not. And the geometry of the world that we're looking at, when we look at dynamical systems, this is typically the stuff that is convergent, where we can make models. And so it turns out that Newtonian mechanics is these convergent dynamics have too many parts to count visit certain ranges. It's not real, because you cannot really make a Newtonian mechanics perfectly working from individual parts, it's only within a certain region of many, many parts to many parts to count that you get something that looks a lot like Newtonian mechanics, and for a different region. It's true for Einsteinian mechanics, right. But these systems are not real, it's just a level of the modeling, that gives you a coherence. So when you are an observer, and you zoom into the universe that contains you, and the many, many parts that make up yourself, you basically will often find layers of description, where you can make a coherent model. And these are the ones that you latch on as description layers, and then we discover that they form a hierarchy. And then we try to establish causal relationships between them. But these foster relationships are not causal relationships that exist in the physical universe. Personality is a model category. It's a property of the models that we are making. So when we talk about these big conundrums, like the mind body problem, you're not talking about how is one physical set of things like bodies connected to one other possibly non physical set of things minds, but we have to talk about this. We have here one category of model that is our body map that is dynamically arranged in space and articulated with skeletal muscles. And on the other end, you have mental states and mental processes and software states and so on. And these two disparate categories of models, how can we make them congruent,

Unknown 44:50
whether actually, they obviously have to operate together, and I'm just gonna give an example about what does reality and models really mean? We talked earlier about companies Right, they're virtual, you can't really put your finger on saying that's the company, right? It's a standing wave essentially of action in motion. But they're real in the sense that they have traction in the physical world. And that's, I think, a reasonable assessment of what is real. Now, as an example, think of a coal mining company, a company who digs coal out of the ground. So in terms of traction in the real world, they dig holes, and they deliver coal to people who turn it into energy. So there are actual things that are done in the world by this virtual thing called the coal mining company. And obviously, trying to track that at the level of atoms would be ridiculous. And even tracking it at the level of human beings would be exceedingly difficult. And would maybe if you had billions of dollars, you could simulate a coal mining company at the level of individual humans. But interestingly, at the level of abstraction of accounting is quite simple, right. And people make large bets based on the future of one coal mining company versus another based on the signal, very abstract, very high level of accounting information that comes out. And the result is Company A gets smaller, and company B gets bigger based on people's assessments of this high level information. And yet, at the end of the day, we have to say that the mining company is real, because it is having very significant impact on the real world.

Joscha Bach 46:24
But not everything that has a significant impact on the real world is real in particular sentence, right? So you could say that ideas have a significant impact on the real world. And it's very often difficult to say what the idea actually is because it only exists approximately across mines. Right? So if you think about the political movement, how would you say that the political movement itself is real, if the idea behind the political movement is understood by most people in different ways, but for a company, it's much much easier because we have a software or legal system that defines the conditions under which the company exists, right. And so you have a criterion by which you can decide whether the companies there or not, and what state it is in. But this is because we have created a substrate for the company to run. And it's similar to what happens in our computers, we have a built a deterministic system, this clear rules that allow us to decide whether a bit set in the gate or not, or in a register or not. And this allows us to construct extremely precise models of the behavior in the computer and preordained the behavior of the computer. It's a very specific thing that is probably different from minds for the state that the mind is in is still somewhat probabilistic.

Unknown 47:41
Yes, I would say that is true. But it also seems to be at least in many cases in nature, that emergencies to higher level, structural entities are built from relatively well defined lower level units. And when you lack those more defined lower level units, appears to be more difficult to get emergent properties to come into being. So for instance, you make the good point that the fact that our laws are relatively uniform, and they result in currency that has equal value, and that people can only be exploited so far, because the limits of the law, so at some level, they're almost fungible, may actually be part of the mechanism that facilitates the emergence of the mining company, perhaps in the same way that the fact that neurons while they, of course, they vary, and there's at least 100 Different varieties are not that different compared to non neurons, right? They are relatively fungible units of construction. And they give evolution something to work with to produce higher level emergencies, and this case, mind and we take mind to be not just human minds, but minds all the way down to wherever minds first come into being on our evolutionary tree. And so I think that's interesting and important thought that we typically have a level of emergence that has relative simplicity at the outer envelope of the component pieces at that level, and that those combining allow us to reach the next level of emergence.

Joscha Bach 49:20
But you also know that the rules that are implemented in the world that are so uniform and so on, for instance, the financial system needs to be in order to work to be implemented in a way that is by the uniform, you don't have large opportunities for arbitrage, right. But you have leaky abstractions. And yet we both know people that got extremely wealthy by specifically looking for the fine print.

Unknown 49:42
Absolutely. And that none of these those systems are perfect, right? Biology is subject to attack by viruses, for instance, right? Virus is not actually a biological entity. It's essentially a flaw in biological systems, that they're exploited by a dead chemistry in the same sense that arbitrage you're errors are essentially like a virus operating on business looking for the flaws in the system, and there will always be that.

Joscha Bach 50:07
So the two interesting questions one is how much fine print is there in the mind. So, to which degree does the mind not emerge over the activity of neurons, for instance, to what degree is this simplification, and to which degree is a very good abstraction and should guide all our thinking and not and there are some people which feel that the neurons are not the right description at all and might've even superstition connected to that. But I think it's really worth keeping that in the back of the mind. So that there is usually some degree of fine print involves when we make such models and circumstances under which this is not the entire truth and more interesting things are going on. With respect to viruses, where the Coronavirus is not a life form, it's more like a text that the cell cannot help itself not to read. And when the cell reads this text, it's doomed. Because it cannot sandbox, the idea that is contained in the text, it will have to turn it into an action. And these viruses exist also in society in a way, right. But it's not as if the cell or the biological life ever existed. For a long time, at least without these viruses. These viruses have been around briefly after cells came into being probably so the cells already contain a lot of viruses, the all the existing cells are the result of many, many interactions that they had with viruses, many of which permanently migrated into the cells that later on divided and became us, right. So the same thing is true for societies, a lot of the ideas that we have are the result of the interaction with viruses that interacted with the pure host ideas that had been formed in a natural convergence rather than being an infection process that interacted with the natural convergence state of emergent mind, and then took roots in there and formed an immune system to make sure that competing ideas don't take root in the same mind and so on.

Unknown 52:01
Exactly, I've often used the term mimetic viruses for, you know, radical ideas that challenge the status quo. You know, for instance, the scientific revolution of starting around 1700, and probably reaching its pinnacle least with respect to the Christian thing that came before with Darwin, or some very virulent mimetic viruses that were brought out by individual thinkers and collectives of thinkers. And they put a substantial hit on the pre existing status quo model the universe. So I think that concept of virus were broadly constrained makes a lot of sense.

Joscha Bach 52:38
There's, of course, the question whether the virus increases the fitness of the individual in the group. And it seems to be quite obvious that if you look at society that the viral evolution, the mimetic evolution, does not necessarily have to lead to improvements,

Unknown 52:54
nor does the biological ones don't either, right.

Joscha Bach 52:58
In the long run, I think that the things that don't work out, are going to be removed from the playing field. This is how evolution works. But it can be a temporary breakdown of complexity that you observe. So it could be, for instance, that you have a species that spreads over a very large area of your ecosystem, and is very homogenous, and this makes it very susceptible to an infection and then the entire population gets or large part of the population gets wiped out by a relatively simple attack vector. And if you have more diversity across species, you have more resilience against viruses. And the same thing can happen in a society. So everybody is using the same kind of social media and the same news sources, then society can have very homogenous virus infections. And as long as the virus is adaptive in the sense that it makes the group coordinate better, it can even convey an evolutionary advantage on the group and make the group out compete other groups. So I wonder to which degree we are the result of such a viral domestication process that we basically are living in a civilization that has out competed other civilizations because people in it, the very susceptible to this same mind viruses, and as long as the viruses accompanied with some kind of church, immune system, like an inquisition, that would make sure that everybody would be susceptible to the same viruses and not rogue viruses, right? The society is possibly more successful than other societies. And then if you remove the church, and you have all these superstitious people without individual epistemology in any kind of firewall, against rogue ideas that have no chance of being true and seen, edit with bright eyes, that this might create a dangerous situation where your society just falls apart because it splinters off into random cards

Unknown 54:48
that were running that experiment right now. All right,

Joscha Bach 54:51
possible. It's also possible that everybody just suddenly seeing the light at the same time, right? And this amazing thing happens that After several 1000 years of human evolution, we suddenly get to the point where we have the right moral opinion about everything that we didn't have in the 1500s, or in the 1800s, or in the 1950s, or the 1970s, or 1990s. Now we see it.

Unknown 55:17
Of course, everybody thinks that they always think that they're right, every Apoc thinks that they're right. But I do think that one of the, you know, the experiment that we're running of mimetic viruses everywhere, and eliminating many of the quality control mechanisms that more autocratic regimes have may destroy us, or may take us in a phase change to the new level. And that's, you know, what some friends of mine myself are working on is, can we get to a new level of civilization? Well, not all of our answers will be the right ones. But there'll be a lot more right than the status quo. In particular, learning how to operate within the limits of our ecosystem, the current status quo seems to have no brakes on it, it does not know how to stop, it keeps producing new things, whether they're actually good for us or not. And indeed, many of them are dangerous to the continued existence of the human race, think nuclear weapons, just finished reading this weekend, a very interesting book by William Perry, and another fella, reminding us there are still way too many nuclear weapons out there. And if there should be just a mistake, it could knock us back to the Stone Age quite easily right? Let alone things like CRISPR, or AI risk, etc, which we'll talk about in a little bit. So anyway, that's interesting. But let's move back to our topic a little bit here. And let's go all the way back in time. In fact, before modernism really got started right at the cusp, with Rene Descartes and dualism, dualism seems to be a strong attractor to this very day, right. And I place against that view of swag about consciousness here, essentially, or the mind or the spirit or whatever we want to call it. Decart, of course, famously believed it was of a different substance than the body, or energy or signals, it was literally something very unclear on how it interacted with the physical universe, but it was a different substance. While someone like John Searle, who I have found to be one of the more interesting philosophers of consciousness, argues that no consciousness or mind more broadly, is nothing but an emergent system from biology, very much like digestion. And like digestion, it comes at a high energetic and a high genetic cost to keep it going. And you know, those two seem to be the poles of our historical thinking, and yet the Cartesian Dualism still seems with us. I wonder

Joscha Bach 57:41
to which degree, the generation after Deckard has basically simplified his thinking, and that is especially apparent when you look at or capitalism, the question of how the spheres interact, how is it possible that the mental sphere and the physical sphere can interact when the physical sphere is causally closed? Right, it's if the metal sphere doesn't need to be causally closed, it's possible that something is getting into your dream and missing visit. But how is the dream world interacting with the physical world if the physical world doesn't need any kind of external interaction to go with it? And there must be a reason why take heart didn't see this as a very big problem. Also, what I find is when I read his texts, he is often smarter than people give him credit for. For instance, in the meditations, he will interact with religion, in the same way as somebody say in communism might interact with the political dogma. That is, he will make a note to it and pretend to see no reason to doubt it. And but will defend it with vis implausibly vie documents. So that everybody who is able to, to get to the, to a certain point in their own thinking, realize this is not an argument that is good enough to actually make a point that this person is highly incentivized to make, then you only need to make the next step and understand, oh, maybe Deckard was smart enough to understand this as well. And smart enough to understand that I would possibly be smart enough as well to understand this. So we now we got this out of the way and understand why he wrote it. Right? There is a reading of the card that is relatively straightforward, and that is that both substances are mental substances in a way. So res extensa, is the thing that for instance, Jeff Hawkins, new Numenta is so obsessed with this idea that everything that happens in the mind is in some sense, a representation that maps to a certain region in the same three dimensional space, the same free space is your model, right? It's the space that our mind models about the universe. And this interpretation of Jeff Hawkins is not complete because our mind also has a lot of content that does not refer to anything in the same moving free space. So if you would say these two categories have mental thought the physics engine that our brain is generating to deal with predicting sensory data across all modalities. And all modalities will be mapped on that physics engine, right? Everything that you hear and see and touch is mapped onto the same free space. And all the other things. This would be your escargot. Hence, this is not res extensa. So just say res X tensor is the physics engine that your mind is generating press cognate tensors, everything else. And now you can easily see how they interact with our software. Yeah,

Unknown 1:00:32
I want to hop back to a comment you made earlier about the mind not being causally closed. Do we know that? Is it possible the mind is causally closed? It's just very complex.

Joscha Bach 1:00:43
The question is what kind of causation you will observe in the world. And this was an idea that first occurred to me when I was a kid and was playing on on town it, there was a class of computer games, which were called nuts, they still exist in a way, but most of them are no graphical, multi user dungeon adventures. And many of them were implemented in an object oriented language that allows you to create an arbitrary board from text. And so it was very much like a text adventure. But it was a text adventure that was dynamically evolving, and in which people could interact across many computers. So they would log into the same server, and each of them would have a virtual character and avatar that would play in that world. And some of the people advanced to the point where they would become wizards. And even gods. And the wizard, magician is somebody who has read access to the rules of reality, somebody who cannot just use the surface, they have reality that is producing it's a certain mechanical structure, a certain substrate, but you can go and the substrate beneath that, and the substrate beneath that change the rules by which everybody else has to play, right, this is what magic is about. It's also what magic is in the real world about in which somebody focuses on the way in which other people construct reality and messes directly with that layer. So the people around the rich will have a reality that is open to the attacks by witchcraft, by the right access to the attention of people to the way that people perceive their own relationship to reality into the witch. That was the reason why the witches have met. similar fate, under the expansion of Christianity is deduced that under the expansion of fascism is basically a competing system of seeing the world that the dominant new vector did not claim to be compatible with its own mode. So try to eradicate it. So witchcraft in these games existed, right? It's a way to make people perceive reality different by changing the rules by which people have to perceive reality, and interact with it. And this witchcraft exists in our mind, there are ways in which we can perceive miracles and make other people perceive miracles, and it comes down to creating a mental entity, that you can control the mind of another person, that is changing the other person's memories and perceptions. And as soon as you notice that you can edit your own memories, and you'd catch yourself editing your memories, you notice that the interaction, the causality, in your mind is symbolic, there is stuff going on, like you perform a certain ritual that involves maybe sacrificing a black cat. And as a result, things in the real world change that are not obviously mechanically connected to the sacrifice of the Black Cat, right? So completely Symbolic interaction, the power of symbolic rituals can only be explained, I think, by the fact that our minds are not the cause of the close those layer.

Unknown 1:03:44
So you're saying that sacrificing the Black Cat actually does cause a change in physical reality?

Joscha Bach 1:03:50
No, it must cause a change in the way that you make sense of physical reality in the way in which you relate to physical reality. You're the model that you make, and the actions that you perform as a result of that change. You regulate in a different way. And as a result, reality will now look different to

Unknown 1:04:06
you. That yes, okay, that certainly makes sense. So, for

Joscha Bach 1:04:10
instance, you could make a ritual to become, say, a CEO of a company, imagine you are a person that is an employee of companies difficult to hold on to a job, they're financially struggling and so on. They really don't know what to do about this. And there is no way they can get out of this. They look into the all the rules of reality that exists. They can look into economic theory, and they're realized I'm a member of the working class. In fact, there's nothing I can do about this right? And then they meet a magician, and the magician says, Look, we can do these rituals and a lot of people that offer this magic as a service, they have this abundance meditation and expensive retreats and so on. And they basically reprogram you into becoming a glorified parasite or an entrepreneur or an investor. And the difference between an investor is not some magical ritual that has to be a form that bursts, or change the universe or change with the social order. It's a change in how you relate to the world around you. If you can basically change your expectations in such a way that you consider yourself to be a very different system, you can often gravitate to a very different place in society and the economic order, right. And suddenly, you have this big house and this big cart. And it's not that you are working necessarily longer hours than you did before. But you just interact with the outside world in a completely different way.

Unknown 1:05:31
you've updated your code, all the time.

Joscha Bach 1:05:33
And the same thing happens to save this relationship. So you want to find the perfect partner or you want to meet very particular people, and you perform a certain ritual, and that suddenly changes the way you interact with reality and its downstream effects, also makes other people interact with you in a different way. And suddenly, you find yourself in a very different position in the world.

Unknown 1:05:55
That's true, but I'm not sure about its significance, if we assume that something like a rough distinction between hardware and software, and I understand that there's actually many layers of software in the mind to update your code, and then therefore have a different degree of traction in the world than you did before. It doesn't strike me as particularly mysterious,

Joscha Bach 1:06:17
you know, if there is only one real layer, and it's the layer below quantum mechanics, and everything above that is models, there is a lot of ways in which we can the middle of these models to get the outcome that we want.

Unknown 1:06:30
But so far, we have not found any such mechanisms to actually impact the level of physics, right? We cannot change the mass of electrons via witchcraft, we cannot change the spectral characteristics of Alpha Centauri by sacrificing a black cat.

Joscha Bach 1:06:48
Exactly. So there seems to be a level at which reality is causally closed at which metric is not possible. This was the point that was trying to make this hypothesis that the world is entirely subject to symbolical magic falls apart at some point, because there seems to be a layer outside of our minds, that we cannot change, or the walls do not change. And the question between the magicians, between the people that think that everything is a dream is that this is only because we have agreed with each other that certain parts of the dream are immutable. And we cannot affect from that dream, because then we will go insane from the outside and from the inside reality falls apart, just descends into chaos.

Unknown 1:07:32
And of course, you cannot disprove idealism, right? It's unfortunately, in that area, where could be true just seems fucking unlikely to me. And as I said, I put my flag down many years ago as a naive realist, which is, there is a reality out there magic doesn't work on physical reality. And it's not because we all agreed not to change. It's because it's just a different thing. It's not a realm in which magic can apply. Magic has no category in the actual physical world. In terms of our symbol SPACE, yes, you can believe in magic. And you might actually think about the world differently. Think about people who go to casinos and believe in luck, for instance, right. And I know many such right. And yet, we all know that if you look at games of true chance, with large enough n, there ain't no luck, you know, the house always wins and a highly predictable amount. In fact, believe in done experiments. I love this one where they track the win and loss records of a group of nuns that went to a casino and a group of ex convicts that went to a casino. And guess what they both won and lost at exactly the same rates once N was large enough. So you know, these mind viruses that attempt to claim that they can manipulate the universe, but can't are a specific example of what I might call malware, that the human brain is susceptible to very, very susceptible to just think of the nonsense that's loose in the world today about COVID-19, for instance. But you know, I do believe that we can use a sharp enough knife and say, you know, this is just not true about reality.

Joscha Bach 1:09:09
So, the Oculus might say to you, Tim, you've locked yourself into a reality in which you will never win the lottery because you have made that commitment in the way that you in which you constitute your relationship to reality, that you can never beat the odds, right? That magic is not possible. And it's hard to say whether that's true for but when you compare the hypothesis from the outside, you can basically see which one leads into a consistent model of reality. You can, of course, will always perform magic. Imagine you run a company and everybody in the company is depressed because the numbers don't add up and they're pointing towards doom. And then you hire a consultant and the consultant performs magic and changes the benchmark. And suddenly everything is awesome again, right so you pay the consultant and now the question is What's happened to your company? Did the consultant impose a better model on your company by which attracts its performance in a better way, and regulates in a better way? Or did they just cheat. And this is the issue of his magic that a lot of magic comes down to cheating. Of course, you can edit your memory and your expectations and your interpretations of what happens in between, but might also change the way that what you feel like for instance, even if you feel terribly, you can just imagine that you are basically a king that presides over an awesome kingdom. And that tomorrow is going to be awesome. Again, and this is just a very, very short intermission. That is does not actually mean anything. And there's movement, if you look at it from this perspective, it's actually quite bearable. Right? From this perspective, you're probably going to be much happier person. But of course, the question is, in the long run, how well do you track reality?

Unknown 1:10:49
Yeah, let's say for instance, you decide that I am the king of infinite space, and I decide I'm not going to work and I'm not going to do anything, and then I'll end up starving to death. Right. So at the end reality bats last, you know, again, when in terms of public affairs, you can claim that COVID-19 is a hoax. But that doesn't stop the virus from doing its thing.

Joscha Bach 1:11:11
Yes, of course, you can also do the opposite. For instance, since my early use, I think was early teens, when I stumbled on the same thing as Greta Thornburg did, which the limits to growth and the environmental pollution that was, you know, on a one way trajectory, and the fact that we didn't have regulation mechanisms implemented in our civilization that could make it sustainable for Breakstone. And that seemed to be an obvious thing, right? That we are instigating dynamics that when unchecked, will lead to the demise of our civilization. And our main defense against that is visual thinking. And once you realize that, you get depressed, right, it's terrifying. And the same thing is also true. When you look at society, you mostly focus on the things that get worse, or institutions get senesin for people defect from what they should be doing, and all levels of responsibility. And everything is constantly breaking down and getting worse. And this was my dominant perspective for most of my life. And I must say the world didn't disappoint. Right, there was always enough evidence to support this worldview. So I spent my life being extremely worried. I did the inverse to the king that thinks that what you see today is just a short intermission, of let's actually analyze unpleasant things happening in our life that is overall totally glorious. I basically perceive the world as something that is pretty much miserable, where the past and the future are miserable. And the present is quite bearable. But this is an exception that will surely be corrected in the near future. Right. And this is an opposite distortion. That is unhealthy. I think,

Unknown 1:12:47
though, on the other hand, I think your analysis is approximately true, as we talked about before, that the current status quo seems to be in a runaway state where it is going to run over off a

Joscha Bach 1:12:55
cliff, it totally is right. 2020 is not an aberration. It's exactly the future that we always expected would start to manifest around 2020.

Unknown 1:13:04
Yeah, and it's starting, and it will get worse until we do something

Joscha Bach 1:13:07
about it, he could have enjoyed the time in between so much more. That is

Unknown 1:13:11
true. All right. Well, that's this was interesting. This is interesting, but it's not quite on the main line of the topics I wanted to go through. But it was very interesting. Let's move back a little bit more to some of the specifics of cognitive architectures, you know, the nature of cognitive processing. And particularly, I'd love to talk a little bit about what your views are on the gap between humans and other animals. You know, you alluded to the fact that, you know, elephants have much bigger brains than we do whales do to some dolphins, killer whales, I think. But we don't see, you know, elephants sitting around philosophizing. And of course, one of the theories and probably the leading theory is the difference is that somewhere along the line, we added a new class of object into our brains, something like symbols, maybe or language of thought, or perhaps it was a more powerful form of procedural memory that allowed us for instance, to conceptualize multi part tools that maybe that was accepted for language, but something in that space. What are your thoughts from examining AI and cognitive science about this only 1% one and a half percent difference in genes between us and a chimp and yet seemingly a giant gap in terms of our cognitive ability?

Joscha Bach 1:14:29
So there is an experiment that would be very interesting to make and is, how smart Can dogs be? There are obviously extreme differences in the intelligence of dog breeds, right. And typically, these small dogs that we would like to have in our home tend to be quite dumb. And the dogs that we use to hurt our sheep tend to be very smart, but they are the dogs that hurt our sheep tend to be less controllable and that's to double as to keep around, because you need to negotiate the relationship to them at a more fundamental level, their stomach less domesticated, and harder to domesticate. And it almost happens also seems to be domesticated a minute, sometimes wonder whether the Neanderthals were individually smarter than us. But they didn't have scalable tribes that have that would scale into states into societies with unlimited numbers of individuals beyond the Dunbar number. And in order to get people to cooperate at scale, you need to domesticate them in such a way that you would selectively tamp them down to tamp down the epistemology, so they are able to believe the same thing without proof. And welcome, Doug step. It's interesting,

Unknown 1:15:45
though, I will point out that the confrontation between Homo sapiens sapiens and Neanderthals happened when we were still operating below the Dunbar number that was obviously in our forage or stage, you know, at the latest 36,000 years ago, so I'm not sure I buy it with respect to Neandertal. On the other hand, it's a fact that archaeologists tell me is true, that if you compare modern man to CRO magnon man, say 12,000 years ago, at the very end of our forger days, CRO magnon man's brain was 10% larger than ours.

Joscha Bach 1:16:20
Exactly. So what I wonder is if the evolutionary advantage that allowed us to displace the Neanderthals to genocide them, which is probably what happened was coordination,

Unknown 1:16:33
you actually employ reasonable cooperation as the human superpower?

Joscha Bach 1:16:37
Yes, it's not just the baby cooperate in the sense that we make a choice individually to cooperate with somebody else, which would cooperation is usually about it's that we do this without thinking, if you do this automatically. That's

Unknown 1:16:52
interesting. But again, we're really interested in the line between let's say, humans and chimps, right, which is much bigger than between CRO magnon, Neanderthal Neanderthal and chimps is gigantic, to just a little bit smaller, perhaps.

Joscha Bach 1:17:05
Yes, so the main issue seems to be length of childhood, I suspect, the length of our childhood is not too much given by social circumstances, that does play a role. But the main issue seems to be the match speed of the maturation of the brain. And what you see is that an ancestor societies it takes at least 15 years before you're able to forward more than you can eat. And in our society, this period is even longer. Right? So the time by which a kid can basically earn more than it needs, in terms of upkeep is typically longer than 18, and our society. So it's a very expensive period to maintain, in which you're mostly doing exploration instead of exploitation. And what you notice that in this period, it's not just a decision that the individual is making to focus more on exploration, the individual is, in some sense, the truly insane, it has an incomplete model of reality. It is an incomplete architecture. They don't think this is just not because it has not learned enough yet. But it's like the capstones are missing. It's like the training happens layer by layer. And the infant spends a longer time than a cat infant, to learn basic spatial relationships, and learn contrast and object permanence and so on, and then spends a longer time on engaging with social relationships, and so on. So you'll find that a cat housecat can have a better model of the social reality and the family and the capability capabilities and relationships of the individuals between them, and then it will your baby will have, right. And it's despite the baby obviously being in some sense, much smarter when it comes to spatial reasoning, and so on, even at that age, and definitely in terms of using language, because most two year olds do have some kind of language that far surpasses what a cat can do. So it seems to me that our ability might be conjunction of slightly larger brain and optimized architecture, but mostly more training data per day when we bootstrap our brains so we can make better abstractions. And that would be a very simple genetic switch. So you could have a genetic switch that basically delays childhood, every phase of it makes it slower. And as a result gives you smarter chimps at the expense of longer childhood, which means that humans need to have much better environmental circumstances and more benefit from exploiting these circumstances especially. So I suspect that moving into temperate zones where you have a benefit from planning ahead, so you can make agriculture and decide that if you put stuff in the ground, now it might sprout. And if you keep a certain fraction of the stuff that you will not eat as seedlings for the next year or four years in which you have less vegetation coming, all these planning ahead and so on, is going to give a huge benefit to a long childhood allows you to generalize over a very, very long Time spins.

Unknown 1:20:02
Interesting. And then of course, humans. Of course, this is just one of these Just So Stories about evolution. So it may not be true. But one of the theories is that once we started standing on two feet, bipedalism, it produced evolution that constricted the opening of the pelvis, that limited the size of the head of the human baby. And hence, while there was seemingly something going on with rapidly increasing brain size, when our brains are almost three times the size of a chimp brain, even though we have similar body size, we're a little bigger body size, but not anywhere close to 3x. The constraint was the pelvis arrangement in the bipedal method of getting around. And hence, the evolutionary adaptation was to be delivered very, very, very prematurely, so that we required a much longer time to fully develop our brains. Unlike actually, the model animal I use in my cognitive science work is a deer, white tailed deer. And white tailed deer is fairly competent two hours after it's born, right, it can get up and walk around, it can find its mother, it can flee from prey, not very well, but at least a little bit, compared to a two hour old baby can't do a damn thing, right? Because the dear pelvis allows a much larger baby relative to the size of the mother. And they have not been under evolutionary pressure for really large brains either. So maybe that is the causal factor of this very long learning process, which is interesting, but very interesting point you make about however we got there, the fact that we have a very long maturity period, would tell us that we've had more training cases to run more layers to build and more abstractions. And that's interesting.

Joscha Bach 1:21:46
Having a large brain is super nice. I also see some people that are obviously super smart, like, say, to unlearn and Steven Paul from it also have extraordinary large scouts. So it seems to be possible to have a little bit more leeway in the human pelvis to get larger skulls out there. And sometimes it also has good results. We also find people that have brains that are similar to say, a gorilla brain, and these people are not necessarily mentally impaired in any way they can hold down a job, they often study at university and can be reasonably smart people, right? So the size of the brain is not absolutely everything that is certain the way in which you can use it. And it's probably nice to have a brain that scales up better. But I don't think that brain size by itself is the deciding factor. What about the theory

Unknown 1:22:34
that symbols or language per se, is the bright line? Yeah,

Joscha Bach 1:22:40
I wonder about this. That's a very tempting idea. And it seems to be that the ability to do grammatical decomposition is something that distinguishes the ability of humans and other apes. Right. So for instance, elephants don't seem to be able to produce new images. So you can learn to draw in what they will apparently those, at least on the instances that I've seen so far, they don't generalize, they don't make a portrait, they don't capture a new scene, they will produce the same image, stroke by stroke again, and again, they can learn to do this, they have extremely good motor control. But there is no obvious generalization and observation going into the thing that at all, it's not a symbolic depiction in the same way as we do it. And if you look at the gorillas that has been raised in environments that are exposed to human like stimuli, and human like familiar structures, and so on, they did get in many ways to be more similar to humans than many people thought possible. But they also didn't do the dramatical decomposition. So when Coco draws a dog, it looks like Jackson Pollock, it's basically an arrangement of colors that seem to be related to what he was looking at, that you don't see the decomposition of the dog into limbs and torso and the head and the arrangement of the parts. And this has not been properly reproduced, that it's tempting to think that the lack of chromatic decomposition in visual scenes corresponds to the lack of the ability of the gorilla and the tendency to use grammatical language, and

Unknown 1:24:21
maybe the grammatical language because it's such a compression, right? If we don't have symbols, we don't have something like least partially recursive language. And we'd have to manipulate images only, which is at least one argument about what's in the brain in the pre human era. The density and ability to manipulate easily images is way less than symbol symbols are tiny, right? The concept of dog even if I don't have a word for I don't have written language, conceptual dog is much smaller than many, many images of many, many different dogs. And so having symbols may just make the brain exponentially more effective.

Joscha Bach 1:24:59
As an interesting question, also, if there is a continuum between human intelligence and deep intelligence rather than a sharp cut off

Unknown 1:25:07
what I've read, it seems to be, it's not sharp. But there's a big, big gulf, right? As you say that you can teach cocoa to put together very simple linear sentences, but nothing at all like a recursive sentence.

Joscha Bach 1:25:22
Yes. But of course, there are human beings with developmental deficits that have a similar cognitive capacity. Right? So there are certain syndromes where the brain does not develop in the same way as it does for the others. And the question is, what exactly are the differences are these all pathologies, of course, they are, in some sense, because our genetic code is the same, for the most part, and they're just local changes in the genetic code or environmental conditions, that prevented development to the specification that we are normally evolved to. And yet, if you look at the differences also between human beings, and notice, this is a tutor in computer science, that the performance that people achieve, as programmers can often be predicted very, very early on, depending on the kind of abstractions that they are making in the first few hours when you are confronting them certain ideas. And that is basically a hierarchy of concepts that you could see in computer science, say, from variables to loops, to pointers to functions, to closures, each of these concepts basically requires more and more inversion and abstraction, more and more pointers that you need to keep stable in the same representation. The more abstract these concepts become, the harder it is to teach them.

Unknown 1:26:43
Yep, that is very true. I found that same thing in my technology career I hired, oh, I don't know, 1000 software developers, perhaps. And I got to be very, very good at it. Right? You know, I'm a pretty damn good programmer, but I know many better ones. But I do have probably a better theoretical basis in computer science than most. But I was able to recognize at a very high level by asking relatively few questions, where they stood on this hierarchy of understanding and the ability to grasp increasingly abstract software development concepts. And you're absolutely right, and our conversation, I could predict at about 80 or 90% level of confidence how far this person would go in their career.

Joscha Bach 1:27:28
And that's the thing that most of these concepts can be taught. It's just the the amount of time that it takes to teach the concept is very variable. Yep.

Unknown 1:27:38
Yep. And realistically, you only have a budget of education period, right? Yeah.

Joscha Bach 1:27:43
And realistically, the individual also has a few decades. Right? So if you are able to just learn 5% better than somebody else, this is going to compound. And so I'm totally envious when you look at Stephen Wolfram, who understood things at 22 that I understood in my 40s.

Unknown 1:28:04
Yep, I certainly saw that in my dealings with the people of the Santa Fe Institute. You know, in the business world, I was almost always the smartest guy in the room. At the Santa Fe Institute, I am almost always the dumbest guy in the room or damn close, right? Yeah, these

Joscha Bach 1:28:18
are great rooms. Yeah, those

Unknown 1:28:20
are great rooms. You know, as I said, That's not quite true. But in business, I was definitely in the 99th percentile in the world of complexity science, on a good day, I be the 25th percentile. And that is it is, you know, you learn so much so fast. But you also come to appreciate that there are people who just operate at a very different level of abstraction that which I will never be capable

Joscha Bach 1:28:41
of. But that's okay. Yeah, these people make me very happy.

Unknown 1:28:45
I'm glad they exist, I liked them a lot. And frankly, I spent a fair amount of my effort making their life better, right, so they can do their work. Let's now switch a little bit, let's get a little moved down some in the stacking of abstractions. You know, in your writings, particularly in the book, you talk a fair amount about cognitive architectures as an approach to we talked about the very beginning, thinking about the brain through software in ways that may help us understand ourselves and by the way, maybe do practical things but at least understand ourselves better. Could you maybe tell our audience a little bit about what cognitive architectures are in the sense you know, things like soar Act are and the OSI model, and how they differ from what we read about in the newspaper all the time, you know, that machine learning deep neural network approaches.

Joscha Bach 1:29:34
A cognitive architectures are a tradition that mostly originated in psychology is in people that were strongly influenced by the ideas of cybernetics and AI, and then decided to get real about this and try to get a look at the way our mind structure because our mind obviously has a lot of structure to identify the architecture of our mind, and then identify the principles that would need to be employed. mended. And I think that most people in the field of AI would agree that there are two directions that we need to look into. One is the general principles of learning and function approximation. So when confronted with data, how do you efficiently build a model over the data that allows you to predict future data and interact, visit and build control models? And the other question is, in which particular way is this organized in the human mind to give rise to the particular fields that humans have, like learning language, interacting socially interacting with the environment in which their bodies to reflect symbolically over their perceptual representations such as feelings, and so on. So to how to get these two perspectives together? Is, is for me a very interesting and challenging question. And most of the work that is being done in machine learning is not looking at architectures, the architecture is only instrumental to a certain task, which could be for instance, text completion. So we think about how to organize structure into layers, and then how to stack the right number of layers together, or maybe implement an algorithm that automatically searches for the right number of layers. But we can also see that the brain is not organized into layers. It's organized into regions that have very complex interconnectivity, right. So it's much more like a city with a rich set of different ways of transporting information around in it, right, so there is going to be some street network that is low level where you can reach your immediate neighborhood, and then, but it's quite pedestrian, and it takes longer for the signals to cross large distances. And then there are long range connections like a subway, and then there is some general interconnection network that goes by the thalamus and allows to, for information from basically all every region in the neocortex to get to every other to route information around. So how that works is a very interesting question to me, you could also look from a perspective of training network in terms layer by layer. And then as soon as you introduce a new layer, you make this a function of the existing layers. And once that thing is trained, you introduce recurrent links. So the predictions of a later layer and your architecture are going to inform the predictors of the earlier layers and become inputs to them, right. So they become the context in which the lower layer makes its next prediction. And the result is the same. So instead of getting a nicely tidied hierarchy of things, where you have an input and an output, and the input is your sensory apparatus, and your output is the highest layer of your attention, it turns out to be fully interconnected and going everywhere, backwards and forwards. And suddenly, your visual cortex is not the first stage of processing is just the area where you store that saw the textures.

Unknown 1:32:52
And of course, that seems to be how the human mind is structured. And when I reacted deep learning mostly feed forward, though they're now adding some simple recursion, I always ask myself, what are they missing by not having these feedback loops?

Joscha Bach 1:33:06
I think that everybody is aware of the fact that they want to have recurrences right from the start, when you look at the original work, for instance, by Hinton, and Sejnowski and clay on Boltzmann machines, that you have already a very, very general form of a model that understands that a model is a set of parameters that constrain each other. And each constraint is a computable function that says, if a parameter has business value, the influence that has on all the other parameters in the model, and then you can say that the deviation from these constraints is energy, and you minimize the energy. So it's very similar to spin last model in physics where you try to minimize the global energy state of the system. And when you achieve that the system converges to an interpretation of reality. And in some sense, theoretically, this works very well as a model, it's pretty close to optimal. But it's impossible to train, it turns out because the search space for these variables and constraints between them is so dramatically large, it's basically not trainable beyond a few parameters. And so Hinton introduced the constraint on the seeds that instead of having all these natural links between the parameters, or these hidden links, the only link them in the forward manner and in between the parameters, we don't have links in what's called a restricted Boltzmann machine RBM. And, of course, suddenly, the thing cannot model many things anymore. And the solution to that was to string many of these are VMs together in a network. So each of them is individually trainable, even though it's limited, and overall, it produces behavior that the individuals could not. And this eventually leads to our current deep learning architectures via a few steps. And it's not optimal right? The search space is too large. The too many models states the ideal model should be able to be so tight that every model states corresponds to a possible state in reality, most evil networks Have many magnitudes more possible modelled states, which gives rise to adversarial examples and limits generative creativity because most of the states that the system can be in does not correspond to a world state. Right? So, for me the thing that a lot of people don't pay enough attention towards what the transformer model is achieving seems to be a way to think about embeddings into a space of features in a more general way. So it gets back to this original notion of the Boltzmann machine, from a in a different projection from a different perspective, but still, and it is this notion of attention itself, attention binds features together across the dimensions into a relational graph. And this allows you, for instance, to generate a text in which a noun and a pronoun associated over a very large distance or where the initial part of the text mentions the person by name that performs a scientific experiment in the data, part of the text just refers to this as the scientist or the researcher, and uses them as synonyms and understands in some sense, or represents that these are all these entities refer to the same concept and the text, right, this is something that was very hard to achieve in previous neural network implementations of language. And it's striking that this doesn't only work for text, it also works for images. So you can train this on images, and you feed it, the first few lines of an image is going to continue the image, which implies that internally, we're predicting the image, it's building a representation during the prediction of the next thing of the entire image until the end, right. So that's a tremendous achievement, it seems to open the door to embeddings. In general, across all modalities, what happens if you are not just modeling the perception of a system like this, but also its decisions? Is there a difference between making a decision and predicting your decision, it's probably the same thing, just from a different perspective, right? There is still going to be some differences in terms of the way we predict reality, because we do not predict reality just from the past. They also predict reality from the perspective of the future that we want to have. So we limit our search space to certain results that we want to have achieved in the end. And this is a thing that the way we access the GPT to class or transformer class of models currently are not doing. But there's nothing that is inherent to the way these models are constructed. It's just inherent to the way we're currently using them. That's

Unknown 1:37:38
very, very interesting about where we may be able to go. And using transformer based architectures to get back to, you know, the ability to do things that long range.

Joscha Bach 1:37:48
And you know, the transformer architecture is still a heck, if you look at it, it's a very simple idea, of course, very smart, simple idea that is then scaled up to see how far I can go. There's not an obvious limit that we have hit yet to offer it can go which is in some sense, terrifying, because it's so simple. And you've immediately wonder, what are the optimizations going to be that evil quite inevitably discovered in the next few years?

Unknown 1:38:16
Yep, that'd be very interesting. Let's keep a lookout. And we're getting long on time here, granite gone over our time limit, but that's okay. I'd like to drill down a little further into details into some of your own work. Now, let's maybe give it another 10 minutes if we can. And talk a little bit about the psi theory. Dietrich Dorner is that the guy's name, who came up with it. And he wrote the very interesting book on the topic. And one thing I found interesting about it was that it was connectionist. But the elements in the connection architecture, while they all use the same architecture, could be at varying levels of abstraction from quite high to quite low and you know, the system self organized and hierarchical all that stuff. So anyway, if you could explain how all that works.

Joscha Bach 1:39:01
Dietrich Turner is a German psychologist, seventh edition, strongly influenced by these ideas in the 1960s. For a while she had a desk in the hands of colleague is standard stuff them who became a good friend office. And at some point, their directions diverge, even though they remained friends over the years until them died, and then decided that the biggest influence that he could have on the development of artificial intelligence in cybernetics would be to become a philosophical science fiction author, because he would be free of the constraints of academia and to actually get things to work. And instead, anchor ideas in the minds of people that would have a larger influence that writing a few papers about systems that he would not be able to get to work in the next decade or two decades. And Donald was more optimistic. He thought that behavioral psychology which was all the rage at the time, is not cutting it, and instead, we need to do cybernetic and computational psychology. just implement a model of how people work. And then we'll be done. And he thought that he'd be done in the late 1970s, originally and told his wife, that they would have an awesome time on the beach after that, because their job would be finished, we would have computers that think and solve all our problems for us. And of course, didn't quite work out. But he, mostly on his own, reinvented or invented a parable, many of the ideas that AI was into. So he started out with monolithic systems that later became situated connected to environment, and then this environment could be changed by the system. So it became an ancient architecture. And then he invented multi agent architectures. And all the wire these architectures had models of autonomous motivation in them that were based on this cybernetic idea of a feedback loop that would regulate it all. And what I liked about his work was that he was extremely serious about building minds. And his heart seemed to be in the right spot. And also his ideas seem to be on the right spot. So I started reading his ideas in the 1980s. Most of the psychologists ignored him because there was theoretical psychology, for a long time had the only Chair of theoretical psychology in Germany, there was no such thing as theoretical psychology. And that basically tried to bridge between AI ideas in psychology while he was mostly unaware of the discourse that would take place in AI. And you would read sometimes something about it, but always come up with his own solutions. The first interview that I read vism, the very constellated, journalist of the German magazine, Spiegel, which is the equivalent of the times in us, asked him why he would claim that these systems are have two emotions, it would be wouldn't everybody understand that it's impossible for a computer to have emotions. And Turner replied very earnestly, that it really depends on your definition of emotion. And that if you have a definition of emotion that doesn't have an extension that you can understand, you probably don't know what you're talking about. And then he went on to try to define emotion, and then try to explain why his systems would have emotion in the sense. And I agreed with them. And while I thought that this notion of emotion does not capture everything, that emotion captures, for me, when I define emotion, it seemed to me that there is a trajectory along which we can make this definition richer and extended, and then implement all these missing things, until we all agree. So I thought, this is probably the way to go. And I started reading all this stuff, and then decided to systematize it and translate it into something that could be actually implemented. And because it was less bold than him, I took his size theory site, this letter that psychologists love to use, and they make a theory of everything, and translate it into Microsoft, in my humble attempt as a computer scientist to get some of the concepts, at least to work. And I spent almost a decade with that. And this book principles of synthetic intelligence is an attempt to turn the site into an acronym for a book title, of course, and to systematize his work and make it accessible to people in cognitive science and artificial intelligence. So this is what the first third of the book is doing, summarize donors ideas, and systematize them, contrast them with ideas that were around in the field compared to related work. And then the second part of the book is implementing these ideas. And the third part of the book is critiquing them and explaining where I think we need to go beyond them. And this is a snapshot of my understanding back then. And my thinking has, since then, in many areas, evolved a great deal and moved on. It's not that I still think that he's now saying that these are bad ideas. It's just, this would be the first third of the next book that I would write if I find that.

Unknown 1:43:56
Okay, interesting. And what is the status of the Microsoft Project I saw there was a microsite one which ran only under Windows. And then there was a microsite two that was written in Python. But I looked at the GitHub project look like there hadn't been any updates on it for five years. Is anybody working on it as it's being used at this point?

Joscha Bach 1:44:16
Yes. So the first Microsoft, we always tried to be platform independent, because the people that I worked with, they had Macs, they had Linux, they had windows. And we wanted to make this accessible to anyone. So the first one was done in Java and was written directly is plugging into the Eclipse IDE. And it was using all the typical things that you would use in 2003. So lots of XML and lots of factories. And I think that back then it was respectable software engineering, but it was very different from what we would do five years later, when everything was going to be pious and you would put your UI in the browser. So the way to make platform independent implementation of a research cognitive architecture was different than you did the second edition. And the second edition was being used in two startups one went defunct was an AI planning startup. The other one was started later by students of mine mostly, I'm also a co founder. And this is called microsite industries, and uses the microsite architecture as a framework to implement control networks for industrial robots mostly, and also does a little bit of basic research. But most of the things that are done are in house so why we still host the architecture for people that want to use it, and some people use it and play around visit, the main evolution takes place within the company for proprietary projects in Britain. And at the moment, I am using microsite internally for trying out certain models that I have about using spreading activation networks to produce procedural strips that interact with cellular automata. representation and processing. There's also thinking about what the next edition of Microsoft is going to be and how it's going to be implemented. And we have some ideas about this, but it's too early to talk about this.

Unknown 1:46:07
Okay, I was gonna see if I could get you to talk about what Microsoft three might be looking like, I'm gonna throw out some ideas, which I also am always throwing at Ben gertle, about opencog, which is, I hope when you do it that you think big. So many of these cognitive architectures or AI platforms were unfortunately conceptualized to only run on a single machine or a small cluster. And one of the things that we now have is really cheap computation and really fast networks. And if I were designing a platform for thinking machines, I would look carefully at some of the Apache, large scale, very big cluster very large throughput platforms like Ignite and Flink. And Spark has two big advantages, one that they operate at massive scale. And secondly, it gets the implementer out of having to write a whole lot of low level stuff. And so you can leverage your manpower in the higher levels of the actual value add rather than trying to optimize how you move pointers and things of that sort. These guys have already figured that out.

Joscha Bach 1:47:14
Exactly. I also wonder whether we should still think so much of vision system and more across systems. So instead of thinking about how we can make a representation that is completely homogenous, think about how different parts of the architecture, implement general principles that allow them to learn how to interact with all the other parts. And if that happens, you can for instance, instead of reinventing linear algebra on your GPU that then reinvents how to render graphics on the GPU using linear algebra. You can, for instance, use existing shader programs and graphics engines and learn how to use them instead.

Unknown 1:47:50
I think that's right. And again, there is no free lunch. So people say, oh, yeah, well, you have Ignite, you know, a true gigantic key value store. Well, guess what, on distributed architectures, there is no free lunch, right? queries that have to traverse the network have very different costs than ones that don't. And so having a system that can self organize, to take advantage of the realities of its network is probably the real secret to maximize these super powerful, gigantic scalar tools. But using them naively, you can produce degenerate queries quite simply that yes, you have 100,000 processors. But guess what, it's still slow, because the data is all over the place. So that makes any single query inefficient. So these things are by no means panaceas. But if I were going to go down that road, I would be thinking of these very large scale data processing architectures, rather than writing something to run on a single machine or a small cluster. Well, this has been a very interesting conversation. We went a little bit longer than I was thinking we didn't get to some of the topics I had on my list, but that's okay. I think our people will find this to be quite interesting, deep dive into the mind of your Shabbat.

Joscha Bach 1:48:58
Thank you. I really enjoyed our conversation, and I'm sure we have more topics left for future. Thank you very much.

Unknown 1:49:09
Production Services and audio editing by Jared James consulting music by Tom Mueller at model

This transcript was generated by https://otter.ai