Joscha Bach 0:10
Good morning, dear fellow conscious beings. And Good day to you, fellow human beings in front of the displace at home. I would like to talk about four basic questions, actually, probably, I'm not able to answer them completely today, because they're sort of the first questions that we have might not be quite true, I think the first questions that we had, as humanity was, where's the foot? And then how can we push back and to pee far enough to get warm and to get the dirt of us? And then once that was solved? Where can we find love? Because love is important. And when this was solved these questions remained. That is, what's the nature of reality? What does the universe look like? What's the state of affairs out there? And then what can we know about it? What's accessible to us? Who are we? What our minds? And what should we do? Philosophy hasn't found final answers to these four questions, but it has asked them very nicely. And I think that if you want to turn to answers, we should look into individual sciences. And I looked into computer science mostly for the last 23 years or so. And I would like to focus on a particular small sub question, and that is the question of how it is possible that the mind experiences universe and make sense of it? How is it possible that signals enter our mind somehow, and are assessed by arrays of finely tuned classifiers that react to them, and then create dynamic representations of objects and things and give rise to desires and needs and vicious, and then this whole thing triggers associations in our memory in our mind. And this all gets into graded into a coherent experience of awareness, this spreads out and stabilizes throughout our mind. And then this gives rise to new memories and imaginations, and goals and plans and expectations. And then it feeds back into the world somehow. How's that possible? I think this is basically the most interesting questions of all. Reality is not given directly to us, the only thing that we get from it is appearances. Or as a result set with more than 100 years ago, you get phenomena. And somehow our mind is able to turn these phenomena into ideas and concepts that will so called Noma. And the process by which he does it is what he called noises. You cannot really say much about the state of affairs, whatever you want the fact that it's able to yield phenomena, appearances. And because we cannot say anything definite about their, how the structure of the universe really looks like was all said, We shouldn't say anything about this, we should just shut up about it. And he calls this if okay. So far, so good. But then his pupils came along. And then they tried to apply this idea of new Asus upon new Asus itself. And they realized, if we try to explain races, or we end up this is no mo again, it's all the explanations that we possibly get about the state of affairs are part of our ethics fear, they're just ideas and concepts. So to formulate them, we already need to presuppose noises, science cannot reduce noises itself, Max Taylor said. And therefore, it must presuppose the existence of its object in the first place. This has given rise to continental philosophy, and eventually to this division of most of philosophy in the sciences that we experienced throughout most of the last century, which I think is very unfortunate. But there might be a way out of this. If you look upon the idea of how a robot perceives the world, it has an interface to the environment, this interface face might be a bunch of sensors, and these sensors yield a vector of bits, that is discernible differences, patterns, that is the semi boundary that might be used to reduce uncertainty. And these bits are encoded into some low level encodings. And then we might have a cognitive architecture implemented in the robot some processing that turns this into a conceptual representations that allow the robot to reason about the world and to tell itself a story about what the world looks like, like and what itself looks like in that world. But of course, we're a robot there are no phenomena. It's nothing what this feels like to be in this world what the appearances are, and so on to the robot, there are only bits at the interface To the world.

Joscha Bach 5:02
But perhaps it's possible to build a cognitive architecture in a robot that is able to encode these bits at its systemic interface into something that looks like percepts to the robot that looks like phenomena to the robot. And that gives rise to concepts in a very similar way. It's noises that and humans object, the phenomena in this way might result from a robot information processing architecture. And if we buy into this paradigm, of course, we might ask ourselves, if humans are robots, too. And this idea that humans are actually information processing machines, is what underlies most of the cognitive sciences, whether they aware of this or not. How do we perceive reality? You probably know this well known picture. I think I turned it upside down. Okay. There's something odd with this picture going on. Yeah, this is the normal version. The thing that was odd about it in the first place was that the eyes and the mouse have been turned around. And maybe some of you didn't notice at first. Why is that the case. And I think that's because we don't process and take in faces as a whole. But rather, we process features in the face independently. And then we combine them into a face schema that we mentally scan. If we look about visual information processing, first of all, we have a retina and this retina gives us a vector of bits. That is information patterns that are systemic boundary that reduce uncertainty that we can encode, to form concepts about the world. Data on the retina is not a very good semblance of what what's out there in the world or whatever, there is a very sharp spot in the middle that is large enough to read, it's pretty small, then there is a lot of machinists around color vision is only there in the center, there is a blind spot in which the optic nerves that connects to the retina and where we have no photoreceptors. But we don't see any of this, of course, this data is first projected into what neuroscientists call the lateral geniculate nucleus, which is a fancy that is Latin way of saying that it's some sideways knee like looking protrusion protruding core. It's in the center of the brain. And it's part of the thalamus. And the thalamus determines chamber and it's sits conveniently on top of the spinal cord. And it relays a lot of sensory data into the cortex. So you have a crude touch and temperature and pain and so on, this all gets transmitted by the thalamus, the cortex, you can think of it like a switchboard. And this switchboard puts projects information into the primary visual area, the striaght cortex. And this thing, if you look at the cross section of it, this basically two millimeters of highly packed neurons on top of lots and lots of wiring. In the brain, there is something like 180,000 kilometers of wiring, depending on your age, and gender, this varies a bit. And on top of this wiring in the cortex, we have these two millimeters of neurons that are organized in columns. And in the visual cortex, these columns have the highest density of neurons, which is probably because graphics is so expensive to compute. And right now, Most neuroscientists believe that the primary organizational unit of these neurons is the mini column, the mini column is something like a circuit that is made up of something like 200 to 400 neurons, half of that and the rest of the cortex. So if you do the math, there are about 160,000 million neurons in the primary visual cortex, you get about something like 300,000 features that can be encoded in the primary visual cortex. And if you look into this, two measurements in the brain there, you find that in the middle, there is an expanded area because there are more features detected in the middle and it gets compressed around the corners. There's even the blind spot somewhere in there. And the different humans in this spatial alignment, they code for orientation, and for frequency and for color. The primary visual area v1 Then projects into v2, which has a stable visual map. So all the movements of the retina are combined and something like a coherent visual field is somewhat stable. Alto has more complex patterns and textures it also projects into v3. And in v3 and visual areas, we have color and some motion direction and into V for very simple geometric shapes before we have mostly looked at in non human primates. People probably have an equivalent to that.

Joscha Bach 9:58
It also All these areas project into V five, which has object motion, and ego motion in V six. And you can see that now the these processing paths split up. And we found that there are two primary directions of processing in the brain that work in parallel. One is what paths, it's down there in the brain. And it tells you about the nature of objects and the their parts, which tells you where they are. And this, the bad parts reaches into those areas of the brain that are then responsible for grasping and attending to objects and their positions. This area that encodes for the water of objects is what we call the inferior temporal gyrus, which again, is Latin for the lower side baseballs. And this lower side baseball helps object schemata and enables us to separate figures from ground and also has numerosity. That is the ability to discern numbers, which actually without actually counting. So if we look at, for instance, inside of a dice, and we see this a single look how many dots that are on this side of the dice, this is numerosity. And it's done in the inferior temporal gyrus. And there's an area in the inferior temporal gyrus, which is called the fusiform gyrus, the spindle leg rich and this spindle leg, which is responsible for face recognition. Because it is not working in your brain or you don't have it you have prosopagnosia. That is you don't recognize human faces and emotions and so on very well. And you have difficulty to discern people by their faces, surprisingly common. Then there is an area in the brain that is able to direct attention. And this is the dorsal lateral prefrontal cortex, it's somewhere in the forebrain. And you can think of it as an area that helps a lot of pointers in the rest of the cortex. And using these pointers, it can pump activation in there and create a coherent pattern of activation. It directs our attention it it scans the schemata. For instance, if you have a face representation, or this representation of the Mona Lisa, it can scan down from the face level, to the eye level, and so on. And so the most level discern features there. The great thing about a model like this is that we can actually turn it into a specification for a computer program. And then we can implement this and test whether our theory about how the mind works, all these observations that we have taken from neuroscience, and from heart engineering, like thinking, if you are in nature, how would you do this, we can turn this into a coherent model. And then we can test this model and see that it actually is able to perform pretty good vision. Of course, this is a simplification, and a lot of the details are missing. But it can do most of the tricks that we wanted to show. So I think that we are pretty much on the right path here. So what types of representations do we have, we have schematic representations, this thing that distinguishes between faces, and bodies, and eyes, and so on. And then we have non compositional representations, those that we cannot combine where we cannot reuse the features. Throughout the representation. This is more associative and vague and so on. And it's hard to turn this into language, we have these language representations that enable us to organize our schemas on a high level, and to communicate them to others. And then we have a class of representations that I would call generative. And these generators allow us to build simulations of the world dynamic simulations. So for instance, if you think about music, or sound, but we need something like a synthesizer, in our mind, for instance, here, an artist has made a representation of what the sound of a canary would look like, if you take it from the visual into the visual domain, like synesthesia. And I think this looks a lot like synesthesia if you ever had an synesthetic experience. So in a way, I think this is an equivalent of what the brain does to model sounds like this. And imagine sounds like this somewhere in the brain, a computational structure must be built that looks a lot like this. And it's not a schema. It's not just this static neural pattern, but rather, it's a generator.

Joscha Bach 14:14
The difference between a perceptual representation and an idea is that the perception representation is tagged as being verified in somewhere in the sensory area. So it gets projected down as a hypothesis into the sensory areas of the brain and the nervous system. And then you can get a verification and when it's labeled as verified, our brain takes this as being real by the rest of us being in an idea. So if we try to generalize this, we have the dorsolateral prefrontal cortex that somehow accesses distributed hierarchical representations. And these hierarchies of distributed representations are picked out by the attentional selection. Usually, most of the time there is a superposition of many alternative interpretations. It's very hard to translate this into language. But using the dorsolateral prefrontal cortex, we can make this coalesce into a coherent representation. Imagine you have superimposed images or superimposed photography and have different layers projected onto the same image, we are still able to discern the different layers. This is because we can direct our attention onto a part of the representation, and then make it coherent by suppressing those parts that are not compatible with it. And this attentional filtering is orchestrated, apparently by the dorsolateral prefrontal cortex. And this bottom up, top down perception extends down on the into the sensory perceptual areas that is you get predictive attention and motor control that allows us to pick us stimuli from the environment to verify our hypothesis what's actually being the case. And then, as a result, we get back filtered representations that formed this intermediate stage. Not all of our representations have sensory grounding. Of course, our world model and our self model have some sensory grounding. In proprioception, for instance, or in visual perception, but our mental state, we can freely manipulate it as does not. And our memories, of course, don't have anymore. You could also see memory, by the way, as something like visual perception where it's something like a perceptual process that you ask the memory, what hypothesis are true. And as a result, you get back object abstractions and episodic episodes that didn't happen in the past and procedural memory, which tells you how to do things, and templates frames that allow us to interpret the current situation. The sensory perception basically is an interface to the universe, it's gives us a universe gives us your bits, and we use those bits, encode them into the mental stage into the world model, self model, and so on. And the level of attentional awareness, we are able to perform symbolic operations. That is we can do a conceptual thinking based on these representations by manipulating them. And dreams, something interesting happens because we don't have access to our sensory organs anymore. And what would normally be the output of those lower level sensory areas gets replaced by pretty much random noise. And this random noise then is encoded in the same way as the sensory data was encoded before. So we get something that looks like we weren't model into self model, but it looks pretty weird. Thankfully, our long term memory formation is turned off during that time, too. So usually, we don't remember this actually might be useful process, that maybe some links are getting strengthened, and we find new associations and so on. And some housekeeping is the getting done on the mental representations. So the purpose of dreams is not completely explored and fully known. But I think the nature of dreams is caused by the fact that the lowest level is replaced by random noise. If we do meditation, we can completely tune out this interface to the universe, if we want to, we also can turn out the framing of mental representations in terms of the templates that we have acquired in the past. So we get more awareness of what's actually the case. And if you go very, very deep into meditation, you can even turn off the model of self.

Joscha Bach 18:17
How's it possible that we can be conscious with the outer self? I think that's because our self is not identical to our mind. Our self is also not an agent, our self is a representation. It's a story that the mind tells itself, about what happens with it in the world. And we need this story to do high level learning on what we do in the world. Because for instance, if you play ping pong, you need to react very, very quickly in the course of a few 10 or 100 milliseconds. And this doesn't leave enough time for quality for processing. But this reflex arc is unable to determine whether we've just won a match to decide whether we want a match of ping pong and use this as reinforcement learning to improve our moves, we need to have this high level of story and this high level story is what we perceive as the self. Likewise, Seville is not what drives our decision making, but rather the will is a representation on the level of the self. It's a representation of the fact that somewhere in the mind, a motive has been raised to an intention that we have committed to do something. And freewill is actually a social notion. It means that this decision could have been influenced by discourse, by cognitive thought by conscious thought and by talking to other people. So freewill is actually a social notion. It's determines whether we can be made socially responsible discursively responsible for our actions. So what's consciousness Dan? Is it a behavior? It's tempting to say because for instance, if you have this mirror test, it's quite famous, if consciousness for instance, the ability to recognize yourself in the mirror. This is observable behavior psychologists slough observable behavior. So they took a lot of animals and humans and put marks on their faces and put them in front of a mirror, and then their tests where they were able to recognize themselves in the mirror and thereby prove that they have a concept of self and consciousness. difficulty there is that it's actually not a test of consciousness. But it's a test of your ability to recognize that the mirror shows your body surface tests that I might fail on a bad day. And then relate between that mirror image and your body, and then be able to care about this. For a long time, people thought that elephants don't have a concept of self because they don't remove the marks on their faces, before people realize that elephants usually don't care about marks on their faces. That is about two other three elements to elephants don't care. Also, dogs fail this test. And maybe dogs fail this test, because they recognize each other mostly by smell, and by hearing not so much by vision. So this is not a really good test for consciousness. And because it's neither necessary nor sufficient for consciousness, to be able to recognize yourself in the mirror. Maybe it's something else entirely. Maybe it's the awareness of what happens in our mind. I think it's a pretty good idea that on Lochhead. But, you know, we don't really get much awareness of what actually happens in our mind. For instance, discontinuity of experience is fake. If you look at these small eye movements this decade, they're very small and jerky. And during this small and jerky movements, the world doesn't jerk around. How does this work it takes works because our brain blanks our vision during those movements. It also blanks our vision during blinking most of the time. So the world doesn't turn black and bright again. And yet we receive a perceive this as a continuous stream of experience. So somehow, this story of this continuous experience that I have with you, this visual experience is a fake, it's being stitched up into a coherent experience. Then came, Giulio Tononi, who suggested that consciousness is something else entirely. It's something that is emergent over the integration of information in your brain. Giulio Tononi is a neuroscientist. And he has suggested that if representations are very disconnected in your mind, then we are not conscious. And if they start to form a coherent image, we start being somewhat minimally conscious. And if almost all of the cortex is recruited for a coherent representation, then you're fully conscious. The beauty of this is that we can actually measure this and we can come up with information theoretic measures, which equals phi. And phi somehow stands for a degree of consciousness that a system can have. The drawback of the theory is that we can build a very trivial a computer program that has a very, very high fi and is obviously not conscious. So I think it's a good idea if you look for consciousness to look for large, coherent representations. So somehow, that's necessary, but it's certainly not sufficient. I don't think it's a very good idea, but it's a much better idea than earlier, neuroscientists had, like Bob singer who suggested that consciousness is a 40 hertz oscillation in the brain. I think you were scientists really coming along here.

Joscha Bach 23:18
I think that consciousness is actually a set of functions. It's a suitcase term, that stands for a bunch of very different mechanisms. And these mechanisms are qualitative, they need to be present. If these mechanisms are missing, they're not conscious. So it's not just emergent in some magical way. But rather, it's a bunch of things that the brain needs to do. And for instance, it needs to create a local perceptual space and the experience of where we currently are, we need to have access to perceptual content, we need to have the current world model, which also includes the things that you're not currently looking at, we have to have some directed attention. And this attention can either be focused or white, or it can be inward, overly directed, but it needs to be there. And we need to have access to our concepts and simulations, and linguistic content, and so on in the mind to be able to follow along on connections that it has to have this stream of consciousness. And we need an ability to create new concepts and to manipulate them. If you need to be able to put them onto onto a mental stage and observe them on that mental stage. These features are missing, I think we are not conscious, we need to have these features. Of course, there are different states of consciousness and these different states of consciousness have different functionality. For instance, during dreaming, we don't have access to our outer perceptual data. We don't have access to our motor functions. We don't have access to agency. So we cannot control what we do in dreams, except in lucid dreams. In lucid dreams. These are somehow an intermediate stage we get additional functionality that bootstraps our agencies so we can have goals and plans and reflect upon what we do to some extent, but you still don't have access to our bodily experiences and we don't have access to our muscles except maybe the eye muscles. So we can move around in our own minds in cyberspace during a lucid dream. And of course, we are conscious and that state, then we have a bunch of competencies that are nice to have things like the ability to learn from experience, or the ability to create intentional models of other agents, or the ability to create mechanical objects of processes in the world, and so on. If these things are missing, because you have a neurodegenerative disease, or because you're a very small child, you are still conscious. But you could argue that you are conscious to a lesser degree. Then there is meditation. In meditation, you tune out some of your abilities, and you get access to new functional mechanisms. And you can learn, for instance, to control pollution, voluntarily some parameters of your physio physiology of your cognition that would normally not be accessible. And then of course, there are the altered states of mind, for instance, states of psychosis, or of psychedelic states, in which you also have access to different mechanisms and lose access to others. So in the middle, we have this core consciousness, and we have a bunch of functionality that may or may not be present. And consciousness, in this sense, is really big set of functions. And it's similar to laugh. Love is also a set of overlapping states that are giving rise to by different mechanisms, for instance, in need of closeness or a need for affiliation, or a need for caring for others. And all these together form this big compound that we call off, but it's actually a set up very different mechanisms. Love is important.

Joscha Bach 26:44
So, in my perspective, the mind is an information processing system to perform all this information processing, what we need to have is computation, we need to have some substrate that gives computation to the mind. And currently, we tend to believe that this computational substrate is mostly the brain with its neurons. But how can we account for the regularity of the patterns that the universe throws at us? How is that possible? What can we say about the universe? Apparently, these patterns that we have at our systemic interface are quite regular. That's why we can encode them so successfully onto concepts and things like time and space, and so on. To produce these regularities and patterns, the universe needs to compute to this is the only thing that we can say with some certainty, it's necessary and sufficient to produce regularities and patterns that you can compute. You can define computing and in very abstract ways, so one way of computing a universe would be that we have a machine could call this machine that computes the universe, in honor of, quote, girdle, for instance, good. And this machine good, that has a set of possible instructions, and it has the current instruction at each time. And it has a current state of the universe, which is a vector of bits, it's really bad in many, many minutes. And these many, many bits are basically small, discernible differences, small yeses and noes. And then we need a position at least of a single bit in the universe that we're currently working with. And each instruction has this format, that it takes a bit at this current position. And depending on the value of that bit, whether it's zero or one, or yes or no, we write in a new bit at this position, and then we advanced one position to the right or one position to the left. And then we pick a new current instruction. And that's it. With this we can define the Turing machine. And there are many other ways to define computation. For instance, we could use multiple bits at each position. And we can write or read more than one position with one instruction, or the transitions between the entrance instructions that is between the different states of good, that could be probabilistic. Or we could have one good at every position of the universe and not move them at all, but rather have them be static and just read the positions of the neighbors, the data from the neighbors. In this case, we define a salad automaton. And all these different approaches to computation, can do the same stuff, some of them much, much faster than others, but who cares when you are inside the universe? What we just saw is something like this duelist solution, this dualist solution, we have two computational substrates that are separate. And the mind can read data from the universe, but it cannot write it back. And this has some drawbacks, because it means that nothing that you experience can be causally relevant for what happens in the universe. This is called EPIPHENOMENALISM. And it's a bit inconvenient. A way to get out of this would be to make the universe somehow duplicate the equivalence of some states of your mental processing This is called occasional ism in philosophy, but why should the us do this. So a solution is to have the mind as part of the universe to embed it into the universe and let the universe compute the mind because the universe is computed in its own computational substrate, it can do computation. That's why it comes for all these nice regular patterns as it can also compute the mind. So we can have nested computational systems, like for instance, we can build a computer from redstone blocks in the game, Minecraft. And the so for instance, this game of Minecraft is powerful enough that you can build a computer with a display and inputs and it's powerful enough to play games on it, but very, very, very slowly.

Joscha Bach 30:51
It looks like this, we have this minecraft game. And in the minecraft game, we have the redstone computer, and the redstone computer does the computation based on redstone blocks. And the minecraft game itself runs on a PC or on a Mac on the tablet. But the redstone computer will never know because it doesn't have access to the subset of the minecraft game, which is its universe, it's good. And this is pretty similar to our current ideas of physicalism. Physics is sort of the science that tries to find a possible implementation on how of how the universe does its computation so it can produce the observations that we can make. And our currently dominant set of theories says that the universe is based on quantum computation. And in there we have computation that is mostly classical, that is neural computation that produces the mind. Actually, it's a bit of a simplification, because we can also use other things than brains to do thinking or to then help us thinking for instance, we can use the internet or we can use notebooks and so on and put parts of our minds out there. And in a more general sense, what the universe uses to perform the computations that are happening in our mind is it increases entropy, to allow us to build structure to sync to compute, we need to create structure and to create structure, we need to reduce structure somewhere else that is we increase noise. And if you have a universe that is maximally noisy, there can be no more cognition or computation in it. That's why we need to push back entropy. Entropy is the enemy. It could also be the other way around. It could also be that the universe actually is embedded into the mind. In that case, our mind is good. Probably don't know it. But the universe would be a dream is this whole situation our dreams, right? The regularities and dreams is there, because it's caused by our mind, it's produced by our minds. And there is no way to disprove that we currently would be could be living in a dream, right? It just maybe not the best possible theory. Could we be living in a simulation? Well, I don't think that there is any difference between reality and simulation, it doesn't really make sense to distinguish between reality and the simulation anymore, that it makes sense for a robot to distinguish between a simulation that is currently in and reality to it's when it's Well, only thing that matters is that what patterns are thrown at my systemic boundary, what encodings can I make over those patterns? If you buy into this, then we have to realize that concepts cannot really read refer to facts in the world. And there is no truth that we can get by referring to facts out there, we have to abandon the notion of meaning or life becomes meaningless. What we have to do now is we have to resort to something else that does the job that meaning that before and I would call this suitable encoding. The good news is that suitable encoding can do everything that you wanted to have from truth and meaning only better. We can no longer tell whether our picture that we make of the world is true or not. But what we can say whether it's whether it's a suitable encoding, if you compare to an alternative, it doesn't work all of the times, but most of the time it works. So most of the time, we can find the criteria. And that tells us that this encoding is better than an adequate encoding. And criteria for these encodings are things like sparseness, for instance, how many representational entities do I need to represent this stability? How much do I need to update my image of the world? If my observations changed consistency? How many contradictions do I have in my representation? Coverage? For how many of my observations can account for integration? How well does it fit into my existing representations? Then how relevant is it to my needs that I have as a system in the world? Then how adaptable is it to my goals and plans over time? And how difficult is it to build those encoding? just how difficult is it to acquire them? How difficult is it to store them? And how difficult is it to maintain them. And these are all criteria that I can define, I can define them and information theoretic terms, which is very nice. I can have very robust, non metaphysical definitions of those. But if there is no truth, you might ask me how it's possible that I make statements like that mind and universe are computational, and there is no truth? Well, I don't say it's true, I just say it's the most suitable encoding.

Joscha Bach 35:40
So to come back to our four big answers to our four most suitable encodings. What's the nature of reality? I think that's the universe produces patterns that are systemic interface information, little discernible differences, that reduce uncertainty, and computation is necessary and sufficient for that. What can we know, information? And we can call it can encode this information into presets into concepts into simulations into worldviews into culture. And who are we? I think that we are computational systems that encode information and that store that information and process it and interpret it in very, very, very specific ways. And we can find out details about this class of computational systems that we call minds, by doing models of those computational models. These are called artificial intelligences. Let's think it's super important to build them to find more about the state of affairs about what minds are what we are, our relationship to the world is. And this ties into the first question, what should we do? First of all, of course, we should push back entropy. Because to think we need to put energy into our bodies, and we need to push out wastes and push waste away from us and get clean again. And then we need to laugh. And if you have still time, I think we should build artificial intelligence.

Unknown 37:35
Thank you very much for this great talk. We still have about 20 minutes for questions. So I encourage you to line up at the microphones. And just go ahead. Number two.

Unknown 37:52
Thank you, Dr. Bach, for absolutely brilliant talk as jiggling around in my seat, I thought it was going to be a left brain non materialistic explanation of, of the brain and consciousness. And I thank you so much for just pushing the boundaries further there. But I've got some questions. As far as the brain being a manifestation of an informational computational processing system of information coming from the universe. I was very interested in the end part of your talk, we will inverting whether our mind is inside universal, were embedded the embedded model. Very interesting. I'm wondering if you could make comment, because I'm sure you've looked at this literature on the falling asleep these with you observation and two slit experiment. It's I think it's an interesting one. I'd be interested in your impressions. If you read the literature on near death experiences. At first, this was a phenomenon. But now I think the documentation on this that is perception in states of no brain function. I'm wondering if you have any comments on that?

Joscha Bach 38:49
Could you repeat this last bit

Unknown 38:51
near the phenomenon and it's a well documented in the literature now? I think it's I think from a scientific perspective, we can say it's a phenomenon. It's a phenomenon of perception. In the absence of brain function, for example, in terms of cardiac arrest,

Joscha Bach 39:07
yeah. Once these studies, for instance, there was one at universe at the University Hospital in the UK. And they did studies on people with cardiac arrest and the ER. And they looked at things like extrasensory perception, out of body experience that these people had, and they apparently formed memory while they begin recording flatlines. And once they started to talk about this, I wrote emails to the people that did this survey and to get to know more about the data. And what they have found. For instance, they put a board on top of the beds for those formulas made out of body experiences and wrote something on top of that board and wanted to see whether people floating out of their body could read what's on top of the board. They never quit, which doesn't mean it's impossible just means that That couldn't show evidence that this out of body experience is something else, then our sense of position in the local perceptual space getting this is attached from our body image, which apparently can also be triggered by, for instance, ketamine, you can trigger out of body experience with some degree of reliability for certain drugs. And it's the associative phenomenon. So we have to account for the fact that these people were flatlines on the EEG while they were doing those processes. And I think this can be accounted for by the fact that our EEG doesn't pick up the activity when it's very low. But this is still sufficient to do the necessary computations in the brain. So I think it's the easiest and simplest explanation is that our measurement was not good enough to really measure whether was really conscious activity going on the brain at this point.

Unknown 40:50
So So you would say that was a hypothesis for further examination? The hypothesis is that the level of measurement does not detect brain activity when it still may exist.

Joscha Bach 41:02
Yeah. Okay.

Unknown 41:04
Thank you. Microphone number one.

Unknown 41:07
Yes, thank you very much for this presentation. I think it was really good. It also really resonates with things I like. And I think with most people here in the room, but something that keeps concerning me with these comparisons with computation and human being is that it feels like it's a bit present cystic. I've read literature from 100 years ago, where people thought, yeah, we figured out what human beings are their valves and their pipes, just like the whole steampunk stuff, because that's the mode of thinking and is there anything that makes you believe that right now, this is special, that it's not just our way of thinking applied to the current times?

Joscha Bach 41:52
Well, the number of thinkers that existed in the pre modern age, compared to the number of thinkers that exist in the modern age is pretty small. And the thinking of the pre modern age is mostly available, at least those parts that we know, of course, just a tautology to our current thinkers. So I think that it makes sense to assume that there's a bit of progress. And I think a very important bit of that progress that was not accessible, and years ago, or even 50 years ago, is the notion of computation. We simply didn't have this, before that we had this mechanical worldview. And it's very counterintuitive that a mechanism, something that makes us into it, wheels and quarks and pulleys can produce things like a mind. And now we have abstracted this into a more general causal mechanism, a computational machine. And this mechanism that the world provides is only incidental, this is only important because it is able to produce computation. And this notion of computation, in my view, is pretty watertight, in the sense that it can account for the fact that the mind is an information processing phenomenon. And we can actually prove properties about this. So we got these nice, abstract and synthetic concepts about how minds could be implemented. And I think that even in an idealistic universe, my mind is primary, we would have to account for the fact that the mind is able to process information that is somehow appearing at a systemic boundary. So in some sense, it's a general theory. But as experienced role, better theories tend to come along. It just appears to me now, right? That this is a pretty watertight theory and a paradigm that is going to carry us very far.

Unknown 43:31
Thank you very much. I believe there is a much better model still than what we used before. But how can we say that it is and you would say that it's a suitable representation? Probably. But you mentioned computation that still can emerge from a mechanical systems, of course, we can make McCann fully mechanical computers. So would you then say that the mind emerges from the physicality of the body?

Joscha Bach 43:57
If we admit that emergence is not a thing out there, but that emergence is actually a relation between different systems of description then yes. So in a way the universe is providing us with the causal system that is somewhat insulated from the causal structures of the universe itself in visited computational causality, we can be minds. Okay, thank you.

Unknown 44:22
Next is a question from the internet. Okay.

Unknown 44:29
Do you think if we could build a machine that more or less works like the human brain and give it the necessary sensory input? Would it become conscious by itself?

Joscha Bach 44:39
Yeah, I think that consciousness is a set of functions. If these functions are implemented the system the system is going to be conscious. If these functions are missing, and the system is not going to be conscious. All these functions are information processing mechanisms. I think that we can disassemble them that we can research them and then we can combine them into a coherent whole. I think it might take Many decades, and I think that it might take many more decades than we have civilization left on our clock. But in principle, it's possible. And I don't see why not.

Unknown 45:11
Thanks. Next from for,

Unknown 45:14
thank you, thank you very much for your again for your challenging talk here. I totally agree with the love thesis and with the, let's say monist point of view. But at the moment, I think we have to accept that if the universe, it's a basic feature of the universe to create consciousness, whatever consciousness might be or not. But at the moment, we have to accept that, that our living systems will have cognitions. And for example, volitions. And if you look at the basic construction principles of living systems, you have a violation of the rustle theory of types, seen from the point of the DNA, a protein is an operator and the DNA is an operant. And seen from the point of view of a protein, the DNA is an operator, and the protein is the operand, you cannot get that logical. So my question is, do you think that our actually available formal concept of math and logic is sufficient to lead to a really constructed artificial intelligence?

Joscha Bach 46:27
Yeah, I think so. computation is a true subset of mathematics, mathematics is more language in which you can produce statements like for instance, Russell's antinomy antinomy. And these statements need to be to be meaningful. computation is basically those parts of mathematics that runs. Okay, and I think that you need to build computational models. So in a way, I'm arguing for a new kind of philosophy as a subfield of analytical philosophy, which is the part of philosophy that could be expressed in a formal language. I'm arguing for a philosophy that is computational, that relies on theories that actually run.

Unknown 47:07
But okay, they realize on theory, theories which run but you have a broken hierarchy in living systems. And every computational system is on hierarchical systems and not Dakka Dakka. One. So how can you solve this contradiction.

Joscha Bach 47:28
And I think this is simply because this idea of hierarchy and heterarchy are conceptual ideas, they're not parts of the territory, they're parts of the map. And in many cases, these descriptions break down, they're just not suitable encodings anymore. And so we have to refrain from concepts that are tempting, for instance, the concept of outpaces is, is in that category, because they seem to be a good idea at the time, and then we try to make our ideas of the world conform to this idea that is almost right, until it breaks down. So we shouldn't be invested into those concepts, we should pick concepts that work. And I think in those cases, we have a description of our domain that is not working, that is breaking down at some time. So at some point, so we really need to find a new description.

Unknown 48:14
So without pauses, I agree with you, because it's not a formal concept. It's an iterative concept, but there are formal contract concepts which are non hierarchical, and at the moment, they are not, I'm sad about that. They are not scientific mainstream, for example, poly contextual logic by God. Gunther?

Joscha Bach 48:32
Yeah, I also agree that we probably need to develop better formalisms to describe a lot of things. Mathematics is an ongoing area of research, but I'm not sure of if we need completely new paradigms. So I think more needs to be done. Thank you for the question.

Unknown 48:49
Okay. Next is two and then three.

Unknown 48:52
Thank you for the really beautiful talk. As an engineer, I accept everything, as someone psychonaut and someone who studies philosophy, I have issues. I think it was Alan Watts, who said that trying to define yourself is like trying to bite your own teeth. And I think it's the same with consciousness. I think consciousness little is a little bit more fundamental than this. In quantum mechanics, you have, you know, you need a conscious observer to manifest matter from energy. Right.

Joscha Bach 49:25
Now, I don't think so. I think that the observer in quantum mechanics, and the observer and relativity in the observer, and cognition are very different entities. The Observer and relativity, for instance, is a system that could interact with another system. Observer. Quantum mechanics is a system that actually interacts with another system and observer and cognition is a conscious system. And as I think these are entirely different notions.

Unknown 49:52
I was under the belief that you need a conscious observer to manifest matter.

Joscha Bach 49:56
I don't agree at this point, because I don't see why you would, I think You need to have a system that interacts quantum mechanics is the theory on the possible implementation of the universe. And at no point in the formulas of the theory, because it's just a bunch of mathematical formulas, or are the computational formulas that tell us how this is implemented? Does it state that there is consciousness?

Unknown 50:17
Or do you think about E is equal to mc squared? C, being the spirit of light? I think consciousness works on light, we think in the form of light, I think light is the currency of consciousness. I think that's very practical. It is whether it's really metaphysics at this point, because I have an issue with people who like to discount anything that's, that's beyond empirical as, as foolish, because what is empirical, empirical means we have a limited set of tools based on the knowledge that we have now to demonstrate certain things, and it's always changed as a species have evolved. Right? That does not necessarily mean that just because we can't measure it, that we say, Hey, this is not true. Instead, as real engineers, as real scientists, we should maybe, you know, take it into account and maybe, you know, come up with stuff that could make it empirical. So the issue that I have as a second art is that you try to scope down consciousness into a set of empirical models, and you try to say that this is this is consciousness, like you take a JPEG image, a 640, by 480 image in it is the possibility, if you permute, the faces of every single person, everything that has happened, everything that could not have happened, that jpeg image has the capacity to show, right? The problem is that we can't do it because we don't have computing systems that can deal with the beauty of infinity. And until then, I think we can only create pseudo consciousness. And that's not the same as real consciousness.

Joscha Bach 52:03
Now, my problem is that I probably cannot deal with the beauty of infinity either. Yeah, I can trick myself into this. But I don't have any experience of infinity. I don't have any experience of those things that you find so mystical, I can create those concepts. And I don't see any reason why a computer program couldn't create equivalent concepts. But I don't think that our minds can fathom concepts like infinity, which is also just a metaphysical idea.

Unknown 52:31
If you're not yet, right, we are constantly evolving as a species. But we like to think that we are the apex of evolution, when are we constantly changing? It's happening in the form of races? Yep. Yeah, it's a mental construct. And I really appreciate the work that you're doing. And I think we need stuff like this to advance the species. Thank you so much. Thank you.

Unknown 52:58
Okay, next is microphone three.

Unknown 53:02
Hello. Thanks for that invigorating talk. And thanks for putting some Minecraft in the mix. You had a very nice list, kind of like a checklist for consciousness. So I want to which seem basically like a feature list almost. So I was wondering how much of that do you think will be portable on chips in the sense of interplaying software hardware? And the second part would be once we get there and get all the stuff on that list, implemented somehow, chips, sensors, software, whatever? Do you think that implementations will be more or a numbers, there will be more complete AI implementations in the sense of my, no, my toaster will talk to me, or be my psychologist or it would be a subset, which is more kind of like on a neat basis.

Joscha Bach 53:59
I think there's this more a question about how society is going to pan out and economy is going to pan out and the world that we live in, is going to pan out, it's very difficult to say how this is going to be, I think once we are able to build fully sentient, fully intelligent and fully self conscious systems, these systems are probably not going to be Roombas that are going to battle their way up the cognitive hierarchy and try to appeal for human rights. But it's more likely that they are going to descend upon us from top down, because they're going to be business intelligence and organizational intelligences that are going to augment the non human agency that already exists on the planet. And so in a way, I think these intelligences are already there. They're just not very conscious yet. And they're not very efficient yet because they have to borrow human intelligence for that task. And in a way, they're probably going to push the agenda of the existing system much further.

Unknown 54:54
But as an engineer, I'm interested in like how we can get there. So I was just wondering what your guess was because in the past, we always had like very basic computing power, and then we extract it more elf those possibilities into software. And this seems kind of like the other way around, where most of the computation or like everything is simulated. In large supercomputers or clusters, enrolled, people are trying to bring it back down to hardware, basically. So the process seems very new to me. So I'm just wondering if you have any guests on how that might,

Joscha Bach 55:32
I think that compute computer power is not the issue anymore for quite some time. Now, if you look, for instance, at bird, birds, flowers are able to build sledges and slide down roofs, miss them and play and solve little problems and to plants. Gray parrots are able to learn some basic language and to learn negation and so on. And so it seems that we don't need all the neurons that we have in our brain. And then if you look at the neurons, we find out that they're very noisy, and that our brain is built for redundancy. In the most part, I think that the main issue right now is not so much computational power, we can get computational power very cheaply from Amazon, what we need is better algorithms, we need to have research into the mechanisms. And in many ways you're making tremendous progress, especially in the last few years is deep learning. But we are still way off from understanding all the algorithms and the computational structures that are involved. Thank you very much.

Unknown 56:35
Thanks for those people migrating between groups, please quiet down a little bit. We have only time for two more questions. I'm really sorry to those who have been lining up for a while, but I think the Speaker will gladly answer them after the session. So number one, and the signal Angel.

Unknown 56:53
Yes, I'm here. First, I didn't understand correctly that you didn't talk much about identity and difference in relation to the minds that did I understand the Corcoran correctly? Yeah. Okay. Then how do you connect it? I mean, how do you describe this kind of concept of identity and difference, and also maybe alienation, and even violence? Because these are, I think, also things that are kind of, from a society perspective, I think very important to consider. I mean, how we relate as humans to each other. So identity and difference, alienation, violence, how do you talk about this? In terms of the other language you're using?

Joscha Bach 57:37
I will try to answer your question on the lowest symbols possible level, because it leads very, very far into cultural implications. And on this lowest level, if you try to build little robot advance around in your physical or virtual world, and then it counters objects, at some point, you realize that it will have to make a determination whether it just found objects that look very similar to objects that he found before. Or if it just found the same objects that had now has a different location and maybe has different features than before. It's a different way of processing things of storing things. In one case, you have different objects with maybe similar identical properties. In the other case, you have objects that might have similar features, but that are identical. And this notion of identity is identity, basically means that we stick things, representations of objects onto a common world line, that we have different instances of objects, any object of the mind, share a biography, it's a cognitive processing works. And we apply the sense of identity as an extension of ourselves, as part of the concept of self, the concept of self. And the simplest case might be the set of features that some are always with us, there's always a compelling isn't always mostly accessible to us. Whereas there are features that are changing all the time, this is what we call the environment. And if we find a structured representation of all those features, that would be part of ourself, and stick them onto a worldline. on something like a biography, we have what we call personal identity. And this personal identity is augmented with intentional interpretations, which is one of our main modes of interpreting the world. So we have this mechanical mode of interpretation, if you can see a mechanism if you have intentional interpretations, where we attribute desires, and needs and wants and intentions to objects and the world to agents. And then we have Karthik representations where we just take the events to be random. And we take this intentional explanation and apply it to our self concept. And then we expand this into a social persona into somebody who relates to the role to the environment, to society and so on. And this is what we've I think, would call our personal identity. It's not a thing in the world. It's a representation. It's a construction I think I wouldn't need more than an hour. I'm sorry, but I think we should talk afterwards.

Unknown 1:00:09
Okay, thank you very much. One last question. I think I'm switching from the internet to this little guy on microphone number four.

Joscha Bach 1:00:19
Get job thank you

Unknown 1:00:31
thank you very much.

Joscha Bach 1:00:34
Thank you. Thank all of you. It was very pleasant.

This transcript was generated by https://otter.ai