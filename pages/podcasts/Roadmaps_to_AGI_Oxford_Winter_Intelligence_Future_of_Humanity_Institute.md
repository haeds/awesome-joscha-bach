Unknown 0:12
So this this time is set aside basically for a brief discussion which is supposed to be highly participatory, on the roadmap to AGI and, or the possibility of multiple roadmaps to AGI. And I guess, this is a topic that we've all been bouncing around for a while with the mixed results so far. And it's it is still something I think that is quite important for the field. So what I wanted to do now was have basically, each of the three of us just say a few words of our own thoughts and visions on the need and the nature of a roadmap for AGI and then open it up for comments and discussion. So this will be a break in the in the sequence of PowerPoints. I didn't return any

Joscha Bach 1:20
drastic, I think it is beneficial if our points

Unknown 1:27
don't have one, I may as well consider these beneficial. So yeah, I'll get started. So the first endorsement I have in an attempt to make some kind of roadmap for AGI was a workshop. A workshop that Pat nine, John led to the titans of traditional mainstream US talking of architectures and AGI within your show you were there in that workshop as well. And that was interesting. I mean, it was a group of all quite good researchers. And the goal was to come up with some set of milestones and some ideas about a common environment, common tasks and common goals. And the most notable thing about that workshop was at the end of it, we had agreed on pretty much nothing whatsoever, except we each agree to our own approach was obviously better than everybody else's approach. I mean, it was it was interesting, there were good conversations, but clearly wasn't leading to a roadmap to AGI now, out of that Leonard and Langley, and a couple of their closer collaborators who grew up wrote a paper giving a lesson what they felt were requirements or AGI, an AGI environment, which is an interesting set of AGI 2010, which was a reasonable paper, but it was really their view. It wasn't even the consensus of everyone in that workshop. Now, following on that each law around it AGI collaborative learning professor at University of Tennessee, Knoxville, I mean, he and I organized another workshop, the AGI roadmap workshop, 2009, University of Tennessee, and I tried to more carefully pick the people who would be there. So I picked only people who thought that either virtual or robotic embodiment, were reasonable, worthwhile and very useful things to do for AGI development. And I picked only people who want to build learning systems, knowing who thought you should load your AGI with knowledge and a bunch of hand coded rules in the form of production systems or expert systems. So I was trying to bundle things down to people with some semblance of a, of a common perspective, hoping that that would let us have some agreement on things. And that didn't really succeed. We still disagreed in each dollar on where it was better than everyone else's, and quite concur. Now it works a little better. I mean, we, we managed to squeeze out a paper, there was an AI magazine called mapping the landscape of AGI, which actually had all the participants in the workshop as co authors. And we, we all agreed on the conclusions. I mean, the paper was relatively Toothless compared to what any of us would have written on our own. But it did represent some kind of consensus understanding of what we're trying to work toward. And we, I mean, we discussed a bunch of ways to frame the goal of human level AGI which I wouldn't call the end goal of AGI because we could go way beyond the human level in principle, but we talked about things besides the Turing test, like say a robot college student test where a robot could go to college and get a degree or a virtual, Virtual College test or have the test of having an AI go through online In elementary school curriculum and so forth, so we, we talked about various ways that we agreed, will be interesting to validate that you had either a human level AI or something along the path there, Josh Hall kept talking about the Wozniak coffee test, you make a robot going to a random person's house and figure out how to make a cup of coffee. Where, you know, they have many different ways of making coffee maybe stored all over the place, we have to use a coffee maker, not the coffee beans by being some job or it's hard to take the lid off. And I mean, we all kind of agreed on what kind of end goals would be important. And we basically agreed on what general competencies and capabilities an AGI should have to have if it's going to be human level and roughly human life. While also agreeing there could be other types of AGI

Unknown 5:50
were very different. What we didn't seem to agree on was what makes sense to work on first, what makes sense to work on after so, I mean, some people thought, you know, start with language, that's what makes humans really distinct from other animals. Once the AGI can understand some language, you can teach it by talking to it. And Josh Hall basically, if you're gonna, if you're not using a robot, you're just fooling yourself and you won't be one to start with perception and embodied action in the robot, get that down like a young child does, and then work up to more complex things. And if you work on language, before, you've had this robotic grounding, then you're basically just playing with formal civil systems and where that has nothing to do with what your Ultimate Body AGI is gonna have to do. So this is why the paper came out being titled mapping the landscape. Because we get Sam Adams for IBM introduced the metaphor, like instead of just one path, I mean, the roadmap map has many different roads over it, right? So if you view AGI as the peak of a mountain, maybe with many little, little smaller things with the top representing different ways of getting to different forms of human level AGI, then there can be different roads up the mountain. So the top one guy could go up the mountain by the robotic spat, one guy could go up the mountain by the natural language path and put in a robot only at the end, and so forth. And I was sort of happy we arrived at some moderate level of agreement and what made sense, what we couldn't agree on. Unfortunately, with like a common environment or set of tasks for measuring early stage incremental progress toward AGI this was a major issue. I mean, it's not too hard to agree on tests for when you have a human level AGI I mean, the Turing test, say one hour Turing test with educated people is one example. Having a robot that can can get a degree from Oxford, following the same procedures as a human student is another example. I mean, there's plenty of things that you would come and sensibly accept as having achieved a human level AGI. But how do you know when you're 25% of the way there? What does that actually what does that actually mean for Windows? How can you make a test ring partway to AGI that can't just be gained in some conceptually trivial way to string together a bunch of different things? I mean, he said the IQ test, I mean, surely someone could hack a system just to take the IQ test and even Wozniak coffee test. I wonder if you gave like a list of every possible type of coffeemaker every ever made geometry of like, 10,000, American kitchens and trained it on all those? Could you use a combination of machine learning and expert coding to get something that would go in and make coffee in 95% of people's houses? I mean, it's hard to say which of these intermediate tests you could gain and which ones you could not. And so we didn't really agree on a series of incremental milestones, we're okay, we all agree, but we'll make our AI systems past this. And then we're 20%. And go a little further and more fully. Because each one takes different, different routes. I mean, the final conclusion I came to is, you know what, we're not going to get everyone to agree on anything in the AGI field. I mean, psychologically, those of us who go into AGI tend to be very strong willed, idiosyncratic type of people, you have to be very stubborn minded to want to push ahead with AGI when most of the world the most of your profession doesn't want you to so getting all these stubborn minds and deniers and crack people to agree on something is, is quite difficult. But yeah, I haven't quite given up on this effort. When David's gonna talk about when I finally shut up is we're working together to make a robotics platform with very easy API's for AI developers to use and hoping if you release a low cost robot With API's that are very easy to plug an AI system into, then you can get more and more of the AGI community to get the low cost robots, plug the AI into that robot and have it go through a series of milestones and tasks for greater and greater robotic intelligence. No. But that's to me interesting to folks who want to play with robots. And that and that's, that's only a subset. And maybe someone else could do something, something like that in other domains, besides besides robotics, but that's somewhat unfinished quest really, to find, find a way to get more and more of the AGI field to cooperate together and common environments, tasks and milestones.

Joscha Bach 10:49
Thanks, man, I don't agree with your pessimism because we got to augment that all. First of all, I don't think that all of the AGI researchers are egomaniacal and stubborn, if we wonder that's just a very shy person. And the only thing I'm just trying to casually say is the truth. And so this brings up a problem. Rather, I think that some of the issues you might have experienced, which to your pessimism about the possibility to agree on roadmap might be due to the fact that a particular set of people that we invited for the workshops were project leaders of existing projects, which of course, try to further the project to a large extent, and try to find an opportunity to expand on that project, which is a very natural thing to do. But if we look at this from a different perspective, if find a good project, and we offer this project, it's pretty likely, if it's a very good project of any project, that people flocked to this, precisely because it is helpful for them, there are a few things I would like to get off my chest first, because we are already making some assumptions with respect to the nature of the kinds of benchmarks that we need. And of course, in this conference, we have seen conflicting assumptions. For instance, there's this mathematical spanking idea that you treat the mind as a reward Maximizer. And the kind of benchmark you would want to have for this is quite different from the one that we have in mind, because we are looking at possible implementations, not at abstract specifications. And if the distance between specification and possible implementations becomes very large, we, as engineers don't know what to build. And there's a neuroscientific perspective, which has a tendency to treat the mind as a product of neural or sub neural activity. And there is this problem that you look to the microscope, and you look at all these intricate things that neurons do, it's a little bit like you try to understand flight, and then you look at birds. And then you look at feathers. And then you realize, oh, it's not just the feathers, test steps between defenders, every feather is connected to its neighboring feathers, while you have 10s of 1000s of intricate steps. And these set of standards actually do have an implication on the vortices that the air is going to have, that you move the way. So actually, maybe you have to go to the atomic level understanding of what flying is about. Of course, you're probably not happy if some engineer comes along and says, but maybe you can build something completely without feathers. And if you build something with lots of feathers, maybe it turns out to be a penguin doesn't fly, even though it has proper feathers. And let's not forget most of the things with a brain are not super smart. There's really also a problem with this developmental perspective when you start with simple robotic bodies. And then try to make them move in environment and so on. Because let's not forget that on all this planet with 2 billion years of evolution. And lots and lots of different species there are only homosapiens above the age of about three and back into CRO who are intelligent. So this means that maybe it is a very very long developmental trajectory that you are going to take if you aren't with growth Pfeiffer and building things which are basically just critters and environment and move about and then hope eventually you can free Language and Thought writing novels and coming up with AGI is an extension of that some kind of scaling process. So we already do have some assumptions that are a little bit counter to that you have a function with construction instead of ideas basically the mind as a processing, information processing architecture. And in the case of humans, it's also more than that it's a solution of a particular kind of control problem. That is how to navigate a social primate successfully in a very complex environment. And these assumptions shape of course, how I'll be approached as benchmark problems. And traditionally, in artificial intelligence, we had this tendency to see intelligence as some kind of particular function. Like, for instance, the ability to play chess with this idea when we make this function, this seemingly impossible thing real, that we have practiced, not that we have understood intelligence. But we realized soon that we end up with a chess playing toaster.

Joscha Bach 15:23
And then we realized, okay, you need to look at different functions that are working in an open, open environment that Have they started playing soccer job at social, and then people soccer playing toasters. And then we are building car driving toasters and so on, it seems some kind of consensus by now, I hope that just by building better and better toasters, you're building alibi, but you want to build something different, you want to build something, which is very more general, that is different perspective, the one of the psychologists that psychological cognitive architectures, and they kind of reinvented a lot of what we did in AI and revive it after he killed it off in AI, more or less. And they try to generalize over human information processing, learning. And their paradigm was because you cannot sell theories in psychology to pair each of their ideas up with an experiment. This experiment takes a human into the lab or a small group of humans, and then you take tiny results. And then you compare this with the result of your cognitive architecture. Unfortunately, it turns out that isolated performance and mental rotation task or the basic book part experiment does not scale up to general intelligence either. So I'm not saying that the cognitive architecture paradigm on the psychologists it's not productive, it is tremendously productive. But we need to augment this with a different way of doing our research. And then there is the embodiment perspective, of course, in the extreme case, it's really the environmentalists perspective don't do representation so much. Treat the mind as something which emerges from the interaction between body and environment. And the brain is just a funny feature of the body. And I personally doubt that it's very productive, because for the time being, the environment is just what it affords production set of words. So for instance, for a robot, the world is only then what it can interact with. And our robots cannot do many interesting things. Politics will have different opinions than me. But I think that right now, it's very, very difficult for a robot to climb a tree and to break down a little bit of wood there and to turn it into a tool or be inventive about the environment. But robots live in a very, very impoverished environment, which is much more impoverished than any kind of virtual environment you can build for the next decade or so I guess, at some point, that might be a trend over point. But until this, I don't think that, personally, I think that robots are not the most productive paradigm, you're that you disagree in a productive way. Okay. On the other hand, what I do see some kind of convergence, I do see convergence between roboticists also use virtual robots make bridges between virtual environments and real world, I see a convergence between AI methods and cognitive architectures. And there's also a big convergence among the ideas that we have among the cognitive architecture teams. And cooperation, I think is no longer just limited by the egos of people. But it's mainly also a function of funding. So I mentioned that we get funding for bigger cognitive architecture projects, that we will also see bigger convergence there. And I'm actually quite optimistic. So I do think that what we need are productive benchmark paradigms, it should be clear that we should have a paradigm that doesn't allow us to progress only in 20 years from now. So the college robot is probably out of the question. I don't see the prerequisites for building a robot that can go successfully to college. Within the next couple of years, I want to have a benchmark that I can address right now where I can start programming coding now and give you results in a year from now and comparable results. So it needs to be incremental. And it needs to be aI complete, I want to have a benchmark that forces us not to build a toaster, something or a coffeemaker, I want to have a benchmark that forces us to build something that is actually smart that we can talk to that makes sense of the world. They can make sense of other worlds to maybe it can make sense possibly in other ways as humans too, but which can do this. And I think controlling your body is something of course, given a body in AI should be able to make something out of it. But I don't think that it's necessarily that it has the body in order to do that. It's bodily control is an important issue. I don't think that the mind can be conceived of as being unable to control the body, but it could also in He didn't mind that his work was thesis like it built in World of Warcraft, that keeps us busy for all eternity. So it doesn't go insane and gives it enough room to play this to come up with new ideas forever. So I think philosophically speaking, physical environment or an external world is not a necessity. But it can be a very productive research paradigm at MIT, very practical reasons to go for it.

Joscha Bach 20:24
One, one thing, which we should look at is, besides scalability is we do not want to go further look at our performance, we want to go from a development perspective. And we also need to look at the funding perspective, we need to make something that is obviously scalable, that the public understand the funding agencies understand that makes sense, it doesn't look insane, that is productive.

Unknown 20:49
You're about the genius.

Unknown 20:51
All right, great perspective guys. Going to say that, as dedicated as I am to building hardware, and to the value of robotic hardware, I think that a generalist perspective that integrates simulation and pure math and theoretical approaches, with with practical applications

Unknown 21:18
is the way for this server integrative perspective, I believe is, is the, the only way. And taking that integrative perspective also means considering that our culture, in inventing these things, is an evolutionary ecology. And that includes business and funding cycles. And it also includes the ecology of memes or emergent memes, evenings, we might say, that plague throughout an event like this particular conference, or when, when a group of people get together and invent something new. So in that sense, an interplay of the evolution of AGI with real world is, is absolutely key to all the progress we've made so far. And we'll make in the future. Now, if we consider the fact that physically embodied robots can interact with the noisiness the chaos of the world, and then extract information from it, then we can realize that's how babies developed. And you know, Skinner, Skinner boxes don't work for children, right? I mean, children need rich, stimulated upbringing, in order to become intelligent beings, you know, regardless of the DNA, regardless of, you know, in addition to I should say, the, the DNA and the 2 billion years of evolutionary heritage, they go into a child. So if we, if we consider this, and maybe, and it's just a proposition, and maybe that I'm developing platforms that can interact with the real world, in this kind of, you know, nonlinear resonation, and then extract that information, and then use that data to build on a more elaborate of novel, The world, maybe one very productive path or not, not every researcher needs to agree with this proposition. What what needs to happen, however, is an integration across community where researchers who don't agree can still plug their software into a standards based system, so that you can have potentially hundreds of 1000s of researchers working on the same project from multiple fields, fields that they don't think interact with each other. And yet, you can have people who take an interpretive perspective and make the systems interoperate as a whole. If this if this kind of common platform and common approach is as adopted globally, then you have something like a Cambrian explosion of research and AGI, you start seeing many diversified examples of AGI instantiations. And I believe that you will see a rapid acceleration of progress in the field. And I believe that we should not exclude any toolset. So just because I have a bias for physical robots doesn't necessarily mean that anybody else needs to, but it shouldn't be excluded and neither should simulation and neither should other approaches to the field. And what will be interesting is that if you can define these kinds of common standards and common platforms, then you can benchmark the performance of of these, these developments in various fields, whether it's computational neuroscience, computational linguistics, or or physically embodied cognitive robotics and, and start to compare those performance metrics to each other as well as the actual performance Have the platforms. So then the performance metrics themselves begin to, to evolve. So and then within that you wind up with, with a powerful set of common tools for developing products for developing practical applications, and then testing those practical applications. So I think that underline, if you're going to devise a total integrated architecture like this, you know, the goal being to have some kind of AGI performance within some period of time or get an Apollo space program, Grand Challenge for for AGI research, then the critical things to happen would be, you would need to define the overall platform and the team to develop this based on the grandest ambitions that you could specify. And that's where the term genius machines comes out. Because we don't want to just develop some something that is, that is a little bit smart, we don't want to develop something that is the, we certainly would like to see, you know, more general, generally capable toasters, you know, I mean, I sure would, like, you know, a smart kitchen that, you know, has my coffee waiting for me in the morning, I wouldn't hurt my feelings. But, um, but I would, I would like to see us aiming past the performance of a three year old child. And if we, if we are aiming for the performance of a one year old, or a three year old, then we won't get to the point where, where our machines, take their letters from Oxford, and, and then go on to win the Nobel Prize, I think we need to aim for machines that have the capabilities of the greatest of us that the capabilities of human genius, and that that's not mere intelligence, it is also creativity, we have to understand the mechanisms of creativity, the mechanisms of social relationships, and ethics. And and in, in so doing, we also want to impasse, the greatest of human genius, and sort of say, well, you know, of all human genius that has existed, that's only a minor fraction of the potential human genius that could exist.

Unknown 27:27
incremental progress, superhuman?

Unknown 27:31
Well, I think I think what you do is you is you lay a path of continuum, continual incremental advances, so you have a continuum from, from, you know, today's, you know, sort of baby insect type robots, I mean, we can have, we have robots that, that may be able to understand speech with, you know, college level vocabulary, and I can understand where the, you know, sort of, you know, tongue in my cheat there, but what I mean, is that, um, you have, you have, you know, these machines that have like, insect like performance, they're not smart, like a baby, but they're smarter than a lot of humans in a very, very narrow regard is that idiot savant, effectively, I mean, they have, they have more, you know, idiot, the word idiot, she's,

Unknown 28:21
in your views during the idiot savant, and then progressing is a good idea. In other people's point of view, that's the wrong place to start, and you want to start with something else, and only get to language understanding of any level much later along the path. And that's, that's the tricky issue that comes up sometimes in discussions of these things, absolutely. We all we all want to make genius machines, but we want to take different routes together,

Unknown 28:49
well, the way the way that I see it, if we look at the evolutionary landscape of possible approaches to to realizing AGI genius machines, then you sort of see little plots of development like here and there some very, you know, low level, some based on you know, sort of fundamental evolutionary drives and you know, this kind of way GM, you know, dopamine motivation cycle and then you have some that are that are very high level performance and sort of top down in their architecture. But you also see these these kind of tenuous bridges happening between the sector's which when formed and when tinkered with that tinkering is perhaps undervalued because if you if you sort of Tinker them into something, then you start seeing often more general capabilities come out of the out of the machines, I mean, just basically by integrating across these multiple approaches, then you inch towards generality and and then you are able to test And cycle. So the, again next inclusive nature of the field should be appreciated. You know, I think, you know, as far as a roadmap is concerned, I think that we shouldn't just, you know, map one, you know, rural county in Kentucky or something, you know, we should we should wait create try to create as global a map as possible. And, you know, just because, you know, I may live in in this little County in Kentucky doesn't mean that that's the only one that should be this young man who you're

Joscha Bach 30:41
wondering what should we do with the microphone?

Unknown 31:00
Hi, my name is Rick Schwab with, say humanity from homosapiens. So first of all, I must plead to have nothing near the education or expertise in the field that you gentlemen do but I'm going to throw out only some I tongue in cheek, your benchmark tests for the next couple of years is the robot taxi cab. Now here's the thing, we're, we're close with autonomous cars, that pretty much work, I understand. But to actually be a taxi cab driver, you not only have to interact with the complex environment of the road universe, but your customers, okay. And so I would think you could get within a year or two, to be something that was functional enough that you could be competing with each other. You know, like literally an annual test where 20 test customers try to different taxi cabs and taxis. You know, and but to really be a good taxi cab driver, you need to be able to hold down the conversation, right? So you got to level up from your committee both to be acceptable and to be great.

Joscha Bach 32:24
And you can also show them movies. Appliance.

Unknown 32:32
Interesting says one, one practical issue is buying under a bunch of taxis to experiment with, again, the researchers permission to drive these taxis onto the street. Is there significant practical obstacles, right? I mean, what, what David and I are hoping to do is have a cost robot that a researcher or even a hobbyist could buy and experiment with and plug the software in into the API. And that's hard to do with it with a taxi. Right?

Unknown 33:02
I think that the taxi idea would be a wonderful concept for a business plan. And you might actually get some funding to develop this robot taxi, if you if you have the right large corporation, you know, it starts with a G that totally guided self driving vehicles. So towards a sort of common platform. So you know, Ben and I are working to integrate a, a constellation of existing AGI tools and components that relate to AGI into a cognitive robotics platform that would generalize. So we have this small robot platform that we're developing that we think would be a really beautiful common platform, very low cost, and also provide commercial opportunities for deployment at, you know, through apps with, with developers in the world through through one of my startups, handsome Robo Kai, really beautiful platform. But because we've open sourced the software and, and worked very hard to generalize this, it should work on many other potential platforms. So you can start to explore what kind of small robots might work in the marketplace and develop applications that would be more general so that way, it's a lot easier, potentially, if you have this generalizable architecture, to develop, to develop, you know, toasters, that that really want out of the box.

Unknown 34:41
More questions?

Unknown 34:44
I'd like to frame the question in a couple of ways that I think are novel. First off, I'd like to make the observation that the fact that we that we see a AGI researchers being unable to agree on a benchmark tasks is not mere consequence of the fact that AGI researchers tend to be stubborn. Because we fundamentally don't know which paths to the top of the mountain are the longest or the shortest or blocked. We really have no idea which way to go. And thus, anyone who is doing anything useful and concrete is necessarily massively overconfident about which is the best path. And so I think we need to take it as a premise that each person with their own approach and their own idea of what part of the space have tasks that humans can accomplish is the right part to start with. And, and say everyone has their own benchmarks. And so what we need is not a single benchmark, but rather a meta benchmark, some way of categorizing how general a particular researchers chosen subset of human tasks space. Yes, I think we can do that by sort of formalizing not in a not in a computer science standards based, let's use this particular API sort of way, but in a mathematical formalization. Saying that every researchers set of benchmarks should be should be representable as a environment generator. And that the the AGI should then be able to survive in some high fraction of the environments generated by that environment. And then we measure is the fraction and the generality of the environment generator. And it might generate in environments that look like virtual worlds, it might generate environments that look like IQ tests, it might generate environments that look like question answering problems, or any number of different sorts of things that people believe capture the fundamental aspects of what's necessary to build an AGI. But what we can measure, in some sense is the height on the mountain, how much generality you have gotten to, and such that if you go all the way and expand your task subset, at the rate your content content currently going that you will eventually encompass everything

Unknown 37:25
in principle, but in practice, it's hard for me to see how you apply the math of general intelligence or to compare, say, the, the complexity, or the generality of making coffee in the kitchen with the generality of say, going through elementary school reading curriculum, I mean, there's, we don't have a formalization of the real world. And I mean, counting the pixels doesn't work. So it's, it seems hard in practice, to really calculate and compare the generality of these, these these very different tasks. And there's going to be many different ways to do that math, each of which will favor some kinds of tasks over others. And then each researcher would naturally favorite the computational model, or the specific generality measure, the rate in their own type of task is being more generally,

Unknown 38:19
I think it should be possible to do this sort of thing. But there's a second proposal that I'd like to make, which is Wait,

Unknown 38:27
just before that second proposal, I just want me to point out to everybody that the lunch is currently on and ends at one o'clock. You're welcome to stay here and continue the conversation, if you want to, but Well, lunches

Joscha Bach 38:44
on should give the audience the opportunity to talk more, because we already know what we say, I want to know what you say. Let's spend the next 10 minutes on the panel. And let's have some lunch and let us separate, go forward. Okay, so very quickly. Very well. Some people have spoken,

Unknown 39:12
I just want to say thanks to the neuro. First I want to say that you did give me a very good vision of the post singularity hell, which is to be defending the whole of eternity and World of Warcraft. But but just in defense of the of the neural approach. Of course, this this analogy with flight has been, you know, it's the oldest analogy in AI. And I used to throw it out for people when the focus of my research was, was very much on symbolic AI. But when you spent 20 years watching the engineers strapping sails to steam engines, then then it seems like maybe it's a good idea to go back and look at the birds and try and come up with some deep principles analogous to aerodynamics. And that's what I'm really interested in doing and certainly taking the neural approach I do For me, it's not about, you know, going down to the molecular level, but is eventually coming back up to deep principles of cognition that would apply equally to the things that might be built through an engineering approach as well. But I don't see us getting there through the engineering route, personally, that, you know, historically doesn't seem to be going terribly far. And so that's why, for me, it seems the right thing to do is to go back to two brains and look at brain. And I have some idea of what the deep principles might involve. And I think it's all to do with rich dynamics, which is the thing that often is often lacking in many of the sort of more conventional AI architectures that we find in in the brain.

Unknown 40:44
Okay, hello, yeah. So actually, look, it looks as though people want to collaborate, even though they come from different backgrounds and have different, different sort of philosophies and how all this should be done. This is not really working anyway. So this microphone. So anyway, if you imagine the landscape, or the roadmaps of possible roads to AGI as a, you know, some sort of big tangled gap sharp, is there any way that you can collaborate? Is there any way that people come up with different philosophies, totally neuro inspired, totally, mathematically inspired or somewhere in between? Can they share some of these votes? Are there certain milestones that you can all benefit from, by their sort of critical paths that you can all agree on?

Joscha Bach 41:43
What about three benchmarks, for instance, let's agree not on one pass, but let's find out that there are some major a different approaches, and not try to build a spaceship that had everything including the coffeemaker, but try to build three spaceships and see how far they go.

Unknown 42:02
I think it would be extremely useful for us to knock off in a public way, with perhaps a, a, you know, a graphic visualizer attached to a sort of Wikipedia representation, Wikipedia, like representation, tomography, the field of AGI research and AGI related research, that would then also link to developer sites. And and then, within this, if it was a regulated, commented, representation, you could then have, you know, proposed challenges. And it seems like that a group, like AGI society, is perfect for organizing this kind of aspiration of public representation, which would also be extremely useful for the field because because researchers wind up getting fragmented and isolated, and not being fully aware. So if you were able to then cascade through a network like that, you'd be able to find out who else is out there.

Joscha Bach 43:14
Some of the problems, yeah, works against. I

Unknown 43:22
think coming back to what our friend or Pierre said is that we sort of missing the whole process, the importance of relationship. And it's not in terms of the taxi driver in his being able to relate to his customers, even it's important in terms of learning, but in order to move on, you have to form relationships. And so you will have to have relationships. And that any, you know, AI is going to have to have a general intelligence, nice verb to form a relationship, and it needs to get pleasure, an extra reinforcement from that relationship, or it will go on to do more learning and other things. And I think it seems that part of the reason we focus on the science and the cognition rather than the relationship, which is the more emotional side is because it's a very male dominated group. And I don't know how you solve that problem. But there are you need, you need more gender mix in order to get some of these more generally intelligence issues, because otherwise we'll just create machines, which are very, you know, rational cognitive machines, which general intelligence is not. It's not rational and cognitive. It's It's very different to that.

Unknown 44:46
I agree. I think in direct mail, just David is doing a lot to foster this. So far.

Joscha Bach 45:00
Your concern so far has been motivation. And we haven't had any talks on that topic. Almost known a little bit about creativity. Yeah, a little bit. So that was. But I do think that we didn't shed much light on the topic this year. And I have to agree, it's a very, very important topic. Also, I think it's a completely different issue. I think that gender diversity would be a good thing. Also, diversity of perspectives in general.

Unknown 45:33
I'm curious for Congress, your hundreds. This talk about Okay,

Unknown 45:41
so one of the things that, that I've been thinking about is that, you know, we used to have a very vague idea of intelligence 50 or 100 years ago, that we kind of had a very, you know, logical or, you know, being a master chess player was the definition of intelligence or, and, but, and so, you know, we began to realize how, how silly that was, and, and to, you know, that there's, you know, look starting to look at the intelligence, say, for instance of a toddler human being, in some ways is so, so completely beyond what we get out of, you know, a computer today, but, but the, but, but I guess one thing that's that's clearly starting to really happen now is that, that in in narrow in the narrow AI areas, we really are starting to get some some breakthroughs that are happening, because of working things at scale. And the result is on on. In these vertical areas of intelligence, we're having something that is completely off the charts, relative to human beings, human beings aren't capable of consuming 10s of millions of bucks. Now, maybe what we have right now are things that aren't terribly good at doing the Semantic Processing part of it. But in terms of doing things like information retrieval, question and answering, they're, they're really, really going well beyond what any particular human being is capable, or any animal can make. So I guess my question is, when you're talking about your benchmarks, I understand the idea of, of how having something that's embodied and learns, like a human being does that idea how that's important, and I understand the idea of like, well, you know, maybe the benchmark, is that you, you know, can it can it be that do things at a similar cognitive level to say, for instance, that a young human being as a benchmark, but I guess the thing that doesn't quite make sense to me about that is that we're already in a place that where we have systems that are performing acts of intelligence, that are way beyond even an adult human being. And so, you know, can we talk about breaking this down in a way that talks about the general intelligence characteristics? Like what is it, uh, what are the general intelligence components? It's, again, this, this

Unknown 48:30
gets back to the question of causal pathways, right. So one pathway that someone could think is feasible, although I don't particularly is to start with the Google search engine or some other big data thing, and tried to get more and more semantic understanding worse, my own personal view of the the right pathway to get to AGI is that there's, there's some core of common sense understanding that that's missing from these big data applications. And it's probably not going to come from incrementally improving them. And what I want to get from building robot toddlers or virtual robot toddlers is a system that has that kind of basic common sense understanding of itself in the world basic ability to generalize and create, I then think once you integrate that, with the sort of software you're doing for this big data, then you'll get something that combines human human like generality of understanding and reflective capability with a trans human capability to crunch massive amounts of data. And that will be awesome. But it's plausible to think of another path where you start by expanding the Semantic Web into general intelligence. And I'm not going to follow that path. But I'm not going to try to stop someone else from doing trying that path. And that gets back to the idea that there's many different many different pathways and we don't currently have the scientific knowledge to tell which one is the best but each of us has our own intuition.

Unknown 49:57
I would like to humbly add to that is that if you take this kind of approach often for these, you know, more generalized versions of narrow AI, that you see with self driving vehicles, and, you know, what a garage work and, and, you know, you know, IBM's Watson? Well, they often are, you know, just like on sort of Cluj ins, if you will, you know, you take all these chunks and pieces, and you move them together to make them do something pretty well, it's a little more general than has been done before. But it doesn't generalize the artificial intelligence in any deep way. But if you were taking this kind of pragmatic approach to solving a problem with a more general framework and attempted a general framework, then it may start to move a little more towards generalization. And that's where that's where, you know, it's exciting to see a platform like opencog, applied to, you know, a controlled human robot interaction for an educational context, what we're doing with the Google Chrome project, but that's just one example there. There are other examples out there with, with other AGI projects that I want to I did want to mention very quickly that in this course of progress towards genius machines, we we are seeking what we call the genie initiative, and that is to develop on this open source global framework that allows for people to commercialize to develop proprietary software, but with the goal of, of, you know, achieving these G GPS,

Unknown 51:41
we also have the last word.

Joscha Bach 51:43
Yeah. So I think that you are the remark has triggered something very beneficial. That is, we see one of the differences, what we believe is missing, and I think this is actually the question that we need to Unversed in building our roadmap. So for instance, we have seen new developments and how concept formation can work automatically by number crunching. And I think this is tremendously useful. You also agree that we are far from being there yet. And one of the question is, do we need additional modes of representation with respect to identity, space, time interaction, and so on? And what's missing? Is it a body to interface with the world? Which as Ben has suggested, or is it motivation and the creation of relevance by a motivational system and sociality, sociality and personal and so on, as I would tend to suggest, and do we need to find particular benchmarks that allow us to explore these perspectives? I think was that the chemical weapons, we have really happy about the food in the session and keep see if we find something to eat. And I do thank you very, very much for your good arguments. And I also like to thank you for the euroscience perspective, and I've got enough time to go into back and forth their arguments about that. Yeah.

Unknown 53:03
Thanks for coming, guys.
