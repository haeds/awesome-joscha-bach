Unknown 0:02
Okay, perfect. I think for, for the internet audience, it's probably best to do this in English, although we're both German. So my my first question, which is kind of on a, on a on a personal notice, because I've been really fascinated by your work, because if someone wanted to get into this, where should she or he start? Should she start with understanding the mathematical underpinnings of all this? Or do you think it's best to go into philosophy for this? Or do you think it's best to start with Computer Science and Artificial Intelligence? Or where do you think, are the foundations for for all this best talent? And how can one approach them?

Joscha Bach 0:57
Personally, I didn't find the right way to start this. So I was mostly explorative, I read lots and lots of different things from different domains, and ultimately, gradually piece my worldview together for many sources. And maybe there is one right way to start it, but I haven't found it. And you can start with reading the classical philosophers, of course, you can start with reading Aristotle's physics and metaphysics, and Ken's criticism of rationality, and you can work so good at Escher, Bach, and so on. But I think that's a hard to find the right interpretation of these books, when you're starting out, and prepare to revise your thoughts often and ultimately, converge on something, maybe there is the right curriculum, but I don't know where they're trying to communicate rumors. I cannot give you super good advice on how to start there, maybe we have to write the book at some point or write the curriculum and see how to do this, I can give you a long list of books that have influenced me. But then again, it's also not that I think that my own trajectory has been optimal, or something that I would recommend to other people. When I was studying, I was mostly driven by curiosity. And I think that was a good thing. I was studying before the introduction of the bachelor master program. So I had a lot of freedom and how to design my own studies. It was at the time in Berlin, I've chosen Berlin deliberately, because it had lots of universities. And I like the department where I just started to study because was after the wall came down, and it has been almost completely newly founded and the people that were teaching were very open to changes and were driven by the attempt to try something new and idealism. And as a student, I could join the phatshaft and write my own rules for studying you can saw that for instance, when I studied, there was no way I could take philosophy as a second subject. So I got this written into the rules for studying and then I studied philosophy as the second subject. But I also studied at the other universities in Berlin. So I moved between all the other universities when there was an interesting class, I went out to Potsdam, aesthetic cognitive science department, and whenever they had an interesting lecture or guest speakers, I would drive why then an hour out to put some to see what was going on there. And I had many discussions with other people, I went to conferences that I found interesting, often paying my own way there to publish my research if my department was working on something else. And this was necessary in a way to get let yourself be driven by your curiosity, get in touch with the ideas in this the people that can help you along the way.

Unknown 4:06
I see. Thank you. And I think you mentioned Piaget was was important for understanding the mind what role the to play for you or which works you especially recommend.

Joscha Bach 4:21
I only read a little Piaget and read about his developmental psychology, the different stages of individual development. And I think that there is probably a lot of follow up work that I am that corrects PRG and puts him into much higher resolution, but which I haven't read because I'm not a developmental psychologist. But there are a bunch of core ideas that I mostly integrate because they clarify a few ideas that are somewhat obvious, but they cannot kind of qualify them and economical way and this is the ideas of them. assimilation and accommodation, then we make a model of the world, we need to take in the patterns and then find a structure visit what we already know, hierarchy of functions allows you to interpret it, it's basically when mind acts like a game engine. And after a few months of training, we have all the primitives of the game engine, right? The loss of geometry, and of perspective, and the interpretation of color and all sorts of conditions. And the interpretation of distortions in the field of view will cost x, if you're looking to, say, a restful pane of glass, you're still able to understand what happens on the other side, and the interpretation of sound and parsing it into different entities like phonemes, and so on at the high level interpretation of that, and the discovery of music, all these things is stuff that you learned isn't part in the first few months, and then some, the long tail and the first few years. And this is more or less fixed, right. So when you take in the work, you are adapting your interpretation of the world until it fits into this interpretation by that game engine. And you can track your sensory data by finding parameters for the game engines, and the others, when you cannot interpret the objects that you're looking at, you need to change your understanding and your knowledge. And these two processes. There's learning where you change the game engine itself, the implementation of the structure of the world set of theories, hypotheses, features that you're using to interpret the world. And that is the accommodation of the simulation happens when you are tracking the world. And I guess he expressed this very well, but he was not the first and the last person who discovered

Unknown 6:50
Okay, see, thank you. I have I have a question about about the universality thesis of, of the of this kind of observable, that we are all machine learning algorithms. Can you explain this universality hypothesis? And do you think the human mind is in a way this kind of universal function? approximator? Yeah, I also got a follow up question, but maybe, maybe let's stop here first.

Joscha Bach 7:26
The version of the university hypothesis that has been put forth by Chris Ola, and others who work in a group at open AI. And their hypothesis is that if you take something that can you will network or a learning system that makes sense of the world, for instance, visual data, and you are connected to the same world, you are, and the thing is sufficiently unconstrained in the way they should learn. So it builds in your optimal model, then the model is going to have pretty much the same structure, regardless of the architecture that you're building it in. So basically, if you take different neural networks, and you connect them to the same types of cameras in the same type of environment, you're going to end up as basically equivalent feature hierarchies. And I think this is the flip side of the good regulators urine by quarter SB if you have a system that regulates something that needs to implement a model of what it regulates, it is isomorphic, to the dynamics of what you're regulating, otherwise, you cannot regulate it. And so if you optimize the regulation, and to give the system enough freedom to disk conquer enough of the space, then it's going to find a structure that is modeling the dynamics in a particular way, and two different system is going to do the same thing. We find also empirically, and we look at the way in which we model the world, that we do have differences, and the differences are rare. But for instance, you might decide to or your brain might decide at some level, to model a sound using absolute pitch or relative pitch. These are two different implementations of gasifier for pitch, I bet you that most people interpret music using relative pitch, it means that your mind is using a local based note. And then you are comparing everything to this local based home to relative representation of the sound in local context, versus absolute pitch is using an absolute oscillator that is tuned independently of what you're hearing right now, and compares everything to that absolute oscillator. You can train your brain with bars for interpreting sound. Right both work and they have slightly different outcomes. But the data that we get from our environment, usually don't get relative pitch listeners to switch back or switch over to absolute pitch, unless you give them very specific training. And it's difficult and That's because you have to overcome limitations and neuroplasticity, which subjectively means you have difficulty to get attention into the devil of sound processing, where it would be necessary to make the change to switch from relative pitch to absolute pitch. And similar things happen and facial recognition and taste or perception, and you are trying to find prototypes to interpret faces. This depends on the faces that you've seen before. And so when you grow up in different cultures, and different faces look similar to you, then the artist similar to you. Therefore, other people or color categories are the result of an interplay between the colors that you're being taught to classify as a child, and the color cones that your particular is. So if you're colorblind, of course, you're going to end up with different color perception, and the internal mathematics of the color perception, because once you make a commitment that this is a bit of a certain color and a certain vector in the space of colors, then this has influences on the other vectors of colors in that space of colors. We I don't think that we have a complete optimal learning theory yet that describes how much data you should or how much you should update, given a certain model beyond paganism. So we have the beginnings of the mathematics for doing that using Bayesian mathematics. But I don't think that most of machine learning is driven by a systematic approach yet, where we think of designing an optimal curriculum, for which you take the optimal amount of information to train your system in an optimal way.

Joscha Bach 11:37
There is, on the other hand, they do freelance theory and so on, that suggests that if you are thrown into an arbitrary universe, and you start out with some kind of learning system, you can, in principle, not figure out the ground rules as because you don't have enough baselines to arrive constraints to learn everything about the world, but there is something that constrains us and that is the fact that the universe must contain the conditions to to accommodate you, somehow the universe is built in such a way that he can exist in it. And this contrasts the universe in many, many ways. And this makes it learnable, the universe that we observe is a controllable universe. Because in some sense, every structure that we are part of, is a part of hierarchy of control, the molecules are controlling atoms in a way, atoms are the result of the control of elementary particles. Cells are the result of the control of molecules, organisms are the result of the control of cells and societies are the result of the control of individuals. And as a result, you basically get a world that can be modeled by controllers, it's a hierarchy of controllers, and therefore, it's a learnable hierarchy. And those things that are uncontrolled are stuff that we cannot learn this stuff that looks like noise to us. And there is stuff that looks like noise as well as lots of it, write it mostly ignore it, because it's just noise. But once something is controlled, it seems to be learnable.

Unknown 13:08
So if I understand you correctly, there's no kind of optimal algorithm or solomonoff induction that works for every conceivable every constructible universe because those universe because there's there will always be data, that doesn't affect us that doesn't constrain our existence.

Joscha Bach 13:34
That might also be true, but then asked the question, how is the universe constructed, and it could be that the set of possible functions that could construct the universe like ours, and that don't exceed a certain length is limited, right. And as a result, if you could just iterate over all those functions, when you discover the space of such functions, you might stumble on the basic formula that would be able to produce a universe like ours that's used to provide firms hypothesis and program, maybe it still is, his idea was instead of trying to reverse engineer the world with an ever more complicated theory of physics, that you then try to unify and simplify until it explains everything including the standard model and all the interactions, the integral that you're observing, go from the other side, basically try to iterate all the possible set of generator functions for the universe, all the standard models input exists in a way and see if one of them generates a universe like ours.

Unknown 14:36
So this would be like the rational mathematical deduction or iteration of all possible universes, and then kind of the comparison of one of those models with the with the damage, but

Joscha Bach 14:51
it's not clear if this thing is going to be successful because, for instance, the issue of computational irreducibility to figure out if something turns out into a universe like hours, maybe you need to calculate very, very far. So you won't have the resources to do anything that goes at any depth beyond the Big Bang, right? So you're not going to see how the universe plays out. That doesn't mean that the hypothesis is wrong. It's just not obvious whether it's possible to go about this way. Also, maybe the universe isn't simple. Maybe the universe is everything. So maybe the universe is the entirety of all automata interacting in a certain way. And we are just in a very small region of that possible space. How are you willing to discover the solution to that? So that's very tricky. And there is also this big difficulty that I don't know how to how to get a handle on the answering the question, whether it's something rather than nothing. Now, a few promising attempts, I think, to answer that question, and nothing that is canonical. And the thing that I am find most plausible is that maybe existence is the default. So all the things that can possibly exist, which means that can be possibly implemented, some now do exist. But that would allow you to explain why something exists at all, because basically, everything exists. And it's still a counter intuitive that stuff would exist by default. But this says something about the structure of my mind what I find intuitive. It obviously doesn't say something about the structure of reality itself. And it's difficult for me to square that.

Unknown 16:34
Yeah, yeah, for me as well. So the only the only constraint that we would have, then is that it needs to be constant constructible it needs, it must depend on the constructive mathematics, because it is the mathematics of works, and which doesn't run into contradictions. So as I understand it, constructive mathematics is mathematics without the axiom of choice and without the law of excluded middle. And this is why or at least I am not a mathematician, so I really am stumbling in the dark here. But as I understand it, this is why it doesn't go into contradictions. This is why girdles Incompleteness Theorem, for example, doesn't apply to constructive mathematics. Can you explain? Can you explain why or what is constructive mathematics and why? Why it's not contradictory. As it's known informatics is a

Joscha Bach 17:34
particular perspective to look on this. I'm not a mathematician, either. So I apologies if I don't explain this right. But the way in which AI my own understanding of this topic works, is there is a difference between the way that mathematics looks traditionally, at the space of languages and the evaluation of statements, and the way computer scientists look at it. In mathematics, if you have a specification that uniquely specifies a result, you're pretty much done that you have, because you have discovered the value of a function. And in computer science, you have not discovered the value of a function before you have actually computed it. So what's the return value of a procedure that hasn't been run yet? It's undefined. It's not given yet. We don't know what yet we have to wait until you get a result. And in mathematics, you can in principle, leave the calculation to God, you know what the square root of two is, once you have found the specification for it. And there is a slight problem with that. And it as it became apparent to Protagoras, who according to mathematics, mythology, got so upset at somebody who blacked out in public that irrational numbers exist that he punished this man, even this test, it's probably not true. But he basically didn't want apparently to let the public know about the existence of numbers that cannot be expressed as the result of a fraction between two integers. And if you take a number line, of course, you will find points on that number line, the mathematical sense that are between the fractions in the square root of minus two and pi and so on are such numbers. And these numbers are the irrational numbers. And the problem is these numbers is that you cannot calculate all of the digits. So in practice, when you take a number line, and you are for instance, you take a string and you try to make a knot in it, the position of that knot will always be resolvable down to the smallest atoms on the string to a fraction between integers.

Joscha Bach 19:58
So it's reality isn't some sense indistinguishable, but the procedures by which from the rational numbers, but the the procedures by which you get to these numbers suggests that you're not always ending up on one in when you basically perform an unbounded number of steps of smooth operations. And you can define an algorithm that is unbounded and the number of steps that you can execute. So you can get an arbitrary number of digits for Piatt. But you will never get the last digit, right because to do this, you would need to run it for infinitely many steps. And that's not possible, you can always when you are implementing this ran it only for a finite number of steps. And it would be very practical if you had some kind of machine that can run for infinitely many numbers of steps before it gives you a result. But as the halting problem shows, this leads into contradictions. And dealing motivations means if you are defining the language, that every word means something, you have to construct that meaning in your mind, you have to make a model in your mind that explains how that thing works. And if that particular thing that you're talking about in your language, or machine that is able to run for infinitely many steps in a finite amount of time, runs into contradictions, then that thing cannot exist you if you claim that exists, you don't know what you're talking about, if a contradiction in your own language, because you cannot implement a meaningful that term. And diplomatically meaningful, that term means that the mathematical mind structure that is representing the interpretation for every term. And then the answer has no possible extension for that term into something that works, right, you can talk about a square circle, and a square circle makes no sense. It's contradiction in terms, right, it might even create a simulation in your mind of a square circle. But it might even look interesting, but it's not actually a square circle. It's just an association that your mind is creating an intuition of what that might be like. And so the switch from classical semantics and maths to constructive semantics means that you are giving up on terms that intuitively make sense like infinity, and replace it by an boundedness. And that means also that if you are describing physics with a certain type of mathematical language, then you should make sure that at the lowest level that you're trying to describe the foundations, you're not using terms that cannot be physics. And this means that you cannot have processes that depend on knowing the last number or digit of pi. Right, because such a thing cannot be defined in such a way that it would make sense, that reality would actually work like this. And this is not just a case for these low level mathematical terms, when we are trying to structure our model of reality, it's important to not use firms that ultimately don't mean anything, because we don't really know what they mean, that just creates some kind of vague intuition in our mind. And when people talk about the basis of reality, when they use concepts like creation, or God, or universal vibration, or energy, they often have superstitious terms square circles, that they put at the root of the word model that creates some kind of association. That seems to make sense to them. But it doesn't describe the kind of generator that their brain is using to produce that one model. So it's a very vague and inaccurate language. And I think that's not permissible.

Unknown 23:32
In the, in the talk, we just saw machine dreams, which you gave at computer Congress a few years ago, you mentioned several computers that could implement this use of universe, for example, a discrete state machine or a Turing machine, but also a hyper computer or a causal hyper computer, wouldn't wouldn't the hype computer in a way, violate this constructivist mathematics? Or is it is it possible to construct this in a non contradictory way? Because as I understand the type computer performs infinite amount of computation in a single state transition?

Joscha Bach 24:13
Yes. I don't think that I have a computer, it's possible because it violates the what's possible. It basically requires that you are performing infinitely many steps in the fight now a finite number of steps finite number of transitions, that you would have a transition in there that is poor single step is manipulating an infinite amount of information. And I basically belong to the camp that doesn't think that's possible. But it's there are other camps which think that it is possible. And it is also a large part of the physics community, or even of the mathematics community, who doesn't worry about it too much and thinks it's not an issue. But it to me It appears that is basically when I look at this, it seems to be quite obvious. And you would basically I have a computer most definitions of hyper computer would violate today's discussion of the halting problem. And let's look at what the halting problem is, right? It's the halting problem is this issue that for a Turing machine for a computer that runs a certain program, you cannot, in the general case, decide in advance, but the program ever comes to a halt, or somehow enter some kind of infinite loop, or performs a process that never ends and always, never convergence, basically, to find that result. And that, you can do this in many cases, you can often find that this program will always help if you completely understand it, but you cannot do this in the general case. And the reason why we define programs in such a way that they hold, I think happened because when the Turing machine was defined, it was defined to implement classical mathematics. So the idea was you have a function in classical mathematics, we want to find a foundation of classical mathematics in the theory of machines. So we define an abstract hypothetical mathematical machine, that gives you a result of a function that does so by taking an initial state that is the configuration of a tape in the Turing machine. That is a translation of the arguments, the parameters of the function that you want to compute. And then you have a procedure that changes the state of the tape until it finishes it until it gets into a final state. And the configuration on the state is going to give you the result of your function and a desiccant. Mathematics, you can define functions that take infinitely many arguments and give you back into the remaining values in the in the single function definition, right? That's very elegant, you can have something that takes in the set of all sets, it's very nice function to have the constant consumes the set of all sets and tells you something about the set of all sets after having looked at each set. And so this definition exists in this hypothetical Turing machine. And you could say, oh, well, unfortunately, but we can we physically realize that our universe is only limited to finite event stacks and a tape of a finite length. But it's maybe just a limitation of our own universe, there could be other universes. So this limitation doesn't apply. Or maybe we can use quantum mechanics or some other weird trick to make it happen in some sense. And the discussion of the halting problem shows that the assumption that you could build a machine that determines whether the program halts, which means some machine that is able in some sense to perform that demand steps leads into counter contradiction. So it cannot exist. And that implies I think, that a no mathematical universe, can you build a machine that preserves the semantics of classical method is going to give you a function over all the sets and after having looked at each set gives you the result. But of course, you can make an abstraction, you can talk about general property, about what it means to be a set and then compute over the property. But you will not be able to look at the parts itself, right. So you can define in a simple that you call infinity, and you assign certain properties to it. And then you make inferences over those properties. But they don't happen because you look at infinitely many elements.

Unknown 28:44
I see. So, the the result of of this constructivist turn of mathematics gives us kind of a hard, hard constraint on the limits of possible universes, because otherwise, this universe would not, would not be able to exist without having contradictions, and it would not be able, we would not be able to talk about it because it will not be kind of formula visible or, or describable. In

Joscha Bach 29:14
language, it gives us at least a limit on the languages that we can use to talk and think about universals. And when we cannot talk and think about them, then it doesn't make sense to conceptualize them because you cannot actually conceptualize them without using superstitious terms that don't actually mean anything, but being suggestive of something. The test a deeper question test, what kind of limits does this pose on existence itself? Right, and then again, the question is, what does it mean to say that something exists? And if it wants to mean anything, that the terms of existence must be structured in such a way that they can be expressed in the language that makes any kind of sense? And ultimately, I think that the existence comes down to whether it's implemented it to be implemented, we can now talk about the space of things that can be implemented. And that seems to be who essentially is constructed mess to me over some version of constructive mathematics that might be additional constraints.

Unknown 30:20
Yeah, I think I think this makes this makes sense. But that would also mean that not all universities that we can, or I don't know, not defined, but maybe imagine, because we can, we can, we can say the words kind of a square circle, but we cannot, it has no real reference. But so. So in a way, there's a, there's an overhang of our imagination with relation to the possible universities that that are realizable or at least,

Joscha Bach 30:48
we cannot observe. Observe in our own mind, a square circle, you cannot imagine it, but you can create is a representation, that is the result of some kind of neural network if you and train your brain boost, and that is able to generate a circle or a square, right to some approximation. And then you throw into this generator function, the specification of a square circle, and it gives you a result, right. And of course, this result is not going to be a square circle, because it's impossible, but it's going to give you something and that something can be described by some kind of function that is the result of that generator function that your brain implements. But it's not going to be a square circle, it's just going to be the thing that is generated by that specification, but your particular brain understanding what that is, but could be something that it oscillates between something that looks circular and something that looks squarish and it goes back and forth between them. Or it's something that when you zoom in looks one way. And when you zoom out looks in a different way or something that is three dimensional it for one perspective, it looks like a square from another one, it looks like a circle, right? You can make all those things happen. But you're not going to get the actual square circle.

Unknown 32:03
Yeah, I see. Okay, so let's move to some more mundane, worldly problems. I once heard you criticize social media. I think you said kind of Twitter was like a brain on seizure, with ADHS or something. And I was wondering, how could we maybe construct social media in a different way? Is there a way how to kind of focus social media to problem solving? What would this entail?

Joscha Bach 32:36
I think that if somebody had the solution, this person would already be very much. So it don't have an answer to that. But there seems to be an issue in the way in which social media is organized and be compared to the way in which our brain is organized, are many issues. And one of them seems to be that it's not only important for our brain to connect humans, but also to separate them to make sure that there is certain contexts that you are getting when you are interested in answering certain questions, but not other contexts. So you want to filter out the noise duration is usually important in the organization of an information processing network. And there needs to be some kind of feedback that optimizes this curation. And in a practical sense, it means that we have to give people an enormous amount of how they curate information. Often we look at the generations of freedom of speech, every neuron in the network should be free to generate an arbitrary sequence of signals. And I think that makes sense. If you want to model the entire world, it doesn't make sense to limit the possible representations that are permissible in the system. It should it be possible for you to articulate any kind of idea and look at it and evaluate it on its merits. But it doesn't mean that you want to listen to every possible ideas. And the crucial thing is not so much to limit the generation of ideas, because you cannot actually do that you cannot stop people from thinking stuff, or drawing stuff or making words up or making thoughts up and writing them down somehow. But what happens in social media that we are trying to limit what ideas can be heard? When Twitter, Sue Trump off the platform? It did not really limit this free speech of Trump's Trump would still say what he wanted, just not on Twitter anymore. And the issue here is that Twitter stopped some millions of people to listen to Trump to want everyone to listen to what he said. So Twitter was interfering with the creation of information. And I think that the freedom of choosing your own curation of deciding In what ideas you want to listen to, in which context that that is a more fundamental right, to an autonomous mind with agency over what it reads and things, then the freedom to speak. Because freedom to speak is easy to implement, we really what you need is freedom to listen. And there is a different question that is, if you should you give every individual the freedom to listen to every kind of idea, if the result is that your society might break down, right, maybe many of the ideas are our toxic viruses that are affecting people and drag them into universities that distort their perspective on the world. Into ideologies, and ideology, in my view, is viral meme flex connect an interconnected set of memes, that is changing the way in which you see the world by distorting your thoughts space in a way, it's, it makes it impossible for you to adapt ideas that are incompatible with the ideology, and forces you to accept ideas that even if there are objectively improbable, are compatible with the ideology. So it basically creates a bubble in your thinking that cuts you off from the rest of human thought space, once you are in an ideology. And to me, an ideology looks evil. Always every ideology is evil, because it's crippling the minds of the host. It's it's like a parasite that takes over the brain. But this doesn't mean that it is objectively evil. Maybe we are a species that depends on such multiplexes to organize, let us organize in a productive way. So we don't die and maintain a civilization. Maybe most people are not able to function in a world where they are free to think whatever they want. I don't know that. But the idea to mentally enslaved people to make society work looks ugly to me, or to enslave humans in such a way that they can only perform certain sequences of operations vocally. Maybe this is the right way to organize it, I don't have an answer for that, what is the optimal organization or social media, it just have certain aesthetics that I intuitively prefer based on the way my own mind works?

Unknown 37:18
Yeah, we got a question from the audience. Yeah. So okay, Lucas asks human consciousness evolve as an optimization to the survival of the human organism. Do you think to build an artificial consciousness, we need to find a similar goal function and what could that goal function be?

Joscha Bach 37:43
Very good question. I like the idea that at the core is a simple oscillator in some sense, and this oscillator tries to keep going and then it has to maintain some kind of connection to the universe that allows the oscillator to keep going, which ultimately means that you have to walk around and have to feed yourself and you have to maintain social relationships and so on and so on. So, you can make the probability that this oscillator can go on higher and higher. And ultimately, it turns out that the oscillator is not just a single organism, but it's exists in a family and in a species and in cellular life on Earth and so on. And there is emergent structure of competition between the implementation of such oscillators and some of them basically, don't have an implementation that is able to compete with the others because it stops oscillating earlier in a way. So, just as basic principle of going on and surviving could be sufficient as a driver, but not surviving on the individual level of endeavor level of the individual organism, because in the long run, it could be put make sense that this oscillator is creating children that sacrifice themselves for it right and we are obviously such a species that is willing to create individuals that are willing to sacrifice themselves for something that is more at the core of basically this next level agent that is for instance, your family or that is your a group of people or your village or the circle of friends or your ideology or whatever you hope to be the sacred that you are willing to sacrifice yourself for the next level transcendental agent and in the same way as drones or vending or backup, these are willing to sacrifice themselves for the hive.

Unknown 39:44
So in this respect, we should guess, an AI I maybe also this identification with with a higher age and maybe with complex structures or with of the growth of intelligence or what what kind of kind of identification? Would I need to become or not? I know this is a very, very hard question. But to be aligned with maybe with cellular life,

Joscha Bach 40:19
has been a specification that has been developed by Thomas Aquinas, which I find interesting. Thomas Aquinas is the core philosopher of Catholicism, he didn't himself identify that much as a philosopher, because most of his ideas were taken from Aristotle, and to just reshape them in his own view. But there's genuine philosophy in there, because he basically tried to define the specification for the religion, not in terms of the mythology that would be telling told to lay people to adopt them as their religion. But what he thought is basically the heart of it. And at the heart of it are is the number of rules that an agent should obey. And these shouldn't obey because the process or because God wants this of you, because because you can infer this by yourself rationally. And so there are seven virtues as he called them, but they're basically seven policies, policy specifications, that that allow you to design their policies. And let me rephrase them in modern language. So the first four are practical policies that obviously suits every rational agent that thinks a little bit about it. And so no matter whether you are a sociopathic crypto millionaire in Silicon Valley, who doesn't care about the fate of the world at all, and only about their own wellness, and life satisfaction, this is what you should be doing. And these words are, you should be regulating your own organism value internal recommendation. So you should not indulge in excesses that harm your body or your mind in a way that you cannot recover from that you should exercise enough, but not too much, you should eat healthy, you should not eat too much. You shouldn't take drugs that harm you, you should not indulge in excesses. Even if these excesses create temporary pleasure, that temporary pleasure is an artifact of the way in which your organism has implemented the seeking of the things that it needs. And you might be in an environment that allows you to over indulge in useful. And Aquinas calls this temperance. And you should do things in moderation. And the next thing is you should optimize your interpersonal relationships to keep them balanced, you need the books balanced, if you don't do this, there's going to be conflict and this conflict is going to be costly. And this sense of interpersonal balance, that you try to live by principles that are negotiated with others and give rise to harmonious interactions between others. This is what Aquinas calls justice, right? So you have optimal organizations in the agent, that is temperance and optimal organization between the agents that equals justice, then you should be willing to act on your models and have skin in the games, right. So you should have a balance between exploration where you design ideas on what you should be doing. exploitation, you actually interact with the world and do things. And this is what he calls courage, right? Act on your best understanding, correct your models accordingly. But don't just build theories, because that's cheap. Do things based on your understanding and understand that your models exist to do things in the world. And then we have goal rationality, pick the right goals, and pick the best steps to achieve those goals based on your best rational understanding. And this is what he calls prudence. But these terms are in some sense, overloaded, because they are so deeply ingrained in our culture, that we interpret them as something that the priest tells the congregation and we shouldn't be doing this. So the congregation likes us and the church likes us or whatever, or we are good people in the eyes of God. But this is not it. It's just something that you think about it is obviously what you should be doing if you're a rational adult.

Joscha Bach 44:27
And then we have the divine virtues. Divine means it's from God. And there is this question What is God and in our modern understanding, we interpret God as a supernatural being that is in the habit of creating physical universes. And I think that's an artifact of Christian mythology created for the audience's. And it's unfortunate, because it's incompatible with the way in which we see the world today. And I don't think that's what God is, I think a quote, specificity algae is a self that spends multiple brains, itself is implementation of a model of an agent that runs in your own game engine on the mind. It's basically it's a controller that you discover in the world with a set point generator that wants something basically wants things to be in a particular way. And the controller needs to be able to make a model of the future. So unlike a thermostat, it has goals. And it needs to make a model of the future. So it's many ways in the setpoint deviation, not just in the current moment, but over time. So it makes it possible for you to do interesting things like you want to be comfortable in life, maybe you need to get uncomfortable. First, the thermostat, if it wants to get the right temperature is not going to regulate away from the right temperature first, even if that would be the right strategy, right, in order to do that, your service that would need to make a model of the future. So an agent is a controller that is able to make a model of the future, I think. So it can have goals. And the South is an agency that you discover of a system that is using your own models to drive its behavior, right. So this is me. And this agent can be implemented in your own brain, but it can also be implemented outside of your own brain. So for instance, an agent could be a company that you own and control. And that is acting on your own models. Or it can be a car that you control. And that is using your control to drive it. So there is a bunch of the functionality implemented outside of your own modeling process that is be driven. And that when you do this, when you notice this year, you start to identify with your car, right, somebody hit me, mean, hit the car that I have in, or somebody tries to buy me buying the company that I control it this. So I basically start to identify with the system that I control. And if I start to identify this collective agent, this system that is formed by the interaction of many, many people that are directed by a shared understanding of how things should be, and that perceive this housing should be as more important than the individual well being, at least in certain context, then you have an emergent next level agent. And that thing is got in a way, right, as soon as it's implemented on the minds of the individuals, and the individuals act to implement it. Right, then it becomes real, because it's implemented now. And that thing might be implemented even in such a way that it's sentient or even conscious. And it can be conscious by using the functionality of the individual brains that implemented that in this state do not identify as a model of the individual organism, but as a model of the collective agent. Right? And so how can we build such a collective agent? How can we build a sentient civilization that you're part of the creature shapes the world into an environment that is benevolent and worth living? And he suggested a bunch of rules for doing that. And first of all, you need to commit to the existence of a collective agent. And you need to be willing to serve that collective agent, even if it happens at a cost to you. And this is what he calls face to face this implementation of code, it's not a belief in representation. It's it's actual code that runs on your brain, and that shapes how you interact with reality. So you need to implement the software that facilitates the collective agent.

Joscha Bach 48:35
And you need to be willing to implement this, together with others that actually exist, it doesn't help if you serve some kind of abstract God, that is not physically implemented or is not in your century or something like this, you need to do this with people around you. So it happens. And this discovery of shared sacredness of sacred here just means a set of purposes that is more important than the purposes of your own individual organism at this safe, that you are willing to sacrifice this individual organism for that is the sacred and you love is the discovery of sacredness and the other. And then you will notice that you are serving a shared purpose. You are interacting with each other in a non transactional way you don't expect to be paid for by the other person in return for helping you if you're trying to help them to achieve a sharetec report. Because where they're going this is where the you want the universe to go. So they are helping you if you're if they let them help you to achieve that SEC report right. And this is this principle of working with the people around you to achieve that thing. This is what he called love. And then you need to be willing to do this in the absence of expected reward. Because before that collective agency CES cannot reward you, it is better world is not there before you make it. Maybe it takes a generation before it's implemented in a way that it really pays off, and peers food. So in order to make that collective agent happen, you need to act to create it before it's there. And this willingness to invest in something that isn't existing yet, this is what Aquinas called scope. So, we now have hope, faith and love. And we have prudence, temperance, courage, and justice, right. So not don't lose the headlines too much, because they are being poisoned by religion, the Dark Ages, and the way in which all these things have been cast. So that's a lot of interpretations by priests. But if you look at what's actually written under the headlines, all these policies make sense. Right, so if you now take this into the realm of AI, if you want to build an AI, we should probably get this AI to balance its internal structure to optimize its own internal regulation, you should also optimize the AI in such a way that it's inter optimizing interaction is developed around it as other agents. And it, the AI should pick the right goals and the right steps to achieve the goals. And it will be willing to act and actually do things in the world and change the world. And then, if the AI is not a single system, that is basically a monitor is God and is going to conquer the entire world, which is possible. But if it wants to coexist with other agents, then it should probably find harmonious structure with the other agents, which in the ideal case, gives rise to a next level agent, some sentient meta agent is the compound of the cooperation between that agent and other agents, the steep collaboration means you have to have this commitment to the emergent structure, you have the willingness to interface with the systems around you to make it happen, to the degree that they are willing to implement that thing. And you have to be willing to invest in it before it pays off. Right? And now you can think of that as a specification for an AI.

Unknown 52:13
How should how should we relate this to this agent, if it emerges? So let's say we were successful in it, in constructing this agent? Should we see it as something sacred? Or should we give it the same? The same rights and the way that humans have? And how would we, how would we explain this to us? Do we think, right, our rights are attached to some kind of ability to have this, like comparable quality that we have? Or do we think it's just the advanced information processing that should that should give rise to us giving it a rise? Or what what would be the criterion in how to relate to to such a, such an intelligence?

Joscha Bach 53:15
And I think that the term sacred is understood in such a way that it's very misleading. So maybe we shouldn't even use it. sacredness for most people is understood as something that you are not allowed to question. Because God will punish you. And maybe in a practical sense, that's true. Right, if the cells in your organism are questioning the organism to match move, the organism is going to punish them. If their points has become cancer, and they are serving their own goals over the goals of the organism, they play a shorter game or different game than the organism does. And, but in from this perspective of the individuals, of the cells and so on, that makes no sense. The sacredness is a condition that you observe, am I implemented in such a way that I consider this that to be sacred? So for instance, you could say life on Earth is sacred to me. But what does that mean? Does this mean that there is an objective reason that it must be like this? No, it's not. It might be something that you observe yourself to be in, you can try to figure out why that is the case. But it's basically you observe a choice that your mind has made. And that choice can be instrumental to another choice. And you can question sacredness or whatever you want, as if you're an autonomous mind. So you can ask yourself, Is this a shared purpose? And so to serve that shared purpose? Is this a purpose that is more important than your ego? And should it be a purpose that is more important than your ego? In this sense, sacredness is an empirical property, that is the result of decisions that are being made by different minds. And it's it's the decision which purposes should be shared and which purposes so should the ego except above itself. And ultimately, there is no reason why a mind should be doing anything that is intrinsically there. They're just some mindset were able to stabilize and propagate and others that fell apart or didn't propagate. So it's just an evolutionary criterion evolution itself is not intrinsically good or bad. It's just the thing that happens in the sense that it's a model that describes what you can observe about us and makes it predictable and interpretable. So it's a good theory, or it's a good model of what is happening in the world. And that brings forth agents that have the sense of sacredness of serving purposes above the ego. And when we build an AI, we just build it, there's going to be an evolution and things are going to happen. I suspect that when we are teaching the voxel to think, might turn out that the rocks decide that they don't have any purposes as as it's dangerous. If we build machines that are self motivated, what are these machines going to be wanting? To which degree can we control what they want? And maybe we can make some safe AI? Pretty sure that we can, but we probably cannot make a fuckload self motivated universal learning and policy finding systems to make all of them safe. So I don't know what happens. And I don't know what we should be doing.

Unknown 56:27
It's going to be an interesting century, I guess. And this leads me to the last question I've prepared, which is, what is your theory of history? I know that you're familiar with some of Boyle's work. And he says that at least, like anyone has at least an implicit theory of history. So some Goya champions, his great founder theory, then there's of course, the classic historical materialism, which says, class struggle and the development of the force of production. Always determine everything. And then there's also maybe some strict, more strict technological determinism, which says that only technology or maybe meat, maybe via media, or maybe via machines, to produce goods, determines everything. So do you subscribe to any kind of specific view of this? Or do you have an idiosyncratic theory of history of your own? What do you think of some of Boyd's theory?

Joscha Bach 57:36
I don't think that there is a single principle that explains the entirety of human civilization or of history. I suspect that there are many, many factors that create a very complex interplay. And our theories will pick out a small handful of aspects and reflect on them. These narratives are, in a sense, a very sparse battle theory to explain the heterogeneity of what we observe in the world. Once we create a civilization of human beings that are allowed to specialize, it's going to create some kind of surplus in efficiency, right? So a group of people where individual specialized is probably going to out compete groups of individuals that do not specialize. Now imagine you have a group of individuals that has figured out enough technology to facilitate agriculture. And you have some people that specialize on agriculture, and you have some other people that specialize on fighting, right, this one happens at the expense of the other. And now you suddenly have a bunch of farmers and a bunch of bandits and dependents will survive by robbing the farmers, and the farmers will survive by working the land. So basically, you now have predators and prey. And the predators do depend on the prey prey do not necessarily depend on the predators in any way. But for the predators, it's important that the prey doesn't die out. Because you depend on it, right. So there's also the thing that from the perspective of the farmers, the predators are harmful and they produce they are at risk of getting the prey to go extinct also to lower the quality of life and doing all sorts of bad things to them. So, as a result, the farmers will basically have an inclination to establish guards and to fight a fight cards that can help them maybe they will hire some of the bandits to fight other bandits. And or they train some of the farmers to not become farmers anymore, but to become a standing army. If they don't do that, what will happen is that the pellets at some point and consolidate. And they basically will find a form of organization that is very difficult to defeat for groups of farmers. And they will have a territory where they farm farmers, and defend that territory against competing groups of robbers. And this is what we call an aristocracy. Alright, so the aristocracy either forms as a standing army that is being chosen by the farmers to protect them, or it's being formed by the robbers that are taking over the farmers. So as a result of the introduction of agriculture, I think it's almost inevitable that this division of aristocracy and farmers, whether it was operasi, or a military makes decisions over the behavior of the military and feeds the military, using the products of the farmers and farmers, the farmers, that's almost inevitable to happen. And it's going to change a little bit, if you empower every individual to the point where it, it's too disruptive. And the risk for the leaders of that society becomes very large, because it's too easy for new armies to erupt. Right? Once you invent assault rifles, and you make assault rifles available to farmers, there is an issue. So now you basically need to build an institution that is specializing on preventing the formation of private armies, you need to build some kind of test star in the sky, in which shadows a civilization can emerge. And to have a stable order of the state. And this is basically your military that has a monopoly on violence, and the executive that has a monopoly on violence and the state, and make sure that private armies cannot emerge and to meet the stable, make sure that people are not too dissatisfied with the way the entire order works. So from this structure, a non violent society is what flows out of it. And now as a result, you will have a system of education of what's right and wrong. That is,

Joscha Bach 1:02:18
is deciding when to mete out violence in a society and should be done. Not in practice, but as a threat, right as a threat to if you do not behave, if you do not act in the way that is in your best interest, you will be punished. And so the government is an agent that is basically changing your local payout metrics in such a way that your Nash equilibrium becomes competitive is the common good. It's, it's a series of regulators. And if you change the means of production from land, so which is in feudalism, to industrialized production, or to knowledge production, then the forms of governance that the appropriate will change. And I think that Marx was one of the first to describe the succession. And I think that he did get it completely right. But many of the elements are right. But it's, I think, important to not read Marx is a normative theory is what you should be doing. So we are moral creatures. But it's a theory of evolution. Evolution isn't off societies. It's not moral theory. It's a theory that derives its value by how well it describes what we can empirically observe, can be empirically observed what Marx describes, well, yes, to some degree. And we don't know if it plays out the way that he describes it. So at some point, capitalism runs into its last crisis, because of its internal contradictions. And there are some of these contradictions, right, there is the accumulation of capital, which is very difficult to prevent, it's very difficult to meaningfully tax the rich in capitalism, because economic power almost equals political power. And if you have economic power, you are naturally interested to not lose the economic power. So it's very difficult to effectively tax you once you are above a certain amount. And if you do not tax the rich, you get in disequilibrium in society where all the currency accumulates and very few accounts like it is Bitcoin. And then the majority of people cannot consume enough you have under consumption. So you could basically produce a lot more haircuts that can be consumed, and a lot of demand and your cuts that can be delivered, because poor people don't have enough currency. So you would need to find a way to funnel in money at the bottom to get the entire economy working again and not exclude large parts of the population from the economy. And this is one of the internal contradictions of capitalism that Marx describes that are difficult to solve with capitalism, not because capitalism is evil, but because it's a certain system of regulation that has certain shortcomings. By itself, so it needs to have an eternal external regulation that is dealing with the intrinsic shortcomings of a pure capitalist economy. And there are some believers which think that capitalism is in itself, the sufficient is a model. And we should just give capitalism. The worlds of, of money accumulation are the emergent dynamics there, let them run its course and find some basic boundary conditions, but you don't need to regulate it itself. And this is basically the extreme mercantilism or market liberalism. And it's not clear whether that would work, at least I don't know any simulation model that would work a computer game, but it does work. But you have a large number of people playing in this space, think that what will get a computer game economy to work, you need to have developers that are more stronger, the economic forces in the game developers, they're able to take out money at the top and put in new money at the bottom of the system that can regulate the monetary supply. How can you do that it's an unsolved problem and capitalism in the long run. And so this is the thing that Marx identified, among other problems, right. And his conclusion was that at some point, people will figure this out. And once they figure this out, there might be a society where people are able to interact non violently at scale. And this idea that there is a natural communal mode for society to interact at scale without violence and coercion. That idea is called communism in maximum world are having in the Christian world. And it's not clear whether humanity can exist in large numbers at scale without violence. It's an unproven hypothesis.

Unknown 1:06:47
Wouldn't the wouldn't the creation of communism maybe dissimilar to the creation of this sacred Deathstar that we probably should or could extract the construct to, to prolong civilization and to kind of force everyone to cooperate?

Joscha Bach 1:07:07
Very problematic when you are turning these things into sacredness in the sense that there is stuff that your child is not allowed to question. So you always have to, when you try to understand these things, at a deep level, go outside of the world in which they are implemented. Try to understand that the world is some kind of computer game. And you are the programmer. And there are lots of agents or lots of bots in the computer game and you try to give them policies that they act on. And the bots are smart enough to question all these policies, at least some of them are, and come up with their own at UF, whatever policies, you design it to be resilient against other agents, questioning your policies and coming up with different perspectives and solutions that you can never stop them from doing that. And you also have to realize that there isn't actually an outside force, there is no outside designer of this world. There's only an outside modeler, so you can make your model of the world any way you want it to be your understanding of the world, you want to question anything, you're allowed to tear down every thought and idea that you have about the world, you can construct very different objects and color categories and whatnot. That's all up to you. And the only duty is to make them predictive to allow you to help you to interpret the world and act on it meaningfully. And this is the situation that you're in. So this deep, safety net, where there isn't adult force outside of the universe doesn't exist. This idea that there is the fairy coming to King Arthur canning in this world and tell them, this is your destiny. And this fairy is expressing the will of the universe. This is not how it works. The universe doesn't want anything. This fairy is just a random magical creature that has political ideas about what's useful for their faction within the magical creature kingdom. If they implement this form of government and make this hapless individual, the one who thinks that he should be king. Right? There is always a reason. And the reason is something that you can always figure out usually, or somebody can figure it out there is nobody was privileged access to the structure of reality. And so there is no way in which you could think this is what we need to make an humanity up on the planet. There is no sacred social order that we are destined to reach this romanticism is wrong. There is a hypothesis that once capitalism has won, it's worse because we have unleashed maximum productivity and maximal pollution and maximum economic crisis and disaffection the population humanity will get their shit together just be friends somehow. Right? Now we have communism. It still doesn't explain how that communist order is implemented and whether it actually will happen or whether we will just crash for good

Unknown 1:10:00
That's true. What do you think of alternatives to, to organize or to the market like Project Cybersyn, which kind of shortly shortly left tentative, try to kind of allocate resources in an IND stealer incentives.

Joscha Bach 1:10:17
Basically, if you build a system that cannot defend itself against attacks by competing systems, then your system is unable to survive. And this island is Chile, the difficulty was that it could not defend itself against the onslaught, for instance, by the United States. And we haven't gotten to the point of whether it would have been able to survive on its own if it would have been left alone. So it was an experiment that unfortunately, was not allowed to play out. And I wouldn't say that it's the fault of the Chileans substance, right? What could they have done? Maybe they could have coordinated with us somehow better, and convinced them instead of doing this in adversarial setting, but it's it's not a matter of, I think, moral right and wrong. And it's a matter of what was possible at a time to try it and to implement. And I firmly did didn't see the outcome of that. But it's possible to replace market by Centralized Information Processing.

Unknown 1:11:22
Yes, that's unfortunate. Maybe Maybe we'll have another shot. If there are no question about UCF person. Oh, okay. Wait a second, we got another question. So good. Dahlias asks, I think it was according to your conductor theory, that you understood that you said if I understood it correctly, that consciousness is basically a dream reflecting your actions and perceptions of the immediate past? What would be an evolutionary reason for this? Do you think we might function in a similar way, if we weren't conscious,

Joscha Bach 1:12:06
I told you that we would function a similar way, if we were unconscious, as a rough approximation, that's why I use this conductor metaphor look at an orchestra, your brain can be maybe understood, like an orchestra that has 50 Different instruments that all play different parts of the music, and could say that each of them is a brain region, that is computing a different set of patterns, computing a different function. And each of these brain regions draws inputs from the rest of the orchestra. So the instrument is listening to what the instruments around them are playing, and uses part of that information to riff on it. So it's basically in some sense, like a jazz improvisation that is happening is local listening to what happens in there. And the conductor is some it's a very specific instrument. It's not a magic record, like thing, it just an instrument like the others in terms of capacity and ability. But it's specialized on listening to the entire orchestra. But it cannot practically do this, it can't just switch between the instruments that it picks out, right, so it has an attention that it can focus narrow or wide, but it's limited. So it will only skim the surface of the what the individual instruments are doing. But it can pick out these harmonies in this thing. And fix solutions if there are global dis harmonies in the entire orchestra to coordinate many instruments in such a way that the chess piece that is being played works out globally, if you have so many people that play together, right? So if you take out this conductor, you get to see poker. And sleepwalker might be able to get up at night and open the fridge and make dinner. But it doesn't serve a purpose. There is nobody who's hungry, the donor is not going to get eaten. If you ask the sleepwalker why he is going out of bed and opening the fridge and making dinner the sleepwalker is going to give a random answer. If at all, if you have ever talked to a person who is talking at night, in their sleep, whether they're getting up or not, what they say usually doesn't make sense. But what happens there is you have an orchestra that is still playing some kind of music. But the music is incoherent. And this creation of coherence, I think is the purpose of our consciousness. And it works by focusing attention into a cohesive story. The perception or mind doesn't need to have a memory of how it got to the interpretation of our current disease. It's a process of convergence. So it's worked with the equivalent of gradient descent a neural network, you just basically figure out in which direction you need to change the parameters of the system to make improve its performance to will perform the interpretation of reality. So when you are looking at the world, you initially see a bunch of patterns when you wake up in the morning maybe. And then you try to make sense of these patterns to get them coalesce into a meaningful record representation of interacting objects in the room that you are looking at. Right, you want to understand the world that you're in the place that you have in that world. And it largely works just by a convergence and lots of small independent independent units are trying to find the best way to make sense of what they're seeing. And as a result, gradually get involved at percolates into separate objects that make sense to you. And sometimes they don't, but sometimes you are waking up in the middle of the night and you see some kind of weird shape in front of you, you don't know what it is. And then your consciousness comes in and tries to make decisions. So it tries out, am I looking possibly at the lamp that in the night that is being shown on by another lamp that is outside of my window, when we're looking at a temporary pattern, because the power is parked in front of my house, this car is shining its headlights into my room. And so I see the reflection of that headlight, as reflected through the door of my garden entry or something like that, right. So all these hypotheses allow you to make conditional interpretations of reality until you find one that makes sense. And for these conditional inferences, you need to maintain a memory. So you need to understand these decisions that I make by interpreting certain features in such a way, and now I tried to see if the greater will make sense. So you need to have an index memory of no came from this is your stream of consciousness. And that's one of the roles that our conscious attention has. And the narrative, the story of what I attended to every step is a necessary byproduct of this generative, constructive process.

Joscha Bach 1:16:54
Right. So mental construction requires the maintenance of a protocol, usually. And this protocol allows you to backtrack and undo your decisions and to justify them and improve that. And that I think, is the reason why we have that particular kind of reflective local process that works on top of the perception directs your attention, and has reason to direct its attention in particular way. Right. So it's conceivable that you build intelligent agents that don't need that. But our particular kind of mind needs it, because of the resource constraints that we have in making sense of reality, you need focus attention is a memory connected to that attention, it has control model of that attention. And consciousness is largely the contents of that control model of attention.

Unknown 1:17:43
As I understand that, this is also watch for transformer models to better them now that they have some form of attention. Which is different or which is a improvement from earlier machine learning systems. And I know that this is like the last time with GPT three and now GPT. Four, which is upcoming, I think, what are you currently working on? Maybe as a last question, what are your like concrete interests at this moment in this week, or this month, or this year or whatever?

Joscha Bach 1:18:17
Let's briefly talk about the transformer. And when I was working on interpreting language in the 90s, I was a student in the lab in New Zealand. And my professor thought I was bored. And so he took me out of the class and gave me a job, he told me try to figure out grammar and unknown language from medical structure just using statistics. And the unknown language that I picked was English because it was not because I didn't know it, but the computer didn't know it. So if at least I didn't let it know what it didn't give it any knowledge about the structure of English, but it was the one where I could easily compile a large corpus by pasting lots and lots of texts telephone together and feed this into the computer program to do statistics about. And so I first parse this into a vocabulary. So it would identify all the different words into this vocabulary. Each of them would be basically a symbol and an alphabet, this something like a couple 100,000 terms, because I had so many words in my text that come up with 20,000 different passwords. About half of those only appeared once because there was misspellings of something of this. So I would throw out everything that only appeared once or twice. And then you can get down to a vocabulary that is similar to the number of words that you would have in dictionary for the English language. You maybe useful are the least frequent of those. And then you look at the statistics of maybe the most important 30,000 words in English and divide In which we did that, or our editors were first was to use engrams, which means the Secretariat succession of words. And turns out, it doesn't work very well, because the statistics do not fit into the memory of a very large computer. So if you try to make the probability statistics over which words follow after every word, you can do this easily for pairs of directly adjacent words. That's, that's not a difficulty. But now to make it for triples, or quadruples of words is very hard. But in order to properly price language, in this way, you would need to be able to understand the relationship between an article and a noun, if there are five adjectives between them. And you cannot make statistics over groups of six words. So you discover all of the combinations. And do you notice, oh, only the connection between the first and the last words were the important one. Right. So I needed to now look at pairs of words that could be not adjacent but distant. And I limited my search only two sentences, so it wouldn't be manageable at all. So I would look at all combinations of pairs of words in the sentence, and then try to encode them independently and together and figure out if there was an optimal order to encode the parents offered or the dependencies of words in the sentence in this first auto model, just one word depending on other words, and the optimal structure that I discovered was a tree like structure that turned out to be the same structure as the grammatical structure of the sentence. So you could basically recover the grammatical structure of language using this type of encoding. And I thought that we could get more you can probably get to meaning, or something that is much more meaning if you're able to make more subtle statistics. But we would need to make higher order statistics, not just pairs of words, but triples of words, quadruples of words, whether they are adjacent or not. How can you make that happen. And at this point, my appointment ended because I was only there for a year. And it didn't go into this any further and also found probably not smart enough to solve that problem right now. And then I never did natural language processing ever again. And only 2017. When the attention is all you need paper came out, did I start looking at this quant context of attention a little bit but didn't pay that much attention until GPT two happened. And then I looked at GPT. Two, and I realized, oh, they solve that problem. So what they realized is, we need to make statistics over what we need to make the statistics over. And you need a principled approach of where you think is the information that you should be paying attention to. So you can efficiently learn, instead of making statistics over everything, like vision human network might be doing. If you just look at a convolutional neural network doesn't do this for the entire space. But for everything in the neighborhood of a pixel, it's going to look for all the possible relationships, the statistics are all of them. And it's very difficult to do this, we have to limit it somehow. And

Joscha Bach 1:23:08
for the transformer model, it basically checks for every layer of the representation, which parts of the previous layer should you be paying attention to, in the current context. And there is no universal rules, we have to learn it. So you have basically a neural network that learns, but the main you will network should learn or should use for learning. But it's not the same as the attention our own mind because it's not coherent, it's independent, on every individual layer, have multiple attention pets that work in parallel, to make these statistics. So the attention to the transformer is not the same thing as the attention our own mind. It's just as a way to make statistics over which what you should make statistics over. And we we don't have a model that I'm aware of that is modeling attention in the way that the human mind is doing. And so this is one of the things that I am interested in personally. And my day job is currently at Intel rocket labs, as in principle of AI researcher that is trying to figure out what comes after deep learning, and how to measure the progress of different systems. What are the dimensions of the next category of intelligence systems that we are going to build along with which we can understand and evaluate them? And things that are particularly important is what are useful representations to represent both knowledge and perception? How does the interaction between knowledge and perception work? And how can we think more productively about newer symbolic artificial intelligence and so on?

Unknown 1:24:50
Okay, great. Do we have any more questions here or otherwise? I think I'll stop the recording then.
