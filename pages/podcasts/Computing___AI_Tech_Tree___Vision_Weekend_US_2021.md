Unknown 0:00
So what you just heard is our more decentralized computing angle. And actually mark is our Chair of the intelligent Cooperation Group in which many of these seminars have been taking place. We're now moving on to the more computing focused session, which has very much the same layering of the last session before. But now we're also adding different things like D web, AI, compute into the mix. Okay, so perhaps we will start with who's ever slides, I'm picking out first to tell us a little bit about what it is that you are working in, and how it is that we're going on to the longer term future. And I'm picking on Peter Norvig, who has done a fantastic recently GORUCK event with us in person who was there the reason that garlic in person event, that was one of the first ones, really post pandemic, and it was really, really lovely to see all of you in person. Thank you again, for joining there, Peter. Peter, what is it that you're working on? How does it relate to the very long term? And what is it that people can help solve here?

Unknown 1:07
Okay, a decade ago, Sebastian Thrun and I did the first online class to reach 100,000 students. And we thought the time was right to say we can change the way learning is done by analyzing the data of how students interact with the system. So we started that, and we were very naive. One of the things we thought going in is that our job was to convey information, we quickly realized that it was more important to convey motivation. And that was harder to quantify. And we started looking at the data and we didn't get as far as we thought we could. And so I kind of put that away for for a while and worked on other things. So why was it? Why was it hard? And I think the reason is, because we don't have the ability to stimulate the learners mind. And we look at other areas of AI, which we've seen great progress in recent years. Areas like playing Go, which was thought was going to be decades before we could solve it completely. And we did that. One of the reasons we did it is because we have a perfect simulation of go, the game is literally black and white. So we know exactly what the result is of every move. And you can experiment and run billions of games in simulation. Things like self driving cars, we're doing pretty well. And there we can simulate to high degree of fidelity, the physics of how a car moves. But there's still some things we can't get quite right. But the learners brain, we just have no idea of how to go from simulation to real. And and that's what stopped us. That's the idea of human psychology. It's just too difficult to crack. Now I'm taking another crack at it. And I've put a.edu At the end of my name spending some time at Stanford. And I think the time is right to revisit this question for a couple of reasons. One is there's just an ordinate order of magnitude more data available now. So more of these online systems have come up different companies and organizations have a lot of experience with a lot of students. And in the last two years, everyone has gotten used to this idea of you're going to interact online rather than in person in the classroom. So there's more data available. And there's also better tools available available. Things like these large language models like GPT, three, that are tantalizingly close to being able to carry on a conversation, and maybe act like a tutor or conversant, and they still do some things, surprisingly wrong. So we got a ways to go. But it seems like this is the right time to figure out how it works. That's what I'm doing now.

Unknown 4:00
Lovely. Thank you so much. Okay, and you also have a challenge. What do you want other people to solve here?

Unknown 4:07
I guess to me, you know, I started out my graduate school career in natural language processing. So it's really understanding how these language models work.

Unknown 4:18
Lovely. Okay, so we have a challenge here for you guys to solve. Okay, next one up, we have Rosie, Rosie, what eight when you work on what is the long term potential trajectory? And what is a challenge that you would like this community to solve?

Unknown 4:33
Thank you so much. And actually, that was a perfect segue. So thank you, Peter. I want to talk about the concept of truthful AI. So can I just check how many people have heard of GPT? Three? Okay, pretty much everyone. That's what I would have thought how many people have had a chance to actually like interact with it, use it, play with it. Okay. Oh, wow. All right. That's pretty good as well. Just to bring everyone up to the same page. GPD three has a large language model. It can do all sorts of things from summarization. churn and classification through two generation of text. So you give it some kind of prompt a sentence, and it will continue writing in the style of that sentence. So as Peter said, you know, you can have conversations with it, it can write articles, that kind of thing. And I am on the product safety team at open AI. So my job is to think a lot about what kind of policies we need in order to make sure that these models are being used safely and responsibly. And how the API what what kind of products people can build with the API. And one thing that really breaks my heart is how many amazing socially beneficial use cases that could be for these models in high stakes domains like healthcare or politics, but because we just aren't confident in the model being able to produce accurate outputs, we are generally very hesitant to approve products in those fields. And so I'm really excited about the idea of truthful AI. So trying to get these models not to just sort of make up nonsense, which sounds very plausible, and it seems human readable, but have things that are actually based in fact and reality. And so a few things that I think can be useful for that include truthfulness, datasets, and fine tuning. So can we develop datasets that teach models to give us confidence intervals or express uncertainty, when they're not sure of things? Can we get them to just generally be more reliable and accurate and the information they are producing? Prompt engineering is a really interesting emerging field as well. So when I first started work with duty three, I assumed that there would be some kind of parameter I wouldn't need to set in order to get it to produce content in a certain style or a certain in a certain way. And it turns out, you can just literally write in your prompts like say, I don't know if you don't know the answer to this question, or like to be a polite chat bot or something. And that is enough to sort of nudge it in that direction, in that direction. So I'm really excited about advances in prompt engineering. Another aspect here is regulatory technology. I'm Gillian Hadfield, who I think is a friend of foresight Institute has done a lot of really interesting work in this area. And I think if we're going to be trying to ensure these models are producing accurate output, we're going to need ways to audit that to benchmark it all of those things. I'm very excited about lots of different capabilities, this will unlock from accurate comprehension and summarization, getting it to synthesize and explain complicated concepts to us, and trying to prevent malicious use and be robust against intentional attempts to produce disinformation.

Joscha Bach 7:32
Love, yes. Okay. So

Unknown 7:36
and then the last thing I will say is, I think this is all ultimately aiming to try to produce things that we can interact with that will actually enhance our decision making capabilities rather than diminish it. And so that's what I'm really excited about. And that's, you know, a very lofty goal as a more concrete challenge that I will put forward. For you guys today. Even if we can't immediately jump to AI that never tells a lie and is always accurate. I think one thing that would really help in the meantime, is if we can at least just get it to cite sources. So if I ask it a medical question or a political question, and it gives me a response, it can kind of send me a link or at least like tell me where it got that information from and I can use my own judgment then to decide whether to trust it.

Unknown 8:21
Wow, that would be a very nice first start. Okay, thanks a lot. So for those of you who don't know, Jane Hepburn, who Rosie just mentioned, Jillian's seminars. Emery is here, which was, I think, a really fantastic one. And we have Peter Norvig presentation also here. So if you want to read up more on what has just been discussed, please go for it. It's all on our seminar summaries. Thank you so much, Rosie, super excited to have you on as a fellow next year couldn't be more pleased. Very, very, very excited. Okay, next one. Are we moving into diva bland booster, will you tell us a little bit about what it is that you're working on and how people here in this room can help.

Unknown 9:00
We need some help at work here with the Internet Archive. And welcome back. There's about 15 petabytes of the 70 petabytes. That's the primary copy of the Internet Archive blinking away, which is kind of fun, built by a lot of the people that are represented in the little statues around the edges, but we're running to some troubles in the world wide web. And it's based on a lot of centralization that's been going on, not only I would say just big tech, but also big publishers. The people that control the book industry, the academic publishing industry is really consolidating. And they're leveraging this to make it so there's never digital ownership. So you can't actually take things and own them independently of a license agreement, every light every reading event. They want to be a licensed event you have to have a license to read, then that's not bad. So this is sort of one of the trends that's going on now with the web. It makes it very difficult to be the Internet Archive as a library are a to go and make copies of these perpetually available in new and different ways such as sort of the open AI kinds of data mining fundamentals. So as a Hail Mary, we, we started talking about the decentralized web, the idea of having a web that operates a little bit more like oldstyle, publishing the publishing goes and puts things out, it lives in multiple places, so that if any of those particular places go away, you don't lose the work. That's not the how the web currently works. Can we go and make a peer to peer back end for the World Wide Web and solve some of these problems so that people can make money by going in publishing on the net without being plugged into a platform? That does kind of the idea of this? So can we have robust, private Web? How do we get there, one, we need some of the tech and browser technologies needs to be able to support this upgrade. So that's going to be an interesting issue. But we also need government support, like we did for the first, you know, worldwide web, also the ARPANET and the like. And we need people that think differently about how they're going to compete, rather than join into a big publishing conglomerate, and was the only way that your words are going to get out there. So we need entrepreneurs to be able to make all of this come about. So I think if we're going to have these sort of third party participants, whether it's or open the eyes of the internet archives, to be able to go and make an ecosystem work in new and different ways. We're going to have to go and have a decentralized web technology. So what's the challenge here? Which Allison, I think correctly pointed to, and I would say it's the ethics because when you when you have one of these new technologies, things can go really badly wrong if it steered by the wrong, folks. I think Tim Berners, Lee was an amazing man to go and basically sit out the gold rush, he didn't make billions of dollars off of the World Wide Web, he went to be basically a statesman, a civil servant of this evolving world wide web, who are going to be the next generation Aaron Schwartz is sorry, to be the statesman of this next generation to try to keep us kind of onboard. So yeah, there's going to be you know, this is a group of has a lot of libertarian. So you know, motivations of greed are sort of calculated in fine. But let's keep that at a small such that the structure works, that we end up with a game with many winners that we have an ethics and a structure that makes it so that there's not higher and higher barriers to entry, as this new technology weaves through. And we've sort of tamp down some of the the bad impulses that will be put in place that will basically fuel enemies of a decentralized web technology. So if you have ideas in this kind of area, we're trying to figure this out, let's build a better web.

Unknown 12:59
Right? His slide will also be added over there and someone's already taking photos. I'm loving it. Okay, lovely. And Mark, you have no slide. But nevertheless, I'm sure if I can hurdle if you prompted you, you will be just as well. So what is something you work on? What's an exciting and go for your field? And what do you need help with? What what what what would you like other people here to solve for you as you moving about?

Unknown 13:25
It's interesting, the I actually have sort of rehearsed in my head a different answer to a different

Unknown 13:30
show to with your different rehearsal, because I want to know,

Unknown 13:35
so being on this panel, I'm going to be speaking in an AI centric way, which is outside of my main area of expertise. But other people are doing much better job than I would hope to do, and actually building outward to create make computers intelligent. I'm going to speak about the risks at many levels of abstraction, and, and our approaches towards building a world in which we coexist cooperatively with AI. Get past the risks and benefit from the wonderful benefits that AI has to improve our lives. So the the first thing is basic computer security below AI this is what I'm part of what I'm working on. And it's surprising to me that so much of the discussion of AI risks starts at the API level of abstraction of assuming that the AI is actually working according to its code. And the issues are, what it's trying to do or how it might be misled or fork that fall signals to miss learn. But that AI code is running on some computational platform. If that computational platform is insecure, you can reach up through it and corrupt the AI with using AI technology to corrupt it, you can just use the capacity and has to lead it to different goals. At this point, the finally well known example, is when I was at Google, and I knew that Google was working on self driving cars, I assumed for a long time that Oh, my God, these are guided missiles, were putting on the street that have all the intelligence needed to recognize crowds and plow into them at high speed. Surely, the smart people at Google would be running these on some underlying higher highly secure computing platform. And that's what I thought until I asked, and they're running it on the same, you know, Linux style basis that all of our other insecure double systems are running. So that's, that's the first level of abstraction of threat. Another level? So let's say we solve that one. That one's necessary, but it's way far from sufficient. Next level of interesting just to

Unknown 16:03
put up the SEO for slide as well. Yes. You always

Unknown 16:07
yes. Yeah. I have no commercial affiliation with them. So I hope so. I just did fan. But I will say, I think this is the single most important software project in the world. They are the only ones that have built a really practical high performance operating system that can be used in production without penalty, other than legacy compatibility, and has a formal end to end proof of correctness of the implementation, not of a model of the implementation. And this This project is certainly is surviving on a shoestring while governments spend many billions of dollars allegedly addressing the computer security problem. Okay, next level of obstruction up is epistemic threats is the a lot of the the, you know, shouting about fake news, or algorithms by big tech or, or, or recommendation systems, leading to, you know, optimized for leading the clicks or whatever, whatever. The problem is, that you've got these big AI systems, targeting the behavior of individual defenseless humans. And what I would like to see and what I think is a practical thing to work on is epistemic assistance of a where the human combined with his epistemic assistant, is a much more defensive unit for engaging with a world that might be using AI to try to mislead them. And then finally, projecting forward to a civilization in which most of the computation, that that that's most of the copy most of the cognition is non human cognition is of cognitive architectures that we find incomprehensible. What does it mean to have a framework of rules a law like framework for interacting with them cooperatively, and in a way that we can both benefit each other. And I think the basic neutral framework of volunteerism is a sufficiently universal concept for enabling various parties to pursue their goals without having to model their utility taking some utilitarian framework that requires us to have some notion of what their utility is the simple universal notion of, of revealed preference is an adequate approximation of utility, such that they can be getting what they want help while helping us get what we want.

Unknown 18:59
Lovely, I just put up the podcast in which you talk about civilization is irrelevant super intelligence actually depend on that rooster and hosted us for here at intelligences and ag eyes, and corporations. And I am putting out for those of you who are interested in finding out more. And Mark is leading our intelligent Cooperation Group, which is a group that has seminar summaries and seminars on these types of topics. And we are currently co authoring a book on intelligent voluntary cooperation. If you want to know more about this, then let us know. But in one of our first sessions on this topic, Mark and Robin actually talked about this concept in a really lovely way. And I think this is still one of the I think more interesting slide presentations to actually explain the concept of intelligent voluntary cooperation. So if you're interested in this, and then please take a look at the seminar summaries in this group. Okay, cool. Last but not least, we have Yoshua so Yasha, what's going on for you? What are you working on? What are our long term consequences and challenges along By the way,

Joscha Bach 20:01
I have a slide too, if you find it, it's not that important. But I'm your Java. I am a Principal Research Scientist at Intel Labs, I am part of 100 people group that is working under the headline, emergent AI. And the topic that interests me personally is understanding the vectors of intelligence, what we currently see is, I think, the second phase of AI or it's one of the many surfaces on which you can project the development, the first phase of AI, we're now task based systems that where you construct it systems and algorithms with respect to a single problem that had to be solved. And now we have flexible AI, where we are constructing algorithms that learn how to solve a problem. And the same algorithm can be deployed across a wide range of problems. And the next phase of AI, I think, will be systems that are somewhat universal, that are able to tackle an extremely wide range of problems and learn how to learn in the soul meta learning is going to be one of the topics. And when we think about how to assess such systems, it turns out that there is not a single benchmark that you can deploy, but there will be many different tasks and domains in which we will have to evaluate the systems along many dimensions. And some of these dimensions include things like the ability to deal with knowledge and the ability to represent the universe, the ability to interact in real time with the universe that you're coupled with. And to make an integrated model of that universe, the ability to act on your own autonomous levers developed and understand what you should be acting on the ability to collaborate deeply, which includes what Peter mentioned, the ability to deeply model your interaction partners, their goals, and the shared goals that you should be having to the shared purposes. And this is something that eventually will enable ethical AI, I think so you cannot have ethics without shared purposes above the level of the ego. And this means that you have to understand a larger aesthetic of the world, you have to have an idea of what the world is going to develop itself into. And systems that are capable of doing this need to be sentient. And sentience is not the same thing as consciousness, I think that consciousness is our solution to get to sentience. I call it sentience, the ability of a system to understand its own nature and its place in the universe, which means it has to build an integrated model of the universe that it's part of, and the creation of a coherent, integrated model of the entire universe, this big function that is able to track reality in real time that is large and rich enough to relate everything that we understand that we are considering to be some kind of relationship. This is the problem of meaning. And it's the biggest unsolved problem in AI how to make this big, coherent model of the universe. What is coherence? I think that coherence is the global minimization of constraint violations in a system that represents the world in such a way that you minimize uncertainty, based on the value of that uncertainty, it's expensive to reduce uncertainty. So you have to have valence, you have to have preferences about what you think is important. And this means that you have a system that is motivated by something, and ultimately, what every system that is alive, that is part of the universe that is creating complexity has to be motivated by is depending on its place that it has in this bigger scheme of things. And the systems of the future will have to understand their place. And they will also have to help us to understand our own place in the bigger scheme of things. So I think that we are, in the long term, going to look if everything pans out in the best possible way at systems that help us to collaborate with life on earth, and to collaborate between people and machines. That's the best possible outcome. And there are many, many risks on that way. But I think what's much more near term is that we will be able to automate many of the processes in which people are making sense of reality. And this is an old dream of philosophy to be able to mathematize the way in which we think and perceive and make sense. And I think this is going to trigger a scientific revolution, a second scientific revolution, sometimes wonder if the eyes of the future will love to get drunk. So they're only able to integrate the universe over something like 12 layers. And they will be as confused as human physicists when they look at the universe.

Unknown 24:47
Okay. Yeah, leaving it at a humorous note. And are there any comments questions that people panelists want to make to each other? Any problem that you think you can already solve here? From someone else or want to give a nod to someone else, or like just a universal nod across the pedal. All right, any questions from the audience? Okay, we have one who? I think you haven't asked a question yet. So please, let's go with you. And maybe say your name as well. I'm very sorry, I don't know your name. Yes. Yep.

Unknown 25:23
Hi, thank you. My name is Molly, nice to meet everybody. My question is for Peter. I also work in the education tech space in the, in the past, and I'm really curious about what things you've learned about how to motivate large communities of learners. And kind of the work you're doing in that space, trying to apply language models to the motivation problem, because that's really interesting.

Unknown 25:43
I guess a couple of things. One is trying to be at the right level of where they are now, and trying to figure that out is important. Another is meeting their goals. So, you know, in the early days of these online classes, there's all this criticism, oh, you know, only a few percent people are completing the classes. You know, if only 2% of high school students were completing, that would be a big problem. And so one of the things we did ask them upfront, what are you trying to accomplish, and we found most of these people who are dropping out, that's exactly what they wanted to do. They didn't want to take the class, they just want it to come in, get a little bit of a feel for it, and then move on to something else. So I think making sure you know, what they're trying to achieve and help them achieve that. I think it's important. And then community is important of having somebody else to motivate you. You know, because it's all too easy to say, oh, you know, I don't feel like it today. I'm not going to work on this. But if you say, Oh, well, there's a study group, with my four buddies, I can't let them down. I'm going to show up. And I'm going to do that. And so trying to find the right ways to do that. And, and one of the things we did sort of accidentally, when we were launching the class, we said we were going to have a discussion forum. But the code for that it's not ready. So we'll cancel it. And that was great. Because what happened was students invented their own, right. So one group of students would say, well, we're going to make a Reddit forum. And another one said, we're going to do something on four, we're going to do some thinking someplace else. And that way, they felt like they owned it, rather than like it was imposed on them. And that actually worked out much better. So finding ways to give them ownership, I think is important. And, and we let the programmers off the hook, who didn't get it finished.

Unknown 27:36
All right, lovely. Okay, everyone, we are now moving on to our lunch break. I do want to say thank you so much for this fantastic panel. I feel like we got like individual dibs that went really deep. And I really look forward for how we how we constructing that technology tree from the individual nodes. Throughout the afternoon, your node is over there. So in the afternoon, that's where you guys will be gathering. So if you working in decentralized computing and AI, then this is the place where you'll be gathering. And I do also want to just let you know the first two panels, the newertech panel, and the space panel where the panels were were just in the next year kicking off the individual technical groups. One chair by Korean avid was the chair and the other one by Rand Hakuna was also here on stage. This one here already exists. It is Mark Miller, the chair as I mentioned, and you can find all of the different seminars on these. Here we have the 2021 program seminar summaries of each of the individual seminars that we had in this group. If you want to know more about this group, talk to Mark, there's an application form you can apply to join it. And we do take application on a rolling basis. All right, everyone, I don't want to stand between you and the food. And I do want to say if you have a grabbed your food, there is the NFT gallery happening and it is down those stairs. And then right at the front, down basically below this room. If you go down the stairs around the corner, there's a gallery happening. And for now, enjoy your lunch. We'll be meeting here again at 130 for the biotech and rejuvenation part of the day. So meet you here at 130 again and enjoy your lunch. It is down out there where you guys were mingling and getting coffee. Thank you all for joining. Thanks
