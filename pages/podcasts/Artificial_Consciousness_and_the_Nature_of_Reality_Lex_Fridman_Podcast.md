Lex Fridman 0:00
The following is a conversation with the OSHA Bock, VP of research at the AI foundation. With a history of research positions at MIT and Harvard. Yoshida is one of the most unique and brilliant people in the artificial intelligence community, exploring the workings of the human mind, intelligence, consciousness, life on earth, and the possibly simulated fabric of our universe. I could see myself talking to your show many times in the future. Quick summary of the ads to sponsors ExpressVPN, and Cash App, please consider supporting the podcast by signing up at expressvpn.com/flex pod and downloading Cash App and using code Lex podcast. This is the artificial intelligence podcast. If you enjoy it, subscribe on YouTube, review five stars on Apple podcast supported on Patreon, or simply connect with me on Twitter at Lex Friedman. Since this comes up more often than I ever would have imagined, I challenge you to try to figure out how to spell my last name without using the letter E. And then it'll probably be the correct way. As usual, I'll do a few minutes of ads now. And never any ads in the middle that can break the flow of the conversation. This show is sponsored by ExpressVPN. Get it at expressvpn.com/flex pod to support this podcast. And to get an extra three months free on a one year package. I've been using ExpressVPN for many years. I love it. I think ExpressVPN is the best VPN out there. They told me to say it. But I think it actually happens to be true. It doesn't log your data. It's crazy fast. And it's easy to use literally just one big power on button. Again, for obvious reasons, it's really important that they don't log your data. It works on Linux and everywhere else to shout out to my favorite flavor of Linux, Ubuntu monta 2004. Once again, get it at expressvpn.com/flex pod to support this podcast and to get an extra three months free, and a one year package. This show is presented by cash app, the number one finance app in the App Store, when you get it use code Lex podcast, Cash App lets you send money to friends buy bitcoin, and invest in the stock market with as little as $1. Since cash app does fractional share trading, let me mention that the order execution algorithm that works behind the scenes to create the abstraction of the fractional orders is an algorithmic Marvel. So big props to the Cash App engineers for taking a step up to the next layer of abstraction of the stock market, making trading more accessible for new investors and diversification much easier. So again, if you get cash out from the App Store, Google Play, and use the code Lex podcast, you get $10 in cash, Apple also donate $10 to first, an organization that is helping advance robotics and STEM education for young people around the world. And now, here's my conversation with the OSHA block. As you've said, you grew up in a forest in East Germany, just as we were talking about off Mike to parents who are artists. And now I think, at least to me become one of the most unique thinkers in the AI world. So can we try to reverse engineer your mind a little bit? What were the key philosopher scientist ideas, maybe even movies are just realizations that impact on you when you're growing up that kind of led to the trajectory, or were the key sort of crossroads in the trajectory of your intellectual development.

Joscha Bach 3:49
My father came from a long tradition of architects distant branch of the bath family. And so basically, he was technically a nerd. And notes need to interface in society with non standard ways. Sometimes I define a nerd as somebody who thinks that the purpose of communication is to submit your ideas to peer review. And normal people understand that the primary purpose of communication is to negotiate alignment. And these purposes tend to conflict which means that nerds have to learn how to interact with society at large. Who is the

Lex Fridman 4:27
reviewer in the nerds view of communication,

Joscha Bach 4:32
everybody who you consider to be a peer? So whatever hapless individual is around where you will try to make him or her the gift of information.

Lex Fridman 4:43
Okay, so you're not by the way, my research will mal informed me so your architecture artist

Joscha Bach 4:53
study architecture, but basically my grandfather made the wrong decision. He married an aristocrat and I was drawn into the into the war. And he came back after 15 years. So basically my father was not parented by entered by by somebody who tried to tell him what to do, and expected him to do what he was told. And he was unable to is unable to do things if he's not intrinsically motivated. So in some sense, my grandmother broke her son. And her son responded by when he became an architect to become an artist. So he built Hoonah advisor architecture, he built houses without right angles, he'd build lots of things that didn't work in the more brutalist traditions of Eastern Germany. And so he bought an old watermill and moved out to the countryside, and did only what he wanted to do, which was art. Eastern Germany was perfect for him, because you had complete Material Safety put was heavily subsidized health care was free, you didn't have to worry about rent or pensions or anything. So a socialized communist side. Yes. And the other thing is, it was almost impossible not to be in political disagreement with your government, which is very productive for artists. So everything that you do is intrinsically meaningful, because it will always touch on the deeper currents of society of culture and being conflict visit and tension visit. And you will always have to define yourself with respect to this.

Lex Fridman 6:18
So what impacted your father is this, outside the box, outside of the box thinker, against the government against the world artists have, he was actually

Joscha Bach 6:27
not a thinker, he was somebody who only cuts half of it to the degree that he needed to make himself functional. So in some sense, he's it was also late 1960s. And he was in some sense a hippie. So he became a one person caught, he lived out there in his kingdom, he built big sculpture gardens and started many avenues of art and so on, and convinced a woman to live with them. She was also an architect, and she adored him and decided to share her life with them. And I basically grew up in a big cave full of books, I'm almost farewell. And I was bored out there. It was very, very beautiful, very quiet, and quite lonely. So I started to read. And by the time I came to school, I read everything until fourth grade, and then some. And there was not a real way for me to relate to the outside world. And I couldn't quite put my finger on why. And today, I know it was because I was a nerd, obviously. And it was the only nerd around so there was no other kids like me. And there was nobody interested in physics or computing or mathematics and so on. And this village school that I went to was basically a nice school. Kids were nice to me, I was not beaten up. But it also didn't make many friends or build deep relationships that only happened in starting from ninth grade when I went to school for mathematics and physics. You remember any key books, basically read everything. So I went to the library, and I worked my way through the children's and young adult sections, and then I read a lot of science fiction. For instance, Stanislav LEM, basically, the great author of cybernetics has influenced me back then I didn't see him as a big influence, because everything that he wrote seem to be so natural to me. It's only later that I contrasted it with what other people wrote. Another thing that was very influential on me were the classical philosophers, and also the tutor of Romanticism. So German poetry and art draws to hilltop and hyena, and up to Hesser, and so on, as

Lex Fridman 8:30
love has. So I which point is the classical philosophers? And at this point, when the 21st century, what's what's the latest classical philosopher? Does this stretch through? Even as far as Nietzsche? Or is this Are we talking about Plato and Aristotle? And

Joscha Bach 8:45
I think that Nietzsche is the classical equivalent opposite poster. Read and Yeah, but he's not so much tolling others, he's trolling himself because he was at odds. First of all, largely, his romantic relationships didn't work out, he got angry, and he basically became a nihilist. And

Lex Fridman 9:06
the reason is that a beautiful way to be as an intellectual is to cause him be trolling yourself, to be in that conflict and that

Joscha Bach 9:15
lack of self awareness, at some point, you have to understand the comedy of your own situation, if you take yourself seriously, and you are not functional. It ends in tragedy, as it did for Nietzsche. I

Lex Fridman 9:26
think you think he took himself too seriously in that in that tension,

Joscha Bach 9:29
and it's the same thing and hassle and so on. This step involves syndrome is classic adolescence, where you basically feel misunderstood by the world and you don't understand that all the misunderstandings are the result of your own lack of self awareness, because you think that you are a prototypical human, and the others around us would behave the same way as you expect them based on your innate instincts and it doesn't work out and you become a transcendentalist to deal with that. And so it's very, very understandable and have great sympathies for this to the degree that I can have some perceived for my own intellectual history. But

Lex Fridman 10:03
it was an intellectual life well lived a Journey well traveled is one where you don't take yourself seriously

Joscha Bach 10:10
from now, I think that you are neither serious or not serious yourself because you need to become unimportant is a subject that is, if you are a philosopher belief is not a verb. You don't do this for the audience, you don't do it for yourself, you have to submit to the things that are possibly to and you have to follow wherever your inquiry leads, but it's not about you, it has nothing to do with you.

Lex Fridman 10:36
So do you think then, people like iron Rand believed sort of an idea of there's objective truth? So what's your sense in the philosophical? If you remove yourself and subjective from the picture, you think it's possible to actually discover ideas that are true? Are we just in a measure of relative concepts that are neither true nor false? It's just a giant mess,

Joscha Bach 10:57
you cannot define objective truth without understanding the nature of truth in the first place. So what does the brain mean by saying that discover something as truth, so for instance, a model can be predictive or not predictive, then there can be a sense in which a mathematical statement can be true, because it's defined as true under certain conditions. So it's basically a particular state that a variable can have an assembled game. And then you can have a correspondence between systems and talk about truth, which is, again, a type of model correspondence. And there also seems to be a particular kind of ground truth. So for instance, you're confronted with the enormity of something existing at all right? It's stunning when you realize something exists, rather than nothing. And this seems to be true, right? There's an absolute truth in the fact that something seems to be happening.

Lex Fridman 11:49
Yeah, that's, that, to me, is a showstopper, I could just think about that idea, and be amazed by that idea for the rest of my life and not going any farther. Because I don't even know the answer to that. Why does anything exist at all?

Joscha Bach 12:01
The easiest answer is existence is the default. Right? So this is the lowest number of bits that you would need to encode this was the answer, who probably the simplest answer sentences is that existence is

Lex Fridman 12:10
the default. What about non existence? I mean, that seems

Joscha Bach 12:14
non existence might not be a meaningful notion in the sense. So in some sense, if everything that can exist exists, for something to exist, it probably needs to be implementable. The only thing that can be implemented is finite automata. So maybe the whole of existence is a superposition of all finite automata. And we're in some region of the fractal that has the properties that it can contain us.

Lex Fridman 12:35
What does it mean to be a superposition of fanedit? Spanish superposition volpato, like all possible rules,

Joscha Bach 12:43
imagine that every automaton is basically an operator that acts on some substrate. And as a result, you get emergent patterns, most of substrate has no idea to know so it's based on substrate, some something that can store information, something that can

Lex Fridman 12:59
store information is something that can hold state still doesn't make sense to me the why that exists at all, I could just sit there with a with a beer or, or a vodka and just enjoy the fact monitoring the why

Joscha Bach 13:11
may not have a way, this might be the wrong the reason I ask you into this. So there could be no relation in the y direction. Without asking for a purpose or for cause. It doesn't mean that everything has to have a purpose or cause. Right.

Lex Fridman 13:26
So we mentioned some philosophers in that early just taking a brief step back into into that. So

Joscha Bach 13:31
we asked ourselves, when did classical philosophy and I think what Germany largely ended with the first revolution, that's basically even which was that this was when we entered the monarchy, and started a democracy. And at this point, we basically came up with a new form of government that didn't have a good sense of the this new organism that society wanted to be an innovative decapitated the universities. So the universities went on to modernism like a headless chicken. At the same time, democracy failed in Germany, and we got fascism as a result. And it burned down things in a similar way, as Stalinism burned down intellectual traditions in Russia. And Germany, both Germany's have not recovered from this eastern Germany, this fog or dialectic, materialism, and Western Germany didn't get much more edgy than harbor mass. So in some sense, both countries lost their intellectual traditions and killing off and driving out the Jews didn't help.

Lex Fridman 14:28
Yeah, so that was the end. That was the end of really rigorous What will you say is classical classical philosophy is also this

Joscha Bach 14:34
thing that in some sense, the low hanging foods in philosophy were mostly wrapped. And the last big things that we discovered was the constructivist turn in mathematics. So to understand that the parts of mathematics that work our computation, there was very significant discovery in the first half of the 20th century, and it hasn't fully permeated philosophy and Um, even physics yet physicists checked out the code libraries for mathematics. Before constructivism became universal.

Lex Fridman 15:07
What constructivism? What? Are you referring to girdles and completeness theorem that kind of those kinds of

Joscha Bach 15:12
basically, girdle himself I think didn't get it yet Hilbert could get it to Birdsall that for instance, a country's set theoretic experiments and mathematics lead to contradictions. And he noticed that with the current semantics, we cannot build a computer and mathematics that runs mathematics without crashing. And Google prove could prove this. And so what girdle could show is using classical mathematical semantics, you run into contradictions. And because girdle strongly believed in the semantics, and more than in what he could observe, and so on, he was shocked to basically shock as well to the core because in some sense, he felt that the world has to be implemented in classical mathematics. And for curing, it wasn't quite so bad. I think that your input see that the solution is to understand the question, mathematics was computation all along, which means you, for instance, pi in classical mathematics is value. It's also a function, but it's the same thing in computation. A function is only a value when you can compute it. And if you cannot compute the last digit of pi, you only have a function, you can plug this function into your local sun, let it run until the sun burns out. This is it this is the last digit of pi, you will know. But it also means there can be no process in the physical universe or an any physically realized computer. That depends on having known the last digit of pi. Yes, which means there are parts of physics that are defined in such a way that cannot strictly be true, because assuming that this could be true leads into contradictions. So I

Lex Fridman 16:39
think putting computation at the center of the world view is actually the right way to think about it. Yes.

Joscha Bach 16:46
And Vidkun Stein could see it, and Vidkun Stein basically preempted the logic of this program of AI that Minsky started later, 30 years later, Turing was actually a pupil of Vidkun Stein.

Lex Fridman 16:57
And I didn't know there's any connection between

Joscha Bach 17:00
Vidkun Stein even canceled some classes when Turing was not present, because he thought it was not worth spending the time. If you read the Tractatus, it's very beautiful book by capacity, one thought on 75 pages, it's very non typical for philosophy because it doesn't have arguments in it. And it doesn't have references in it, it's just one thought that there's not intending to convince anybody uses says, it's mostly for people that had the same insight as me just spell it out. And this insight is, there is a way in which mathematics and philosophy ought to meet. Mathematics tries to understand the domain of all languages by starting with those that are so formally visible that you can prove all the properties of the statements that you make. But the price that you pay is that your language is very, very simple. So it's very hard to say something meaningful in mathematics. Yes. And it looks complicated to people. But it's far less complicated. And what our brain is casually doing all the time, it makes sense of reality. And philosophy is coming from the top. So it's mostly starting from natural languages with vaguely defined concepts. And the hope is that mathematics and philosophy can meet at some point. And Vidkun, Stein was trying to make them meet. And he already understood that, for instance, you could express everything was the non calculus, that you could reduce the entire logic to NAND gates as we do in all modern computers. So in some sense, you already understood to one universality before Turing spelled it out. I think, when he wrote the Tractatus, he didn't understand yet that the idea was so important and significant. And I suspect then, when Turing wrote it out, nobody cared that much you were doing was not that famous when he lived, it was mostly his work in decrypting, are the German courts that made him famous, or gave him some notoriety, but this same status that he has to computer science right now in the eye? Something that I think he got acquired later?

Lex Fridman 18:47
It's kind of interesting, do you think of computation and computer science? And you kind of represent that to me is maybe that's the modern day, you in a sense, are the new philosopher by sort of the computer scientist who dares to ask the bigger questions that philosophy originally started? Is the new philosophy is the new philosopher,

Joscha Bach 19:07
certainly not me, I think I'm mostly it's still this child that grows up in a very beautiful valley and looks at the world from the outside and tries to understand what's going on. And my teachers tell me things, they largely don't make sense, right. So I have to make my own models, I have to discover the foundations of what the others are saying, I have to try to fix them to be charitable, I try to understand what they must have thought originally, or what the teachers or the teachers, teachers must have thought until everything got lost in translation, and how to make sense of the reality that we are in. And whenever I have an original idea, I'm usually late to the party by say 400 years and the only thing that's good is that the parties get smaller and smaller. The older I get, and the more I explore

Lex Fridman 19:47
the part of the parties get smaller and more exclusive and more exclusive. So it seems like one of the key qualities of your upbringing was that you're not tethered whether it's because your parents up or in general, maybe your something within your, within your mind, some genetic material, that we're not tethered to the ideas of the general populace, which is actually a unique property. We're kind of through, you know, the education system and whatever from that education system just existing in this world forces are certain sets of ideas that you can you disentangle that? Why were you? Why are you not so tethered? Even in your work today, you seem to not care about perhaps a best paper in Europe's right being tethered to particular things that current today, in this year, people seem to value as a thing you put on your CV and resume, you're a little bit more outside of that world outside of the world of ideas that people are especially focusing on the benchmarks of today, the things what's Can you disentangle that because I think that's inspiring. And if there were more people like that, we might be able to solve some of the bigger problems that sort of AI, dreams to solve.

Joscha Bach 21:05
And that's a big danger in this because in a way you are expected to marry into an intellectual tradition, and visitors traditional into a particular school. If everybody comes up with their own paradigms, the whole thing is not commutative as the enterprise, right. So in some sense, you need a healthy balance, you need private dogmatic thinkers. And you need people that work within given paradigms. Basically, scientists today define themselves largely by methods. And it's almost a disease that we think is a scientist, somebody who was convinced by the guidance counselor that they should join a particular discipline, and then they find a good mentor to learn the right methods. And then they are lucky enough and privileged enough to join the right team. And then they will, their name will show up on influential papers. But we also see that there are diminishing returns with this approach. And when our field computer science and AI started, most of the people that joined this field had interesting opinions. And today's thinkers and AI either don't have interesting opinions at all, or these opinions are inconsequential for what they're actually doing. Because what they're doing is they apply the state of the art methods with a small epsilon. And this is often a good idea. If if you think that this is the best way to make progress. And for me, it's first of all, very boring. If somebody else can do it, why should I do it? Right? If the current methods of machine learning lead to strong AI, why should I be doing it right? I will just wait until they're done. And wait until they do this on the beach, or read interesting books or write some and have fun. But if you don't think that we are currently doing the right thing, if you are missing some perspectives, then it's required to think outside of the box. It's also required to understand the boxes. But it's necessary to understand what worked and what didn't work and for what reasons. So you have to be willing to ask new questions and design new methods whenever you want to answer them. And you have to be willing to dismiss the existing methods, if you think that they're not going to yield the right answers. It's very bad career advice to do that.

Lex Fridman 23:13
So maybe, to briefly stay for one more time. In the early days, when would you say for you was the dream? Before we dive into the discussions that we just almost started? What was the dream to understand, or maybe to create human level intelligence born for you?

Joscha Bach 23:35
I think that you can see AI largely today as advanced information processing, if you would change the acronym of AI into that most people in the field would be happy, it wouldn't change anything, what they're doing. We're automating statistics, and many of the statistical models are more advanced than what statisticians had in the past. And it's pretty good work. It's very productive. And the the other aspect of AI is is philosophical project. And this philosophical project is very risky. And very few people work on it. And it's not clear if it succeeds.

Lex Fridman 24:10
So first of all, let's this is you keep throwing sort of hot, really interesting ideas, and I have to pick which ones would go with, but sort of, first of all, you use the term information processing, just information processing is if it's, it's the mere, it's the muck of existence, as if it's the epitome of exotic that that the entirety of the universe may be information processing, that consciousness and intelligence might be information, so that maybe you can comment on if that's if the advanced information processing is, is a limiting kind of realm of ideas. And then the other one is What do you mean by the philosophical project?

Joscha Bach 24:52
So, I suspect that general intelligence is the result of trying to solve general problems. So Intelligence, I think is the ability to model. It's not necessarily goal directed rationality or something many intelligent people are bad at this. But it's the ability to be presented with a number of patterns and see a structure and those patterns and be able to predict the next set of patterns, right to make sense of things. And some problems are very general, usually Intelligence Service control. So you make these models for a particular purpose of interacting as an agent with the world and getting certain results. But it's the intelligence itself is in the sense instrumental to something but by itself, it's just the ability to make models. And some of the problems are so general that the system that makes them needs to understand what itself is and how it relates to the environment. So as a child, for instance, you notice you do certain things, despite you perceiving yourself as wanting different things. So you become aware of your own psychology, you become aware of the fact that you have complex structure in yourself, and you need to model yourself to reverse engineer yourself, to be able to predict how you will react to certain situations and how you deal with yourself in relationship to your environment. And this process in this project, if you reverse engineer yourself and your relationship to reality and the nature of a universe that can continue, if you go all the way, this is basically the project of AI, or you could say the project of AI is a very important component in it. The Turing test in a way is you ask a system, what is intelligence? If that system is able to explain what it is how it works, then you will assign it the property of being intelligent in this general sense. So the test that you're doing was administering, in a way, I don't think that he couldn't see it, but he didn't express it yet. And the original 1950 paper is that he was trying to find out whether he was generally intelligent, because in order to take this test, the wrap is, of course, you need to be able to understand what the system is saying. And we don't yet know if we can build an AI we don't yet know, if we are genuinely intelligent. Basically, you win the Turing test by building an AI.

Lex Fridman 27:01
Yes. So in a sense, hidden within the Turing test is a kind of recursive tests. Yes, it's

Joscha Bach 27:07
a test on us. Yeah, Turing test is basically a test of the conjecture where the people are intelligent enough to understand themselves.

Lex Fridman 27:16
Okay, but you also mentioned a little bit of a self awareness, and then the project of AI, do you think this kind of emergent self awareness is one of the fundamental aspects of intelligence. So as opposed to goal oriented, as you said, kind of puzzle solving, is coming to grips with the idea that you're an agent in the world. And like,

Joscha Bach 27:39
many highly intelligent people are not very self aware. Right? So self awareness and intelligence are not the same thing. And you can also be self aware if you have good priors, especially without being especially intelligent. So you don't need to be very good at solving puzzles if the system that you are already implements the solution.

Lex Fridman 27:58
But I do find intelligence. So you can you kind of mentioned children, right, is that the fundamental project of AI is to create the learning system that's able to exist in the world. So you kind of drew a difference between self awareness and intelligence. And yet you said that the self awareness seems to be important for children.

Joscha Bach 28:23
So I call this ability to make sense of the world and your own place, and so to understable, make you able to understand what you're doing in this world sentience. And I would distinguish sentience from intelligence, because sentience is the possessing certain classes of models. And intelligence is the way to get to these models if you don't already have them.

Lex Fridman 28:44
I say so. Can you can you maybe pause a bit and try to answer the question that we just said, we may not be able to answer. And it might be a recursive meta question of what is intelligence?

Joscha Bach 29:00
I think that intelligence is the ability to make models.

Lex Fridman 29:03
So models is I think it's useful as examples, very popular now, neural networks, form representations of large scale data set they they form models within datasets. When you say models, and look at today's neural networks, what are the difference of how you're thinking about what is intelligent in saying that intelligence is the process of making models?

Joscha Bach 29:31
There are two aspects to to this question. One is the representation is the representation adequate for the domain that we want to represent? And the other one is the type of the model that you arrive at adequate. So basically, are you modeling the correct domain? And I think in both of these cases, modern AI is lacking still. And I think that I'm not saying anything new. We are not criticizing the field. Most of the people that design our paradigms We are aware of that. And so one aspect that we are missing is unified learning. When we learn, we at some point discover that everything that we sense is part of the same object, which means we learn it all into one model. And we call this model the universe. So experience of the world that we are embedded on is not a secret direct via to physical reality, physical reality is if you're a quantum graph, that we can never experience or get access to, but it has this properties that it can create certain patterns that are systemic interface to the world. And we make sense of these patterns. And the relationship between the patterns that we discover is what we call the physical universe. So at some point in our development is a nervous system, we discover that everything that we relate to, in the world can be mapped to a region in the same three dimensional space. by enlarge, we now know in physics that this is not quite true. Well, there's not actually three dimensional, but the world that we are entangled with, at the level of which we are entangled with is largely a flat, three dimensional space. And so this is the model that our brain is intuitively making. And this is I think, what gave rise to this intuition of res extensa of this material world, this material domain. It's one of the mental domains, but it's just the class of all models that relate to this environment is three dimensional, the physics engine in which we are embedded

Lex Fridman 31:19
physics engine or embedded. I love that. Just slowly pause. So the quantum graph, I think you call which is the real world, which you can never get access to. There's a bunch of questions, I want to sort of disentangle that. But maybe one useful one, one of your recent talks I looked at, can you just describe the basics of can you talk about what is dualism? What is idealism? What is materialism? What is functionalism? And what connects with you most in terms of because he's just mentioned as the reality we don't have access to, okay, what does that even mean? And why don't we get access to it? And we part of that reality? Why don't we? Why can we access it.

Joscha Bach 32:03
So the particular trajectory that mostly exists in the West, is the result of our indoctrination by a cart for 2000 years called which carts mostly, and for better or worse, right, it has created or defined many of the modes of interaction that we have that have created this society. But it has also, in some sense, scarred our rationality. And the intuition that exists, if you will translate the mythology of the Catholic Church into the modern world is that the world in which you will meet interact, is something like a multiplayer role playing adventure, and the money and the objects that we have in this world. This is all not real. Or is Eastern philosophers would say it's my eyes, just stuff that is it appears to be meaningful. And this embedding in this meaning, if you believe in it, is samsara. This, it's basically the identification with the needs of the mundane, secular, everyday existence. And the Catholics also introduced the notion of higher meaning the sacred, and this existed before, but eventually, the natural shape of God is the Platonic form of the civilization that you're part of. It's basically the super organism that is formed by the individuals, as an intentional agent. And basically, the Catholics used the erasure of decode mythology, to implement software on the minds of people and get the software synchronized to make them walk in lockstep. So basically, you get to get this god online, and to make it efficient and effective. And I think God technically is just a self that spans multiple brains, as opposed to your and myself, which mostly exists just on one brain, right. And so in some sense, you can construct yourself functionally as a function that is implemented by brains that exists across brains. And this is God with a small g.

Lex Fridman 33:55
But that's one of the if you Yuval Harare, kind of talking about. This is one of the nice features of our brains, it seems to that we can all download the same piece of software like God in this case, and kind of share it.

Joscha Bach 34:08
Give everybody a spec, and the mathematical constraints that are intrinsic to information processing, make sure that given the same spec, you will come up with a compatible structure.

Lex Fridman 34:20
Okay. So that's, there's a space of ideas that we all share. And we think that's kind of the mind. And but that's separate from the idea is from from Christianity for from religion is that there's a separate thing between the mind there

Joscha Bach 34:35
is a real world and this real world is the world in which God exists. God is the quarter of the multiplayer adventure, so to speak, and we are all players in this game. And

Lex Fridman 34:46
that's dualism you

Joscha Bach 34:49
aspect is because the mental realm is, exists in a different implementation than the physical realm. And the mental realm is real. And a lot of people have this intuition that there is this Real room in which you will meet, talk and speak right now, then comes a layer of physics and abstract rules and so on. And then comes another real room where our souls are. And our tool form isn't the thing that gives us phenomenal experience. And this is, of course, a very confused notion that you would get. And it's basically it's the result of connecting materialism and idealism in the wrong way.

Lex Fridman 35:24
So okay, I apologize. But I think it's really helpful if we just tried to define, tried to define terms like what is dualism? What is idealism? What is materialism for people who don't know.

Joscha Bach 35:35
So the idea of dualism in our cultural tradition is that there are two substances a mental substance, and a physical substance. And they interact by different rules. And the physical world is basically causally closed and is built on a low level causal structure. So the basic bottom level that is causally closed, it's entirely mechanical, and mechanical in the widest sense. So it's computational. There is basically a physical world in which information flows around. And physics describes the laws of how information flows around and those jobs,

Lex Fridman 36:06
would you compare it to like a computer where you have hardware and software,

Joscha Bach 36:10
the computer is a generalization of information flowing around, basically. But you won't discover that there is only one universal principle, you can define this universal machine that is able to perform all the computations. So all these machines have the same power. This just means that you can always define a translation between them, as long as they have unlimited memory, too, to be able to perform each other's computations.

Lex Fridman 36:34
So would you then say that materialism is this whole world is just the hardware and idealism as this whole world is just a software?

Joscha Bach 36:42
Not quite I think that most idealists don't have a notion of software yet, because software also comes down to information processing. Right? So what you notice is the only thing that is real to you and me is this experiential world in which things matter in which things have taste in which things have color, phenomenal content, and so on. And you're bringing up consciousness, okay, right. And this is distinct from the physical world in which things have values in only in an abstract sense. And you only look at cold patterns moving around. So how does anything feel like something and this connection between the two things is very puzzling to a lot of people, of course, to many philosophers. So idealism starts out with the notion that mind is primary materialism, things that matter is primary. And so for the idealist, the material patterns that we see play and playing out are part of the dream that the mind is dreaming, and be exists in the mind on a higher plane of existence, if you want. And for the materialist, there is only the this material thing, and that generates some models, and VR, the result of these models. And in some sense, I don't think that we should understand if you understand it properly, materialism and idealism is a dichotomy. But as two different aspects of the same thing. So the weird thing is we don't exist in the physical world, we do exist inside of a story that the brain tells itself.

Lex Fridman 38:09
Let me let my information processing take, take that in. We don't exist in the physical world, we exist in the narrative,

Joscha Bach 38:18
basically, your brain cannot feel anything. No urine cannot feel anything. There are physical things, physical systems are unable to experience anything. But it would be very useful for the brain or for the organism to know what it would be like to be a person and to feel something. Yeah, so the brain creates a simulacrum of such a person that it uses to model the interactions of the person is the best model of what that brain this organism thinks it is in relationship to its environment. So it creates that model. It's a story, a multimedia novel, that the brain is continuously writing and updating.

Lex Fridman 38:47
But you also kind of said that, you said that we kind of exist in the head. Yes, that story? Yeah. What is real? In any of this? So like, there's a, again, these terms are, you kind of said there's a quantum graph. I mean, what is what is this whole thing running on then? Is the story in is it completely fundamentally impossible to get access to it? Because isn't the story supposed to is in the brain in a in something in existing in some kind of context, is what we

Joscha Bach 39:25
can identify as computer scientists, we can engineer systems and test our theories this way that may have the necessary and sufficient properties to produce the phenomena that you're observing, which is there's a self in a virtual world that is generated in somebody's neocortex that is contained in the skull of this primate here. And when I point at this, this indexicality is of course wrong. But I do create something that is likely to give rise to patterns on your retina that allow you to interpret what I'm saying, right? But we both know that the world that you and me are seeing is not the real physical world. What we are seeing is a virtual reality generated in your brain to explain the patterns on your retina, how

Lex Fridman 40:08
close is it to the real world? That's kind of the the question is that? When you have when you have like people like Donald Hoffman, let's say that like that you're really far away the thing we're seeing you and I now, that interface we have is very far away from anything. Like we don't even have anything close, like to the sense of what the real world is? Or is it a very surface piece of architecture?

Joscha Bach 40:32
Imagine you look at the Mandelbrot fractal, right? This famous thing that went on Monday board discovered everyone, if you, you see an overall shape in there, right, but you know that if you truly understand it, you know, it's two lines of code. It's basically in a series that is being tested for complex numbers and the complex number plane for every point. And for those were, the series is diverging. You paint this black, and where it's converging, you don't. And you get the intermediate colors, by taking how far it diverges, yes, right. This gives you this shape of this fractal. But imagine you live inside of this fractal and you don't have access to where you are in the fractal, or you have not discovered the generator function even. Right. So what you see is all I can see right now is the spiral and this variable moves a little bit to the right, is this an accurate model of reality? Yes, it is. Right? It is an adequate adequate description is you know that there is actually no spiral in the middle about fractal, it only appears like this to an observer, that is interpreting things as a two dimensional space, and then to find certain regularities in there at a certain scale that currently observes because if you zoom in the spiral might disappear, and turn out to be something different that the different resolution, right, yes, so at this level, you have the spiral, and then you just cover the spiral and move to the right, at some point it disappears. So you have a singularity. At this point, your model is no longer valid, you cannot predict what happens beyond the singularity. But you can observe again, and you will see it in another spiral. And at this point, it disappeared. So maybe now I have a second order law. And if you make 30 layers of these laws, then you have a description of the world that is similar to the one that we come up with, when we describe the reality around us. It's reasonably predictive, it does not cut to the core of it. So you explain how it's being generated, and how it actually works. But it's relatively good to explain the universe that you're entangled with.

Lex Fridman 42:25
But you don't think the tools or computer size of the tools of physics could get could step outside, see the whole drawing and get it the basic mechanism of how the pattern the spirals generated.

Joscha Bach 42:36
imagined, you would find yourself embedded into a Mandelbrot fractal, and you try to figure out what works and you somehow have a Turing machine, there's enough memory to think. And as a result, you've come to this idea, it must be some kind of automaton. And maybe you just enumerate all the possible automata until you get to the one that produces your reality. So you can identify necessary and sufficient condition for instance, we discover that mathematics itself is the domain of all languages. And then we see that most of the domains of mathematics that we have discovered, are in some sense, describing the same fractals is what category theory is obsessed about, that you can map these different domains to each other. So they're not that many fractals. And some of these have interesting structure and symmetry breaks. And so you can discover what region of this global fractal, you might be embedded in from first principles. Yes, but the only way you can get there is from first principles. So basically, your understanding of the universe has to start with automata, and then number theory, and then spaces and so on.

Lex Fridman 43:37
Yeah, I think like Stephen Wolfram still dreams that he's that he'll be able to arrive at the fundamental rules of the cellular automata, or the generalization of which is behind our universe. Yeah, it's, you've said on this topic, you said in a recent conversation, that quote, some people think that a simulation can't be conscious and only physical system can, but they gotta completely backward a physical system cannot be conscious. Only simulation can be conscious consciousness is a simulated property that simulate itself. Just like you said, the mind is kind of the call it story narrative. There's a simulation or our mind is essentially a simulation.

Joscha Bach 44:19
And usually, I try to use the terminology so that the mind is basically a principles that produce the simulation. It's the software that is implemented by your brain. And the mind is creating both the universe that we are in and the self, the idea of a person that is on the other side of attention and is embedded in this world.

Lex Fridman 44:40
Why is that important? That idea of self? Why is that important feature in the simulation?

Joscha Bach 44:46
It's basically a result of the purpose that the mind has. It's a tool for modeling, right? We're not actually monkeys. We are side effects of the regulation needs of monkeys. And what the monkey has to regulate is In the relationship of an organism to an outside world that is, in large part also consisting of other organisms. And as a result, it basically has regulation targets that it tries to get to these regulation targets slide was priors, their basic like unconditional reflexes that we are more or less born with. And then we can reverse engineer them to make them more consistent. And then we get more detailed models about how the world works and how to interact with it. And so these priors that you commit to are largely target values that our needs would approach set points. And this deviation to the set point create some urge some tension. And we find ourselves living inside of feedback loops, right? Consciousness emerges over dimensions of disagreements, because the universe thinks that you care, things are not the way they should be, that you need to regulate. And so in some sense, the sense of self is the result of all the identifications that you're having. And that edification is a regulation target that you're committing to, it's a dimension that you care about, that you think is important. And this is also what locks you in, if you let go of these commitments of these identifications, you get free, there's nothing that you have to do anymore. And if you let go of all of them, you're completely free. And you can enter Nirvana because you're done.

Lex Fridman 46:15
And actually, this is a good time to pause and say, Thank you to sort of a friend of mine, Gustav Surah, strim, who introduced me to your work, I wanted to give him a shout up. He's a brilliant guy. And I think the AI community is actually quite amazing. And Gustavo is a good representative that you are as well. So I'm, I'm glad, first of all, I'm glad the internet exists that YouTube exists where I can watch your talks, and then get to your book and study your writing and think about you know, that's, that's amazing. Okay, but the you've kind of described instead of this emergent phenomena of consciousness from the simulation. So what about the hard problem of consciousness? The Can you just linger on it? Like? Why Does it still feel? Like I understand you're kind of the self is an important part of the simulation. But why does the simulation feel like something?

Joscha Bach 47:11
So if you look at the book, by, say, George RR Martin with the characters of plausible psychology, and they stand on a hill, because they want to conquer the city below the hill that dominate in their Look at the color of the sky, and they are apprehensive, and feel empowered, and all these things, why do they have these emotions, it's because it's written into the story, right, and it's written to the story, because it's an adequate model of the person that predicts what they're going to do next. And the same thing is true for us. So it's basically a story that our brain is writing, it's not written in words, it's written in perceptual content, basically, multimedia content. And it's a model of what the person would feel if it existed. So it's a virtual person. And you and me happen to be this virtual person. So this virtual person gets access to the language center, and talks about the sky being blue. And this is us.

Lex Fridman 48:01
But hold on a second, do I exist in your simulation,

Joscha Bach 48:06
you do exist in a almost similar way as me, so their internal states that I that are less accessible for me, that you have, and so on, and you're my model might not be completely adequate. There are also things that I might perceive about you that you don't perceive. But in some sense, both you and me are some puppets, two puppets that enact this play in my mind. And I identify with one of them because I can control one of the puppet directly. And with the other one, I can create things in between. So for instance, we can go in an interaction that even leads to a coupling to a feedback loop. So we can sync things together in a certain way or feel things together. But this coupling is itself not a physical phenomenon. It's entirely a software phenomenon. It's the result of two different implementations interacting with each other.

Lex Fridman 48:55
So that's interesting. So I used to just thing I like the way you think about it, is the entirety of existence, the simulation, and we're kind of each mind is a little sub simulation that, like, why don't you Why doesn't your mind have access to my mind's full state, like,

Joscha Bach 49:19
for the same reason that my mind hasn't had access to its own full state?

Lex Fridman 49:23
So what I mean, there

Joscha Bach 49:26
is no trick involved. So basically, when I say know something about myself, it's because I made a model of your brain is tasked with modeling what other parts of your brain are doing? Yes.

Lex Fridman 49:36
But there seems to be an incredible consistency about this world, in the physical sense, that is repeatable experiments, and so on. Yeah. How does that fit into our silly descendent of apes simulation of the world? So why is it so repeat? Why is everything so repeatable? And not everything? There's a lot of fundamental physics experiments that are repeatable for Long time all over the place, and so on laws of physics quite how does that fit in,

Joscha Bach 50:05
it seems that the parts of the world that are not deterministic, are not long lived. So if you build a system, any kind of automaton, so if you build a simulation of something, you'll notice that the phenomena that endure, or those that give rise to stable dynamics. So basically, if you see anything that is complex in the world, it's the result of usually have some control of some feedback that keeps it stable around certain attractors. And the things that are not stable, that don't give rise to certain harmonic patterns and so on, they tend to get weeded out over time. So if we are in a region of the universe that sustains complexity, which is required to implement mines like ours, this is going to be a region of the universe that is very tightly controlled, and controllable. So it's going to have lots of interesting symmetries and also symmetry breaks that allow to the creation of structure.

Lex Fridman 51:00
But they exist where there's such an interesting idea that our mind is simulation that's constructing the narrative. My question is, just to try to understand how that fits with this. With the entirety of the universe, you're saying that there's a region of this universe that allows enough complexity to create creatures like us. But what's the connection between the brain, the mind, and the broader universe, which comes first, which is more fundamental, is the is the mind the starting point, the universe is emergent is the universe, the starting point in the minds are emergent,

Joscha Bach 51:37
I think, quite clearly, the latter is at least a much easier explanation, because it allows us to make causal models. And I don't see any way to construct an inverse causality.

Lex Fridman 51:47
So what happens when you die to your mind simulation?

Joscha Bach 51:51
My implementation ceases. So basically, the thing that implements myself will no longer be present. Which means if I'm not implemented on the minds of other people, the thing that I identify with this, the weird thing is I don't actually have an identity beyond the identity that I construct. If I was the Dalai Lama, he identifies as a form of government. So basically, the Dalai Lama gets reborn, not because he's confused, but because he is not identifying as a human being. He runs on a human being, he's basically a governmental software, right, that is instantiated in every new generation and new so his advisers will pick someone who does this in the next generation. So if you identify with this, you will no longer human and you don't die in the sense the what dies is only the body of the human that you run on you to kill the Dalai Lama, you'd have to kill his tradition. And if we look at ourselves, we realize that you to a small part like this, most of us, so for instance, if you have children, you realize something lives on in them. Or if you spark an idea in the world, something lives on, or if you identify with the society around you, because you are in part that you're not just a human being.

Lex Fridman 53:01
So in essence, you're kind of like a Dalai Lama, in the sense that you jasha Bach is just a collection of ideas. So like, you have this operating system on, which has a bunch of ideas live and interact. And then once you die, they kind of part some of them. Jump off the

Joscha Bach 53:18
short, put it the other way, identity is a software state, it's a construction. It's not physically real. Your identity is not a physical concept. It's basically a representation of different objects on the same world line.

Lex Fridman 53:32
But identity that lives and dies, or you attach this is, what's the fundamental thing? Is it the ideas that come together to form identity? Or is each individual identity actually a fundamental thing?

Joscha Bach 53:46
It's a representation that you can get agency over if you care. So basically, you can choose what you identify with, if you want to

Lex Fridman 53:53
know big themes. If if the mind is not real, it's not that the birth and death is not a crucial part of it. Well, maybe I'm silly. Maybe I'm attached to this whole biological organism. But it seems that the physical being a physical object in this world is is an important aspect of birth and death. Like it feels like it has to be physical to die. It feels like simulations don't have to die.

Joscha Bach 54:30
The physics that we experience is not the real physics there is no color and sound in the real world. color and sound are types of representations that you get, if you want to model reality with oscillators right. So colors and sound in some sense, have octaves. Yes. And it's because they are represented properly with oscillators right. So that's why colors form a circle of use. And colors have harmonic sounds have harmonics is a result of synchronizing oscillators in the brain, right? So the world that we subjectively interact with is Fundamentally, the result of the representation mechanisms in our brain, they are mathematically to some degree universal, there are certain regularities that you can discover in the patterns and not others. But the patterns that we get this is not the real world, the world that we interact with is always made of too many parts to count, right. So when you look at this table, and so on, it's consisting of so many more molecules and atoms, that you cannot count them. So you only look at the aggregate dynamics at limit dynamics, if you had almost infinitely many patterns of particles, what would be the dynamics of the table, and this is roughly what you get. So geometry that we are interacting with, is the result of discovering those operators that work in the limit that you get by building an infinite series that converges. For those parts where it converges is geometry. For those parts where it doesn't converge. It's chaos.

Lex Fridman 55:49
Right? And then so all of that is filtered through the cuts of the consciousness that's emergent in our narrative, the consciousness gives it color gives a feeling gives a flavor.

Joscha Bach 56:00
So I think the feeling, flavor and so on is given by the relationship that a feature has to all the other features. It's basically a giant relational graph, that is our subjective universe, the color is given by those aspects of the representation, or the this exponential color where you care about that you have identifications for something means something where you are the inside of a feedback loop and the dimensions of, of caring are basically dimensions of this motivational system that we emerge over

Lex Fridman 56:29
the meaning of the relations, the graph. Can you elaborate that a little bit? Like where does the maybe you can even step back and ask the question of what is consciousness to be sort of more systematically? What what what do you how do you think about consciousness,

Joscha Bach 56:47
consciousness is largely a model of the contents of your attention. It's a mechanism that has evolved for certain types of learning at the moment, or machine learning systems largely work by building chains of weighted sums of real numbers for some non linearity. And you will learn by piping and error signals, who are these different change layers, and adjusting the weights and these weighted sums. And you can approximate most polynomials with this. If you have enough training data, but the prices you need to change a lot of these weights, basically, the error is piped backwards into the system until it accumulates at certain junctures in the network. And everything else evens out statistically, and only at these junctures This is where you had the actual error on the network, you make the change there, this is a very slow process. And our brains don't have enough time for that, because we don't get old enough to play go the way that our machines learn to play Go. So instead, what we do is an attention based learning, We pinpoint the probable region in the network where we can make an improvement. And then we store the this binding state, together with the expected outcome in the protocol. And there's the ability to make index memories for the purpose of learning to revisit these commitments later. This requires and memory of the contents of our attention. Another aspect is when I construct my reality and make mistakes, so I see things that turn out to be reflections or shadows and so on, which means I have to be able to point out which features of my perception gave rise to present construction of reality. So the system needs to pay attention to the features that are currently in its focus. And it also needs to pay attention to whether it pays attention itself, in part because the attentional system gets trained with the same mechanisms with reflexive but also in part because your attention lapses if you don't pay attention to the attention itself. Right. So it's the thing that I'm currently seeing just a dream that my brain has spun off into some kind of daydream, or am I still paying attention to my percept. So you have to periodically go back and see whether you're still paying attention. And if you have this loop, and you make it tight enough, between the system becoming aware of the contents of its attention, and the fact that it's paying attention itself and makes attention the object of its attention. I think this is the loop over which we wake up.

Lex Fridman 59:09
So there's this there's this attention mechanism that's somehow self referential, that's fundamental to our consciousnesses. So, just ask you a question. I don't know how much you're familiar with the recent breakthroughs in natural language processing, they use attentional mechanism, you use something called transformers, to learn patterns and sentences by allowing the network to focus its attention to particular parts of the sentence and each individual so like parametrize and make it learnable. The dynamics of a sentence by having like a little window into the into the sentence. Do you think that's like a little step towards that eventually, we will take us to the intentional mechanisms from which consciousness can emerge.

Joscha Bach 1:00:00
Quiet. I think it models only one aspect of attention. In the early days of automated language translation, there was an example that I found particularly funny when somebody tried to translate a text from English into German. And it was a bet broke the window. And the translation in German was an felida. Mouse. It's a practice Fenster, Medina and baseball schlager. So to translate back into a bet, the flying mammal broke the window with a baseball bat. Yes. And it seemed to be the most similar to this program, because it somehow maximized the possibility of translating the concept bet into German in the same sentence. And this is a mistake that the transformer model is not doing because it's tracking identity. And the attentional mechanism, and the transformer model is basically putting its finger on individual concepts, and make sure that these concepts pop up later in the text. Yeah, and of tracks basically, the individuals. So the text is why the system can learn things that other systems couldn't before it, which makes it for instance, possible to write a text where it talks about the scientist, and the scientist has a name and has a pronoun, and it gets a consistent story about that thing. What it does not do, it doesn't fully integrate this. So it is meaning falls apart. At some point it loses track of this context, it does not yet understand that everything that it says has to refer to the same universe. And this is where this thing falls apart. But the attention in a transformer model does not go beyond tracking identity. And tracking identity is an important part of attention. But it's a different spirit specific attention mechanism. It's not the one that gives rise to the type of consciousness that they have.

Lex Fridman 1:01:42
Okay, just to linger on what what do you mean by identity in the context of language.

Joscha Bach 1:01:47
So, when you talk about language, we have different words that can refer to the same concept. And in the sense concepts. So yes, and it can also be in a nominal sense, or indexical sense that you say, this word does not only refer to this class of objects, but it refers to a definite object or some kind of agent that waves their way to the story, and is only referred by different ways in the language. So the language is basically a projection from a conceptual representation from a scene that is evolving into a discrete string of symbols. And what the transformer was able to it learns aspects of this projection mechanism that other models couldn't learn.

Lex Fridman 1:02:32
So have you ever seen an artificial intelligence or any kind of construction idea that allows for unlike neural networks, or perhaps within neural networks, that's able to form something where the space of concepts continues to be integrated. So what you're describing, building a knowledge knowledge base, building this consistent larger and larger sets of ideas that would then allow for deeper understanding

Joscha Bach 1:02:59
Vidkun Stein thought that we can build everything from language from basically a logical grammatical construct. And I think to some degree, this was also what Minsky believed. So that's why he focused so much on common sense reasoning, and so on. And project that was inspired by him was like, there was basically a lot going on. Yes, of course, ideas don't die, only people die. And that's true, but it outside is a productive project is just probably not one that is going to converge to general intelligence, the thing that Vidkun Stein couldn't solve, and he looked at this in his book, at the end of his life philosophical investigations, was the notion of images. So images play an important role in track titles, the Tractatus an attempt to basically to end philosophy into logical probing language to design a logical language in which you can do actual philosophy that rich enough for doing this. And the difficulty was to deal with perceptual content. And eventually, I think he decided that he was not able to solve it. And I think this preempted the failure of the logic test program in AI and the solution as we see today is we need more general function approximation, there are functions geometric functions, that we learned to approximate that cannot be efficiently expressed and computed in a grammatical language, we can of course, build automata that go via number theory and so on to learn linear algebra and then compute an approximation of this geometry, but to equate language and geometry is not an efficient way to think about it.

Lex Fridman 1:04:32
So functional, we kind of just said that neural networks are sort of the approach a neural net always takes is actually more general than the than what can be expressed through language.

Joscha Bach 1:04:45
Yes. So what can be efficiently expressed so language at the data rates at which we process grammatical language?

Lex Fridman 1:04:52
Okay, so you don't think so? You don't think language is so you disagree with Wittgenstein. That language is not fundamental to

Joscha Bach 1:04:59
agreement. Let me It couldn't stand it just if we was delayed Vidkun Stein. And I also agree with the beauty of the early Vidkun. Stein, I think that the Tractatus itself is probably the most beautiful philosophy text that was written in the 20th century.

Lex Fridman 1:05:13
But, but language is not fundamental to cognition and intelligence and consciousness.

Joscha Bach 1:05:18
So I think that language is a particular way, or the natural language that we're using as a particular level of abstraction that we use to communicate with each other. But the languages in which we express geometry are not grammatical languages in the same sense. So they work slightly differently, more general expressions of functions. And I think the general nature of a model is you have a bunch of parameters. These have arranged the variances of the world. And you have relationships between them, which are constraints, which say, if certain parameters have these values, then other parameters have to have the following values. And this is a very early insight in computer science. And I think the some of the earliest formulations is the Boltzmann machine. And the problem is the Boltzmann machine is that it has a measure of whether it's good, this is basically the energy on the system, the amount of tension that you have left in the constraints, where the constraints don't quite match. It's very difficult to despite having this global measure to train it, because if you as soon as you add more than trivially few elements of parameters into the system, it's very difficult to get it settled in the right architecture. And so we the solution that Hinton and Sinofsky found was to use a restricted Boltzmann machine, which uses the hidden links the internal links in the Boltzmann machine and only has based the input and output layer. But this limits the expressive civility of the Boltzmann machine. So now he built a network of small of these primitive Boltzmann machines. And then some sense, you can see almost continuous development from this to the deep learning models that we're using today. Even though we don't use Boltzmann machines at this point, but the idea of the Boltzmann machine is you take this model, you claim some of the values to perception, and This forces the entire machine to go into a state that is compatible with the states that you currently perceive in this state is your model of the world. Right. So I think it's very general way of thinking about models. But we have to use a different approach to make it work this is we have to find different networks that train the Boltzmann machine. So the mechanism that trains the Boltzmann machine. And the mechanism that makes the Boltzmann machine settle into its state are distinct from the constrained architecture of the Boltzmann machine itself.

Lex Fridman 1:07:33
The the kind of mechanism that we want to develop, you're saying yes,

Joscha Bach 1:07:36
so that's the direction in which I think our research is going to go is going to, for instance, what you notice in perception is our perceptual models of the world are not probabilistic, but possibilistic, which means was them you should be able to perceive things that are improbable but possible, right? If this natural state is valid, not if it's probable, but if it's possible, if it's coherent. So if you see a title coming after, you should be able to see this even if it's unlikely. And the probability is necessary for convergence of the model. So given the state of possibilities, that is very, very large, and a set of perceptual features, how should you change the state of states have the model together to converge with your perception,

Lex Fridman 1:08:21
but the space of the space of ideas that are coherent, with the context that you're sensing is perhaps not as large, I mean, that that's perhaps a pretty small

Joscha Bach 1:08:35
degree of coherence that you need to achieve depends, of course, how deep your models goal is, for instance, politics is very simple when you know very little about game theory and human nature. So the younger you are, the more obvious is how politics would work, right? And because you get an aquarium statics from relatively few inputs, and the more layers you model, the more layers you model reality, the harder it gets to satisfy all the constraints.

Lex Fridman 1:09:01
So you know, the current neural networks are fundamentally supervised learning system with a feed forward neural network is back propagation to learn. What's your intuition about what kind of mechanisms might we move towards to improve the learning procedure?

Joscha Bach 1:09:18
I think one big aspect is going to be meta learning and architecture search starts in this direction. In some sense, the first wave of AI classical AI work by identifying a problem and the possible solution and implementing the solution right program that plays chess. And right now we are in the second wave of AI. So instead of writing the algorithm that implements the solution provides an algorithm that automatically searches for an algorithm that implements the solution. So the learning system in some sense, is an algorithm that itself discovers the algorithm that solves the problem like go go, it's too hard to implement it by the solution by hand, but we can implement an algorithm that finds the solution. So now, let's move to the third stage right the third stage meta learning, find an algorithm that discovers a learning algorithm for the given domain, or brain is probably not a learning system, but a meta learning system. This is one way of looking at what we are doing. There is another way, if you look at the way our brain is, for instance, implemented, there is no central control that tells all the neurons how to buy our app. Yes, instead, every neuron is an individual reinforcement learning agent. Every neuron is a single celled organism that is quite complicated, and in some sense, quite motivated to get fed. And it gets fed if it fires on average at the right time. And the the right time depends on the context that the neuron exists in, which is the electrical and chemical environment that it has. So it basically has to learn a function over its environment that tells us when to fire to get fat. Or if you see it as a reinforcement learning agent, every neuron is in some sense, making a hypothesis when it sends a signal and tries to pipe a signal through the universe and tries to get positive feedback for it. And the entire thing is set up in such a way that it's robustly self organizing into a brain, which means you strike out with different new types that have different priors in on which hypothesis to test on how to get this reward. And you put them into different concentrations in a certain spatial alignment. And then you can train it in a particular order. And as a result, you get a well organized brain.

Lex Fridman 1:11:22
Yeah, so Okay, so the brain is a meta learning system with a bunch of reinforcement learning agents, and what I think you said, but just to clarify, where do the there's no centralized government that tells you, here's a loss function, here's a loss function, here's a loss function like what? Who is who says, What's the

Joscha Bach 1:11:49
government governments which impose loss functions on different parts of the brain. So we have differential attention, some areas in your brain get specially rewarded when you look at faces, if you don't have that, you will get posted agnosia, which basically means the inability to tell people apart by their faces. So

Lex Fridman 1:12:06
the reason that happens is because it was had an evolutionary advantage, like evolution comes into play here about

Joscha Bach 1:12:11
it's basically an extraordinary attention that we have four phases, I don't think that people have as opposed agnosia have proceeded to effective brain, the brain just has an average attention for phases. So people who supposedly agnosia don't look at faces more than that look at cups. So the level at which they resolve the geometry of faces is not higher than the one that then for cups. And people that don't have prosopagnosia look objectively at faces, right for you and me, it's impossible to move through a crowd without scanning the faces. And as a result, we make insanely detailed models of faces that allow us to discern mental states of people.

Lex Fridman 1:12:45
So obviously, we don't know 99% of the details of this meta learning system. That's our mind. Okay. But still, we took a leap from something much Dumber To that film through the evolutionary process. Can you first of all, maybe say how hard D how big of a leap? Is that from our brain? From our ape ancestors to small T cell organisms? And is there something we can think about? About as we start to think about how to engineer intelligence? Is there something we can learn from evolution?

Joscha Bach 1:13:24
In some sense, life exists because of the market opportunity of controlled chemical reactions, we compete with dumb chemical reactions. And we win in some areas against the dam combustion because we can harness those entropy gradients, but you need to add a little bit of energy in a specific way to harvest more energy. So we out competed combustion, in many regions, we do and we try very hard because when we are in direct competition, we lose, right? Yeah. So because the combustion is going to close the entropy gradients much faster than we can run. Yes, you gotta quit. So yeah, so basically, we do this because every cell has a Turing machine built into it. It's like literally read write, and positive. And everything that's more complicated than a molecule that just is a vortex around the tractors that needs a Turing machine it for its regulation. And then you bind cells together, and you get next level organization or organism where the cells together implement some kind of software. And for me, very interesting discovery in the last year was the word spirit because I realized that what spirit actually means it's an operating system for an autonomous robot. And when the word was invented, people needed this word. But they didn't have robots that they built themselves yet the only autonomous robots that were known were people, animals, plants, ecosystems, cities and so on, and they all had spirits. And it makes sense to say that the plant is an operating system, right? If you pinch the plant in one area, then there's going to have repercussions throughout the plant. Everything in the plant is numb sense connected into some global aesthetics. Like in other organisms, an organism is not a collection of cells is a function that tells cells how to behave. And this function is not implemented as some kind of supernatural thing. Like some morphogenetic field, it is an emergent result of the interactions of the each salvus each other cell. Alright

Lex Fridman 1:15:21
guys, so you're you're saying is the organism is a function that tells what's what what the south says what to do. And the function or is an emergent emerges from the interaction of the cells? Yes.

Joscha Bach 1:15:38
So it's basically a description of what the plant is doing in terms of macro states. And the macro states, the physical implementation, or too many of them to describe them. So the software that we use to describe what the plant is doing, the spirit of the plant is the software, the operating system of the plant, right? There's a way in which we, the observers make sense of the plant. Yes. And the same is true for people. So people have spirits, which is their operating system in a way, right. And there's aspects of that operating system that relate to how your body functions and others, how you socially interact, how you interact with yourself, and so on. And we make models of that spirit. And we think it's a loaded term, because it's from a pre scientific age. But we took the scientific age, a long time to rediscover a term that is pretty much the same thing. And I suspect that the differences that we still see, between the old word and the new word or translation errors over the centuries,

Lex Fridman 1:16:35
can you can you actually linger on that? Like, why do you say that Spirit just to clarify, because I'm a little bit confused. So the word spirits is a powerful thing. But why did you say in the last year or so that you discovered this? Do you mean the same old traditional idea of a spirit or Jamie and try

Joscha Bach 1:16:51
to find out what people mean by spirit, when people say spirituality in the US, it usually is the refers to the phantom limb that they develop in the absence of culture. And culture is in some sense, you could say the spirit of a society that is long game, this thing that is become self aware at a level above the individuals where you say, if you don't do the following things, then the grand grand grand grandchildren of our children gonna have nothing to eat. Yeah. So if you take this long scope, and you try to maximize the length of the game that you're playing as a species, you realize that you're part of a larger thing that you cannot fully control, you probably need to submit to the ecosphere instead of trying to completely control it. Right, there needs to be a certain level at which we can exist as a species if you want to endure. And our culture is not sustaining this anymore. We basically made this bet with the industrial revolution that you can control everything and the modern societies with basically unfettered growth led to a situation in which we depend on the ability to control the entire planet. And since you are not able to do that, as it seems, this culture will die. If we realized that it doesn't have a future might be called our children generations that it's not very optimistic.

Lex Fridman 1:18:10
Yeah, so you can have this kind of intuition that our civilization you said culture, but you really mean this. The spirit of the civilization the the entirety, the civilization may not exist for long. Yeah. So what's your Can you can you untangle that? What's your intuition behind that? So you kind of offline mentioned to me that the Industrial Revolution was kind of the moment we agreed to accept the offer sign on the paper on the dotted line with the industrial revolution we doomed ourselves. Can you elaborate on that?

Joscha Bach 1:18:47
There's a suspicion I, of course, don't know how it plays out. But of course, it seems to me that in a society in which you leverage yourself very far over an entropic Airbus facade land on the other side, is relatively clear that your cantilever is at some point, going to break down into this entropic Airbus and you have to pay the bill.

Lex Fridman 1:19:08
Okay, Russia is my first language. And I'm also an idiot. Me too. This is just to apes, instead of playing with the banana trying to have fun by talking, okay, anthropic what and what's anthropic

Joscha Bach 1:19:26
and tropic and trop and so entropic in the sense of entropy and all entropic guys, so this and entropic what was the other word? Yeah, this was that it's a big court or this is yes,

Lex Fridman 1:19:39
and tropic abyss. So many of the things you say are poetic, it's an amazing, right. It's mispronounce, which, which makes it even more poetic. Wittgenstein would be proud. So in Tropic abyss, okay, let's let's rewind then. The Industrial Revolution Question. So what? How does that get us into the entropic abyss?

Joscha Bach 1:20:05
So in some sense, we burned 200 million years worth of trees to get everybody plumping. Yes. And the society that we had before that had a very limited number of people. So basically, since the OBC, we hovered between 300 and 400 million people. And this only changed with the enlightenment and the subsequent Industrial Revolution. And in some sense, the Enlightenment have freed our rationality and also freed our norms from the pre existing order gradually, it was in process that basically have a feedback loop. So it was not that just one cause the other, it was a dynamic that started and the dynamic work by basically increasing productivity to such a degree that we could feed all our children. And I think the definition of poverty is that you have as many children as you can feed before they die, which is, in some sense, the state that all animals on Earth are in

Lex Fridman 1:21:04
the definition of poverty is having enough. So

Joscha Bach 1:21:06
you can have only so many children as you can feed. And if you have more than die, yes. And in our societies, you can basically have as many children as you want, they don't die. Right? So the reason why we don't have as many children as we want is because we also have to pay a price in terms of you have to insert ourselves in a lower source of dread. Because yeah, if you have too many, so basically, everybody in the under middle and lower upper class has only a limited number of children, because having more of them would mean big economic hit to the individual families, yes, because trauma, especially in us super expensive to have. And you only are taken out of this, if you are basically super rich. Or if you are super poor. If you're super poor, it doesn't matter how many kids you have, because your status is not going to change. And these children are largely not going to die of hunger.

Lex Fridman 1:21:54
So how does this leads us to self destruction. So there's a lot of unpleasant properties about this process. So

Joscha Bach 1:22:00
basically, what we try to do is we try to let our children survive, even if they have diseases, like I would have died in before my mid 20s. Without modern medicine, and most of my friends would have as well. So many of us wouldn't live. Without the advantages of modern medicine and modern industrialized society, we get our protein largely by subduing the entirety of nature. Imagine there would be some very clever microbe that would live in our organisms and would completely harvest them and change them into a thing that is necessary to sustain itself. And it would discover that, for instance, brain cells are kind of edible, but they're not quite nice. So you need to have more fat in them, and you turn them into more fat cells. And basically, this big organism would become a vegetable that is barely alive. And it's going to be very brittle and not resilient. when the environment changes,

Lex Fridman 1:22:57
you have the some part of that organism, the one that's actually doing all the using of the, they'll still be somebody thriving.

Joscha Bach 1:23:05
So it relates back to this original question. I suspect that we are not the smartest thing on this planet, I suspect that basically every complex system has to have some complex regulation. If, if it depends on feedback loops. And so for instance, it's likely to that we should describe a certain degree of intelligence to plants. The problem is that plants don't have a nervous system. So they don't have a way to telegraph messages over large distances almost instantly in the plant. And instead, they will rely on chemicals between adjacent cells, which means the signal processing speed depends on their signal processing with a rate of a few millimeters per second. Yes. And as a result, the if the plant is intelligent, it's not going to be intelligent. It's similar timescales as yes,

Lex Fridman 1:23:53
they believe was the timescale is different. So you suspect, we might not be the most intelligent, but we're the most intelligent and this scale in our timescale.

Joscha Bach 1:24:05
So basically, if you would zoom out very far, we might discover that there have been intelligent ecosystems on the planet that existed for 1000s of years in a almost undisturbed state. And it could be that these ecosystems actively related their environment. So basically, change the course of the evolution within this ecosystem to make it more efficient and as brittle

Lex Fridman 1:24:26
as possible. Something like plants is actually a set of living organisms, an ecosystem of living organisms that are just operating a different timescale and a far superior intelligence to human beings. And then human beings will die out and plants will still be there, and they'll be there.

Joscha Bach 1:24:42
They also there's an evolutionary adaptation playing a role at all of these levels. For instance, if mice don't get enough food, and get stressed, the next generation of mice will be more sparse and more scrawny. And the reason for this is because they in the natural environment, the mice have probably hidden a drought or something out. And if they overgraze, then all the things that sustain them might go extinct. And there will be no mice few generations from now. So to make sure that there will be mice in five generations from now, basically the mice scale back. And a similar thing happens with the predators of mice, they should make sure that the mice don't completely go extinct. So in some sense, if the predators are smart enough, they will be tasked with shepherding their food supply. And it may be the reason why Lions have much larger brains and antelopes is not so much because it's so hard to catch a antelope as opposed to run away from the lion. But the lions need to make complex models of their environment, more complex than the antelopes.

Lex Fridman 1:25:40
So first of all, just describing that there's a bunch of complex systems and human beings may not even be the most special or intelligent of those complex systems, even on Earth, makes me feel a little better about the extinction of human species that we're talking about.

Joscha Bach 1:25:54
Yes. And if you adjust gas flow to put the carbon back into the atmosphere,

Lex Fridman 1:25:57
this is just a nice,

Joscha Bach 1:26:00
big stain on evolution is not as it was trees, evolve trees before they could be digested again, right? There were no insects that could break all of them apart. Cellulose is so robust that you cannot get all of it with microorganisms. So many of these trees fell into swamps. And all this carbon became inert and could no longer be recycled into organisms. And we're the species that is destined

Lex Fridman 1:26:22
to take care of that. So this is kind of

Joscha Bach 1:26:25
dig it out of the ground, put it back into the atmosphere, and the earth is already greening. So vision, million years or so when the ecosystems have recovered from the rapid changes that they're not compatible with right now. Yeah, this is going to be awesome again,

Lex Fridman 1:26:38
and there won't be even a memory of us of us a little apes,

Joscha Bach 1:26:42
I think there will be memories of us, I suspect we are the first generally intelligent species in the sense we are the first species was industrial society, because we will leave more phones than bones in the stratosphere,

Lex Fridman 1:26:53
or see phones than bones, I like it. But then let me push back the, you've kind of suggested that we have a very narrow definition of, of Intel. I mean, why aren't trees more general, a higher level of general intelligence and

Joscha Bach 1:27:09
trees were intelligent than they would be at different timescales, which means within 100 years, the tree is probably not going to make models that are as complex as the ones that we make in 10 years.

Lex Fridman 1:27:19
But maybe the trees are the ones that made the phones, right. Like, like,

Joscha Bach 1:27:25
you say, the entirety of life did you know, the first cell never died, the first cell only split, right. And every divided and every cell in our body is still an instance of the first cell that split off from that very first cell, there was only one cell on this planet as far as we know. And so the cell is not just a building block of life. It's a hyper organism, right? And we are part of this hyper organism.

Lex Fridman 1:27:49
So Nevertheless, this hyper organism know the this little particular branch of it, which is us humans, because the Industrial Revolution, and maybe the exponential growth of technology might somehow destroy ourselves. So what, what do you think is the most likely way we might destroy ourselves? So some people worry about genetic manipulation? Some people as we've talked about, worry about? Either dumb artificial intelligence or super intelligent, artificial intelligence, destroying us? Some people worry, all nuclear weapons and weapons of war in general, what do you think if you had to, if you're a betting man, what would you bet on in terms of self destruction? And there would be higher than 50? Would it be higher than 50%.

Joscha Bach 1:28:34
So it's very likely that nothing that we bet on matters after we win our bet, so I don't think that bets are literally the right thing, way to go about

Lex Fridman 1:28:43
it. Once your data doesn't, you won't be there to collect

Joscha Bach 1:28:47
the soil. It's also not clear if we, as a species go extinct. But I think that our present civilization is not sustainable. So the thing that will change is there will be probably fewer people on the planet and are today. And even if not, then still most of people that are alive today will not have offspring, and 100 years from now, because of the geographic changes and so on in the change in the food supply. It's quite likely that many areas of the planet the only be livable was a close cooling chain in 100 years from now, so many of the areas around the equator and in subtropical climates that are now quite pleasant to live in, but stopped to be inhabitable. Without

Lex Fridman 1:29:27
you honest, wow, cooling chain close knit cooling chain communities. So you think you have a strong worry about the the effects of global warming

Joscha Bach 1:29:38
itself. It's not a big issue. If you live in Arizona right now, you have basically three months in the summer, in which you cannot be outside. Yes. And so you have a close cooling chain. You have air conditioning in your car and in your home and you're fine and if the air conditioning would stop for a few days, then in many areas you would not be able to survive, right Can we

Lex Fridman 1:29:57
just pause for a second? Like you say So many brilliant poetic things like what is a closed is that do people use that term closed cooling chain?

Joscha Bach 1:30:05
I imagine that people use it when they describe how they get meat into a supermarket. Right? Right, the cooling chain and this starts to thaw, you're in trouble and you have to throw it away.

Lex Fridman 1:30:18
That's such a beautiful way to put it, say calling a city, a closed social chain or something like that. I mean, that's right. I mean, the locality of is really

Joscha Bach 1:30:26
what it basically means you wake up in the climatized room, you go to work in the climate test car, you work in the shop, and the climate has supermarket. And in between, you have very short distance which you run from your car to the supermarket, but you have to make sure that you your temperature does not approach the temperature of the environment. Yeah, so the thing is the wet bulb temperature, the what the wet bulb temperature, it's what you get, when you take a wet clothes, and you put it around your thermometer, and then you move it very quickly through the air. So you get the evaporation heat. And as soon as you can no longer cool your body temperature via EPA operation to a temperature below something like I think 35 degrees you die. And which means if the outside world is dry, you can still cool yourself down by sweating. But if it has a certain degree of humidity, or if it goes over a certain temperature, then sweating will not save you. And this means you even if you're healthy fit individual within a few hours, even if you try to be in the shade and so on, you'll die unless you have some climate tising equipment. And this itself if you as long as you maintain civilization and you have energy supply, and you have food trucks coming to your home that acclimatized everything is fine. But what if you lose large scale open agriculture at the same time. So basically, you run into food insecurity, because climate becomes very irregular, or weather becomes very irregular, and you have a lot of extreme weather events. So you need to roll most of your your foot maybe indoor, or you need to import your foot from certain regions. And maybe you are not able to maintain the civilization or throughout the planet to get to infrastructure to get the foot to your home.

Lex Fridman 1:32:09
But there could be there could be significant impacts in the sense that people begin to suffer. There could be wars over resources and so on. But ultimately, do you do not have a lot of faith? But what do you make of the capacity of technology, technological innovation, to help us prevent some of the worst damages that this condition can create? So as an example, as a almost out there example is the work that SpaceX and Elon Musk is doing of trying to also consider our propagation throughout the universe in deep space to colonize other planets. That's one technological step. But

Joscha Bach 1:32:52
of course, what Elon Musk is trying on Mars is not to save us from global warming, because Mars looks much worse than Planet Earth will look like after the worst outcomes of global warming imaginable, right? Yeah, my sense essentially not habitable,

Lex Fridman 1:33:07
it's exceptionally harsh environment, yes. But what he is doing what a lot of people throughout history since the industrial revolution are doing, or just doing a lot of different technological innovation was some kind of target. And what ends up happening is totally unexpected new things come up. So trying to trying to terraform or trying to colonize Mars extremely harsh environment might give us totally new ideas of how to expand the or increase the power of this close cooling circuit, that that empowers the community. So like, it seems like there's a little bit of a race between our open ended technological innovation of this communal operating system that we have, and our general tendency to want to overuse resources and thereby destroy ourselves. If you don't think technology can win that race.

Joscha Bach 1:34:05
I think the probability is relatively low. Given that our technology is points, the US is stagnating since the 1970s, roughly, in terms of technology, most of the things that we do are the result of incremental processes or what Intel, what about Moore's law, it's basically it's very incremental, the things that we're doing is, so after the invention of the microprocessor was a major thing, right? The miniaturization of transistors was really major. But the things that we did afterwards, largely, were not that innovative, right, from changes of scaling things into GPUs into from CPUs and GPUs and things like that. But I don't think that there are basically they're not many things if you take a person that died in the 70s and was at the top of their game, they would not need to read that many books. To be current again, but it's

Lex Fridman 1:35:01
all about books, who cares about books, the there might be things that are beyond books might be papers or papers, forget papers, there might be things that are so papers and books and knowledge. That's, that's a concept of a time when you were sitting there by candlelight and individual consumers of knowledge. What about the impact that we're not in the middle of we're not might not be understanding of Twitter of YouTube. The reason you and I are sitting here today is because of Twitter and YouTube. So the the ripple effect, and there's, there's two minds, sort of two dumb apes are coming up with a new, perhaps a new clean insights. And there's 200 other apes listening right now. 200,000 other apes listening right now. And that effect, it's very difficult to understand what that effect will have that might be bigger than any of the advancements of the microprocessor, or the Industrial Revolution, the ability of spread knowledge, and that that knowledge, the like, it allows good ideas to reach millions, much faster. And the effect of that that might be the new that might be the 21st century is the multiple multiplying ideas of good ideas. Because if you say one good thing today, that will multiply across, you know, huge amounts of people and then they will say something and then they'll have another podcast and they'll say something, and then they'll write a paper that that could be a huge, you don't think that?

Joscha Bach 1:36:31
Yeah, you should have billions fun for Norman's right and offer Norman's right now and Turing's and we don't for some reason, I suspect the reason is that we destroy our attention span. Also the incentives of course, different. But Kardashians. Yeah. So the reason why we are sitting here and doing this as a YouTube video is because you and me don't have the attention span to write a book together right now. And you guys probably don't have the attention span to read it. So let me

Lex Fridman 1:36:54
guarantee you, they're still listening,

Unknown 1:36:57
your attention.

Lex Fridman 1:37:00
But we're, you know, we're an hour and 40 minutes in and I guarantee you that 80% of the people are still listening. So there's an attention span. It's just the form, you know, who said that the book is the optimal way to transfer information that said, this is still an open question. I mean, that's what we're something

Joscha Bach 1:37:15
that social media could be doing that other forms could not be doing. I think the end game of social media is a global brain. And Twitter is in some sense, a global brain that is completely hooked on dopamine doesn't have any kind of inhibition. And as a result is called an a permanent seizure. Yes, it's also in some sense, multiplayer role playing game. And people use it to play an avatar that is not like them. Yes, the awareness, sane world, they look through the world through the lens of their phones, and think it's the real votes. But it's the tweet about the distorted by the popularity incentives of Twitter.

Lex Fridman 1:37:47
Yeah, the the incentives and just our natural biological, the dopamine rush of a like, no matter how, like I consider I tried to be very kind of Zen like, and minimalist and not be influenced by likes and so on. But it's probably very difficult to avoid that to some degree. The speaking that a small tangent of Twitter, what? How can be how can twitter be done better? I think it's an incredible mechanism that has a huge impact on society by doing exactly what you're doing, say, doing exactly you described which is having this. We're like, is this some some kind of game and we're kind of individual RL agents in this game. And it's uncontrollable, because there's not really a centralized control. Neither Jack Dorsey nor the engineers at Twitter, seem to be able to control this game. Or can they? as sort of a question, is there any advice you would give on how to control this

Joscha Bach 1:38:49
device, because I am certainly not an expert, but I can give my thoughts on this. And I, our brain is has solved this problem to some degree, right? Our brain has lots of individual agents that manage to play together in a way. And you have also many contexts in which other organisms have found ways to solve the problems of cooperation that we don't solve on Twitter. And maybe the solution is to go for an evolutionary approach. So imagine that you have something like Reddit, or something like Facebook and something like Twitter, and you think about what they have in common, what they have in common. They are companies that in some sense, own a protocol. And this protocol is imposed on a community. And the protocol has different components for monetization for user management for user display for rating for anonymity for import of other content, and so on. And now imagine that you take these components of the protocol apart, and you do it, in some sense, like communities visit this social network. And these communities are allowed to mix and match their protocols and design new ones. So for instance, the UI and the UX can be defined by the community, the rules for sharing content across communities can be defined, the monetization can be redefined. The way you reward individual users for what can be redefined the way users can represent themselves and to each other can redefined. Be the

Lex Fridman 1:40:15
redefine. So can individual human beings build enough intuition to redefine those things, if they

Joscha Bach 1:40:20
have can become part of the protocol. So for instance, it could be in some communities, it will be a single person that comes up with these things. And others, it's a group of friends, some might implement a voting scheme that has some interesting weighted voting, who knows, who knows what will be the best self organizing principle for this, but the

Lex Fridman 1:40:37
process can be automated. I mean, it seems like the brain can be

Joscha Bach 1:40:41
automated, so people can write a software for this. And eventually, the idea is, let's not make a assumption about this thing. If you don't know what the right solution is in those areas, then you have no idea whether the right solution will be people designing this ad hoc, or machines doing this, whether you want to enforce compliance by social norms like Wikipedia, or this software solutions, or this AI that goes to the posts of people, or is a legal principle and so on. This is something maybe you need to find out. And so the idea would be if you let the communities evolve, and you just control it to serve in such a way that you are incentivized in the most sentient communities, the ones that produce the most interesting behaviors that allow you to interact in the most helpful ways to the individuals, right. So you have a network that gives you information that is relevant to you, it helps you to maintain relationships to others in healthy ways. It allows you to build teams, it allows you to basically bring the best of you into this thing and goes into a coupling into a relationship with others in which you produce things that you would be unable to produce alone. Yes,

Lex Fridman 1:41:47
beautifully put so. But the key process of that was incentives and evolution is things that don't adopt themselves to effectively get the incentives have to die. And the thing about social media is communities that are unhealthy, or whatever you want to define as these centers really don't like dying. One of the things that people really get aggressive protests aggressively, is when they're censored. I especially in America, I don't know, I don't know much about the rest of the world. But the idea of freedom of speech, the idea of censorship is really painful in America. And so what? What do you think about that have been grown up in East Germany? What do you think censorship is an important tool in our brain and the intelligence and in the social networks. So basically, if you're not a good member of the entirety of the system, they should be blocked away, while locked away blocked.

Joscha Bach 1:42:55
Important thing is who decides that you're a good member who is a distributed or and what is the outcome of the process that decides it, both for the individual and for society at large. For instance, if you have a high trust society, you don't need a lot of surveillance. And the surveillance is even, in some sense, undermining trust, because it's basically punishing people that look suspicious when surveyed, but do the right thing anyway. And the opposite, if you have a low trust society, then Surveillance can be a better trade off. And the US is currently making a transition from a relatively high trust and mixed trust society to a low trust society. So surveillance will increase. Another thing is that beliefs are not just invalid representations, there are implementations that run code on your brain, and change your reality and change the way you interact with each other at some level. And some of the beliefs are just public opinions that we use to display our alignment. So for instance, people might say, all cultures have are the same and equally good. But still, they prefer to live in some cultures over others very strongly so. And it turns out that the cultures are defined by certain rules of interaction. And these rules of interaction lead to different results when you implement them, right. So if you adhere to certain worlds, you get different outcomes in different societies. And this all leads to very tricky situations when people do not have a commitment to shared purpose. And our societies where we need to rediscover what it means to have a shared purpose and how to make this compatible with a non totalitarian view. So in some sense, the US is caught in a conundrum between totalitarianism and diversity and doesn't need to how to resolve this and the solutions that the US has found so far are very crude, because it's a very young society. That is also under a lot of tension. That seems to me that the US will have to reinvent itself. What do you think,

Lex Fridman 1:44:52
just philosophizing, what kind of mechanisms of government Do you think we as a species should be evolved with us? Or broadly, what do you think will work? Well? As a system? Of course, we don't know it all seems to work pretty crappy, some things worse than others. Some people argue that communism is the best other say, yeah, look at the Soviet Union. Some people argue that anarchy is the best, and then completely discarding the positive effects of government. You know, there's a lot of arguments, USA seems to be doing pretty damn well, in the span of history. There's respect for human rights, which seems to be a nice feature, not a bug, and economically a lot of growth or technological development. People seem to be relatively kind on the grand scheme of things. What lessons do you draw from that? What kind of government system do you think is good?

Joscha Bach 1:45:54
Ideally, government should not be perceivable. Right? It should be frictionless. The more you notice the influence of the government, the more friction you experience, the less effective and efficient the government probably is, right? So a government game theoretically is an agent that imposes an offset on your payout metrics to make your Nash equilibrium compatible with the common good. So you have these situations where these local incentives, everybody does the thing that's locally the best for them, but the global outcome is not good. And is even the case when people care about the global outcome. Because a regulation mechanisms exist, that creates a causal relationship between what I want to have for the global good, and what I do. So for instance, I think that we should fly less, and I stay at home, there is not a single plane that is going to not start because of me, right? It's not going to have an influence, but I don't get from A to B. So the way to implement this would basically to have a government that is sharing this idea that we should fly less is then imposing regulation that, for instance, makes flying more expensive, and gives incentives for inventing other forms of transportation that are that's putting that strain on the environment. For instance.

Lex Fridman 1:47:12
There's so much optimism and so many things you describe, and yet there's the pessimism of you think our civilization is going to come to an end. So that's not 100% probability, nothing in this world is. So what's the trajectory out of self destruction? Do you think

Joscha Bach 1:47:29
I suspect that in some sense, we are both too smart and not smart enough, which means we are very good at solving near term problems. And at the same time, we are unwilling to submit to the to the imperatives of that we would have to follow and if you want to stick around, right? So that makes it difficult. If you were unable to solve everything testing technologically, you can probably understand how hide the child mortality needs to be to absorb the mutation rate, and why the mutation mutation rate needs to be to adapt to a slowly changing ecosystemic environment, right. So you could in principle, compute all these things game theoretically and adapt to it. But if you're cannot do this, because you are like me, and you have children, you don't want them to die, you will use any kind of medical information to keep Padma, mortality low, even if it means that our vision a few generations, we have enormous genetic drift. And most of us have allergies as a result of not being adapted. Those changes that we made to our food supply,

Lex Fridman 1:48:27
that's for now I say, technologically speaking, which is a very, we're very young, you know, 300 years Industrial Revolution. We're very new to this idea. So you're attached to your kids being alive and not being murdered for the greater good of society. But that might be a very temporary moment of time. Yes, that we might move might evolve in our thicket. So like you said, when we're both smart and not smart enough,

Joscha Bach 1:48:50
you're probably not this first human civilization that has discovered technology that allows us to efficiently over graze our resources. And this overgrazing is thing, at some point, we think we can compensate this because if we have eaten all the grass, we will find a way to grow mushrooms. Right. But it could also be that the ecosystems tip and so what really concerns me is not so much the end of the civilization, because we will invent a new one. But what concerns me is the fact that for instance, the oceans might tip. So for instance, maybe the plankton dies because of ocean acidification and the bacteria take over. And as a result, we can no longer raise the atmosphere. This would be really concerning. So basically, major reboot of most complex organisms on Earth. And I think this is a possibility. I don't know if what the percentage for this possibility is but it doesn't seem to be outlandish to me if you look at the scale of the changes that we've already triggered on this planet. And so Daniella, such as that instance, we may be able to put chalk into the stratosphere to limit solar radiation, maybe it works. Maybe this is sufficient to counter the effects of what we've done. Maybe it won't Maybe we won't be able to implement it by the time it's prevalent. I have no idea how how the future is going to play out in this regard. It's just I think it's quite likely that we cannot continue like this all our cousins species, the other hominids are gone.

Lex Fridman 1:50:14
So so. So the the right step would be to what your wind drew wind towards the Industrial Revolution and slow the slow try to contain the technological process that leads to the overconsumption of resources.

Joscha Bach 1:50:32
Imagine you get to choose, you have one lifetime, yes, you get born into a sustainable agricultural civilization 300, maybe 400 million people on the planet tops. Or before this some kind of nomadic species was like a million or 2 million. And so you don't meet new people unless you give birth to them. You cannot travel to other places in the world, there is no internet, there is no interesting intellectual tradition that reaches considerably deep. So you would not discover Turing completeness, probably, and so on. We wouldn't exist. And the alternative is you get born into an insane world, one that is doomed to die because it has just burned 100 million years worth of trees in a single century.

Lex Fridman 1:51:12
Which one do you like?

Joscha Bach 1:51:14
I think I like this one. It's a very weird thing, then when you find yourself on a Titanic and you see this iceberg, and it looks like we are not going to miss it. And a lot of people are in denial. And most of the counter arguments sound like denial to me, they don't seem to be rational arguments. And the other thing is, we are born on this Titanic. Without this titanic, we wouldn't have been born, we wouldn't be here, we wouldn't be talking, we wouldn't be on the internet, we wouldn't do all the things that we enjoy. And you're not responsible for this happening. It's basically, if you had the choice, we would probably try to prevent it. But when we were born, we were never asked when we want to be born in which society we want to be born, what incentive structures we want to be exposed to, we have relatively little agency in the entire thing. Humanity has relatively little agency in the whole thing. It's basically a giant machine. It's tumbling down a hill, and everybody is frantically trying to push them buttons. Nobody knows what these buttons are, meaning what they connect to. And most of them are not stopping this tumbling down the hill.

Lex Fridman 1:52:13
Is it possible that artificial intelligence will give us an escape latch somehow? So the you know, there's a lot of worry about existential threats of, of artificial intelligence. But what AI also allows in general forms of automation allows the potential of Extreme Productivity growth, that will also perhaps in a positive way, transform society that may allow us to, inadvertently to return to the more to the same kind of ideals of closer to nature that's represented in hunter gatherer societies. You know, that's not destroying the planet that's not doing overconsumption, and so on. I mean, generally speaking, do you have hope that AI can help them?

Joscha Bach 1:53:06
I think it's not fun to be very close to nature until you completely subdue nature. So our idea of being close to nature means being close to agriculture. Basically, if a forest that don't have anything in them, that eats us,

Lex Fridman 1:53:22
see, I mean, I want to disagree with that I, I think the niceness of being close to nature is to being fully present. And in like wetlands survival becomes your primary, not just your goal, but your whole existence. It I mean, that is I'm not just romanticizing, I can just speak for myself, I am self aware enough, that that is that is a fulfilling existence. And it's one that's very hard

Joscha Bach 1:53:56
to be neutral and not fight for my survival. I think fighting and yourself for your survival, while being in the cold, and in the rain, and being hunted by animals and having open wounds is very unpleasant, whether

Lex Fridman 1:54:07
he there's a contradiction in there. Yes, I, and you, just as you said, would not choose it. But if I was forced into it, it will be fulfilling existence, those

Joscha Bach 1:54:19
who are adapted to it, basically, if your brain is wired up in such a way that you will get rewards optimally in such an environment. And there's some evidence for this, that for certain degree of complexity, basically, people are more happy in such an environment because it's what we largely have evolved for, in between. We had a few 1000 years in which I think we have evolved for a slightly more comfortable environment. So there is probably something like an intermediate stage in which people would be more happy than they would be if they would have to fend for themselves in small groups in the forest and often die. versus something like this where we now have basically a big machine, a big mod War in which we run to concrete boxes and press buttons and machines, and largely don't feel well cared for as the monkeys that we are.

Lex Fridman 1:55:13
So returning briefly to not briefly, but returning to AI. What Let me ask a romanticized question, what is the most beautiful to you? Silly ape, the most beautiful or surprising idea in the development of artificial intelligence, whether in your own life or in the history of artificial intelligence that you've come across.

Joscha Bach 1:55:33
If you build an AI, it probably can make models at an arbitrary degree of detail right of the world. And then it would try to understand its own nature, it's tempting to think that at some point, when we have general intelligence, we have competitions, where we will let the AIS wake up in different kinds of physical universes. And we measure how many movements of the Rubik's cube it takes until it's figured out what's going on in its universe, and what it is, and its own nature and its own physics and so on. Right? So what if we exist in the memory of an AI that is trying to understand its own nature and remembers its own Genesis and remembers Lex and Yahshua sitting in a hotel, sparking some of the ideas of that led to the development of general intelligence aware

Lex Fridman 1:56:16
a kind of simulation that's running in an AI system that's trying to understand itself?

Joscha Bach 1:56:22
It's not that I believe that, but as I think it's beautiful.

Lex Fridman 1:56:28
I mean, you kind of return to this idea with a Turing test of intelligence being of intelligence being the process of asking and answering what is intelligence? I mean, what why do you think there's there is an answer what, why is there such a search for an answer? What so does there have to be like an, like an answer, you just had an AI system that's trying to understand the why, of what, you know, understand itself? Is that a fundamental process of greater and greater complexity? greater greater intelligence? Is the continuous trying of understanding itself?

Joscha Bach 1:57:15
No, I think you will find that most people don't care about that. Because they're well adjusted enough to not care. And the reason why people like you will me care about it probably has to do with the need to understand ourselves. It's because we are in fundamental disagreement with the universe that we make up. And was that looked down on me and I see, oh, my God, I'm caught in a monkey. What's that? Feeling, right? Just the government, and I'm unhappy with the entire universe, and I find myself in.

Lex Fridman 1:57:42
So you don't think that's a fundamental aspect of human nature that some people are just suppressing, that they wake up shocked? They're in the body of a monkey.

Joscha Bach 1:57:52
Now there is a clear adaptive value to not be confused by that. And by

Lex Fridman 1:57:58
Well, no, that's not what so. So you have to clear adaptive value, then those clear adaptive value to while fundamentally your brain is confused by that, by creating an illusion, another layer of the narrative that says, you know, that tries to suppress that, and instead say that, you know, what's going on with the government right now is the most important thing, or what's going on with my football team is the most important thing. But it seems to me like it. Like for me, it was a really interesting moment reading Ernest Becker's Denial of Death, that, you know, this this kind of idea that we're all, you know, the fundamental thing from which most of our human mind Springs is this fear of mortality, of being cognizant and your mortality and the fear of that mortality? And then you construct illusions on top of that, I guess I'm you being just to push on it, you really don't think it's possible that this worry of the big existential questions is actually fundamental, as of as existential is thought to our existence. I think

Joscha Bach 1:59:13
that if you have this only place on wall, as long as you don't see the big picture, the thing is that minds are software states, right? Software doesn't have identity. Software, in some sense, is a physical law. But

Lex Fridman 1:59:26
alas, I believe, right off, but it feels like there's an identity I thought that was the for this particular piece of software. And the narrative it tells that's a fundamental property with assigning

Joscha Bach 1:59:38
maintenance of the identity is not terminal, it's instrumental to something else. You maintain your identity so you can serve your meaning so you can do the things that you're supposed to do before you die. And I suspect that for most people, the fear of death is the fear of dying before they're done with the things that they feel they have to do even though they cannot quite put their finger on it, but it is what that is.

Lex Fridman 1:59:59
Right? But in the software world, the return to the question, then what happens after we die?

Joscha Bach 2:00:10
Because you will not be longer there the the point of dying is that you have gotten,

Lex Fridman 2:00:15
well, maybe I'm not this is what you know. It seems like there's so much in the idea that this is just the mind is just a simulation, this constructing a narrative around some particular aspects of the quantum mechanical wave function world that we can't quite get direct access to, then like the idea of mortality seems to be fuzzy as well, it doesn't maybe there's not a clear and

Joscha Bach 2:00:46
fuzzy idea is the one of continuous existence, we don't have continuous existence. How do you know that like that? This is not computable.

Lex Fridman 2:00:55
Because you're saying it's good.

Joscha Bach 2:00:56
It's not a continuous process, the only thing that binds you together with the next Wedeman from yesterday is the illusion that you have memories about him. So if you want to upload, it's very easy, you make a machine that thinks it's you. Because that's the same thing that you are, you're a machine that thinks it's you. But that's, that's more, that's a mortality. Yeah, but it's just a belief, you can create this belief very easily once you realize that the question whether you are immortal or not depends entirely on your beliefs and your own continuity,

Lex Fridman 2:01:23
but then then, then you can be immortal by the continuity of the belief, and you

Joscha Bach 2:01:29
cannot be immortal, but you can stop being afraid of your mortality, because you realize you were never could never continuously exist in the first place.

Lex Fridman 2:01:37
What I don't know if I'd be more terrified or less terrified with it, it seems like the fact that I existed.

Joscha Bach 2:01:43
So you don't know the state in which you don't have a self, you can turn off yourself, you know, I can't turn you can turn it off, you can turn it off, I can, yes. So you can basically meditate yourself in a state where you're still conscious, there's still things are happening, but you know, everything that you knew before, but you're no longer identified with changing anything. And this means that yourself in a way dissolves, there is no longer this person, you you know that this person construct exists in other states, and it runs on this brain of Lex Friedman. But it's it's not a real thing. It's a construct, it's an idea. And you can change that idea. And if you let go of this idea, if you don't think that you are special, you realize it's just one of many people, and it's not your favorite person even right, it's just one of many. And it's the one that you are doomed to control for the most part, and that is basically informing the actions of this organism. Yeah, as a control model. This is all there is. And you're somehow afraid that this control model gets interrupted? Or loses the identity of continuity?

Lex Fridman 2:02:48
Yeah, so I'm attached. I mean, yeah, there is a very popular, it's a somehow a compelling notion that being being attached, like there's no need to be attached to this idea of an identity. But that in itself could be a an illusion that you construct through the process of meditation, while popularity is thought of as getting under the concept of identity, it could be just putting a cloak over it, just telling it to be quiet for the moment. You know,

Joscha Bach 2:03:21
I think that meditation is eventually just a bunch of techniques that let you control attention. And when you can control the attention, you can get access to your own source code, hopefully not before you understand what you're doing. And then you can change the way it works temporarily or permanently.

Lex Fridman 2:03:36
So yeah, meditations get get a glimpse at the source code get under the so basically, control

Joscha Bach 2:03:42
or entire thing is that you've learned to control attention. So everything else is downstream from controlling attention

Lex Fridman 2:03:48
and control the attention that's looking at the attention, not only

Joscha Bach 2:03:52
the only get attention, and the parts of our mind that create heat, where you have a mismatch between model and the results that are happening. And so most people are not self aware, because their control is too good. If everything works out roughly the way you want. And the only things that don't work out is whether your football team events, then you will mostly have models about these domains. And it's only when, for instance, your fundamental relationships to the world around you don't work because the ideology of your country is insane. And the other kids are not nerds and don't understand why you understand physics, and you don't why you want to understand physics, and you don't understand why somebody would not want to understand physics.

Lex Fridman 2:04:32
So we've kind of brought up neurons in the brain as reinforcement learning agents. And there's been some successes as you brought up with, go with AlphaGo Alpha zero, with ideas of self play, which I think are incredibly interesting ideas of systems playing each other in an automated way to improve by playing other systems of in a particular construct of a game that a little bit better than itself and then thereby improving continuously, all the competitors in the game are improving gradually. So being just challenging enough and from learning from the process of the competition, do you have hope for that reinforcement learning process to achieve greater and greater level of intelligence. So we talked about different ideas in AI that need to be solved, is RL, a part of that process of trying to create an AGI system, so many

Joscha Bach 2:05:29
forms of unsupervised learning, but there are many algorithms that can achieve that. And I suspect that ultimately, the algorithms that work they will be class of them are many of them. And they might have small differences of like magnitude in efficiency. But eventually, what matters is the type of model that you form. And the types of models that we form right now, we're not sparse enough.

Lex Fridman 2:05:53
Just Marcel, what does it mean to be sparse,

Joscha Bach 2:05:55
so it means that ideally, every potential model state should correspond to a potential world state. So basically, if you vary states in your model, you'll always end up with valid world states. And our mind is not quite there. So an indication is basically what we see in dreams. The older we get, the more boring our dreams become. Because we incorporate more and more constraints that we learned about how the world works. So many of the things that we imagined to be possible as children turned out to be constrained by physical and social dynamics. And as a result, fewer and fewer things remain possible. It's not because our imagination scales back. But the constraints under which it operates become tighter and tighter. And so the constraints under which our new networks operate are almost limitless, which means it's very difficult to get a neural network to imagine things that look real, right. So I suspect part of what we need to do is we probably need to build dreaming systems, I suspect that part of the purpose of dreams is to similar to a generative adversarial network that learns certain constraints. And then it produces alternative perspectives on the same set of constraints. So you can recognize it under different circumstances. Maybe we have flying dreams as children, because we recreate the objects that we know and the maps that we know from different perspectives, which also means from a bird's eye perspective.

Lex Fridman 2:07:20
So I mean, aren't we doing that anyway? I mean, not without, with our eyes, and with our eyes closed, and when we're sleeping, how we just constantly running dreams and simulations in our mind as we try to interpret the environment. I mean, sort of considering all the different possibilities, or the way we interact with the environment seems like, essentially, like you said, sort of creating a bunch of simulations that are consistent with our expectations with our previous experiences with the things we just saw recently. And through that hallucination process, we are able to then somehow stitch together what actually we see in the world with the simulations that match it well, and thereby interpret it,

Joscha Bach 2:08:09
I suspected you're in my brain are slightly unusual in this regard, which is probably what got you into MIT. So this obsession of constantly pondering possibilities and solutions to problems,

Lex Fridman 2:08:21
or stop it, I think, I'm not talking about intellectual stuff. I'm talking about just doing the kind of stuff it takes to walk and not fall. I guess this is

Joscha Bach 2:08:35
largely automatic.

Lex Fridman 2:08:39
Yes, but the process is, I mean,

Joscha Bach 2:08:41
it's not complicated. It's relatively easy to build a neural network that, in some sense, learns the dynamics, the fact that we haven't done it right, so far, it doesn't mean it's hard, because you can see that a biological organism does it was relatively few neurons. Yeah, basically, you build a bunch of neural oscillators that and train themselves with the dynamics of your body in such a way that the regulator becomes isomorphic in its model, to the dynamics that are regulates, and then is automatic. And it's only interesting in the sense that it captures attention when the system is off.

Lex Fridman 2:09:11
See, but thinking of the kind of mechanism that's required to do walking as a controller as like a, as a neural network, I think. I think it's a compelling notion, but it discards quietly, or at least makes implicit the fact that you need to have something like common sense reasoning, to walk as not as an open question whether you do or not, but the My intuition is to be to act in this world. There's a huge knowledge base that's underlying it somehow. There's so much information of the kind we have never been able to construct in our in neural networks and artificial intelligence systems period, which is like it's humbling. At least in my imagination, the The amount of information required to act in this world humbles me. And I think saying that no that was gonna accomplish it is missing is missing the fact that we don't we don't have yet a mechanism for constructing something like common sense reasoning. And what's your son's about? to linger on how much of to linger on the idea of what kind of mechanism would be effective at walking, you said just a neural network, not maybe the kind we have, but something a little bit better, we'll be able to walk easily, don't you think? It also needs to know? Like, huge amount of knowledge that's represented under the flag of common sense reasoning, how

Joscha Bach 2:10:48
much common sense knowledge to be actually have imagine that you're really hard working for all your life and your form to new concepts every half hour? So you end up with something like a million concepts because you don't get that old? So a million concept, that's not a lot.

Lex Fridman 2:11:05
So it's not just the million concepts, I think it'd be a lot. I personally think it might be much more than a million.

Joscha Bach 2:11:11
Do you think just about the numbers? You don't live that long? If you think about how many cycles do your neurons have in your life, it's quite limited. You don't get that old?

Lex Fridman 2:11:21
Yeah, but the powerful thing is the number of concepts in there, probably deeply hierarchical in nature, the relations as you described between them as the key thing. So it's like, even if it's a million concepts, the graph of relations that's formed, and some kind of perhaps some kind of probabilistic relationships, that's the that's what's common sense reasoning is the relationship between things. That,

Joscha Bach 2:11:49
yeah, so But in some sense, I think of the concepts as the address space for our behavior programs. And the behavioral problems allow us to recognize objects and interact with them, also mental objects. And a large part of that is the physical world that we interact with, which is this rest extender thing, which is basically navigation of information and space. And basically, it's similar to a game engine. It's a physics engine that you can use to describe and predict how things that look in a particular way that feel when you touch them particular way, the law, proprioception, of auditory perception, and so on how they work out. So basically, the geometry of all these things, and this is probably 80% of what our brain is doing is dealing with step two is this real time simulation. And by itself, a game engine is fascinating. But it's not that hard to understand what it's doing right. And our game engines are already in some sense, approximating the manga, the fidelity of what we can perceive. So if we put on an Oculus quest, we get something that is still relatively crude with respect to what we can perceive. But it's also in the same ballpark already, right? It's just a couple order of magnitudes away to home, saturating our perception of the complexity that it can produce. So in some sense, it's reasonable to say that our computer that you can buy the put into your home is able to give a perceptual reality that has a detail that is already in the same ballpark as what your brain can process. And everything else are ideas about the world. And I suspect that they are relatively sparse, and also the intuitive models that we form about social interaction, social interaction is not so hard. It's just hard for us nerds, because we all have our wires crossed, we need to introduce them. But the priors are present in most social animals. So it's interesting thing to notice that many domestic social animals, like cats and dogs have better social cognition than children. Right?

Lex Fridman 2:13:49
I hope so. I hope it's not that many concepts fundamentally, to do to exist in this world.

Joscha Bach 2:13:55
War II, it's more like frayed. So because this thing that we only appear to be so complex to each other, because we are so stupid, it's a little bit depressing.

Lex Fridman 2:14:03
Now, one, that's yeah, to me that's inspiring, for indeed, as stupid as it seems, thinks

Joscha Bach 2:14:11
our brains don't scale and the information processing that we build tend to scale very well.

Lex Fridman 2:14:16
Yeah, but I mean, one of the things that worries me is that, you know, that the fact that the brain doesn't scale means that that's actually a fundamental feature of the brain, you know, the, all the flaws of the brain everything we see that we see as limitations, perhaps there's a fundamental the constraints on the system could be the requirement of its power, which is like, different than our current understanding of intelligence systems where scale, especially with deep learning, especially with reinforcement learning, the Hope Behind open AI and deep mind all the major results really have to do with huge compute. And

Joscha Bach 2:14:59
you have to also be the Brains are so small not just because they take up so much glucose and our body, like 20% of the glucose, so they don't arbitrarily scale. But there are some animals like elephants which have larger brains than us, and they don't seem to be smarter. Right, elephants seem to be autistic, they have very, very good motor control. And they're very good with details, but they really struggle to see the big picture. So you can make them recreate drawings, stroke, by stroke, they can do that. But they cannot reproduce a still life. So they cannot make a drawing of a scene that they see, they will always be only able to reproduce the line drawing at least as far as what from what I could see in the experiments. Why is that maybe smarter elephants would meditate themselves out of existence, because their brains are too large. So the basically the elephants that were not autistic, they didn't reproduce

Lex Fridman 2:15:46
yet. So we have to remember that the brain is fundamentally interlinked with the body in our human and biological system. Do you think that AGI systems that we try to create a greater intelligence systems would need to have a body

Joscha Bach 2:15:58
so I think they should be able to make use of a body if you give it to them. But I don't think that they're fundamentally in the body. So I suspect if you can interact with the world, by moving your eyes and your head, you can make controlled experiments. And this allows you to have many magnitudes fewer observations, in order to reduce the uncertainty in your models, right, so you can pinpoint the areas, new models, but you're not quite sure. And you just move your head and see what's doing what's going on over there. And you get additional information. If you just have to use YouTube as an input. And you cannot do anything beyond this, you probably need just much more data. But we have much more data. So if you can build a system that has enough time and attention to browse through all of YouTube and extract all the information that there is to be found, I don't think there's an obvious limit to what it can do.

Lex Fridman 2:16:49
It seems that the interactivity is a fundamental thing that the physical body allows you to do. But let me ask on that topic, sort of that that's what a body is, is allowing the brain to like touch things and move things and interact with the way whether the physical world exists or not, whatever, but interact with somebody interface to the physical world. What about a virtual world? Do you think? Do you think we can do the same kind of reasoning, Consciousness Intelligence? If we put on a VR headset and move over to that world? Do you think there's a fundamental difference between the interface to the physical world that it's here in this hotel? And if we were sitting in the same hotel in a virtual world?

Joscha Bach 2:17:32
The question is, does this physic this non physical world or this other environment, yeah, entice you to solve problems that require general intelligence? If it doesn't, then you probably will not develop general intelligence. And arguably, most people are not genuinely intelligent, because they don't have to solve problems that make them genuinely intelligent. And even for us, it's not yet clear if we are smart enough to build AI and understand our own nature to this degree, right. So it could be a matter of capacity. And for most people, it's in the first place a matter of interest, they don't see the point, because the benefits of attempting this project are marginal, because you're probably not going to succeed in it. And the cost of trying to do well requires complete dedication of your entire life, right.

Lex Fridman 2:18:12
But it seems like the possibilities of what you can do in a virtual world. So imagine that is much greater than you can in the real world. So imagine a situation it'd be interesting option for me, if somebody came to me and offered, what I'll do is, so from now on, you can only exist in the virtual world. And so you put on his headset, and when you eat, we'll make sure to connect your body up in a way that when you eat in the virtual world, your body will be nourished in the same way in the virtual world. So the aligning incentives between the common sort of real world and the virtual world, but then the possibilities become much bigger. Like I could be other kinds of creatures that can do. I can break the laws of physics as we know them. I could do a lot of I mean, the possibilities are endless, right? It as, as far as we think. It's an interesting thought, whether like, what existence would be like, what kind of intelligence would emerge there, what kind of consciousness what kind of, maybe greater intelligence, even me and me, lacks even at this stage of my life, if I spend the next 20 years in that world, to see how that intelligence emerges. And if I was, if that happened at the very beginning, before I was even cognizant of my existence in this physical world, it's interesting to think how that child will develop and the way virtual reality and digitization of everything is moving. It's not completely out of the realm of possibility that we're all that some part of our lives will, if not entirety of it will live in a virtual world to a greater degree than we currently have living on Twitter and social media and so on. Do you have I mean, does something draw you intellectually or natural In terms of thinking about AI to this virtual world, where more possibilities are,

Joscha Bach 2:20:05
I think that currently it's a waste of time to deal with the physical verge before we have mechanisms that can automatically learn how to deal with it. The body gives you a second order agency, but you can't, what constitutes the body is the things that you can indirectly control. Right? So are our tools, right. And the second order is things that are basically always present, that you operate on them with first order things which are mental operators. And the zero order is, in some sense, the direct sense of what you're deciding, right. So you observe yourself initiating an action, there are features that you will interpret as the initiation of an action, then you will perform the operations that you perform to make that happen. And then you see the movement of your limbs, and you learn to associate those and thereby model your own agency over this feedback, right. But the first feedback that you get is from this first order thing already, basically, you decide to think a thought, and the thought is being thought you decide to change the slot, and you observe how the slot is being changed. And in some sense, this is you could say an embodiment already, right. And I suspect it's sufficient isn't embodiment, really worn elegance. And so

Lex Fridman 2:21:12
it's not that important, at least at this time to consider variations in the second order,

Joscha Bach 2:21:17
yes, but the thing that you also put up mentioned just now is a physics that you could change in any way you want. So you need an environment that puts up resistance against you, if you if there's nothing to control, you cannot make models, right, there needs to be a particular way that resists you. And by the way, your motivation is usually outside of your mind, it resists your motivation is what gets you up in the morning, even though it would be much less work to stay in bed. So it's basically forcing you to resist the environment. And it forces your mind to serve it to serve this resistance to the environment. So in some sense, it is also putting up resistance against the natural tendency of the mind to not do anything.

Lex Fridman 2:21:59
Yeah, but so some of their resistance, just like you described as motivation is like in the first order, it's in the mind, some resistance is in the second order, like actual physical objects pushing against and so on, it seems that the second order stuff in virtual reality could be recreated,

Joscha Bach 2:22:14
of course, but might be sufficient that you just do mathematics and mathematics is already putting up enough resistance against you. So basically just visit a static motive, this could maybe sufficient to form a type of intelligence, it would probably not be a very human intelligence, but it might be one that is already general.

Lex Fridman 2:22:34
So to mess with this zeroeth order, maybe first order, what do you think of ideas of brain computer interfaces? So again, returning to our friend, Elon Musk and neural link, a company that's trying to, of course, there's a lot of trying to cure diseases and so on with the near term, but the long term vision is to add an extra layer to so basically expand the capacity of the brain connected to the computational world. Do you think one that's possible to how does that change the fundamentals of the zeroeth order and the first order,

Joscha Bach 2:23:07
it's taken me possible, but I don't see that the FDA would ever allow me to drill holes in my skull to interface my neocortex debate. Elon Musk envisions so at the moment, I can do horrible things to mice. But I'm not able to do useful things to people except maybe at some point on the line in medical applications. So this thing that we are envisioning, which means recreational and creational, brain computer interfaces, are probably not going to happen in the present legal system.

Lex Fridman 2:23:35
I love it, how I'm asking you out there philosophical, and sort of engineering questions. And for the first time ever, you jumped to the legal FDA, there won't be

Joscha Bach 2:23:48
enough people that would be crazy enough to have holes drilled in their skull to try a new type of brain computer interface.

Lex Fridman 2:23:53
And also if it works, it FDA will approve it. I mean, yes, you're, it's like, you know, I work a lot with autonomous vehicles. Yes, you can say that it's going to be very difficult regulatory process of approving autonomous, but it doesn't mean autonomous vehicles are never going to happen. So

Joscha Bach 2:24:10
no, they will totally happen as soon as we create jobs for at least two lawyers and one regulator per car.

Lex Fridman 2:24:17
Yes, lawyers, that's actually like lawyers. This is the fundamental substrate of reality is

Joscha Bach 2:24:26
it's a very weird system. It's not universal in the world. The law is a very interesting software once you realize it, right. These circuits are, in some sense streams of software. And this is largely works by exception handling. So you make decisions on the ground and they get synchronized with the next level structure as soon as an exception is being thrown. It's a so so it escalates. The exception handling process is very expensive, especially since it's incentivizes the lawyers for producing lot of work for lawyers.

Lex Fridman 2:24:55
Yeah, so the exceptions actually incentivize for firing often But but the return outside of lawyers, is there anything fundamentally? Like, is there anything interesting insightful about the possibility of this extra layer of intelligence added to the brain?

Joscha Bach 2:25:15
I do think so. But I don't think that you need technically invasive procedures to do. So we can already interface with other people by observing them very, very closely and getting in some kind of empathetic resonance. And notice, I'm not very good at this. But I noticed that people are able to do this to some degree. And it basically means that we model an interface layer of the other person in real time. And it works despite our neurons being slow, because most of the things that we do are built on periodic processes. So you just need to train yourself with the oscillation that happens. And if the oscillation itself changes slowly enough, you can basically follow along,

Lex Fridman 2:25:54
right. But the bandwidth of the interaction, the you know, it seems like you can do a lot more computation when there's,

Joscha Bach 2:26:04
of course, the but the other thing is that the band was that our brain, our own mind is running on is actually quite slow. So the number of thoughts that I can productively think in any given day is quite limited. But it's much, if they had the discipline to write it down and the speed to write it down, maybe it would be a book every day or so. But if you think about the computers, that we can build the magnitudes at which they operate, right, this would be nothing, it's something that it can pull out in a second. While I

Lex Fridman 2:26:31
don't know. So as possible, sort of the number of thoughts you have in your brain is it could be several orders of magnitude higher than what you're possibly able to express through your fingers or through your voice, like,

Joscha Bach 2:26:44
so most of them are going to be repetitive, because they have you know that they have to control the same problems every day, when I walk, there are going to be processes in my brain that model my walking pattern and regulate them and so on. But it's going to be pretty much the same every day. But that will be with every step.

Lex Fridman 2:27:01
But I'm talking about an intellectual reason I keep thinking, so the question, what is the best system of government. So you sit down and start thinking about that, one of the constraints is that you don't have access to a lot of like you, you don't have access to a lot of facts, a lot of studies you have to do, you always have to interface with something else. To learn more to, to aid in your reasoning process, if you can directly access all of Wikipedia, in trying to understand what is the best form of government, then every thought won't be stuck in like, every thought that requires some extra piece of information will be able to grab it really quickly. That that's the possibility of if the bottleneck is literally the information that you know, the bottleneck of breakthrough ideas is just being able to quickly access huge amounts of information, then the possibility of connecting your brain to the computer could lead to totally new, like, you know, totally new breakthroughs, you can think of mathematicians being able to just up the orders of magnitude of power in their reasoning about mathematics,

Joscha Bach 2:28:09
humanity has already discovered the optimal form of government to evolutionary process, but it isn't evolutionary. And so what we discover is that maybe the problem of government doesn't have stable solutions for us, right, as a species, because we are not designed in such a way that we can make everybody conform to them. So but there could be solutions that work under given circumstances, or that are the best for certain environment and depends on, for instance, the primary forms of ownership and the means of production. So if the main means of production is land, then the forms of government will be regulated by the landowners and you get a monarchy. If you also want to have a form of government in which a subset, you depend on some form of slavery, for instance, where the peasants have to work very long hours for very little gain. So very few people can have plumping, then maybe you need to promise them that we had paid in the afterlife, the overtime, right? So you need a theocracy. And so for much of human history in the West, you had a combination of monarchy and theocracy. That was our form of governance, right. At the same time, the Catholic Church implemented game theoretic principles. I recently reread Thomas Aquinas, it's very interesting to see this because he was not duelist he was translating Aristotle in a particular way for designing an operating system for the Catholic society. And he says that basically people are animals very much the same way as Aristotle envisions which basically, organism has cybernetic control. And then he says that there are individual rational principles that humans can discover and everybody can discover them. So they are universal. If you are saying you should understand user pseudo submit to them, because you can rationally use them. And these principles are roughly you should be willing to self regulate correctly, you should be willing to do correct social regulation inter organismic, you should be willing to act on your models. So you have skin in the game. And you should have gold rationality, you should be choosing the right goals to work on. And so basically these three rational principles call rationality he calls prudence or wisdom. social regulation is justice, the correct social one, and the internal regulation is temperance. And this thing, willingness to act on your models is courage. And then he says that there are additionally to these four cardinal virtues, three divine virtues, and these three divine virtues cannot be rationally deduced. But they reveal themselves by the harmony, which means if you assume them, and you extrapolate what's going to happen, you will see that that makes sense. And it's often been misunderstood as God has to tell you that these are the things so they're basically there's something nefarious going on, the Christian conspiracy forces you to believe some guy with a long beard that they discovered this. But so these principles are relatively simple. Again, you need it's for high level organization for the resulting civilization that you form, commitment to Unity. So basically, you serve this higher, larger thing, this structural principle on the next level, and he calls that phase, then there needs to be commitment to shared purpose, this basically this global report that you try to figure out what that should be, and how you can facilitate this. And there's this love, the commitment to shared purpose is the core of love, right, you see the sacred thing that is more important than your own organismic interests in the other, and you serve this together. And this is how you see the sacred and the other. And the last one is hope. Which means you need to be willing to act on that principle without getting rewards in the here and now. Because it doesn't exist yet. Then you start out building the civilization, right? So you need to be able to do this in the absence of the its actual existence yet. So it can come into being

Lex Fridman 2:32:04
so yeah, so the way it comes into being is by you accepting those notions. And then you see there, these these three divine concepts, and you see them realize the

Joscha Bach 2:32:14
Divine is a loaded concept in our world, right, because we are outside of this card, and we are still scarred from breaking free of it. But the idea is basically we need to have a civilization that acts as an intentional agent, like an insect state. And we are not actually a tribal species, we are statebuilding species. And what what enabled state building is basically the formation of religious states and other forms of rule based administration, in which the individual doesn't matter as much as the rule or the higher goal, right? But we got there by the question, what's the optimal form of governance. So I don't think that capitalism, Catholicism is the optimal form of governance, because it's obviously on the way out, right? So it is for the present type of society that we are in religious institutions don't seem to be optimal to organize that. So what we discovered right now that we live in, in the West, is democracy. And democracy is the role of oligarchs that are the people that currently own the means of production. That is administered not by the oligarchs themselves, because they, there's too much disruption, right, we have so much innovation that we have, in every generation, new means of production that we invent, and corporations day of, usually after 30 years or so on something other takes a leading role in our societies. So it's administered by institutions. And these institutions themselves are not elected, but they provide continuity. And they are led by electrical politicians. And this makes it possible that you can adapt to change without having to kill people, right. So you can try for instance, if a change in government, if people think that the current government is too corrupt, or is not up to date, you can just elect new people. Or if a journalist finds out something inconvenient about the institution, and the institution is, has no plan B like in Russia, the journalist has to die. This is what when you run society by the deep state. So ideally, you have a administration layer, that you can change, if something bad happens, right, so you will have a continuity in the whole thing. And this is the system that we came up in the West. And the way it's set up in the US is largely a result of low level models. So it's mostly just second third order, consequences that people are modeling and the design of these institutions. It's relatively young society that doesn't really care take care of the downstream effects of many of the decisions that are being made. And I suspect that AI can help us this in a way if you can fix the incentives. This society of the US is a society of cheaters. It's basically cheating, so indistinguishable from innovation, and we want to encourage innovation. Can you elaborate on what you mean by cheating? It's basically people do things that they know are wrong. It's acceptable to do things that you know are wrong in this society or certain degree. You can, for instance, suggest some non sustainable business models and implement them.

Lex Fridman 2:34:57
Right but you're always pushing the boundaries. I mean, yes. If you're in it, yes,

Joscha Bach 2:35:01
this is seen as a good thing largely. Yes. And this is different from other societies. So for instance, social mobility is an aspect of this social mobility is the result of individual innovation that would not be sustainable at scale for everybody else, right? Normally, you should not go up, you should go deep, right? We need bakers. And indeed, we are very good bakers. But in a society that innovates, maybe you can replace all the bakers with a really good machine. Right. And that's not a bad thing. And it's a thing that made us so successful, right. But it also means that the US is not optimizing for sustainability, but for innovation.

Lex Fridman 2:35:35
And so it's not obvious as the evolutionary processes unrolling it's not obvious that that long term would be better.

Joscha Bach 2:35:41
But it's, it has side effects. So you basically, if you cheat, you will have a certain layer of toxic sludge that covers everything that is a result of teething.

Lex Fridman 2:35:50
And we have to unroll this evolutionary process to figure out if these side effects are so damaging that the system's horrible, or the benefits actually outweigh the the negative effects. How do we get to the which system of government is best? That was from I'm trying to trace back the last like five minutes,

Joscha Bach 2:36:10
I suspect that we can find a way back to AI by thinking about the way in which our brain has to organize itself. In some sense, our brain is this idea of neurons. And our mind is a society of behaviors. And they need to be organizing themselves into a structure that implements regulation and government is social regulation. We often see government as the manifestation of power, local interests, but it's actually a platform for negotiating the conditions of human survival. And this platform emerges over the current needs and possibilities and the trajectory that we have. So given the present state, there are only so many options on how we can move into the next state without completely disrupting everything. And we mostly agree that it's a bad idea to disrupt everything because it will endanger our food supply for a while, and the entire infrastructure and fabric of society. So we do try to find natural transitions. And there are not that many natural transitions available at any given point.

Lex Fridman 2:37:10
Are you a natural transition?

Joscha Bach 2:37:12
So we try not to have revolutions? If we can house it, right.

Lex Fridman 2:37:16
So speaking of revolutions, and the connection between government systems in the mind, you've also said that you said that, in some sense, becoming an adult means you take charge of your emotions, maybe never said that. Maybe I just made that up. But in the context of the mind, what's the role of emotion? And what is it first of all, what is emotion? What's its role?

Joscha Bach 2:37:42
It's several things. So psychologists often distinguish between emotion and feeling and common day parlance, we don't don't think that emotion is a configuration of the cognitive system. And that's especially true for the lowest level for the affective state. So when you have an effect, it's the configuration of certain modulation parameters like arousal valence, your your attentional focus, whether it's wide or narrow into reception, or external reception, and so on. And all these parameters together, put you in a certain way to relate to the environment and to yourself. And this is, in some sense, an emotional configuration. In the more narrow sense, an emotion is an affective state that has an object. And the relevance of that object is given by motivation. And motivation is a bunch of needs, that are associated with rewards, things that give you pleasure and pain. And you don't actually act on your needs, you act on models of your needs. Because when the pleasure and pain manifests, it's too late, you've done everything. But so you act on expectations that will give you pleasure and pain. And these are your purposes, the needs don't form a hierarchy, they just coexist and compete. And your organism has more your brain has to find it on dynamic homeostasis between them. But the purpose is need to be consistent. So you basically can create a story for your life and make plans. And so we organize them all into hierarchies. And there is not a unique solution for this. Some people eat to make art and other people are to eat, they might not be end up doing the same things, but they cooperate in very different ways. Because their ultimate goals are different and we cooperate based on shared purpose everything else that is not cooperation on shared purpose is transactional.

Lex Fridman 2:39:18
I don't think I understood that last piece of the Achieving the homeostasis Are you distinguishing between the experience of emotion and the expression of emotion?

Joscha Bach 2:39:30
Of course. So, the experience of Emotion is a feeling and in this sense, what you feel is an appraisal that your perceptual system has made of the situation at hand. And it makes this based on your motivation. And on the your estimates, not your but of the subconscious, geometric parts of your mind that assess the situation in the world with something like a neural network. And this neural network is making itself known to the symbolic parts of your mind to your conscious attention by mapping the MS features into a space. So what you will feel about your emotion is a projection usually into your body map. So you might feel anxiety in your solar plexus. And you might feel it as a contraction, which is all geometry, right? Your body map is the space that is always instantiate and always available. So it's a very obvious cheat, if your non symbolic parts of your brain try to talk to you symbolic parts of your brain to map the feelings into the body map. And then you perceive them as pleasant or unpleasant, depending on whether the appraisal has a negative or positive valence. And then you have different features of them that give you more knowledge about the nature of what you're feeling. So for instance, when you feel connected to other people, you typically feel this in your chest region around the heart. And you feel this as an expansive feeling in which you're reaching out, right. And it's very intuitive to encode it like this. It's a it's an encoded code, it's a code in which the non symbolic parts of your mind talk to the symbolic ones.

Lex Fridman 2:41:02
And then the expression of emotion is then the final step that could be sort of gestural, or visual, so on, that's just part of the communication,

Joscha Bach 2:41:10
we evolved as part of an adversarial communication. So as soon as you started to observe the facial expression and poster of others to understand what emotional state they are in, others started to use this as signaling and also to support your model of their emotional state. So we now look at the inflections that the difference between the standard face that they're going to make in the situation better when you are at a funeral, everybody expects you to make a solid face. But the soul and face doesn't express whether you're sad or not, it just expresses that you understand what face you have to make at a funeral. Nobody should know that you are Trump, Trump triumphant. So when you try to read the emotion of another person, you try to look at the delta between a set a truly set expression and the things that are any made it meeting this face behind the curtain.

Lex Fridman 2:41:56
So the interesting thing is, so having done these having done this podcast, and the video component, one of the things I've learned is that now I'm Russian, and I, I just don't know how to express emotion on my face, when I see that as weakness, but whenever the people look to me, after you say something they look to my face, to to help them see how they should feel about what you said, which is fascinating, because then they'll often comment on, why did you look bored? Or why did you particularly enjoy that part? Or why did you whatever, it's a kind of interesting, it makes me cognizant of part. Like, you're basically saying a bunch of brilliant things, but I'm part of the play that you are the key actor, and by making my facial expressions and therefore telling the narrative of what the big, like, the big point is just fascinating. Makes me makes you cognizant that I'm supposed to be making facial expressions, even this conversation is hard. Because my preference would be to wear a mask with sunglasses, to where I could just listen.

Joscha Bach 2:43:02
Yes. Which is understand this because it's intrusive, to interact with others this way and basically, Eastern European society have taboo against that, and especially Russia, the further you go to the east, and in the US, it's the opposite. You're expected to be hyper animated in your face. And you're also expected to show positive effect. Yes. And if you show positive effect without a good reason, in Russia, they people will think you are stupid unsophisticated person.

Lex Fridman 2:43:33
Exactly. And here positive effect without reason goes either appreciate or goes unnoticed.

Joscha Bach 2:43:40
Now, it's the default, it's being expected. Everything is amazing. Have you seen this? Lego Movie? No, there was a diagram where somebody gave the appraisals that exist in US and Russia. So you have your black curve, and the lower 10% in us? Yeah. Are. It's a good start. Everything above the lowest 10% is it's amazing. It's amazing. And for

Unknown 2:44:07
Russians, everything below the top 10% It's terrible. Then everything except the top percent is I don't like it in the top percent is even so. Yeah, it's

Lex Fridman 2:44:24
funny, but it's kind of true. No, yeah, that's a

Joscha Bach 2:44:27
deeper aspect to this. It's also how we construct meaning in the US. Usually you focus on the positive aspects and you just suppress the negative aspects. And, and our Eastern European traditions. We emphasize the fact that if you hold something above the waterline, you also need to put something below the waterline because existence by itself is best neutral.

Lex Fridman 2:44:51
Right? That's the basic intuition if at best neutral, yes, or just suffering the default there

Joscha Bach 2:44:57
are moments of beauty but these moments of beauty are in is inextricably linked to the reality of suffering. And to not acknowledge the reality of suffering means that you are really stupid unaware of the fact that basically every conscious being spends most of the time suffering.

Lex Fridman 2:45:12
Yeah. You just summarized the ethos of the Eastern Europe. Yeah. Most of life is suffering with occasional moments of beauty. And if your facial expressions don't acknowledge the abundance of suffering in the world and the existence itself, then you must be an idiot.

Joscha Bach 2:45:30
It's an interesting thing when you raise children in the US, and you, in some sense, preserve the identity of the intellectual and cultural traditions that are embedded in your own families. And your daughter asks you about Arielle the mermaid and asked you Why is Aria not allowed to play with the humans and you tell the truth, siren, sevens, if people you don't play with your foot, it does not end well. And then you tell her the original story, which is not the one by Andersen, which is the romantic one. And there's a much darker one, which is in a story. What happened. So when Dean is a mermaid, or what a woman She lives on the ground of a river and she meets this prince and they've fallen off. And the prince really, really wants to be with her. And she says, okay, but the deal is you cannot have any other women if you marry somebody else, even though you cannot be with me, because obviously you cannot breathe underwater. And I have other things to do within managing your kingdom because you have here, you will die. And eventually, after a few years, he falls in love with some princess and marries her. And she shows up and quietly goes into his chamber and nobody is able to stop her are willing to do so because he's fierce. And she comes quietly and said out of his chamber, and they asked her what has happened, what did you do when she said I kissed him to death? Or done? And do you know the origin story right? In the end isn't story, the mermaid is playing with the prints that she saves and she falls in love with him and she cannot live out there. So she is giving up her voice and her tail for human naked appearance. So she can walk among the humans but this guy does not recognize that she is the one that you would marry. Instead he marries somebody who has the kingdom and economical and political relationships to his own kingdom and so on. As he shoots quite tragic. She dies.

Lex Fridman 2:47:25
Yeah. Yeah, instead Disney. The Little Mermaid story has a little bit of a happy ending. That's the Western That's the American way.

Joscha Bach 2:47:37
And my own problem is this this of course that I read Oscar Wilde before I read the other things so I'm not indoctrinated, inoculated with this romanticism. And I think that the moment is right, you sacrifice your life for romantic love. That's what you do. Because if you are confronted with either serving the machine and doing the the obviously right thing under the economic and social and or other human incentives, that's wrong, you should follow your heart.

Lex Fridman 2:48:04
So do you think suffering is fundamental to happiness? Along these

Joscha Bach 2:48:09
lines, suffering is the result of caring about things that you cannot change. And if you are able to change what you care about, to those things that you can change, you will not suffer?

Lex Fridman 2:48:18
would then would you then be able to experience happiness? Yes.

Joscha Bach 2:48:22
But happiness itself is not important. Happiness is like a cookie. When you are a child, you think cookies are very important. And you want to have all the cookies in the world, you look forward to being an adult, because then you have as many cookies as you want, right? Yes. But as an adult, you realize a cookie is a tool. It's a tool to make you eat vegetables. And once you eat your vegetables anyway, you stop eating cookies, for the most part, because otherwise you will get diabetes and will not be around for your kids.

Lex Fridman 2:48:46
Yes. But then the cookie the scarcity of a cookie, if scarcities and forced nevertheless, like the pleasure comes from the scarcity,

Joscha Bach 2:48:54
yes, but the happiness is a cookie that your brain bakes for itself. It's not made by the environment, the environment cannot make you happy. It's your appraisal of the environment that makes you happy. And if you can change the appraisal of the environment, which you can learn to, then you can create arbitrary states of happiness. And some meditators fall into this trap. So they discover the room, this basement room in their brain where the cookies are made, and they indulgent stuff themselves. And after a few months, it gets really old. And the big crisis of meaning comes, because they saw before that their unhappiness was the result of not being happy enough. So they fixed it, right? They can release the neurotransmitters at will if they train, and then the crisis of meaning pops up at a deeper layer. And the question is, why do I live? How can I make a sustainable civilization that is meaningful to me? How can I insert myself into this and this was the problem that you couldn't solve in the first place.

Lex Fridman 2:49:47
And at the end of all this, let me then ask that same question, what is that the answer to that what could be the possible answer B of the meaning of life? What? What could an answer be? What is it to you

Joscha Bach 2:50:00
I think that if you look at the meaning of life, you look at what the cell is, life is the cell, where you resist. So yes, or this principle, the cell, it's this self organizing thing that can participate in evolution, in order to make it work. It's a molecular machine, it needs to self replicator and Nick entropy extractor and the Turing machine. If any of these parts is missing, you don't have a cell and it is not living, right. And life is basically the emergent complexity over that principle. Once you have this intelligent super molecule, the cell, there is very little that you cannot make it to it's probably the optimal computer on human, especially in terms of resilience. It's very hard to sterilize the planet once it's infected with life.

Lex Fridman 2:50:41
So it's active function of these three components of the supercell cell is present in the cell is present in us. And it's just the

Joscha Bach 2:50:51
address and expression of the cell, the certain layer of complexity and the organization of cells, that so in a way, it's tempting to think of the cell as a Von Neumann probe. If you want to build intelligence on other planets, the best way to do this is to infect them with cells and wait for long enough, and there's a reasonable chance the staff is going to evolve into an information processing principle that is general enough to become sentient

Lex Fridman 2:51:15
with that idea is very akin to sort of this the same dream and beautiful ideas that are expressed the cellular automata in their most simple mathematical form. He's just inject a system with some basic mechanisms of replication. So our basic rules, amazing things would emerge

Joscha Bach 2:51:33
at the cell is able to do something that James Hardy calls existential design, he points out that in technical design, we go from the outside in, we work in highly controlled environment in which everything is deterministic, like our computers have our labs, or our engineering workshops. And then we use this determinism to implement a particular kind of function that we dream up and that seamlessly interfaces with all the other deterministic functions that we already have in our world. So it's basically from the outside in. And biological systems designed from the inside out is seed will come to seedling by taking some of the relatively unorganized metal around it, and turn it into its own structure, and thereby subdue the environment and cells can cooperate if they can rely on other cells having a similar organization that is already compatible. But unless that's, that's there is no need to divide to create that structure by itself, right. So it's a self organizing principle that works on a somewhat chaotic environment. And the purpose of life in the sense is to produce complexity. And the complexity allows you to harvest Nick entropy gradients that you couldn't harvest without the complexity. And in this sense, intelligence and life are very strongly connected, because the purpose of intelligence is to allow control under conditions of complexity. So basically, you shift the boundary between the audit systems into the realm of the of chaos, you build bridgeheads into chaos, with complexity. And this is what we are doing. This is not necessarily a deeper meaning, I think the meaning that we have priors for that we have asked for outside of the priors, there is no meaning meaning only exists if a mind protects it. Right? Yeah, that is totally civilization, I think that what feels most meaningful to me is to try to build and maintain a sustainable civilization. And taking

Lex Fridman 2:53:21
a slight step. Outside of that we talked about a man with a beard, and God, but something, some mechanism, perhaps, must have planted the seed the initial seed of the cell. Do you think there is a God? What is a God? And what would that look like, though, if

Joscha Bach 2:53:44
there was no spontaneous abiogenesis that in the sense that the first cell formed by some happy, random accidents where the molecules just happened to be in the right consolidation to each other, but

Lex Fridman 2:53:55
there could also be the mechanism of that allows for the random? I mean, it is like turtles all the way down, there seems to be there has to be a head turtle at the bottom.

Joscha Bach 2:54:06
Or something really wild? Imagine? Is it possible that a gas giant could become intelligent, but would that involve? So imagine your jet, you have vortices that spontaneously emerge on the gas giants like big storm systems that endure for 1000s of years. And some of these storm systems produce electromagnetic fields because some of the clouds are ferromagnetic or something. And as a result, they can change how certain clouds react rather than other clouds and thereby produce some self stabilizing patterns that eventually lead to regulation, feedback loops, nested feedback loops and control. So imagine you have such this thing that basically has emergent self sustaining self organizing complexity, and at some point, this picks up and realizes and basically LEM Solaris, I am a thinking planet, but I will not replicate because I can recreate the conditions of my own existence somewhere else. I'm just basically an intelligence that has spontaneously formed because it could be And now it builds the Von Neumann probe. And the best von Neumann port for such a thing might be the cell. So maybe it will, because it's very, very clever and very enduring, create cells and sends them out and one of them has infected our planet. I'm not suggesting that is the case, but it would be compatible Vistaprint spam Ium hypothesis? And was my intuition that our biogenesis is very unlikely. It's possible, but it's, you probably need to go the cosmic dice very often, maybe more often than the planetary surfaces? I don't know.

Lex Fridman 2:55:29
So God is just a large enough, a system that's large enough, that allows randomness?

Joscha Bach 2:55:37
No, I don't think that God has anything to do with creation. I think it's a mistranslation of the Talmud into the Catholic mythology. I think that Genesis is actually the childhood memories of a god.

Lex Fridman 2:55:48
So the when sorry, the Genesis is the

Joscha Bach 2:55:51
childhood memories of a god, it's basically a mind that is memory, remembering how it came into being. And we typically interpret Genesis as the creation of a physical universe by a supernatural being Yes. And I think when you will read it, there is light and darkness that is being created. And then you'll discover sky and ground, you create them, you construct the plants and the animals, and you give everything that names and so on. That's basically cognitive development. It's a sequence of steps that every mind has to go through, when it makes sense of the world. And when you have children, you can see how initially, they distinguish light and darkness. And then they make all directions, and they discover sky and ground, and they discover the plants and the animals, and they give everything their name. And it's a creative process that happens in every mind, because it's not given right, your mind has to invent these structures to make sense of the patterns on your retina. Also, if there was some big nerd who set up a server and runs this world on it, this would not create a special relationship between us and the nerd, this nerd would not have the magical power to give meaning to our existence, right? So this equation of a Creator God with the God of meaning, is a sleight of hand, you shouldn't do it. The other one that is done in Catholicism is the equation of the first mover, the prime mover of Aristotle, which is basically the automaton that runs the universe Earth total says, if things are moving, and things seem to be moving here, something must move that right. If something moves them something must move the thing that is moving it so there must be a prime mover, this idea to say that this prime mover is a supernatural being is complete nonsense, right? It's an automaton in the simplest case, so we have to explain the enormity that this automaton exists at all. But again, we don't have any possibility to infer anything about his properties, except that it's able to produce change and information. Right. So there needs to be some kind of computational principle, this is all there is. But to say this automaton is identical, again, was the creator of first cause or the thing that gives meaning to our life is confusion. Now, I think that what we perceive is, the higher being that we are part of, the higher being that we are part of is the civilization. It's the thing in which we have a similar relationship as the cell has to our body. And we have this prior, because we have evolved to organize and the structures. So basically, the Christian God in its natural form without the mythology, if you address it, is basically the Platonic form of the civilization

Lex Fridman 2:58:30
is the is the ideal. So

Joscha Bach 2:58:32
it's this idea that you try to approximate when you interact with others, not based on your incentives, but on what you think is right.

Lex Fridman 2:58:40
Wow, we covered a lot of ground. And we're left with one of my favorite lines, and there's many, which is happiness is a cookie, that brain bakes itself. It's been a huge honor, and a pleasure to talk to you. I'm sure our paths will cross many times again. Joshua, thank you so much for talking today. Really particular next,

Joscha Bach 2:59:05
and so much fun. I enjoyed it. Awesome.

Lex Fridman 2:59:09
Thanks for listening to this conversation with Yoshi Bach, and thank you to our sponsors, ExpressVPN, and Cash App. Please consider supporting this podcast by getting ExpressVPN expressvpn.com/flex pod and downloading Cash App and using code Lex podcast. If you enjoy this thing, subscribe on YouTube, review five stars on Apple podcast supported on Patreon or simply connect with me on Twitter at Lex Friedman. And yes, try to figure out how to spell it without the E. And now let me leave you with some words of wisdom from your Shabbat. If you take this as a computer game metaphor, this is the best level for humanity to play. And this best level happens to be the last level as it happens again as the backdrop of a dying world but it's still the best level Thank you for listening and hope to see you next time
