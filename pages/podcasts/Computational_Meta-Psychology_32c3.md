Unknown 0:09
Our next talk is going to be about AI. And it's going to be about proper AI, it's not going to be about deep learning or buzzword bingo, it's going to be a lot of actual psychology. It's gonna be about computational meta psychology. And now please welcome Yoshua.

Joscha Bach 0:33
Thank you. I'm interested in understanding how the mind works. And I believe that the most fruitful perspective at looking at of looking at minds is to understand that your systems that if you saw patterns at them, you find meaning, and we find meaning in those in very particular ways. And this is what makes us who we are. So the way to study and understand who we are in my understanding is to build models of the information processing that constitutes our minds. Last year, but at the same time, I answered the four big questions of philosophy, what's the nature of reality? What can we know? Who are we? What should we do? So now how can I top this?

Joscha Bach 1:18
I'm going to give you the drama, the divided a planet, some of the very, very big events that happened in the course of last year, so I couldn't tell you about it before. What color is the dress?

Joscha Bach 1:38
I mean, if your head do not have any mental defects, you can clearly see it's white and gold, right? Turns out, most people seem to have mental defects and say that it's blue and black. I have no idea why? Well, okay, I have an idea why that is the case. I guess that you got to it has to do with color renormalization. And color renormalization happens differently, apparently in different people. So we have different wiring to renormalize, the white balance. And it seems to work in real world situations and pretty much the same way, but not necessarily for photographs, which have only a very small fringe around them, which gives you a hint about the lighting situation. And that's why you get these huge divergences, which is amazing. So what we see that our minds cannot know Objective Truth in any way, outside of mathematics, they can generate meaning, though. How does this work? I did robotic soccer for a while. And there you have the situation that you have a bunch of robots that are situated on the playing field. And they have a model of what goes on in the playing field. Physics generates data for the sensors, they read the bits of the sensors, and then they use them to update the world model. And sometimes we didn't want to take the whole playing field along and the physical robots because they are expensive, and heavy, and so on. Instead, if you just want to improve the learning and the gameplay of the robots, you can use the simulation. So we wrote a computer simulation of the playing field in the physics and so on, that generates pretty much the same data and put the robot mind into a simulated robot body. And it works just as well. That is if you are the robot, because you cannot know the difference. If you are the robot, you cannot know what's out there, the only thing that you get to see is what is the structure of the data at your systemic interface. And then you can derive a model from this. And this is pretty much the situation that we are in that is the our minds that are somehow computational, that are able to find regularity and patterns, and that we seem to have access to something that is full of regularity so we can make sense of it. Now, if you discover that you are in the same situation as these robots, basically, you discover you are some kind of apparently biological robot that doesn't have direct access to the world of concepts that that has never actually seen matter and energy and other people, all it got to see was little bits of information that were transmitted through nerves, and the brain had to make sense of them by counting them in elaborate ways. What's the best model of the world that you cannot come up with? What's really the state of affairs? What's the system that you are in? And what's the best algorithm that you should be using to fix your wealth model? And this question is pretty old. And I think they have been answered for the first time by Ray solomonoff in the 1900s 60s. He discovered an algorithm that you can apply when you discover that you're a robot and all you got is data. What is the both like? And this algorithm is basically a combination of Bayesian reasoning, induction and Occam's razor. And we can mathematically prove that we cannot do better than solomont of induction. Unfortunately, solve one of induction is not quite computable but everything that you're going to do is some going to be some extra proximation of solomonoff induction. So our concepts cannot really refer to facts in the world out there. They do not get it cruised by referring to stuff out there in the world, we get meaning by suitably encoding the patterns that are systemic interface. And AI has recently made huge progress in encoding data perceptual interfaces. Deep learning is about using a stacked hierarchy of feature detectors. That is we use pattern detectors, and we built them into networks that are arranged in hundreds of layers. And then we adjust the links between these layers, usually some kind of using some kind of gradient descent, if you can use this to classify for instance, images and parts of speech. So we get two features that are more and more complex, they thought that was very, very simple patterns, and then get more more complex until we get to object categories. And now the systems are able in image recognition tasks to approach performance that's very similar to human performance. Also, what is nice is that it seems to be somewhat similar to what the brain seems to be doing in visual processing. And if you take the activation and different levels of these networks, and you will improve this or enhance this activation, little bit, what you get is stuff that looks very psychedelic, which might be similar to what happens if you put certain illegal substances into people and enhance the activity on certain days of their visual processing classifier.

Joscha Bach 6:32
posts that she has the lighting, the dress that she has on her facial expression, and so on, and then we got only to this thing that is left after we removed all the news in STATA. But what if we want to get to something else, for instance, we want to understand poses could be, for instance, that we have several dancers, and we want to understand what they have in common. So our best bet is not just have a single classification clustering. But instead, what we want to have you take the low level input and get a whole universe of features that is interrelated. So we have to develop material relations at the lowest level we have percepts. On a slightly higher level, we have simulations. And on the even higher level, we have a concept landscape. How does this representation by simulation work? Now imagine you want to understand sound. If you are a brain and you want to understand sound, you need to model it. Unfortunately, we cannot really model sound with neurons because sound goes up to 20 kilo hertz, or if you are old, like me, maybe to 12 kilo hertz. And 20 kilohertz is what babies do. And neurons do not want to do 20 kilo hertz, that's way too fast. For them. They're like something like 20 hertz. So what do you do, you need to make a Fourier transform before we transform measures the amount of energy at different frequencies. And because you cannot do this with neurons, you need to do it in hardware. And turns out this is exactly what we are doing. We have this cochlea, which is this snake, snail like thing and our ears. And what this does, it transforms energy of sound, different frequency intervals into energy measurements, and then gives you something like what you see here. And this is something that the brain can model. So we can get a neurostimulator that tries to recreate these patterns, and then it can predict the next input from the cochlea, they did understand the sound. Of course, if we want to understand music, we have to go beyond understanding sound, we have to understand the transformations that sound can have if you played a different pitch, we have to arrange the sound in the sequencer that gives you reasons and so on. And then we want to identify some kind of musical grammar that we can use to, again, control the sequencer. So we have stacked structures that simulate the world. And once you've learned this model of music, once you've learned the musical grammar or the sequence or into the sounds, you can get the to the structure of the individual piece of music. So if you want to model a build of music, you need to have the lowest level of the presets. And then we have a higher level of mental simulations, and which give the sequences of the music and the grammars of music. And beyond this, you have a conceptual landscape that you can use to describe the different styles of music. And if you go up the hierarchy, you get to more and more abstract models, more and more conceptual models, and more and more analytic models. And these are causal models at some point. These causal models can be weakly deterministic, basically associative models which tell you if this state happens, it's quite probable that this one comes afterwards. Or you can get to a strongly determined model, a strongly determined model is one which tells you if you are in this state and this condition is met, you're going to go exactly in this state if this condition is not met, or a different condition is met, you go into this state. And this is what we call an algorithm. It's now you're in the domain of computation. computation is slightly different from mathematics it's important to understand this. For a long time people have thought that the universe is written in mathematics or that minds are mathematical or anything is mathematical. In fact, nothing is mathematical Mathematics is just the domain of formal languages, it doesn't exist. Mathematics starts with a void, you throw in a few axioms. And if you've chosen nice axioms, then you get infinite complexity, most of which is not computable. In mathematics, you can express arbitrary statements, because it's all about formal languages. Many of these statements will not make sense. Many of these statements will make sense in some way. But you cannot test whether they make sense because they're not computable. computation is different. computation can exist, it starts with an initial state, and then you have a transition function, you do the work, you apply the transition function, you get into the next state. computation is always finite. Mathematics is the kingdom of specification and computation is the kingdom of implementation. It's very important to understand this difference. All our access to mathematics, of course, is because we do computation, we can understand mathematics, because our brain can compute some parts of mathematics, very, very little of it, and to a very constrained complexity, but enough so we can map some of the infinite complexity, non computability of mathematics into computational patterns that you can explore. So computation is about doing the work, it's about executing a transition function.

Joscha Bach 11:20
Now we saw that Metro presentations is about percepts, mental simulations, conceptual representations. And these conceptual representations give us concept spaces. And the nice thing about these concept spaces is that they give us an interface for mental representations we can use to address and manipulate them, and we can share them in cultures. And these concepts are compositional, you can put them together to create new concepts. And they can be described using higher dimensional vector spaces. They don't do simulation and prediction and so on. But we can capture a regularity in our concepts. Wisdom, is this vector space, you can do amazing things. For instance, if you take the vector from King to Queen it pretty much the same vector as two between men and women. And because of these properties, because it's really a high dimensional manifold is concept spaces, you can do interesting things like machine translation without understanding what it means that is without doing any proper mental representation that predicts the world. So this is a type of mental representation that is somewhat incomplete, but it captures the landscape that we share in a culture. And then there is another type of mental representation that is linguistic protocols, which is basically a form of grammar and vocabulary. And we need these linguistic protocols to transfer mental representations between people. And we do this basically, by scanning our mental representations disassembling them in some way, or in a disambiguating them. And then we use a discrete string of symbols to get us to somebody else. And he trains an assembler that reverses this process and build something that is pretty similar to what we intended to convey. And if you look at the progression of AI models, it pretty much went the opposite direction. So AI started with linguistic protocols, which were expressed in formal grammars. And then it got to concept spaces, and now it's about to address presets. And at some point in the near future, it's going to get better at mental simulations. And at some point, after that, you get attention directed and motivation reconnected systems that make sense of the world that are, in some sense, able to address meaning. This is the hardware that we have, can do. What kind of hardware do we have? That's a very interesting question. We could start out with the question, how difficult is it to define a brain, we know that the brain must be somewhere hidden in the genome, GG, the genome fits on a CD ROM, it's not that complicated. It's easier than Microsoft Windows. And we also know that about 2% of the genome is coding for proteins. And maybe about 10% of the genome has some kind of stuff that tells you when to extract parts, which protein, and the remainder is mostly garbage. It's all viruses that are left over and has never been properly deleted, and so on, because they're no record revisions to the genome. So how much of these 10% that is 75 megabytes code for the brain, we don't really know. What we do know is we share almost all of this with mice. Genetically speaking, a human is a pretty big mouse, with a few bits changed to fit some of the genetic expressions. And that is most of the staff there is going to code for cells and metabolism and what your body looks like and so on. But if you look at how much is expressed in the brain, and only in the brain, in terms of proteins, and so on, we find it's about well, of the 2%. It's about 5%. That is only the 5% of the 2% that is only in the brain, and another 5% of the 2% is predominant in the brain that is more in the brain than anywhere else, which gives you something like a lower bound, which means to encode a brain, genetically based on the hardware that we're using. We need something that At least 500 kilobytes of code. Actually, the very conservative lobe on it's going to be a little more, I guess, but it sounds surprisingly little right. But in terms of scientific theories, this is a lot. I mean, the universe, according to the core theory of quantum mechanics, and so on, like so much of code, it's like half a page of code. That's it. That's all you need to generate the universe. And if you want to understand evolution, it's like a paragraph, it's a couple lines, really to understand an evolutionary process. And there's lots lots of details that you get afterwards, because this process itself doesn't define what all the animals are going to look like, in a similar way is, the code of the universe doesn't tell you what this planet is going to look like, and what you guys are going to look like it just defining the rulebook. And in the same sense, the gene genome defines the rulebook by which our brain is built. The brain boots itself in a developmental process, and this booting takes some time. So some ancient learning in which initial connections of watch and basic models are built off the world, so we can operate on it. And how long does this building take, I think it's about 80 Mega seconds, that's the time that a child is awake until it's sweet and a half years old. By this age, you understand Star Wars, and I think everything after understanding Star Wars is cosmetics.

Joscha Bach 16:26
You're going to be online, if you get to a ripe old age for about 1.5 Giga seconds. And in this time, I think you're going to get not too much more than 5 million concepts. Why? I don't know, if he took a look at this child, if a child would be able to form a concept essay every five minutes, then by the time it's about four years old, it's going to have something like 250,000 concepts. And so a quarter million. And if we extrapolate this into our lifetime, some point it slows down because we have enough concepts to describe describe the world, maybe it's something it's I think it's less than 5 million. How much storage capacity does the brain has, I think that the estimates are pretty divergent. The lower bound is something like 100 gigabytes. And the upper bound is something like 2.5 petabytes, there is even even some higher outliers. This is points and think that we need all the synaptic vesicles to store information, maybe even more fits into this. But the 2.5 petabytes is usually based on what you need to quote the information that is in all the neurons. But maybe the neurons do not really matter so much because if a neuron dies, it's not like your world is changing dramatically. The brain is very resilient against individual neurons failing. So the 100 gigabyte capacity is much more what you actually store in the neurons if you look at all the redundancy that you need. And I think this is much closer to the actual ballpark figure. Also, if you want to store five 105 million concepts, and maybe 10 times, or 100, times the number of percepts. On top of this, this is roughly the ballpark figure that you're going to need. So our brain is a prediction machine it what it does is it will use this entropy of the environment to solve whatever problems you are encountering if you don't have any other feedback loop to fix them. So normally, when something happens, we have some kind of feedback loop that regulates our temperature, or that makes problems go away. And only when this is not working the employee cognition. And then we start this arbitrary computational process that is facilitated by the neocortex. And the neocortex can really do arbitrary programs. But it can do so only with a very limited complexity. Because, really, you just saw, it's not that complex. The modeling of the world is very slow. And it's also something that we see in our MRI models. To learn the basic structure of the world takes a very long time to learn, basically, that we are moving in 3d and our objects are moving and what they look like, once we have this basic model, we can get to a very, very quick understanding, visit this model, basically encoding based on the structure of the world that we've learned. And this is some kind of data compression that we are doing, we use this model, this grammar of the world. It is simulation structures that we've learned to encode the world very, very efficiently. How much data compression to be get. Well, if you look at the retina, the retina gets data in the order of about 10 gigabits per second. And the retina already compresses these data and puts them into optic nerve at the rate of about one megabits per second. This is what you get fed into the visual cortex. And the visual cortex does some additional compression. And by the time it gets to layer four of the first layer of vision to be one, we are down to something like one kilobit per second. So if you extrapolate this and you get live to the age of 80 years, and you are awake for two thirds of your lifetime, that is to have your eyes open for two thirds of your lifetime. The stuff that you get into your brain via your perception is going to be only two terabytes. Only two terabytes of visual data throughout all your lifetime, that's all you're going to get ever to see. Isn't this depressing? So I would really like to tell you choose wisely what you're going to look at.

Joscha Bach 20:23
Okay, let's look at this problem of neural compositionality. Our brains have this amazing thing that they can put Metro visitations together very, very quickly. For instance, you read a page of code, you compile it in your mind into some kind of program that tells you what this page of code is going to do. Isn't that amazing? And then you can forget about this, disassemble it all and use the building blocks for something else. It's like Legos. How can you do this with neurons? Legos can do this, because they have a well defined interface. They have all these slots, you know, that fit together and well defined ways. How can you do this? Well, humans could maybe learn the interface of other neurons. But it's difficult because every new one looks slightly different. After all, this is some kind of biologically grown natural stuff. So what you want to do is you want to encapsulate this diversity of the neurons to make them predictable to give them a well defined interface. And I think that nature solution to this is cortical columns. And cortical column is in circuit of, between 104 100 neurons. And this circuit has some kind of neural network that can learn stuff. And after it's learned a particular function. And in between, it's able to link up with other cortical columns. And we have about 100 million of those, depending on how many neurons you assume aren't that big. So it's something at least 20 million and maybe something like 100 million. And these cortical columns, what they can do is they can link up like Lego bricks, and then perform by transmitting information between them, pretty much arbitrary computation, what kind of computation? Well, solomonoff induction. And they have some short range links to their neighbors, which come almost for free, because well connected to them, then direct neighborhood. And they have some long range connectivity. So you can combine everything in your cortex plus everything. So you need to have some kind of global switchboard, some grid like architecture of long range connections, they're going to be more expensive, they're going to be slower, but they're going to be there. So how can be optimized what these guys are doing? In some sense, it's like an economy. It's not an energy based system, as we often use in machine learning. It's really an economy you have the question is you have a fixed number of elements, how can you do the most valuable stuff is that fixed resources, most valuable stuff, the problem is economy. So you have an economy of information brokers, every one of these guys have these little cortical columns. It's a very simplistic information broker. And they trade rewards against NIC entropy against reducing entropy in them in the world. And to do this, we just saw that they need some kind of standardized interface. And internally or to use this interface, they're going to have some kind of state machine, and then they are going to pass messages between each other. And what are these messages? Well, it's going to be hard to discover these messages by looking at brains. Because it's very difficult to see in brains, what they're actually doing, you just need all these neurons. And if you would be waiting for neuroscience, we'll discover anything, we wouldn't even have gradient descent learning or anything else, we wouldn't have neural learning, we wouldn't have all these advances in AI, you Schmidhuber is that that the biggest, or the last contribution of neuroscience to artificial intelligence was about 50 years ago, that's depressing. And it might be over emphasizing the unimportance of neuroscience, because neuroscience is very important. Once you know what you're looking for, you can actually often find this and see whether you're on the right track. But it's very difficult to take neuroscience to understand how the brain is working, because it's really like understanding flight by looking at birds through a microscope.

Joscha Bach 23:53
So what are these messages, you're going to need messages that tell these cortical columns to to join themselves into a structure and to unlink. Again, once they're done, you need ways that they can request each other to perform computations for them, you need ways they can inhibit each other when they're linked up. So they don't do conflicting computations, then they need to tell you whether the computation of the result of the computation that they're asked to do is probably false, or whether it's probably true, but you still have to wait for others to tell you whether the details work out, or whether it's confirmed true, whether the concept that they stand for is actually the case. And then you want to have learning to tell you how well this worked. So you will have to announce a bounty that tells him to link up and kind of reward signal that makes them do computation in the first place. And then you want to have some kind of reward signal upon you got a result as an organism when you reached your goal, if you made a disturbance go away or whatever, if you consume the cake, and then you will have some kind of reward signal that you give everybody that was involved in this and this reward signal facilitates learning. So the difference between the announced reward and the concern assumed reward is the learning signal for these guys, so they can learn how to play it Gather and how to do the small amount of induction. Now I told you that small amount of induction is not computable. And it's mostly because of two things. First of all, it needs infinite resources to compare all the possible models. And the other one is that we do not know the prior probability for our Bayesian model if you do not know how likely unknown stuff is in the world. So what we do instead is we set some kind of hyper parameters, some kind of default prior probability for concepts that are encoded by the cortical columns. And if we set this parameter very low, then we are going to end up with inferences that are quite probable for unknown things, and then you can test for those. If you set this parameter higher, you're going to be very, very creative. But we end up with many, many theories that are difficult to test, because maybe there may be too many theories to test. Basically, every of these cortical columns will now tell you when you ask them if they are true, yes, I'm probably too. But I still have to ask others to work on the details. So these others are going to be get active. And they're being asked by this asking element, are you going to be true? And they say, yeah, probably yes, I just have to work on the details. And they're going to ask even more. So your brain is going to light up like a Christmas tree, and it has all these amazing computations. And you see connections everywhere, and most of them are wrong. You're basically in a psychotic state, if you hyperparameters too high, your brain invents more theories that it can disprove. What does actually be sometimes be good and to be in this state? You bet. So I think every night our brain goes in that state, we turn up this hyper parameter, we dream, you get all kinds of weird connections. And we get to see connections that otherwise we couldn't be seeing, even though that because they're highly improbable. But sometimes they hold and we see Oh, my God, the DNA is organized in the double helix. Wow. And this is what you remember, in the morning, all the other stuff is deleted. So we usually don't form long term memories and dreams if everything goes well. If you accidentally trip this up your modulators, for instance, by consuming illicit substances, or because you're just randomly psychotic, you both basically enter a dreaming state, I guess, you get to a stage where the brain starts inventing more concepts that you can disprove. So you want to have a state fair, this is well balanced. And the difference between a highly creative people and very literal people, it's probably a different setting of this hyper parameter. So I suspect that people that are genius, like people like Einstein, and so on, do not simply have better newborns than others, what they mostly have is a slightly hyper parameter that is very finely tuned, so they can get better balance than other people and finding theories that might be true, but can still be disproven.

Joscha Bach 27:43
So, inventiveness could be a hyper parameter in the brain. If you want to measure the quality T of the belief that we have, we are going to have to have some kind of cost function which is based on the motivational system and to identify if the belief is good or not, you can have structural criteria, for instance, how well does it predict the world? Or how well does it reduce uncertainty in the world? Or is it consistency in sparse? And then of course, utility, how well does it help me to satisfy my needs, and the motivational system is going to evaluate all these things by giving a signal and first signal kind of signal is the possible rewards if we are able to compute a task. And this is probably done by dopamine. So we have a very small area in the brain, substantia nigra, and then the ventral tegmental area, and they produce dopamine. And this gets fed into the dorsal lateral frontal cortex and the frontal lobe which control attention and tell you what things to do. And if we have successfully done what you wanted to do, we consume the rewards, thank you. And we do this with another segment, which is serotonin. It's also announced the motivational systems was very small area, that rough and nuclear, and it fits into all the areas of the brain where learning is necessary or connections or strengthens want to get once you get to a result. And these two substances are emitted by the motivational system. The motivational system is a bunch of needs, that centrally regulated below the cortex, they're not part of your mental representations, they are part of something that is more primary than this. This is what makes us go this is what makes us human. This is not our rationality, this is what we want. And the needs are physiological, their social and their cognitive. And they are pretty much born wisdom. They cannot be totally adaptive. Because if you were adaptive, you wouldn't be doing anything the needs are resistive. They are pushing us against the world. If you wouldn't have all these needs, if you wouldn't have this motivational system, you would just be doing what's best for you, which means collapse on the ground, be a vegetable, right? Given to gravity. Instead you do all these unpleasant things. You get up in the morning, you eat, you have sex, you do all these crazy things. It's only because the motivation system forces you to the motivational system takes This bunch of matter and makes us do all these strange things just so genomes get replicated, and so on. And so to do this is going to build resistance against the world. And the motivational system is, in this sense forcing us to do all these things by giving us needs and the need has some kind of target value and current value. If we have a differential between the target value and the current value, we would perceive some urgency to do something about the need. And when the target value approaches the current value, we had the pleasure signal, which is the learning signal, if it gets away from it, we get the displeasure signal, which is also a learning signal. And we can use this to structure our understanding of the world to understand what goals are insulin and goals are learned, needs are not to learn, we need success and failure in the world. But to do things, we need anticipated reward. So it's dopamine that makes the brain go round, dopamine makes you do things. But in order to do this in the right way, you have to make sure that the cells cannot produce dopamine themselves, if they do this, they can start to bribe others to work for them, you're going to have something like a bureaucracy in your neocortex, where different bosses try to subdue others to do their own bidding and pitted against other groups in the neocortex, it's going to be horrible. So you want to have some kind of central authority that makes sure that the brains don't put cells don't produce the dopamine themselves, it's only been produced a very small area, and then given out and pass through the system. And after you're done with it, it's going to be done. So there is no hoarding of the dopamine. And in our society, the role of dopamine is played by money. Money is not reward in itself, it's, in some sense, a way that you can trade against the reward, you cannot eat money, you can take it later, and get an arbitrary reward for it. And in some sense, money is the dopamine that makes organizations and society companies, many individuals do certain things. They do stuff because of money, but money. And if you compare it to dopamine, it's pretty broken, because you can hoard it. So you're going to have these cortical columns in the real world, which are individual people or individual corporations. They're hoarding the dopamine that sit on this very big pile of dopamine, they're starving the rest of the society of the dopamine, they don't give it away. And they can make it do its bidding. So for instance, they can pitch a substantial part of society against understanding global warming, because their profit of global warming or whatever technology that leads to global warming, which is very bad for all of us. So our societies have a nervous system that lies to itself.

Joscha Bach 32:28
How can we overcome this? Actually, we don't know what to do this, we would need to have some kind of centralized top down reward motivational system. If you have this. For instance, in the military, you have this system of military rewards that you get and that these are completely controlled from the top. Also, within working organizations, you have this in, in corporations, you have centralized rewards, it's not like it rewards flow bottom up, they always flow top down. And there was an attempt to model society in such a way that was in Chela, in the early 1900s 70s, The Atlantic government had the idea to redesign society or economy in a society using cybernetics. So at the end, they invited a bunch of cyber nutritions to redesign the Chilean economy. And this was meant to be the control room by the end and his chief economists would be sitting to look at what the economy is doing. We don't know how this would have worked out because we know how it ended in 1973, there was this big push in Chile, and this experiment, and that, among other things, maybe it would have worked, who knows, nobody tried it. So there is something else that is going on in people beyond the motivational system. That is we have social criteria for learning. We also check if our ideas are normatively acceptable. And that's actually a good thing. Because individuals may shortcut the learning so so communication, other people to have learned stuff that we don't need to learn ourselves. And we can build on this. So we can accelerate learning by many orders of magnitude, which makes culture as possible and it makes anything possible because if you are on your own, you're not going to find out very much in your lifetime. You know how they say, everything you do you do by standing on the shoulders of giants, or in a big pile of wars, it works either way.

Joscha Bach 34:26
Social Learning usually outperforms individual learning, you can test this but in the case of conflict between different social truths, you need to have some way to decide who to believe. So you have some kind of reputation estimate for different authorities and you use this to check whom you believe. And the problem of course, is there's an existing society in real society this reputation system is going to reflect power structures, which might distort your belief systematically. Social Learning, therefore leads groups to synchronize their opinions, and their opinions become a get another role. They become an important part of signaling, which Oops you belong to. So opinions start to signal a group loyalty and societies. And people in this in that actual world, they should optimize not for getting the best possible opinion in terms of truth they should get, they should optimize for doing having the best possible opinion with respect to agreement with their peers. If you have the same opinion as your peers, you can signal them you're part of the group, they're going to like you. If you don't do this, then chances are you're not, they're not going to like you. That's rarely any benefit in life to be in disagreement with your boss. Right. So if you evolve an opinion forming system and use certain circumstances, you should be ending up with an opinion forming system that leaves you with the most useful opinion, which is the opinion in your environment. And it turns out, most people are able to do this effortlessly. They have an instinct that makes them adopt the dominant opinion in this horrible environment. It's amazing, right? And if you're a nerd like me, you don't get this.

Joscha Bach 36:08
So in the world out there explanations piggyback on your group allegiance, for instance, we'll find as a substantial group of people that believe the minimum wage is good for the economy and for you. And another one was believed that it's bad. And it's pretty much aligned with political parties. It's not aligned with different understandings of economy, because nobody understands how the economy works. And if you are a nerd, you try to understand the world in terms of what's true and false. You try to prove everything by putting it in some kind of truth and false level. And if you're not a nerd, you try to get to right and wrong, you try to understand whether you're in alignment with what's operating objectively right in your society, right? So I guess that nerds are people that have a defect in your opinion forming system. And usually that's maladaptive. And in under normal circumstances, nerds would mostly be filtered from the world because they don't reproduce so well, because people don't like them so much. And then something very strange happened, the computer revolution came along. And suddenly, if you argue with the computer, it doesn't have you have if you have the normatively correct opinion, you need to be able to understand things in terms of true and false right.

Joscha Bach 37:25
So now we have the strange situation that the viewer people that have these offensive, strange opinion, and that really don't mix valve is real normal people get all these high paying jobs. And we don't understand how is that happening. And it's because suddenly, our ML adaption is a benefit. But out there, there is this world of the social norms, and it's made of paper walls, there are all these things that are true and false in a society that make people behave. It's like these Japanese walls that they may tell us out of paper, basically. And these are bolts by convention that exists because people agree that this is a wall. And if you are a hypnotist, like Donald Trump, you can see that these are paper walls, and you can shift them. And if you are a nerd like me, you cannot see these paper walls. If you pay closely attached close attention, you see that people move, and then suddenly, in midair, they make a turn. Why do they do this, there must be something that they see there. And this is basically a normative agreement. And you can infer what this is, and then you can manipulate it and understand it. Of course, you can fix this, you can do back yourself in this regard. But it's something that is hard to see for nerds. So in some sense, they have a superpower, they can think straight in the presence of others. But often they end up in the living room and people are upset. Learning in a complex domain cannot guarantee that you find the global maximum, you can you know that you cannot find truth because we cannot recognize if you live on the playing field or in the simulated playing field. But what you can do is we can try to approach a global maximum. But we don't know if that is the global maximum, we will always move along some kind of belief gradient that will take certain elements of our belief, and then give them up and for new elements of a belief based on thinking that this new element is better than the one that we give up. So we always move along some kind of gradient and the truth does not matter. The gradient matters. If you think about teaching for a moment. When I started teaching, I often thought okay, I understand the truth of the subject. The students don't so I have this to give this to them. And at some point I realized, Oh, I've changed my mind so many times in the past and probably not going to change it to stop changing it in the future. I'm always moving along great and ever keep moving along the gradient. So I'm not moving to truth. I'm moving forward. And when we teach our kids you should probably not think about how to give them truth. You should think about how to put them onto an interesting radiant that makes them explore the world world of possible beliefs.

Joscha Bach 40:00
all these possible beliefs lead us into local minima that's inevitable. These are like valleys. And sometimes these valleys are neighboring. And we don't understand what the people in the neighboring village Valley are doing unless we are willing to retrace the steps they've been taken. And if you want to get from one rally into the next, people have to have some kind of energy that moves us over the hill, they have to have a trajectory for every step works by finding reason to give a bit of our current belief and adopt a new belief because it's some are more useful, more relevant, more consistent, and so on. Now, the problem is that this is not monotonous, we cannot guarantee that we are always climbing, because the problem is that the beliefs themselves can change our evaluation of the belief. It could be, for instance, that you start believing in a religion and this religion could tell you, if you give up the belief in the religion, you're going to face eternal damnation in hell. As long as you believe in the religion, it's going to be very expensive for you to give up the religion, right? If you truly believe in it, you're now caught in some kind of attractor. Before you believe that religion, it's not very dangerous. But once you've got an attractor, it's very, very hard to get out. So this belief attractors are actually quite dangerous, you can get not only to chaotic behavior, that you cannot guarantee that your current belief is better than the last one. But you can also get into beliefs that are almost impossible to change. And that makes it possible to program people to work in societies. Social domains are structured by values. Basically, a preference is what makes you do things because you anticipate pleasure or displeasure, and values make you do things, even if you don't anticipate any pleasure. These are virtual rewards. They make us do things because we believe that stuff that is more important than us. This is what values are about. And these values are the source of what we would call true meaning deeper meaning there's something that is more important from us than us something that we can serve. This is what we usually perceive as a meaningful life. It's one which is in service of values that are more important than I myself. Because after all, I'm not that important. I'm just this machine that runs around and tries to optimize its pleasure and pain, it just kind of boring. So my PI has positive part of me, my principal investigator in the Harvard department where I have my desk, Martin Novak, he said that meaning cannot exist without God, you're either religious, or you are a nihilist. And this guy is the head of the department for evolutionary dynamics. Also, here's the Catholic. So this really puzzled me and I tried to understand what he meant by this. Typically, if you are a good FAS like me, you would tend to attack gods that are structured like this religious gods that are institutional, they are personal tastes, there are some kinds of person, they do care about you. They prescribe norms, for instance, don't masturbate. It's bad for you. Many of these norms are very much aligned with societal institutions, for instance, don't fit your question the authorities, God wants them to be ruling above you, and be monogamous, and so on, and so on. So they prescribed norms that do not make a lot of sense in terms of being that creates worlds every now and then. But they make sense in terms of what you should be doing to be a functioning member of society. And this, God also does things like they create roles they like to manifest as burning shrubbery, and so on. There are many books that describe stories that these gods have allegedly done. And it's very hard to test for all these features, which makes these gods very improbable for us, and makes SES very dissatisfied with these gods. But then there's a different kind of God is what we call the spiritual God, this spiritual God is independent of institutions, it still does care about you, it's probably conscious, it might not be a person. There are not that many stories that you can consistently tell about it, but you might be able to connect to it spiritually. Then there is a God that is even less expensive, that is God as a transcendent principle. And this God is simply the reason why there is something rather than nothing. This God is the question that universe is the answer to this, the thing that gives meaning everything else about this unknowable. This is the god of Thomas Aquinas. The God that Thomas Aquinas discovered is not the God of Abraham. This is not a religious God. It's a God that is basically a principle that as the universe into existence, it's the one that gives the universe its purpose.

Joscha Bach 44:46
And because every other property is unknowable about this, this God is not that expensive. Unfortunately, it doesn't really work. I mean, Thomas Aquinas tried to prove God he tried to prove unnecessary God the God that has to be existing and the I think you can only prove a possible God. So if you try to prove unnecessary God, this God cannot exist, which means you've got proof is going to fail, you can only prove possible Gods then there is an even more impoverished God. Now this is the god of Aristotle. And he said, if there is change in the universe, something is going to have to change it, there must be something that moves it along from one state to the next. So I would say this is the primary computational physician function of the universe.

Joscha Bach 45:34
And Aristotle discovered it, it's amazing, isn't it? You have to have this because we cannot be conscious in a single state, you need to move between states to be conscious, you need to be processes. So we can take our gods and sort them by their metaphorical political cost. The first degree God would be the first mover second degree God is the God of purpose and meaning. The third degree is the spiritual God and the fourth degree God is bound to religious institutions, right? So if you take this straight statement for Martin Novak, you cannot have a meaning without God, I would say yes, you need at least a secondary reading degree God to have meaning right. So objective meaning can only exist with a second degree God. And subjective meaning can exist as a function in a cognitive system. Of course, we don't need objective meaning. So we can subjectively feel that there's something that's more important to us. And this makes us work in society and makes us perceive that we have values and so on. But we don't need no need to believe that there is something outside of the universe to have this. So the first degree God is the one that is bound to religious institutions, it requires a belief attractor, and it enables complex norm prescriptions, if my theory is right, and it should be much harder for nerds to believe in force to Greek words, and for normal people. And what is God does, it allows you to have state by building mind viruses, basically, originally is a mind virus. And the amazing thing about these mind viruses is that they structure behavior in large groups, we have evolved to live in small groups of a few 100 individuals, maybe something like 150, this roughly the level to which reputation works, we can keep track of about 150 people and after this, it gets much, much worse. So in this system, where you have reputation, people feel responsible for each other, and they can keep track of their doings and society kind of order works. If you want to go beyond this, you have to write a software that controls people. And religions were the first software that that did this on a very large scale. And in order to keep stable, they had to be designed like operating systems in some sense. They give people different roles like insects in the hive. And they have even a part of this, these worlds is to update the religion, but it has to be done very carefully and centrally because otherwise, the original will split apart and fall together into new religions or overcome by new ones. So it's some kind of evolutionary dynamics that goes on with respect to religion. And if you look at the religions, that's actually a veritable evolution of religions. So we have this history tradition and the most atomic mythology that gave rise to Judah is

Joscha Bach 48:13
kind of cool, right? Also, history totally repeats itself.

Joscha Bach 48:36
Yeah, it totally blew my mind when I discovered this. Of course, the real tree of foreign languages is slightly more complicated. And the real tree of religion is slightly more complicated. But still, it's neat. So, if you want to immunize yourself against mind viruses, first of all, you want to check yourself whether you are infected, you should check, can I go let go of my current beliefs without feeling that meaning departs me, and I feel very terrible if I let go of my beliefs. Also, you should check all the other other people around there that don't share my belief, or they either stupid or crazy or evil. If you think this chances are you're infected by some kind of mind virus, because they're just part of the out group. And does your god have properties that you know, but you do not observe? So basically, you have a God of second or third degree or higher. In this case, you've probably also got a mind virus. There's nothing wrong with having a mind virus. But if you want to immunize yourself against this, people have invented rationalism and enlightenment, basically, to act as immunization against mind viruses.

Joscha Bach 49:50
In some sense, it's what the mind does by itself, because if you want to understand how you go wrong, you need to have a mechanism that discovers who you are some kind of auto debugging mechanism that makes the mind aware of itself. And this is actually the self. So according to Robert Keegan, the development ourselves is a process in which we learn who we are by making things explicit by making posters that are automatic, visible to us, and to conceptualize them. So we no longer identify with them. And it starts out with understanding that there's only pleasure and pain. If you're a baby, you only have pleasure and pain, you identify with this. And then you turn to a toddler, and the toddler understands that they are not their pleasure and pain, but there are their impulses. And in the next level, if you grow beyond the toddler age, you actually know that you have goals, and that your needs and impulses are the actual set of goals. But it's very difficult to let go of the goals if you are very young child. And at some point, you realize, oh, the goals don't really matter, because sometimes you cannot reach them. But we have preferences, we have things that we want to happen and things that we do not want to have to happen. And then at some point, we realize that other people have preferences to and then the start to model the world as a system where different people have different preferences, and we have to navigate this landscape. And then we realize that these preferences also relate to values. And the attacks start to identify with these values as members of society. And this is basically the stage if you are an adult being that you get into. And you can get to a stage beyond that, especially if you have people around this, which have already done this. This means that you understand that people have different values, and what they do naturally flows out of them. And these values are not necessarily worse than yours, they're just different. And you learn that you can hold different sets of values in your mind at the same time, isn't that amazing? And understand other people, even if they're not part of your group, if you get that this is really good. But I don't think it stops there, you can also learn that the stuff that you perceive is kind of incidental, that you can turn it off and that you can manipulate it. And then that at some point, you also can realize that yourself is only incidental that you can manipulate it or turn it off. And that you're basically some kind of consciousness that happens to run on the brain of some kind of person that navigates the world in terms to get rewards or avoid displeasure, and values and so on. But it doesn't really matter. There's just this consciousness that understands the world. And this is the state that you typically call enlightenment. In this state, you realize that you are not your brain, but you are a story that your brain tells itself.

Joscha Bach 52:25
So becoming self aware is a process of reverse engineering your mind, it's a different set of stages in which realize what goes on. So isn't that amazing AI is a way to get to more self awareness. I think it's a good point to stop here. The first talk that I gave in this series was two years ago, it was about how to build a mind. Last year, I talked about how to get from basic computation to consciousness. And this year, you have talked about finding meaning using AI, I wonder where it goes next.

Unknown 53:22
Thank you for this amazing talk, we now have some minutes for q&a. So please line up at the microphones. As always, if you're unable to stand up, for some reason, please very, very visibly raise your hand, we should be able to dispatch dispatch an audio angel to your location. So you can have a question too. And also, if you're locationally disabled, if you're not actually in the room. If you're on the stream, you can use IRC or Twitter to also ask questions, we also have a person for that. We'll just start on microphone two.

Unknown 53:53
Well, that's me. Just a guess. What would you guess? When can you discuss your talk with the machine in how many years?

Joscha Bach 54:04
I don't know, as a software engineer, I know if I don't have a specification, all bets are off until I have the implementation. And so it can be of any order of magnitude. I have a gut feeling. But I also I know as a software engineer that my gut feeling is usually wrong until I have the specification. So the question is if there are silver bullets, right now, there are some things that are not solved yet. And it could be that they're easier to solve them you think but it could be that they're harder to solve them. You think before I stumbled on this cortical death organization thing. I thought it's going to be something like maybe 6080 years and now I think it's way less. But again, this is a very subjective perspective. I don't know.

Unknown 54:47
Number one, please.

Unknown 54:49
Yes. I want to ask you a little bit about metacognition. It seems that you kind of end your story, saying that it's still reflecting on the input that you get, and kind of working with your social norms and this and that. But Kohlberg, for instance, talks about what he calls a post cognate, post conventional, universal morality, for instance, which is thinking about moral laws, without context, basically stating that there's something beyond the relative norms that we have towards each other, which would only be possible, if you can do kind of, you know, metacognition, thinking about your own thinking, and then modifying that thinking. So kind of feeding back your own ideas into your own mind and, and coming up with stuff that actually can't get thinking about while processing external inputs.

Joscha Bach 55:45
I think it's very tricky. This project of defining morality without societies exist longer than can't, of course, and can try to give these eternal rules. And others try to, I find it very difficult. From my perspective, we are just moving bits of rocks. And these bits of rock, they are on some kind of test mode and in a galaxy out of trillions of galaxies. And how can there be meaning, it's very hard for me to say that one chimpanzee species is better than another sympathy species or a particular monkey is better than another monkey. It's only happens within a certain framework, and we have to set this framework. And I don't think that you can define this framework outside of the context of social norms that we have to agree on. So objectively, I'm not sure if he can get to ethics. I only think that's possible, based on some kind of framework that people have to agree on, implicitly or explicitly.

Unknown 56:38
Microphone number four, please.

Unknown 56:40
Hi, thank you. It's fascinating talk. I have two thoughts that went through my mind. And the first one is that it's so convincing the model that you're present, but it's kind of like, you present another metaphor of understanding the brain, which is still something that we try to grasp on different levels of science, basically. And the second one is that, that your definition of the nerd who walks around and doesn't see the walls is kind of a definition or it reminded me of Richard word, his definition of the ironist, which is a person who knows that their vocabulary vocabulary is finite, and that there's other people who who also have a finite vocabulary. And then that obviously opens up the whole question of meaning making, which has been discussed in so many other disciplines and fields and I thought about Derrida's deconstruction of ideas and thoughts and buckler and then down the rabbit hole to Nietzsche. And I was just wondering if you could maybe map out other connections where basically not ai ai helping us to understand the mind but were already existing huge huge fields of science into like cognitive processes coming from the other end could help us to understand AI.

Joscha Bach 57:53
Thank you, the tradition that you mentioned, Rorty and Butler and so on, are part of a completely different belief attractor in my current perspective, that is, they are mostly social constructionist, that believe they believe that reality, at least in the domains of the mind and sociality are social constructs, they are a part of social agreement. Personally, I don't think that is the case. I think that the patterns that we refer to are mostly independent of our mind. The norms are part of social contract constructs. But for instance, our motivational preferences that make us adopt or reject norms are something that builds up resistance to the environment. So they're probably not part of a social agreement. And the only thing that I can invite you to is try to retrace most of the different belief attractors, try to read, retrace the different parts on the landscape. All the things that I tell you a lot of this is, of course, very speculative. These are things that seem to be logical to me at this point in my life. And I try to give you the arguments why I think that are plausible, but don't believe in them, question them, challenge them, see if they work for you. I'm not giving you any tools, I'm just going to give you suitable encodings according to my current perspective.

Unknown 59:05
Thank you. And the internet, please.

Unknown 59:19
So someone's asking, if in this belief space you were talking about how do we how is it possible to get out of local minima? And very related question as well? Should? Or should we teach some sort of momentum method to our children so they don't get stuck in local minima?

Joscha Bach 59:41
I believe at some level, it's not possible to get out the local minima. Be in an absolute sense, because you only get to get into some kind of meet a minimum. But what you can do is to retrace the path that you took whenever you discover that somebody else has a fundamentally different set of beliefs and If you realize that this person is basically a smart person that is not completely insane, but has reasons to believe in their beliefs, and that they seem to be internally consistent, it's usually worse to retrace what they have been thinking and why. And this means you have to understand what their starting point was, and how they move from the current point to their starting point, you might not be able to do this accurately. And the important thing is also afterwards, you discovered the second Valley, you haven't discovered the landscape in between. But the only way that we can get an idea of the lay of the land is that we try to retrace as many paths as possible. And if you try to teach our children what I think what we should be doing is to tell them how to explore this world on their own. It's not, if you tell them this is the valley, this is basically it's given, it's the truth. But instead, we have to tell them, this is the path that we took. And these are these are the things that we saw in between. And it's important to be not be completely naive when we go into this landscape. But you also have to understand that it's always an exploration that never stops. And that might change everything that you believe now at a later point. So for me, it's about teaching my own children, how to be explorers how to understand that knowledge is always changing and it's always a moving frontier

Unknown 1:01:16
we are unfortunately out of time, so please swans again. Thank you. Thank you

This transcript was generated by https://otter.ai