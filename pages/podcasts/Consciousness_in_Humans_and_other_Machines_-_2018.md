Joscha Bach 0:09
Thank you, Mara. Which of you have been present in the breakout session today on consciousness? Okay, there's a few of us, I'll see which parts I'll skip and which parts I keep in. But I think we have the opportunity, because we have an extra session to discuss on which ways consciousness could be related to artificial intelligence and how we can be integrated in our machinery. So I expect this is a topic that interests many of us. And it's it is topic where many of us have opinions, even though we don't have that many results. Yet, as far as I know, in the field, they're not that many countries computers around, and that invites discussion. And so I'll just give them a few thoughts as an overview. And if you have the urge to interrupt us with question, please do so. But otherwise, we do this at the end. And let's start. So intelligence in my view is best understood as the ability to make models. It's slightly different from for instance, Microsoft does view who thinks it has to do with the ability to reach your goals. I think that's more like smartness. And then there is something like wisdom, which is the ability to pick the right goals. But all of us know people that are extremely intelligent, very bad at picking the right goals, and often also enable if they have goals to reach them, right? Because intelligence is usually the ability to make models. And sometimes, if you have an excess of models and indication that something is wrong with your control. What is the model and what is a set model is a set of relationships between changes and information. The meaning of information is its relationship to changes and other information. If you have a blip on your retina, the meaning of that blip? Is the relationship yet recovers, students cover two other blips on your retina, right. For those clips, they don't just cover a relationship with trends. This can be a function that models the world as people moving around in the 3d space and exchanging ideas. Those blips that don't match on to relationships like those, these are noise and a lot of blips on our retina, which we classify as noise. And our brain is a machine that, in some sense, tries to filters with the onslaught of patterns on the talent was to find sense, and then find out how they relate to each other. And it does this by making models and modeling is the discovery of a function that makes information predictable and ordered. If you think about AI, VM, maybe now in the Second Age of AI, the first order artificial intelligence, classical AI, good old fashioned AI, started in the 1950s. And it worked basically, by identifying functions, that would be required to perform an action that which humans need to be intelligent, like playing chess, or parsing natural language, and so on smart people would sit down, figure out an algorithm that would be able to perform somebody well at the task, and then code it down and see if it worked. And now we write algorithms that identify this functionality by itself by learning it right. So the second order AI, deep learning, which I think should be better, called compositional function approximation, is something where we write the algorithms that write the algorithms. And most of the algorithms that be right, right now, are chains of normalized weighted sums. And we train this with backpropagation, and stochastic gradient descent. But you all know, it's doesn't have to be limited to this. It's an interesting question whether we will go to third order AI in a big time, right? When right now when you write your TensorFlow code, and it's like, optimizing something in 2000 dimensions, so it automatically optimizes in billions of dimensions, something here cannot be right, maybe we should go level above this, and above automatically optimizing some hyper parameters. But see, the whole learning algorithm itself is a hyper parameter that we should automatically optimize. And also it might make sense to think of the brain as a meta learning system. So maybe you're not learning systems, through your systems that discover how to learn in a given context. And if that is not enough, evolution is slow and principled search for meta learning system in a way right. And evolution is not optimal. It sometimes hangs and defective optimum or some brand that apex predator reptile eats all the more promising upstarts before they reach a sufficient size and have sufficiently large ecosystems. And you have to reset the whole thing with supervolcano or the media or, and it almost didn't happen. Like we have only half a billion years left before the earth loses its atmosphere. So if you are basically in this order of magnitude for evolution, where it almost didn't happen

Joscha Bach 5:00
But probably can do better than evolution, we can move faster and more principled search methods. And there should be a meta theory of search in which we find optimality criteria. So if we discover this theory, there's one optimal way to discover truth. And to do functional approximation, once we have this scientist, you're sadly done only artist left. Otherwise, you only have to follow the algorithm. So what is consciousness consciousness, according to the philosopher's electron block is the awareness of what happens in our mind. And unfortunately, we don't really know what happens in our mind. If I make circuits like this, I don't see the real jerk. How's that possible? It's because there are gaps. In my experience, the experience gets glued together with hindsight. So consciousness is not synchronized to this real time processing in which I take information from the world. If you think about consciousness as a suitcase term, as Marvin Minsky has talked about it, it's a set of functionalities, like the creation of a local perceptual space, and the access to perceptual content, the maintenance of a word model, and so on. And these things are available in dreams. And there's a difference between dreaming and being awake. And the difference is not consciousness itself, it's additional functionality. So being awake is a different conscious state that is characterized by having additional functionality, like the ability to form goals and follow through on that more the ability to remember where and who you are, and the ability to access sensory content. So basically, dreaming is a highly dissociated, conscious state. And the lucid dream is a somewhat less dissociated, conscious state in which you, for instance, can usually not remember in which city you are dreaming, right now, because you don't have sensory access to the outside world, you have difficulty bootstrapping, an adequate state of your world model, but you can still form goals and act on them. And you can remember a few facts about yourself, usually during a lucid dream. So you have some agency, and then you have additional competencies that can go above being vague, like the ability to learn and to reason. And when you meditate, you get additional features when you are in psychotic states, and so on your mind works slightly different use dynamic conscious, and so on. So all these conscious states on different sets of functionalities that share some core awareness. So what is this core awareness, consciousness is not just some functionality, but there's also a feeling of what it's like, and it's feels kind of mysterious. If you go into this thing, you have some elementary sense of directed awareness, I don't know if if you have, if that is the same thing for you. And I'm interested in hearing your experiences, especially if they're different from mine. So when I meditate really deeply and managed to turn off most of my cognitive layers, when I get towards a level that consciousness is elementary, where it's not something where I look at things, and I'm aware of the fact that I look at things, but everything that I think is an expression of that consciousness, it's like consciousness feels like a creative force subjectively in that state. I understand that must feel very mystical to many people, when they go into this thing, especially when they don't look at this as computer scientists think about how that might come about. Then there's a first order consciousness, which I think is the state that most children are in most of the time, in which you are directly aware of the content that you're looking at reality is directly falling into your face. And you are aware of the texture of it, it's taste, it's very sensory, it's nothing that is mediated by reflection. And in my normal state of mind, my consciousness is very reflective. It's mostly the manipulation of content that was held in awareness by another part of my brain. It's a very impoverished way of relating to the world. And then there is reasoning about the previously attended content. And when I talk about my conscious experience to you, within the parts of me that talk about this know about consciousness only, as a far distant.

Joscha Bach 8:58
So when I experienced what I have, there is something like an essence a truth that it feels like reality to me. And this essence, of course, is a model that exists in my brain, it's not the actual reality, the actual reality doesn't fit. So miners, as far as I know, out there, there's some kind of weird quantum graph. And this weird photograph is able to generate patterns and store them on what I take to be my retina. And then later on my talent was and my brain is able to predict those patterns by making this model of reality in this primary model of environment and body. That's my subjective reality in which I live. It's very complicated features and properties. It's very mathematical but in ways that I usually don't know. So when you see a toddler sitting on the ground and the toddler folds a piece of paper pushes a pencil so it that toddler is proving properties have embedded surfaces in a three dimensional Euclidean space. And of course, the toddler is not able to report on that fact, but it's actually what's going on this primary model is being tuned and our declarative knowledge is a secondary model. It's knowledge that we model that we derive over that model. It's one that allows us to reason. And it's one that allows us to prove properties of it to make it more consistent. And it's one that later on allows us to translate it into language and synchronizes with the observations of others. And in this sense, our self is a tertiary model, it's when the system starts to try to understand what is the thing that makes that system. And usually, it only makes models of those partial properties that are wrong, that needs some additional regulation, because the purpose of all that modeling, eventually is regulation, it all happens in the service of regulating something for which the existing feedback loops are not enough. So this self emerges, and there are some feedback loops that you cannot close automatically can imagine you lie away at the crib at night, and it's very dark, and you cry for your mom, and your mom doesn't come come. And so this regulation goal cannot be achieved. And you're forced to make representations to fix this, you make models to regulate this. And at some point, you have to figure out what is darkness? What is the mother, what is me? Why doesn't she come, this kind of water never stops. And here we are. So, in this sense, we are a story, that complicated, dynamic model that the brain tells itself about a fictional person in this mental simulation. And consciousness, in the sense is a model of the contents of our attention. It's what you remember of having held on our attention. This weird thing about this, you sometimes have false memories of consciousness. Like for instance, I sometimes have an hour long dream between hitting the snooze button twice on my alarm clock. Now I know from neuroscience data that my brain is not running on hyperspeed when I'm sleeping, how is it possible that I subjectively experience something that it takes a very long time in such a short amount of time. And the easiest explanation is that the memory is instantiated all at once. And never events, the sequence of experience that was that was necessary to complete that particular kind of dream. But I instantiated it in one moment, and only when I go into my protocol memory, this thing becomes a cohesive conscious experience. On the other hand, we already know that consciousness can never happen in real time, right. So when I, for instance, drink from this glass, I feel something goes on my throat. And the processing of this modality takes something like maybe 500 milliseconds and the sound processing, when this classic things against my teeth take something like 300 milliseconds. And my action perception on this is happens better earlier, because I need to plan to do this whole thing to actuate my nerves, but I have the subjective impression that it all happens at the same time. And this subjective impression must be wrong. This is a fake memory, this experience. But all these things happen at the same time never actually happened. It's a memory of that experience. Right? So in this sense, if consciousness is a physical thing that it's physically implemented in my neurons, it cannot happen in actuality, in the way I experience it. And that means if you live in a mechanist universe, where the universe is a collection of moving parts, I'm not actually conscious, or at least my brain isn't. If I live in a dollars perspective, they're heavy moving parts domain, the rest extends like this, in rough approximation, Euclidean 3d space with this moving solitons around it, that equal particles, and you have an extra mental domain that is somehow outside of this, and they're both reducible and somehow managed to communicate,

Joscha Bach 13:44
then maybe we'll be working or it could be that consciousness and the mind are primary and the physical universe is something that I just dream. So if you think about this mechanist universe, can we map this to computation? Or is it something else is maybe that AI is completely on the wrong track, and we find that there are different models of what the universe could be. The basic idea is that compute if your computation was like me, it's probably a discrete finite state machine. It's a mapping from end to end, every thing that we know how to compute is a mapping between the integers. That's what your Turing machines do. The traditional view of physics was that our universe is a geometric type of computer which means it's continuous everything is a mapping from the reals to the reals. And while most of physics is still built on this foundation, from the computations perspective, the problem is that real numbers and these hyper computations are not constructed, you cannot build a hyper computer, we don't know how to do this even abstract mathematics, you have to postulate it, you have to postulate something that is able to do finite infinite amount of steps in a finite amount of time. Right our computers only to find out when many steps so hyper computer is able to take a stick with the legs of the square root of pi and then either one with the square root of minus two and push them together. And then you get a result. So this is something that doesn't work with infinitely many digits in finite state machine or virtual machine, you can only approximate it. The quantum world is one which maps from the real numbers. So the complex numbers and back to the real numbers, so it's a slightly higher computer in slightly different way. If you think about dualism that doesn't free you from computational ism, if you are a mind and on a different plane of existence, something must compute a different plane of existence because it has discernible states. And these dates are correlated in a way that is not completely random. So something must be progressing from these dates. And this means, in the doulas perspective, you have basically two computers, you can implement them on the same one that you can basically stop your physical universe, to whatever calculations you want to do on your mental domain, right and back with whatever arcane method that doesn't obviously violate the causal causal closure of physical universe in ways that you can find in labs, and then continue. It's a difficult trick to pull off, but it's still a computational so dualism doesn't save you from computational ism and my perspective. There is a difference between mathematics and computation. This is one that for instance, seems to be confusing, Roger Penrose, because there are things in mathematics that can don't compute, right? That's because mathematics is simply the domain of all formal languages. Mathematics is the realm of specifications, you can specify things that don't work, like the set of all sets that contain themselves, it doesn't compute, right? It's very difficult to reason about these things. It's not a thing that is a problem for computation itself, computation is constructive mathematics is the part two can be implemented, I posit that everything that exists must be implemented somehow, the set of all sets that doesn't contain itself can be talked about in the language, but it cannot be implemented, right. So the subset of mathematics that can actually be implemented is the interesting one. And if you are in contact with mathematics, there are a number of things like girdles, undecidability of the halting problem, and so on. And paradoxes disappear.

Joscha Bach 17:18
There is question can we get out of this trap of computational ism? Is it possible that something is more than computation and type of computation doesn't really help us because we can still approximate it if you wait long enough to arbitrarily many digits, right? So is it possible that consciousness is something completely different than computation or continuous computation? The difficulty is that no computational system could constructions are saying which is more than computational obviously, right? You can only mathematics construct something in language and with computation, we can only do computable stuff. So we can never get by building things, or thinking our mind of how that could be built in any way, get to the thing, that is more than computational. And along with logic, language kind of physics, or computational hyper computation is computational. Is there a system that can do more, and I have Christ in this hypothesis, the meta computational operators would be something that it's outside of computation, the bath computation, can produce computation, but itself not constructed, but it cannot think about right, it cannot take it apart, they cannot reason about it in any way. And if that would be the case, we would be living in some kind of thing like a pen psychist universe, maybe if consciousness is a property of this meta computational operator, because we cannot eliminate it from the background. When we look at matter or substance, we cannot separate it from there, because it's not separable with any constructive means. No observation, no act of reason, though. mathematical function can extract it from the background, it would be ubiquitous in some sense, because it precedes everything that is there. But it's something that you cannot think that you can observe and if you're not forced to assume. So, if you are conscious in the sense for probably conscious independently, all of it. So I suspect still that metal computation is what soil Penrose and Tononi and so on, are searching for when they tried to find non computational theories that would explain the mental phenomenon. If you think about idealism, and idealism, the mind is primary. So there is a dreamt universe that we inhabit. And that exists in a mind on a higher plane of existence that computes it. And we, you and me, are character in this I am. In this dream, dreamt by a mind on a higher plane of existence. It's a universe in which magic as possible. It's a universe in which you can learn to meditate, levitate and maybe look into the future and do other things. And it's a universe that many awkward people seem to be living in right and many people that have spiritual experiences support about this and most of Buddhism is firmly anchored in this view that we are basically characters in the dream that is driven by a mind and a higher plane of existence. That's the idea of idealism. And then we have the dualist idea, we have two universes that interface somehow and that they are embedded into two different computational substrates. And then we have computational this monism, which says that the mind is the product of computational processes in the physical universe, right. And I suspect that we need to look at it like this. So in our mind, there is a simulated observer, it's an our mind is a thing that produces a simulated world to predict the patterns that the universe throws at our systemic boundary. So now our mind we create a virtual reality. And our mind cannot observe that virtual reality directly, because it cannot relate to it in any way. It's a mind it's a piece of software, right? So how do you do this, it would be very useful if it would have a model of how a person would react to this, right? Our brain is not the person, our new ones are not capable of feeling anything perceiving, experiencing anything. So what does the brain do, it creates a simulation of a person, very much like a character in the novel, but it's a model that is not written in words, but in the language of our mind, which means perceptual content, hierarchical distributed representations, right? You have this mental representation going on. And then there's this simulated persona and the unit, our mind makes experiments, what's happening to that persona, if I do the following universe to that persona, and then it can look at the results. And I happen to be that persona, and I get access by my mind to my language center, or to the language center of the brain. And then I can talk to you and say, Oh, my God, everything looks so blue. How's that physically possible? How is it possible that I have this intense experience of qualia? And the answer is, yeah, no physical system can be conscious and actuality, and no physical system can experience qualia. But the simulation can, because I am not that person, am I basically, I'm not that brain. I'm not that human primate time, the side effect of the regulation needs of human primate. And that thing is basically

Joscha Bach 22:13
running a simulation and that system, this simulation is now experiencing simulated thing behind site and reporting about it. Okay, how does this work? We know that our nervous system exists to regulate the needs of a colony of cells that have in history, decided to unite their fate and try to attack other cells together to eat them. And that's basically what they do, right. And some of the myself have been tasked to process information formerly petabytes, glorified fat cells, and they have specialized on counting impulses. And mostly they are fine with regulating things in terms of feedback loops. And sometimes the feedback loops are not enough. And I need to have signals like pleasure and pain, pleasure tells me to more of what I'm currently doing. Pain tells me to less of what I'm currently doing. And I need to associate this with situations matter environment. This is done in the hippocampus, which creates an association between my needs which are represented basically as deviations between a target value and the current value of my organism. And the hippocampus creates an association with the current neatness of your situation. So I know what I need to do now. And what I need to stop doing now. And I also want to direct this on future situations. And I want to generalize over this and this is done in the neocortex. So the neocortex generalizes over situations in such a way that I can make plans. That don't mean I just have to eat cookies when they are in front of me, but I can plan for eating cookies, or I can plan for eating something else that has similar nutritional properties as cookies, and constructure, to thing eaten, and so on. Right? This is what all the recordings is allowing me to do. And but thing that's very difficult to do for reptiles that don't have a neocortex like me. So how does this work? The neocortex basically, produces new world synthesizers that at the lowest level, try to predict the patterns that come in from my cochlea, or from my retina, then it unites those finds metal regularities in their metal parents like percepts. And then it unites those again until it gets to mental simulations. And then I generalize over these mental simulations and identify concepts, right. And to make that possible, my mental representations need to be compositional and solve the binding problem, which is difficult for individual neurons, because they need to be fit together like Lego bricks and taken apart different times. So they need to organize into building blocks. And the best candidate for most of these building blocks are the cortical columns, which are circuits from somewhere between 100 and find that neurons and means we have something about target of 100 million moving parts and then your cortex that are able to link together to together approximate functions and sort of the mining problem. And to do this, basically, we need to combine a small function approximator with a state machine, and some control messages that controls how they link up. And they organized into areas, each of these areas of roughly 50 of them is basically taking care of one of the main components of the cognitive domain. And they talk to each other form processing streams, and implement function approximation in Bayesian fashion. And it's parallelizable and exhaustive, modern, distributed, parallel models that we have. But they're also able to do the heavy discrete models, they basically can learn how to do algorithms. And to do all this, they form something like an orchestra. So similar to an orchestra, there's something like 50 instruments, we have these 50 brain areas. But unlike an orchestra, there is no audience which sits somewhere and listens to everything that this orchestra is doing. Rather, this is an emergent music, where most of the musicians listen to the neighbors only, and take some of the features of what the neighbors are playing, and use this as the input to their own play to produce something more. But this orchestra has something like a conductor, which is probably in the dorsolateral prefrontal cortex, this conductor decides what's being played tonight, and it resolves conflicts between instruments. And, to do this, the conductor basically needs to have an attention mechanism that picks out individual instruments, and puts the result of auditors into some kind of an attentional protocol. And this attentional protocol is the only part where the activity of your cortical orchestra gets integrated, right, these individual parts they don't know about each other.

Joscha Bach 26:40
Your visual cortex doesn't know about what the auditory cortex is doing and vice versa. So this gets bound together the simulation in this attentional protocol. And in this attentional protocol is also where you relate the experience at different points in time to each other, which is crucial, right? If you would not have this integrated memory of what your different behavior programs, these different eyes, that you are, in different moments in time, want to do together, right, you would not be able to construct a cohesive self as a single person, you would be multiple selves, you would have multiple personality disorder, if you had multiple attentional protocols. And how does this attentional journey work? So our brain unfortunately, is not differentiable. So we cannot use some kind of global Stochastic gradient descent that types that single loss functions to all the layers, as we often do in neural learning, and stacking it to find something better, right. And one way of doing this is imagine you play tennis, and you want to improve the way you do it, you leave the vision alone, because you basically exhaustively trained vision in the first year of your life, and you don't need to touch it very much anymore. Instead, you decide, I take this particular part of my cognitive architecture, like the thing that controls the way I do my observing. And I want to do this slightly different than you would normally. And I basically memorize the latent variables that allow me to recreate the binding configuration that I have, and then make that app swing and perform that movement. And then memorize the change to one of these variables that I make to perform this feat in a slightly different fashion, and memorize the expected result, and then memorize it triggering conditions, then I can apply the loss function because I've maybe have not won or lost the match. So a couple of minutes later, we're gonna have won or lost the match the trigger is available. And I recall the situation I recreated the partial binding situation that I had, back then when I made the decision, compare the result is the expected result, and I can reinforce my behavior, or undo what I did, right. So that's a very simple and a mechanism that works when you have a brain that has basically an arbitrary structure. The drawback of this is, the thing needs to learn where everything is in the cognitive architecture. And it does this in the same fashion. So you this attention based system needs to train itself. That's why attention is reflexive, you will put the act, or you are able to put the act of accessing your attentional system into this attentional protocol. And use this to improve your attentional recall. Right. And if you have attention deficit disorder, then typically what you have is not some scarcity of the resource of attention, but difficulty with regulating your attention, which means that at some level, there's meta regulation does not work properly, you pay attention, but you're paying attention to the wrong things at the wrong time. So in this perspective, the conductor maintains the attentional protocol and produces a narrative about the self, the exits of the protocol gets integrated into that protocol. So consciousness becomes reflexive and remembering having been conscious is both necessary and sufficient for seeking that you're conscious right. So the availability of those mental simulations of the to the conductor is the necessary and sufficient condition for Access Consciousness. and the integration of the access into the protocol itself gives you the self report and thereby the reflexive consciousness. And our self report about the memory of the awareness. This is what we interpret as awareness and actuality, which doesn't actually take place. So we are, in fact, when we act on reality in real time, we are completely reactive systems we are we don't deliberate when we act in real time, when I talk to you, I don't have time for deliberation. I do this automatically. This is a feed forward net, in my experience, that I read every word that I say to you want to think about it, and so on. This is something that's being recreated after the fact. So I don't say the same stupid thing twice. So in this sense, you can bring idealism and mechanism together, idealism says we live in the dream created by a mind on a higher plane of existence. And the mechanism says the higher plane of existence is a physical universe, the generating mind resides in the skull of a primate. And this also explains why magic is possible, right? You cannot edit your memories, you can remember that you were able to predict the lottery numbers, the bank will still win. But you can edit your memories.

Joscha Bach 31:19
So, in my view, this is the simplest explanation that I found for consciousness and how it works in humans, and other machines. And I don't know if it's possible to make machines that are more conscious than us. I think that the purpose of consciousness is the creation of a protocol of the contents of our attention for learning purposes, which means that AI may be conscious, but probably not for long, because at some point, it's going to surpass our abilities to the point where it has a new optimal strategy for doing everything where it has an optimal strategy for finding truths. And it doesn't need an attention based learning system or something crude like this, to improve what it's doing. So once we build our mind, children, then something like the systems that are smarter than us, we cannot expect that they basically continue with this conscious tradition that we are part of on this planet for very long, I think far future science fiction will be very boring. Because it will not be done by mindset or in any way like us and conscious in the same way as we are. Okay, that's it from me. What do you think?

Joscha Bach 32:42
Yes, maybe, I mean, can you hand the microphone around? Or even second microphone? How does it work?

Unknown 32:51
Yeah, thank you very much. Yeah, I had a couple of keywords down in my notes that you bumped up against. And one of them was magic. I find that the classical, sort of Hinton, heavy and type neural network systems with the backprop, etcetera, etcetera, doesn't have any magic. And what does seem to have magic seems to be well, to name names is more the reservoir computing with the spiking neural nets, spiking neurons? Okay, it adds incredible amounts of strangeness, to a mathematical system. But the problem is, then I started thinking, Well, okay, then you start talking about the orchestra conductor, because I was thinking, hello, okay. Okay, so the orchestra and the conductor, and I was thinking, well, how can I glue together a bunch of these different reservoirs? And first, I was thinking, Well, I would just sort of pass different outputs from one reservoir into the side of another reservoir. And from the art from your description of the orchestra, you're saying, not really, you need an attention mechanism where everything passes through? Is that a decent take on what you said?

Joscha Bach 34:19
So first of all, reservoir computing, for those that don't know, the ideas, basically, how do I learn a function in the absence of a gradient, and it could be an arbitrarily complex function, right? And to phrase that differently, how do I train a very recurrent neural network? Because many lateral and reflexive links and loops in it and so on? And the answer is you don't. So you basically set up your random neural network was sort of a configuration to make it operate at the border to chaos. You put some activity in it and it will start to bubble and the fan To think you're looking for a probably hidden in somewhere there. And you just train the output layer with linear regression looking for this function. And my suspicion is that this happens basically during the training of cortical columns. So our brain is not constructed like clockwork, but more like a cup of tea, no, you will take different ingredients and the roughly the right order, put them into layers. And then you let it bubble for a while, and self organize, train it against the desired output function. And then you call all those neurons that you didn't need that didn't contribute, they don't get fed anymore, and they die. And then you will train this thing layer by layer to discover regularity to the degree that this layer can do this. And when we observe our children, we notice that we seem to have something like they are periods in which they learn something new. And then suddenly neuroplasticity in this layer is dramatically reduced, they unlock the next layer and integrate over the previous layer, so integrate over the available information and find higher order regularities in them. And I suspect that the main difference between us and the other primates is that our childhood is much longer. So the training period for each layer is extended for much longer time, a gorilla after 14 months, can move into their own home. And after 14 years human is barely able to forward enough food to sustain themselves. So we have a very expensive childhood. But it means that we get to see magnitudes more training data per day or before reduce the cognitive plasticity in that layer compared to a chimpanzee or a gorilla. That might be a very interesting thing. But it's speculative hypothesis. I don't know if there's something that wouldn't turn this into an established proven concept. And you'd have some

Unknown 36:48
miles and have an app question here. So I'll run that line. And I'll go to some of according to your understanding, what is the difference between what you call itself and the thing having your subjective experience with a follow up with itself as a contract? And what has what was the experience prior to and necessary for construction?

Joscha Bach 37:07
Yeah, self and consciousness are somewhat orthogonal, right? My experience of self requires something that consciousness that otherwise I'll experience does, but the self is a model of me as the system that is constructing the world. And that model is not even a simulation. A simulation, I think, is best understood as something that recreates the dynamics of a system, but very different functional principles. Right, so you do something that at some level produces similar phenomena as thing that you want to have, like your weather simulation. But inside of the weather simulation, you use very different functional abstractions. So you don't have actual simulations and abstractions of water molecules in the weather simulation, and an atmosphere, you don't need this to operate at a different layer. But because the high level emergent properties of the system are isomorphic, to the system that you want to observe, it's a simulation, and ourselves is a simulacrum, it's more like a doll that the brain creates to tell itself its own story. It's something that doesn't have to have internal integrity in the sense that makes complete sense, we can later on increase the integrity of that model. And you'll find that people that are very perceptive, they make turn they're models of other people and of their own into something that is more like a simulation from a simulacrum. So it has internal integrity, it makes sense. It's a functional model of how that other person or their own self is working. So the self is a model of a person is the one that you identify as being you. And you track it as the one that is being you because you have a connection between the perceptual changes that you're making the changes in your world model, and the aspects of that self that are related to the actions that are necessary to do that, right. So the other selves that are observed, that cannot control them. Reality is the thing that is different from what I can control. That's, that's what the brain is modeling. It's different from imagination. And myself is somewhere at the boundary. Because of that, because I can control its actions. And also it's probably defections, but they're mediated by internal functionality. And this internal functionality is to self.

Unknown 39:23
I'm wondering if you're familiar with Grant Santos theory of attention schema or the attention schema? Can you comment on on a surface?

Unknown 39:32
It seems vaguely,

Joscha Bach 39:35
I mean, I was writing it by that. So can you comment on? Yeah, it is covered, there's a big overlap. So he doesn't look at this conductor aspect basically the control aspect so much. But there is I think that we both agree that the purpose of consciousness is to model the contents of your attain attention to train the attentional system. That's I think his main thesis right So there's an overlap there. There's also an overlap of standards perspective unconsciousness. Basically this cognitive, a Cartesian theater, or dress or quilted the Cartesian camcorder. There's also a slight overlap with the global workspace theory. But in the sense that information is made available throughout the cortex to other systems, and there needs to be something that mediates this, which plays a smaller role in his perspective. So I don't think that ours has a conductor in the sense in his model. And that is also a connection if you want to Frankish perspective of illusionism, that consciousness is not happening in reality, but it's an illusion created in the brain. But Frankish doesn't look very much at the functionality itself. Or if you look at Metzinger, being no one you are not yourself, the self is a story that the brain tells itself, this is something that you also find a Metzinger. So a number of people converge on the same ideas. And usually, if you have an idea that roughly works, you're not the only one that has it. It's only in philosophy where you're incentivized to go to an indefensible hill to get cited, because the good ones are already taken. And philosophy moves so glacially slow that you can build your castle on a completely indefensible Hill and 200 years from now, you will still have conventions and meetings in that castle. Which is, yeah, it's unfortunate. That's why philosophy has become so unproductive, I'm afraid.

Unknown 41:30
Yeah, I got a question. So this observer that's being simulated? It can do everything we can do, I guess, because? So that my question is actually what can it not do? That we can do?

Joscha Bach 41:47
But we are that simulation. So the thing what I consider to be my me, is simulated character in a simulated environment. It's, you can imagine it like George RR Martin model, and as a character in that model world, and George RR Martin creators, and George RR Martin happens to be my brain. And I'm one of the characters in his novel. So there's nothing I cannot do. The limit is only the ability of my brain to create virtual realities, and they're pretty impressive.

Unknown 42:21
Why don't you get into some kind of infinite regress, then?

Joscha Bach 42:26
Because my observer doesn't do many, many things. But what I bring is Christ to them doing things?

Unknown 42:32
Why did this observer not have simulate another observer inside of himself?

Joscha Bach 42:37
Because the observer itself is not a functional unit, it's a representation. It's a story that is being told the observer itself is the self is not a computer. It's not an emerging computer running on another computer, itself is a model that my brain is creating to tell itself its own story, or an aspect of it.

Unknown 42:58
Can you see it? Now?

Joscha Bach 43:02
So it's not the homunculus that is able to do things in your brain? It's a story about how things are done in your brain. And that story is exclusively written by the brain itself.

Unknown 43:14
Okay, yeah, maybe so it doesn't, it doesn't actually do anything. No.

Joscha Bach 43:21
Just wants to play.

Unknown 43:24
Whenever you can't say that. No, it doesn't want.

Joscha Bach 43:27
It's kind of a stripe, it's. Your right. doesn't even want anything.

Unknown 43:42
I can say that. I was wondering, you mentioned quickly, but what are your thoughts on integrated information theory? I think it's a minor slide very quickly. But it's one of the descriptive theories that I've read when you say, well, we don't understand it. But if we can come up with something that describes it accurately, perhaps that's a step forward. But it seems that it doesn't fit with what you were,

Joscha Bach 44:03
to the degree that I understand integrated information theory and talk to Tony Fox. It's an attempt to create an non functionalist theory in information processing terms, which is of course, an oxymoron. It's very difficult to make a basically a functionalist theory that is not functionalist, because information theory is always going to be functionalist. So, the trouble is, I think that Tononi has decided that consciousness takes place in actuality. So it needs to take place in a way that cannot be described by an algorithm. And he now struggles with finding something that can accommodate his solution. He tends towards pan psychism. And as we have seen before pen psychism requires that we where's the expression of the fact that you have some kind of operator that is outside of the universe that can be computationally described and observed. And delta isn't any way, right? So it's something for which there can be no mathematical language. And that's a very big difficulty. And he tries anyway, so the best thing that you can oppose so far, this idea of consciousness has to do with the fact how information is performed. And he looks at the mutual information between different aspects of the information processing system, which means that it looks at how much is the computation and different parts of your brain correlated in a way this ongoing computational process. And this is what you measure is the parameter that is called phi. And if the fire is large, you will are very conscious. And if the fire is low, then you're not very conscious, and correlates with five being high in the neocortex, because you have many of these interconnections and cross correlations. And being low in the cerebellum, that you mostly do motor control of is very sequential stuff. But it has this inconvenient property that you could have a computer which does the same function, and you rearrange the logic on the chip. So the same function is computed finance, spatially different arrangement, and suddenly, it becomes more or less conscious, which I think is a property that you don't want to have. So this idea that your spatial distribution of the substrate suddenly controls whether a system that computes the same function is conscious or not, seems to be very counter intuitive and bed base to me, right. But there is something to this intuition that underlies it. And this has to do with the way I experienced my consciousness when I meditate and turn off my conceptual cognition, and go into the phenomenology of consciousness, what I subjectively perceive as that there is something like a vibration and operator that combines everything into my perception into a single pattern, a single ongoing operator that grows and grows until it fills everything that I perceive at the same time. And I suspect this is the phenomenological equivalent of my cortical columns linking up into a larger structure. So the more my neocortex becomes correlated by linking up with a ping egg problem, solution by columns into a global oscillating pattern that models cohesive part of reality all at once, right, I will also see a cohesive frequency even at one EEG that correlates with me having a larger cohesive perceptual awareness of things. And for some reason, it doesn't work as soon as I start thinking, and I suspect, it's either because my thinking doesn't work very well. And it's very choppy, or it's because this binding operator that works with a very short oscillation rate does not work in the same way on my conceptual reasoning. So it could be that basically, my conceptual representations are so discrete, that I cannot run the same parallel distributed, finding solution on it. I don't know if that is clearly expressed. I hope it helps for some people that thought about it, how I think it relates, because what it is born from, it's this intuition, that you have a very large integration over many areas of the brain that is correlated, the larger the integration is this the amount of consciousness that you have. And I think that actually might be correct for perceptual consciousness.

Unknown 48:13
The end of your speculations about like self awareness and self optimization progresses about of the brain. And that in the future, it might not be necessary or like that it might be different for an AI to have such a thing. And I'm not really sure if others today, but for me, it seems to be quite important for an AI to have like some ongoing self optimization progress. So why do we think it will be superfluous

Joscha Bach 48:43
if you're basically identify a function that discovers the correct gradients for all the problems that you have to solve? Or that you just need to execute an existing algorithm, you don't need to learn anything new, right? Learning is the discovery of new functions. At some point, you will have the global optimum of all modeling functions.

Unknown 49:02
Environment is constantly new things, right? I mean, I discover like travel through space, and that is whatever element you seem to

Joscha Bach 49:11
park. So that's an interesting question. Do you at some point, get to the point, that you have discovered all the interesting regularities in the physical universe. And I suspect this might be the case, because the physical universe seems to be extremely regular. So it could be that there is basically right now our standard model is have a page of code and we all have this strong suspicion that you probably get it down to something much harder than we properly understand it. And AI is going to get there

Unknown 49:39
already 100 years ago, so that they

Joscha Bach 49:43
know you know we did go for 2700 years, and then Alpha zero comes along and after six hours says No guys, you were in a local optimum, and the only did physics 470 years, and deep mind hasn't started trying physics.

Unknown 50:00
If you said that there might be a pint of Eric, a consciousness stops for artificial intelligence. So I'm thinking, would the conductor also cease to exist at that point, because I find it quite interesting. linking to a problem to the human word, the fact that I don't know if you'll learn how to play piano, most of it actually has to be unconscious, in order to, you know, perform your functionality and achieve your results. So, yeah, I don't know if you could elaborate on.

Joscha Bach 50:39
So when you play piano, you have to do actions in near real time. And with a high resolution. And this is something that's probably cannot be done by this by the attentional protocol things where you basically mediate everything, by messing visit, I suspect that reasoning might possibly be understood by using this attention learning, but with an immediate feedback. So it's something that doesn't have delayed rewards like when you play tennis, it takes a while for your ex is manifest in real world. But when you reason, you make a small change to your model, and you immediately see how it turns out, you can immediately apply the loss function, and then improve your mental representation. And by applying that successively, you basically continuously improve your mental representation without doing anything in the physical world. This might be reasoning, right, but it's still a very slow and very sequential. And when you play piano, you need to have actions which are parallel and not slow. So this is something that is being trained on the level of the individual elements that's being trained, visiting the cortical areas and the direct interplay between the cortical areas that's not played done by the attentional system, the tension system can only take out a few threads with its few attentional knitting needles and resolve a single knot at a time, it cannot leave the pattern, the weaving of the pattern, it's done, because these reactive systems, and the attentional system only resolves conflicts. That's basically my understanding. Does it make sense? So hold on, like? Can you just say, What about the conductor for the artificial intelligence gave that to them? Second, we need to build attention based learning and computational substrate that is not neurons, it's going to be very faster, right? Our neurons are super slow, and they don't live very long. Basically, if you would take the number of firing events of a neuron until you die, and you take this to your Nvidia GPU, it will be dead after 10 minutes. So it's possible that if you implement attention based learning that extends into areas where it wouldn't do in the brain, but it's very speculative. Maybe somebody has done it already, maybe, because it's an obvious algorithm. I'm sure a lot of people have implemented under a name I'm not aware of. I think you were first you have been

Joscha Bach 53:19
he's been busy together, but okay, go ahead. You have an idea of who's right. Good.

Unknown 53:26
Okay. Thanks. Sharjah. So I've been reading this book by Stanislaus tahini about consciousness. And it's a, an neurologists, kind of a contemporary ideas about, about consciousness. And the it fits very closely with what you're describing in terms of consciousness, kind of snapping in this, this mind wet web, which is like this almost like cartoon like subjective. Ideal of, of, instead of having all these distributed probabilistic systems that are very confusing, and there's a lot of ambiguity, it kind of creates this simplistic consensus about what we're experiencing from moment to moment. And, but one thing I was thinking about that kind of missing out of these is that in human society, the we have distributed intelligence we have, you know, not one person understands everything, all the details about a computer. It's, it's a, it's, it's our distributed knowledge that we accumulate in our culture. And I'm just thinking that that is something in in an in a future AI as you describe it, it's they have the opportunity to work collectively together. And so there's potentially a higher order model on top of what you have, which is the kind of the collective knowledge Knowledge of collective intelligence the collective belief systems is I'm not sure how that.

Joscha Bach 55:06
Thank you. Connor has an excellent question. I suspect it's sadly the other way around. The reason why groups are in some rare edge cases better than individuals is because our minds don't scale. They first of all, bootstrapping, our knowledge takes a long time, bootstrapping intellectual tradition in the family takes several generation. Bootstrapping, an intellectual traditional society takes hundreds of years, right? Mostly human flourishing does not go over time spans of more than a few 100 years at a time. So you have an unbroken intellectual tradition. And then this global collective intellect, that we built something that's being destroyed when a revolution happens. And couple generations later, the knowledge workers of the next king try to recreate something from the ruins of the thing that has been destroyed in the revolution. And usually it's very misshapen, and it has bugs in its foundations, because it tries to recreate the appearance. And our culture is the result of several such upheavals, right, we have a broken intellectual tradition. And as a result, we have a very strange idea about things like consciousness, and thinking, and sociality, and self, and so on these concepts are basically scars in our cultural conceptions. Because of these breaks that we had in our civilization, at some point, many of the things that Aristotle understood, they had to retranslate and some of them, we probably didn't correctly, we translate, and we see a similar thing that you read Sanskrit, the generations that came after them, didn't understand all the things. So probably in the Sanskrit texts, you have mentioned, periodic processes. And data generations didn't understand four different processes. So there we translated it as real. And then suddenly, you have pulled out temples where monks in front of fields and try to meditate over them and get deep insights over the of the universe. So this is what happens if you have collective intelligence, without cohesion. But all the individual thinking all the real thinking doesn't happen in groups, groups cannot think groups are stupid. Because in order to make a group cohesive, they need to limit the individual agency. That means people are not free to believe what's true based on the evidence. If people are acting as part of a group, they give up agency over their beliefs and policies. They make their belief conformance to group beliefs. And this makes them invariably more stupid, which is why all actual scientific progress is not done by large groups of people that vote. It's done by smart individuals that stand on the shoulders of giants are on big piles of tarps that does the same thing as them. Right? So the reason why we need to do this is because our brains are so small. And because we cannot make them much larger, they already consumed 20% of the glucose of our body. And that is a limit, right, and B, H and V die. But an AI doesn't have these limitations, there is no benefit for an AI to have another AI to talk to, because it can have it inside of itself. There is no obvious limit to the scale of a single AI, I mean, beyond a Dyson sphere that encompasses the sun. Right? So after you take the available matter and harvest the available neg entropy, this is possibly the limit of an AI. But there is no benefit if you hack it in twice or to 1 million pieces. So I don't think that AI it will get better if you have multiple of them. Because it can just in the same sense as others, you wouldn't be better at go if you had two alpha zeros playing against each other, because Alpha zero can play against itself just fine.

Unknown 58:54
So what you're saying is that an AI can have its own imaginary friends, as many segments and just play.

Joscha Bach 59:01
I don't think that I would conceptualize itself as a person. Like when you look at names, books or diaries, you have this thinking planet, thinking planet never has the opportunity or incentive to interact with others based on some kind of social model. So it's probably not the person. It's something else entirely.

Unknown 59:19
Look a ladder easier question than this, but that's a good one. That's a really good one. So you said something really interesting. And he actually asked if anybody had any kind of more insights into the know how they they think and you, you said about the snooze button twice, and that that feeling these you've pressed it once then oh my god, it's an hour later, why didn't it go off and then the alarm goes off five minutes later. And then you said that this is a resynchronisation have lots of ideas, but actually at the moment at the same moment, and then you explain that a little bit more. For instance, drinking glass of water, these desynchronized events. Your brain is rethinking I sing it into a single memory. Now that that's what's new to me. But actually, it's very logical, it makes complete sense. And I'm certainly going to use that now. But then I got to thinking, Could it be that? And I got the Westworld thing as well, by the way? Could it be that consciousness is a lie of synchronization? That we just keep telling ourselves? I mean, are we continuously conscious, or we just giving ourselves lies every 100 milliseconds that we've been consciousness, being conscious, rather, could it be a series of states of memory of being conscious, without ever having actually been conscious,

Joscha Bach 1:00:45
I suspect that's the case. Carried retro says that consciousness might be like the light on the fridge, whenever you decide to look it's on. And most of the time in between, you are probably not conscious. On the other hand, I suspect that a lot of the time you have this family from a knowledgeable experience going on at some level, but you put don't put this into your attentional protocols, or you don't remember it. There's also this strange thing that I noticed, the older I get, the less I have access to my conscious experience. And that probably also means the less it plays a role, because I don't pay attention to it anymore. It's very difficult for me to direct attention on it. And I am afraid that when we get older, we basically turned into mechanical zombies, that goes through the motions of the optimal scripts that we have learned to go through our days. And the remaining spark of our experiential consciousness sits in these ruins. And it's lonely and afraid and angry and upset, but cannot do very much about it.

Unknown 1:01:44
So I'm going to take one more question. I think we're gonna move on here pretty soon. And then I'm gonna have an app question after that.

Unknown 1:01:53
Yeah, just a quick rejoinder to the orchestra metaphor, orchestra conductor metaphor, the attention, protocol, etc. There, I'm not exactly sure about the intimate workings of, for instance, a string quartet or a jazz quartet or a jazz group, there's no conductor. But there is music. And I was wondering, what would be the parallel in this world, this consciousness,

Joscha Bach 1:02:26
so there are a bunch of needs that determine what we regulate for right in need is a primary regulator, that is representing a difference between a target value and the current value. So instead of making an absolute measurement in a world, you measure the deviation from a baseline that you've set, in some sense, ourselves is the product of the identifications that we have, it's the thing where we commit to particular target values that you don't want to let go of, and therefore we want to regulate. So for instance, if you commit to justice, and you think the world should be just at that level, you have an identification there. And then you measure the amount of justice in the world and you measure the discrepancy. And you will have an urge to do something about it, it's part of your identity, right? It's part of what gives rise to your mental structures, because it gives you regulation goals, and you've become conscious about all these things that are related to injustice in the world. And at some point, you might realize, Oh, my God, that just world is not a physical thing. And it probably wouldn't even work. And you let go of this identification. And then yourself changes into something that is seeing the world maybe from a consequentialist perspective and things, okay, what's happening here is, well, there's justice as an algorithm that societies have to make conflict less violent. That's the law basically. And beyond this, you only have something like integrity when you wait, the importance of your family members and friends, and business partner, because each other and their goals, and everything else is just negotiation and evolution. Right. So in this sense, you let go of this particular dimension. And the primary needs that we have are a few 100, social cognitive needs, that doesn't social needs, and maybe three cognitive needs. And one of these cognitive needs is aesthetics. So when you produce music for aesthetic purposes, what you look for is your structure, right? Its structure discovery, it's basically the generational fractals of a generator function that your brain discovers. And by applying these generator functions, or the library of generator functions, you get interesting new structures and this is intrinsically rewarding. And if you are an artist, you have a mutation in your brain, you some of the thing that you mental representations are intrinsically important. They're not the purpose of forming mental representations is to eat more, right? So at some point in your life, you make this decision or your brain makes a decision that the use of life which means you are the machine to eat, and you learn to eat more and have children that can eat more. And you say Evolution right? So it means you are glorified kind of yeast and all the complexity that you create is to create some surfaces on which you outcompete other kinds of yeasts. But there's also this alternative, you can serve the arts. That's a conspiracy against life. It's the cocktail of life. And the arts are about capturing conscious states, because they appear to be intrinsically important to you, an artist is somebody who falls in love with the beauty of the last function itself. Like a musician says, I'm addicted to making super complicated noises, and you should pay me for it. And I want to infect you with it, instead of growing potatoes or doing something that's actually meaningful response back to life. And I suspect that most of the people that do science or philosophy or art have this mutation. They are basically mutants that don't live properly. They don't live to eat and serve the evolutionary goals, but rather, they serve aesthetic goals like finding truths or capturing consciousness. Does that make sense?

Unknown 1:06:01
So I have a suspicion that this topic we could keep talking for probably a couple more hours here. Unfortunately, we have a schedule to finish including dinner at seven. So I do have one question from the app from the harness. Aren't you just avoiding deferring the hard problem of consciousness by positing positing that it's a simulation that experiences qualia instead of emulator on which it runs?

Joscha Bach 1:06:40
Instead of what it says here instead

Unknown 1:06:43
of emulator on which it runs? I don't know if that student the DA emulator on so do you want to describe exactly.

Joscha Bach 1:07:01
Yeah, so basically, I tried to sketch the space of possibilities. I personally, I don't think that you can hope to find the absolute truth. If you are embedded into a system, what you can do is you can map out the space of possible theories that could explain the observables. And part of this space is it could be that there is a meta computational operator said something is more than computation somehow. And I think that you can make a good case in this case, we are lost because we cannot make models about that thing anymore. But I suspect that we are able to explain the phenomenology of consciousness entirely in computational terms. But the consequence of that is that it's not the physical system that is conscious, but it's a simulation inside of the physical system. And then I tried to explain how we can account for the different aspects of consciousness like Access Consciousness, reflexive consciousness, and phenomenology of consciousness. You don't need to buy this, um, this is such a great suggestion. It's the best answer that I found so far. I find it convincing. But I'm the easiest person to fool by myself, but just by run it by you. And you can dismantle it, and I will be grateful.

Unknown 1:08:09
So, as I said, I mean, I find this whole topic fascinating. I would hope that this talk at least stimulated some ideas, and hopefully we can continue these discussions amongst ourselves afterwards. But right now we have a brief break. And then there's the first of the AGI talks, talk session, right afterwards.

This transcript was generated by https://otter.ai