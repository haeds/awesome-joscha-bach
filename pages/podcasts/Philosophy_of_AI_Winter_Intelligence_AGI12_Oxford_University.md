Joscha Bach 0:09
I'm an AI researcher and cognitive scientist, I'm at the moment based in Berlin. And that's about what there is to say, when I was young, I studied philosophy and computer science, because I wanted to find out how the mind works. And I still do. So while I went into cognitive science, I did my PhD at the University of Osnabruck, building a cognitive architecture. And at the moment, I'm working in a small company in Berlin, where we build AI.

Joscha Bach 0:47
Well, one of the motivating factors, most certainly that it was one of the chairs of the conference, and I see the AGI conference as an attempt, or part of an attempt to get back to the original idea of artificial intelligence, that is to see computational systems as an avenue towards developing an understanding how the mind works. I think this is at its heart, the philosophical indoors and philosophical enterprise, but the message that we need some that we do not find in contemporary philosophy. And so my idea is not to build applications, or to develop formalisms that they can be used to, to build applications. But it's about maybe a subset of analytical philosophy. It's a very computational philosophy, where analytical philosophy allows you to express everything that can be or use everything that can be expressed in a formal language and principle. I want to narrow this even further down towards things that can be expressed in a computational system that are computable that can run. This means you do exclude paradoxes that includes not only those things which you cannot specify, but it also excludes those things, that you can specify that a particular paradox that wouldn't run. So eventually, the proof that you have understood something from the point of view for computer scientists is that it works. And I do think that we need such an approach, as it has pervaded most of physics, for instance, already, we need such an approach in philosophy of mind to.

Joscha Bach 2:29
I don't think that there is a mainstream approach to Artificial General Intelligence anymore since then, back in the day, these were people which originally came from cybernetics and other fields. And then the idea of taking the perspective that I had in cybernetics and other disciplines, to gather it up into a new field, to use the newly available computer languages and computing systems, to bring the ideas together to build artificial intelligence systems and many of the ideas that you have now. And they'll be sometimes called new AI, but already alive at that point. And there was very several detrimental factors. For instance, there was a very strong optimism because of ignorance of the problems that people would run into. But also because there were a lot of low hanging fruits, AI made tremendous progress within the span of very, very few years. So suddenly, we had some simple natural language processing, some simple planning, simple game playing, and so on. And then there came a time when it various was very, very hard to go beyond these relatively simple things. And this led to disenchantment of many people with the original goals of AI. But it also let the public catch up with this disliking of the idea of AGI because the idea is basically telling people that there is no metaphysical domain in which their souls reside, that you are basically software. And for many people, this is a very offensive idea. So our culture, especially our Western culture, is not exactly sympathetic to that idea. But nevertheless, A is a discipline in academia has been always very productive. Almost everything that is now interesting in computer science has been AI at some point. So AI has been the moving frontier, Pioneer Battalion of computer science all the time. And there was never a time when this was not a fruitful paradigm. But now, the people that work in AI have pretty much abandoned the original idea they have abandoned the direction of building something that is like human mind or beyond that. And this means that and continue with what they were just doing before they went into the direction they built a deadly goals that equals in description logics into agent based communication protocols, semantic network, formalisms, and so on. The built isolated communities that are no longer united by this general vision. And I do think this is not good. It's not good for AI and as a field that produces you school applications. And especially it's not good for the way we want to do with cognitive science that is building computational platforms that are unified models that take into account models from neuroscience, philosophy, ideas, knowledge that we have from linguistics, and many, many other disciplines into common platforms and tests that make the festival improve on them. And I think we need to revive this. So this is what AGI is for. And I think it's a rather recent development, not only for the AGI conference, but with other conferences like Kocsis and bicarb, and some movements within triple AI and so on, to get back on track with some of the original ideas of AI.

Joscha Bach 5:45
Well, I think the question how the mind works is probably one of the most interesting question that you can ask. And this is part of the discourse that's been going on for centuries. And to work in AGI now is the chance to participate in this discourse, in my view. So it's one of the most exciting things I could possibly come up with. Yeah, I think that there is a needless clash. If you look at the history of philosophy between materialists and mechanist philosophies on one hand, and Panama religious traditions, for instance, on the other, and I do think that we need to take a slightly different perspective, one that focuses on information processing, because for epistemological reason, the only thing that we truly have available is information available, discernible difference and our systemic boundaries in some way. And things like matter and so on that energy, these are just possible in codings. These are possible interpretations of the data that we have of the observations that we have. And our job now as AI people or as cognitive scientists is, I think, to find possible implementations for information processing systems that can bring for us all the phenomena that we are so interested about, like emotion, motivation, phenomena experience, meta representation, imagination, agency, intentionality, sociality, personhood, all those things eventually, are certain modes, I think of information processing. So this taking this Neo mechanistic perspective, I'm not trying to abstract from all those phenomena and grow them and say that they're not relevant. But what I'm trying to find productive way to give answers to them. This basically depends where those people are. So a very, very simple and simplified narrative would be if you take, for instance, our standard Western background, which is informed to large degree by Christian dualism, it looks like this, they have this idea that the world around us is actually not real, it's some kind of World of Warcraft, it's glorified World of Warcraft, of course, it's an amazing amount of detail. But still, the things that we have in there the values that we perceive like money, the quality of our housing, beauty, fame, this is not real, this is just the game currency. And our real souls are outside of this domain, our bodies of experience, this is just the interface of an avatar into this world. And the world has been created, of course, in this traditional narrative by God who has good access and could program it all. And there are also some other guys which might have good access most knows that not only the devil, he also has good access, but he likes conservation. He is just a hacker he corrupts the system at certain points. And since he has this outside perspective, he realizes what it's all about, and he uses his knowledge to corrupt us out of our metaphysical currency, our souls by giving us game money that he can wind up being a hacker easily create. Now, from this perspective, subtract God and the devil and you are where most educated people in the West are right now, including many philosophers. And what AI is telling them is, you guys are NPCs your non player characters, there's no one outside of this World of Warcraft, which controls you, you are a character that is entirely implemented in this domain. And for many ideas, it's a very people that is a very strange perspective. But it resolves a lot of seeming puzzles. For instance, the big puzzle of quantum mechanics, I think the difficulty with the current conventional kind of mechanics is not quantum mechanics itself. It's pretty simple compared to other theories. It's the difficulty to map the concepts of phantom mechanics to a macroscopic experience. So we are asking ourselves, where is the light actually, when it travels from the sun to our eyes? Is it a particle or wave while traveling there? But if you look at the screen, you see game of World of Warcraft and you see Game sign on the screen and you see your arm or on the screen and the sound bounces off the number and hits eventually the screen and so on. You would never ask the question, Where does tonight happen to be during the journey? You ask how is it implemented. And I think we need to take the same perspective towards towards in some very strange perspective for most people, but a very natural perspective for computer scientists.

Joscha Bach 10:30
Actually, I do not have that with the hopes for the future. For instance, this is two degrees centigrade climate goal view are by now know that two degrees centigrade will not leave us in a very comfortable future. But you also know that this means that we are only allowed to burn 20% of the non fossil resources, I think it's pretty unrealistic to expect that existing companies and so on, will leave 80% of the essence on the ground, it's not going to happen. So we are looking towards something like five degrees centigrade global warming, this is just one of the many possible avenues and issues that might concern our future. And maybe this turns out not to be a big issue at all, maybe you're lucky and get away from this, whatever it means that we are probably facing existential risks, that at some point will make it very difficult to continue academic research. And I do not see my work as a part of creating a bigger, better future. I do think that our civilization as it is probably pretty much to, but this is not a reason not to do things that you find meaningful now. And the production of culture and the value of culture, the production of insights, the engaging in discourse between people, I don't think that it really depends on whether the earth will continue to exist forever, or whether it's eventually consumed by the sun. It doesn't matter. I'm not working for the future. I'm looking to get some insights, I'm interested in talking to people to listening to their insights to learn something new. Well, I don't think that we probably have enough time long enough to develop AGI. I don't think that it's so difficult, because nature has managed to come up with it and get it stable in every brain. And there is a very bad signal to noise ratio in biological neurons. And so the computation complexity of the brain is not many orders, orders of magnitude beyond what current computers can do. We don't know that how the software should be written. We have some quick pointers, though. And I think eventually, it'll boil down to a few 100 organizational principles that can be encoded in the genome. And the apparent complexity boundary for this is probably the inflammation content of the genome, which famously fits on a CD ROM. So actually, our blueprint file body is simpler than the blueprint for our current edition of Microsoft Windows. But it's not been built to be re engineered, it's very difficult to find the organizing principles. And it's often very easy to see them as hindsight like, back propagation learning with hindsight is a very, very simple phenomenon. But it took mankind a very long time to hit upon the principle of back propagation learning it I guess, we have a few 100 problems on the difficulty layer, a level of backpropagation learning to solve before we get to AGI and so it my perspective, we have many, many PhD students will which will need to get engaged with this and combine this into a common platform and they don't see an easy shortcuts. So I'm one of those people in the field, which are skeptical of very rapid progress. I think that AGI will be some decades in the future, if it happens.

Joscha Bach 13:52
If you are referring to the question of AGI is an existential risk, the singularity and so on. I think that we need to change perspective a little bit. Nick Bostrom has given a talk on existential risks and his vision. The AGI is something that needs to find its way out of the box, like there is this little Roomba robot and then make it more smart and smarter. And then it becomes sentient. And eventually, it finds its way out of the cabinet out of the basement and starts to dominate the world in something like in the movie iRobot efficient that come to pass. So some superhero will step in and prevent this thing from taking over. And letting mankind continue on its God given righteous force towards oblivion. And I don't think this is going to happen this way. I think that AGI is going not going to escape from some basement but AGI is going to be used as a decision making tool in existing organizations. He is going to borrow its motivation from corporations from governments, from whatever organization is used. It is decision making tools. And these organizations are already agents, they're already agents are stronger than humans. So this singularity take over this thing of the past that has already happened. This planet is no longer ruled by humans, it's used by organizations. If you want to change something on this planet, you better become an organization and make sure that you are very effective and that you can pull off those changes that you want to. But of course, you don't have to do this in the framework of the existing organizations, there's no vacuum left anymore. It's all interaction already. And humans are kind of ephemeral, for the most part, because it's very hard to get to a bifurcation point in a large scale existing organization, where you can really make a difference as Obama can truly tell everybody.

Joscha Bach 15:54
I think one of the most important things, I guess, is to resist the some of the pressures that are currently on academia, academia has become as a job market very, very harsh. And this creates a tendency for streamlining, people are forced to into certain roles in order to become successful. For instance, as philosophers, only a small fraction of the people who aspire to become philosophers eventually get tenure, for instance. And at some point, they will be faced with the grave existential risk and their own careers. So they do tend to adopt methods over questions. And I think this is a very, very dangerous thing to do. Because academia is there to answer questions, it's not there, as some addition to Commerce to produce products that can be commercially applied, or to be used to produce people that can be commercially applied. Academia is there to produce ideas to foster ideas to create people to create society. And I think this is all the disciplines one of the most important things that we should do as academics and scientists, regardless of whether we are working AI or philosophy, or biology, or economics or anything else. So I would say the most important thing for young scientists is to question yourself, what questions do you want to answer and then go for it?

Joscha Bach 17:19
I do think it's valuable if somebody is an AI skeptic, because I do love if people have different opinions from mine, if they have good arguments to defend them, the most important thing is always the argument. And the only thing that I have to offer are arguments and what I consider to be insights and which will probably be overcome by better insights. So I would encourage people to disagree with everything I say, and question it and come to their own conclusions. Actually. On the other hand, I think it's important that people are not motivated by fear, or by the idea that they need to conform to a mainstream opinion, the truth is rarely in the middle, rarely ever. The truth is typically, when the good arguments are better facts are. And I, for instance, I find that anti AI movement, it's very popular to have arguments like AI is impossible for technical or mathematical or other obvious reasons that prevent us from ever realizing it. On the other hand, we shouldn't pursue it because it's so dangerous. These arguments are mutually exclusive. And if people use the same argument, the same boss these arguments, like for instance, Joseph writes about who I am personally greatly admire did. I think there's something wrong with your argument? I think there are different needs you need to satisfy. One is, if you want to produce and foster an academic discipline, you do not even only need to be a very good scientist. What you need to be is also to be a good politician and politicians are not people that take the acute angle, but they are good at pushing the envelopes. And they're not good at that and too much a scientist to do that. And I think that the field also needs politicians.
